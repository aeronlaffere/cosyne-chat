{
    "Function of cortical NDNF interneurons in sound frequency discrimination": {
        "title": "Function of cortical NDNF interneurons in sound frequency discrimination",
        "authors": "Maryse Thomas, Lucas Vattino, Carolyn Sweeney, Esther Yu, Selorm Quarshie, Anne Takesian",
        "date": "Thursday, 9 March 2023",
        "location": "I-001",
        "abstract": "A growing understanding of cortical interneuron circuits has highlighted the role of specific inhibitory interneurons in shaping sensory tuning and discrimination acuity. In auditory cortex, neuron-derived neurotrophic factor-expressing interneurons (NDNF-INs) reside in layer 1 where they receive tonotopic projections from the auditory thalamus. In turn, they inhibit the dendrites of out-of-column excitatory pyramidal neurons while disinhibiting within-column neurons via descending projections to parvalbumin-positive interneurons. This circuitry suggests that NDNF-INs are well-poised to modulate cortical gain in a sound frequency-dependent manner, but their function in sensory tuning has not yet been explored. To establish the contribution of NDNF-INs to frequency tuning, we first characterized their frequency response properties using two-photon calcium imaging in awake mice. We found that NDNF-INs exhibit frequency tuning comparable to excitatory neurons but show greater intensity tuning, suggesting that their network effects may be greatest at near-threshold intensities. We next developed a behavioral frequency discrimination paradigm in which mice distinguish trains of repeating pure tones from alternating tones. Prior to training, a greater proportion of individual NDNF-INs were capable of discriminating between these stimuli than pyramidal neurons. Following training, both NDNF-INs and pyramidal neurons displayed a preference for alternating tones, demonstrating learning-dependent plasticity that may be facilitated by NDNF-IN activity. Finally, ongoing experiments are combining holographic optogenetic stimulation with multiplane imaging to activate subsets of NDNF-INs, such as those with overlapping receptive fields, while recording from pyramidal neurons in behaving mice. This strategy will allow us to assess the influence of NDNF-INs on network activity during both passive listening and behavior. This work will establish the function of NDNF-INs in frequency discrimination and further elucidate the contribution of specific inhibitory cortical circuits to sound processing.",
        "url": "https://www.world-wide.org/cosyne-23/function-cortical-ndnf-interneurons-1b5179ea"
    },
    "Generative models for building a worm's mind": {
        "title": "Generative models for building a worm's mind",
        "authors": "Oren Richter & Elad Schneidman",
        "date": "Thursday, 9 March 2023",
        "location": "I-002",
        "abstract": "The structure and function of biological neural networks are the result of biological “construction rules”, physical limits, stochasticity, developmental noise, and learning. The nature of these building rules and the resulting architectures are fundamental to our understanding of neuro-developmental plans and the structure and function of neural circuits. The detailed reconstruction of connectomes makes it possible to study their design; Recent reconstruction of connectomes during different developmental stages in C. elegans allows for characterization of their development. We present a class of generative models for the development of connectomes, based on neuronal birth times, probability of connections between neuronal types, synaptic pruning, and distance. We use these models to study the formation of the connectome of C. elegans, and compare the importance of the features specified above. We find that the number of neuronal types dominates models’ performance, and that a small number of types is sufficient for highly accurate predictions of individual synapses. Moreover, our models reach Area Under the Receiver-Operator Curve values of 0.85 (on cross-validated data) using 15 neuronal types. Surprisingly, we find that models that use multiple growth epochs (with different growth parameters in each epoch), perform as well as models that rely on a single growth epoch in predicting the connectome of the adult worm. However, analysis of the developmental “trajectories” of the different models shows they follow disparate paths: Models that rely on different growth epochs and include pruning are consistent with the experimentally observed connectomes during development, whereas models that rely on a single developmental epoch, or lack pruning, are not. Our results suggest a framework for studying the construction of connectomes and their underlying design principles. For C. elegans, our models predict multiple developmental epochs and the existence of an error-correction mechanism that may be implemented by minimally regulated synaptic pruning.",
        "url": "https://www.world-wide.org/cosyne-23/generative-models-building-worms-mind-0dafa429"
    },
    "A generalized Weber’s law reveals behaviorally limiting slow noise in evidence accumulation": {
        "title": "A generalized Weber’s law reveals behaviorally limiting slow noise in evidence accumulation",
        "authors": "Victoria Shavina, Alex Pouget, Valerio Mante",
        "date": "Thursday, 9 March 2023",
        "location": "I-003",
        "abstract": "Weber’s law concisely describes a mapping between a true change in a physical stimulus and the resulting perceived change. It states that the perceived change governing the behavior is a relative difference, i.e. the true change divided by the magnitude of the two stimuli (Fechner, 1966). This psychophysical phenomenon is observed in domains as varied as time, weight, numerosity, length, brightness, and statistical inference (Dehaene, 2003; Namboodiri et al., 2014). In sequential decision-making, on the other hand, it is usually assumed that behavior reflects the true physical evidence, even when tasks involve comparing magnitudes of accumulated signals supporting competing choice options (Brunton et al., 2013). Here we introduce a novel dynamic, motion-direction discrimination task which allow us to probe Weber’s law during temporal accumulation of evidence. Human participants were asked to report the prevalent direction of motion in a stimulus consisting of a random sequence of motion pulses (left or right) interleaved with static periods. We controlled the difficulty of the task in two ways, by changing the motion strength of each pulse and the difference in number of opposing pulses, neither of which involves injecting external noise. We find that performance is determined by the product of motion strength and the relative difference of opposing pulses, implying a general, “strong” form of Weber’s law. Fits of a large family of 263 stochastic models show that this generalized Weber’s law implies that performance is limited by “slow” neural variability, which varies over trials, but is constant within dynamic motion sequences lasting up to 2s. This finding suggests that the primary cause of Weber’s law, and therefore of behavioral variability, is slow variability arising for instance from suboptimal inference or computation noise (Findling and Wyart, 2021), as opposed to fast neural variability such as Poisson-like noise.",
        "url": "https://www.world-wide.org/cosyne-23/generalized-webers-reveals-behaviorally-1fe69f46"
    },
    "Experience-dependent modulation of brain-wide visuomotor processing and behavior": {
        "title": "Experience-dependent modulation of brain-wide visuomotor processing and behavior",
        "authors": "Jing-Xuan Lim, Ziqiang Wei, Sujatha Narayan, Xuelong Mi, Wei Zheng, Dwight Bergles, Guoqiang Yu, Mikail Rubinov, James Fitzgerald, Misha Ahrens",
        "date": "Thursday, 9 March 2023",
        "location": "I-004",
        "abstract": "To survive, animals must respond appropriately to changing external conditions. To do so quickly, animals use their past experiences to inform future actions. However, how past experience modulate information processing which ultimately influence behavior is still not well understood. Here we addressed this question by investigating how larval zebrafish use past action-outcome relationships to influence future responses to stimuli at the perceptual and behavioral levels. Fish were first made to adapt to changing locomotor efficacy, the difficulty of translating oneself through space. Fish increase their swim vigor as translation difficulty increases (Kawashima et al, 2016), and might stop trying after a period of vigorous but futile attempts (Mu et al, 2019). Whole-brain calcium imaging revealed that brainwide neural dynamics were modulated after futile swimming, a change that includes but is not limited to neurosensory, neuromotor, neuromodulatory and glial systems. For example, when we subsequently provided optomotor response-driving stimuli, brain regions involved in all stages of this sensory-to-motor transformation -- which included the tectal neuropil, pretectum, nucleus of the medial longitudinal fasciculus (nMLF), cerebellum, parts of the anterior hindbrain and inferior olive -- were altered. Moreover, we found widespread swim-evoked release of norepinephrine, dopamine and acetylcholine during futile swimming, which were followed by a complex sequence of lateral-to-medial astroglia activation that starts off in the lateral medulla oblongata (L-MO). Optogenetic activation of astroglia in the L-MO was found to be sufficient to suppress the visual response. Overall, this study shows how animals switch between adaptive brain states — how detection of environmental changes quickly leads to persistent and widespread activation of neuromodulatory and glia systems, which in turn, by orchestrating multiple downstream circuits, select for an appropriate behavioral response.",
        "url": "https://www.world-wide.org/cosyne-23/experience-dependent-modulation-brain-wide-b49dc748"
    },
    "Sampling-based representation of uncertainty during hippocampal theta sequences": {
        "title": "Sampling-based representation of uncertainty during hippocampal theta sequences",
        "authors": "Balázs Ujfalussy & Gergő Orbán",
        "date": "Thursday, 9 March 2023",
        "location": "I-005",
        "abstract": "Efficient planning in complex environments requires that uncertainty associated with current inferences and possible consequences of forthcoming actions is represented. Representation of uncertainty has been established in sensory systems during simple perceptual decision making tasks but it remains unclear if complex cognitive computations such as planning and navigation are also supported by probabilistic neural representations. The statistical structure of the sequential neural activity during theta oscillation in the hippocampus is consistent with repeatedly performing inference of current and prediction of future positions using a dynamical generative model. Since uncertainty increases gradually with the time span of the prediction in dynamical models, investigating neuronal activity during hippocampal theta sequences offers a unique possibility to identify neuronal correlates of uncertainty. We have established a framework to directly contrast competing hypotheses about the way probability distributions can be represented in neural populations. Importantly, new measures were developed to dissociate alternative coding schemes and to identify their hallmarks in the population activity. Reliability and robustness of these measures was validated on multiple synthetic data sets that were designed to match the statistics of neuronal and behavioural activity of recorded animals. Next we tested our framework in rats performing an open-field navigation task. In contrast with prominent theories, we found no evidence of encoding parameters of probability distributions in the momentary population activity. Instead, uncertainty was encoded sequentially by sampling motion trajectories randomly in subsequent theta cycles from the distribution of potential trajectories. Finally we confirm previous results in simpler mazes by showing that the trajectories sampled in subsequent theta cycles tend to be anti-correlated, a signature of efficient sampling algorithms. These results demonstrate that the brain employs probabilistic computations not only in sensory areas during perceptual decision making but also in associative cortices during naturalistic, high-level cognitive processes.",
        "url": "https://www.world-wide.org/cosyne-23/sampling-based-representation-uncertainty-c56ca548"
    },
    "Geometrical Features of Neural Trajectory as a Computational Motif for the Cue-Stimulus Integration of Pain": {
        "title": "Geometrical Features of Neural Trajectory as a Computational Motif for the Cue-Stimulus Integration of Pain",
        "authors": "Jungwoo Kim, Suhwan Gim, Seng Bum Yoo, Choong-Wan Woo",
        "date": "Thursday, 9 March 2023",
        "location": "I-006",
        "abstract": "Pain is constructed in the brain by integrating multimodal information, ranging from noxious inputs to expectations. Previous studies have identified brain systems that mediate the effects of different components of pain, but the computational mechanisms of their integration have been understudied. Here we examined whether the neural trajectories of different component subspaces would reveal the computational principles of information integration. To this end, we conducted a cue-induced pain expectation experiment with functional Magnetic Resonance Imaging in humans (N = 56) to examine the computational mechanisms of the integration of cue and stimulus information in the brain. Applying a targeted linear dimensionality reduction method on the voxel-level dynamics in large-scale functional brain networks, we derived subspaces of cue and stimulus and examined the decoding performance for cue and stimulus information in each subspace and in each large-scale network. If the decoding performances of cue and stimulus information were high in both subspaces, we considered that the level of integration was high, and if the decoding performance was high only in one subspace, we considered the level of integration was low. We found that the unimodal brain networks, such as visual and somatomotor networks, showed modality-specific decoding performances (i.e., the visual network for the cue information and the somatomotor network for the stimulus information), suggesting a low level of integration. However, the limbic network (which consists of transmodal brain regions) showed high decoding performances for both cue and stimulus information, suggesting a high level of information integration. We also found that the dynamics from each subspace from the limbic network reconstructed pain ratings most accurately. Overall, this study suggests a possible computational mechanism for the integration of cue and stimulus information in the brain and provides a general framework for studying multimodal integration from the dynamic systems perspective.",
        "url": "https://www.world-wide.org/cosyne-23/geometrical-features-neural-trajectory-8bd1efba"
    },
    "Human Neural Dynamics of Elements in Natural Conversation – A Deep Learning Approach": {
        "title": "Human Neural Dynamics of Elements in Natural Conversation – A Deep Learning Approach",
        "authors": "Jing Cai, Alex Hadjinicolaou, Angelique C Paulk, Ziv Williams, Sydney Cash",
        "date": "Thursday, 9 March 2023",
        "location": "I-007",
        "abstract": "Human conversations are one of the most common methods for communication and social interactions. Engaging in a conversation, our brains are able to flexibly transit between speaker-listener alternations, and actively process language comprehension or production planning with ease. Previous work showed a series of interconnected brain areas that support speech production planning, articulation, and speech comprehension, but little is known about the neural relations between these modalities. Here, we use intracranial depth electrode to record local field potentials (LFP) from participants actively participated in natural conversations. We applied pre-trained natural language processing (NLP) models capable of capturing the unique sequence of words and their structures within phrases and sentences to study the neural activities of elements in conversation. Our results showed a remarkable convergence between deep learning embeddings and brain activities in frontotemporal areas at a wide range of frequencies. The neural dynamics diverges between articulation planning and comprehension, suggesting that one is not simply reverse mirroring the other. Finally, we discovered that alpha-beta activities in frontotemporal areas increased at the speaker-listener transition, and these response electrodes overlapped by a large degree to electrodes that are correlated to NLP, suggesting that these neural activities are actively process language information during transitions. Together, our work revealed a remarkable orchestration of language processing across multiple areas and frequencies in our brain, serving as the building blocks underlying smooth conversation and human communication.",
        "url": "https://www.world-wide.org/cosyne-23/human-neural-dynamics-elements-natural-82d6e76e"
    },
    "Characterizing network properties of the whole-brain Drosophila connectome": {
        "title": "Characterizing network properties of the whole-brain Drosophila connectome",
        "authors": "Albert Lin, Runzhe Yang, Sven Dorkenwald, Arie Matsliah, David Deutsch, Sebastian Seung, Mala Murthy",
        "date": "Thursday, 9 March 2023",
        "location": "I-008",
        "abstract": "Characterizing the network properties of animal brains may lead to a better understanding of computation and information flow in these complex organs. However, to date very few whole-brain neuron-level reconstructions have been completed across organisms. The collaborative Flywire project1-2 has completed the proofreading of a connectome for a Drosophila female brain which contains both complete hemispheres of the central brain and includes neurons that receive inputs in the optic lobes. Here, we dissect the network properties of the complete central brain of the fruit fly. We characterized the distributions of synaptic connection weights and network motifs in 75 anatomically defined brain regions, or neuropils, and found that different neuropils have different network statistics. We constructed a projectome describing how connected these neuropils are to each other, and identified the dominant neurotransmitters exchanged between each neuropil pair. To group neurons by connectivity rather than by anatomy, we employed spectral clustering to sort neurons into modules. We found that many of these modules correspond to neuron classes with known biological functions. Finally, we identified groups of neurons which project across the midline, a population which likely plays a critical role in sending signals from one hemisphere of the brain to the other. Together, these results highlight how the topology of the anatomical neuronal network may direct and constrain the flow of information across the brain of the fly.",
        "url": "https://www.world-wide.org/cosyne-23/characterizing-network-properties-whole-brain-fac931cc"
    },
    "Human-like capacity limits in working memory models result from naturalistic sensory constraints": {
        "title": "Human-like capacity limits in working memory models result from naturalistic sensory constraints",
        "authors": "Yudi Xie, Yu Duan, Aohua Cheng, Pengcen Jiang, Christopher Cueva, Guangyu Robert Yang",
        "date": "Thursday, 9 March 2023",
        "location": "I-009",
        "abstract": "Working memory (WM) allows us to hold information temporarily and make complex decisions beyond reflexive response to stimuli. One prominent feature of WM is its capacity limit. Despite decades of study, the root of this limit is still not well-understood. Most previous accounts for this limit assume various forms of memory constraints and make strong, often oversimplified, assumptions about sensory representations of stimuli. In this work, we built visual-cognitive neural network models of WM that process raw sensory stimuli. In contrast to intuitions that capacity limit results from memory constraints, we found that pre-training the sensory region of our models with natural images poses enough constraints on models to exhibit human-like behavior patterns across a wide range of WM capacity tasks. In change detection tasks, the detection accuracy decreases rapidly when the number of stimuli to be remembered increases. In continuous report tasks, the fidelity of the report again decreases rapidly when more stimuli are shown. In contrast, models without realistic constraints on the sensory regions produce super-human performance in these tasks. Human-like behavior cannot be restored simply by restricting the size of these models or adding processing noise. Unlike phenomenological accounts of WM capacity, our neural network models allow us to test the neural mechanisms of capacity limitation. We found that the average neural activation in our model increases and then plateaus when more stimuli are presented, and capacity limitation appears to arise in a bottom-up fashion; both are broadly consistent with previous fMRI and electrophysiological studies. Our work suggests that many phenomena about WM capacity can be explained by sensory constraints. Our models offer a fresh perspective in our understanding of the origin of the WM capacity limit and highlight the importance of building models with realistic sensory processing even when studying memory and other high-level cognitive phenomena.",
        "url": "https://www.world-wide.org/cosyne-23/human-like-capacity-limits-working-memory-61f04ecd"
    },
    "Neural and behavioral evidence for hierarchical and counterfactual reasoning in non-human primates": {
        "title": "Neural and behavioral evidence for hierarchical and counterfactual reasoning in non-human primates",
        "authors": "Mahdi Ramadan & Mehrdad Jazayeri",
        "date": "Thursday, 9 March 2023",
        "location": "I-010",
        "abstract": "When faced with challenging multi-step decisions, humans are unable to evaluate all branches of the decision tree simultaneously and instead rely on piecemeal hierarchical and counterfactual reasoning strategies. To investigate the neural basis of these cognitive strategies, we developed a challenging multi-step decision task for monkeys in which they had to track an invisible ball through a maze using partial cues about the times when the ball makes turns within the maze. Animals were able to use temporal cues to infer the ball’s exit point. To evaluate the animals’ decision strategy, we compared their behavior to models implementing different inference strategies including (1) optimal maximum-likelihood strategy, (2) hierarchical strategy that handles decisions sequentially, (3) postdictive strategy that conditions early decisions on late evidence, and (4) hierarchical strategy with potential revisions using counterfactuals. Comparing behavioral responses to these cognitive models revealed that monkeys, like humans, solved the task using a combination of hierarchical and counterfactual strategies. Several independent behavioral tests involving out-of-distribution maze geometries, targeted temporal perturbations, and post-error eye movements provided additional evidence that animals solved the task flexibly using these strategies. To investigate the underlying neural computations, we recorded simultaneously from large populations of single neurons in the anterior cingulate (ACC) and dorsomedial frontal cortex (DMFC). Single neurons in both areas had highly heterogeneous response profiles and formed structured low-dimensional activity patterns across the population. Further analysis of neural response dynamics with respect to the temporal cues provided clear evidence of hierarchical information processing in low uncertainty conditions and counterfactual processing in high uncertainty conditions when the late sensory cues could help revise potentially incorrect earlier decisions. Together, these results indicate that monkeys, like humans, rely on rapid hierarchical and counterfactual decision strategies and highlight a potential role of ACC and DMFC in supporting the underlying computations.",
        "url": "https://www.world-wide.org/cosyne-23/neural-behavioral-evidence-hierarchical-18dd6454"
    },
    "Beyond perception: the sensory cortex as an associative engine during goal-directed learning": {
        "title": "Beyond perception: the sensory cortex as an associative engine during goal-directed learning",
        "authors": "Celine Drieu, Ziyi Zhu, Kylie Fuller, Aaron Wang, Sarah Elnozahy, Kishore Kuchibhotla",
        "date": "Thursday, 9 March 2023",
        "location": "I-011",
        "abstract": "The sensory cortex is widely considered to be specialized for perception by interpreting complex sensory patterns while also exhibiting structured forms of representational plasticity of behaviorally-relevant stimuli. Recent evidence, however, suggests that sensory cortical neurons directly encode non-sensory variables such as movement and valence. Conjoint representations of sensory and non-sensory variables in the same network could further hone perception or, alternatively, subserve more integrative cognitive processes. Here, we ask the extent to which the sensory cortex is an associative engine, directly linking stimuli with actions that produce desirable outcomes during goal-directed learning. We trained mice on an auditory go/no-go task and exploited a novel behavioral task to isolate rapid task acquisition (measured in non-reinforced trials) from slower, behavioral expression (measured in reinforced trials). Optogenetically suppressing the auditory cortex (AC) throughout learning only during the stimulus (n=4), or only during reward consumption (n=8), weakened stimulus-action associations. Strikingly, AC suppression throughout the trial (stimulus-action-outcome, n=8) led to even greater delays, suggesting that AC is used for associative purposes during learning. Interestingly, the impact of AC silencing gradually waned during learning arguing for a transient, associative, and teaching role for the AC, rather than one focused on task execution. Longitudinal, two-photon calcium imaging throughout learning combined with unsupervised low-rank tensor decomposition uncovered low-dimensional learning-related dynamics at distinct timescales. Learning networks rapidly developed non-overlapping ensembles that encoded the different task contingencies. In parallel, neural populations exhibited no large-scale improvement in stimulus decoding but, instead, exhibited fine-scale changes in stimulus selectivity that matched learning trajectories. Latent knowledge of the task was thus manifested in cortical networks to reflect contingency acquisition and stimulus selectivity despite poor behavioral expression. Overall, our work argues that in addition to being specialized for perception, the sensory cortex is associative in nature and continuous with regions involved in higher-order cognitive processes.",
        "url": "https://www.world-wide.org/cosyne-23/beyond-perception-sensory-cortex-associative-d53408bf"
    },
    "Dynamic endocrine factors shape hippocampal spatial representations": {
        "title": "Dynamic endocrine factors shape hippocampal spatial representations",
        "authors": "Nora Wolcott & Michael Goard",
        "date": "Thursday, 9 March 2023",
        "location": "I-012",
        "abstract": "The computational study of neural circuits canonically assumes that the underlying connectivity of the network is static in the absence of learning. However, it has long been understood that endocrine factors can influence network connectivity in a cyclical manner, as demonstrated by a reliable 30% fluctuation in synaptic density observed across the estrous cycle in vitro. Despite this, the mechanisms underlying endocrine modulation of the hippocampal network remain poorly understood. Here, we used chronic two-photon (2P) imaging to demonstrate that both dendritic spine turnover and place cell remapping are modulated by cyclic fluctuations in sex steroid hormones. This phenomenon was observed using a custom chronically implanted glass microperiscope in a cohort of awake, behaving mice. To concomitantly track endocrine state, we developed a supervised deep neural network for unbiased classification of estrous stage at expert levels. Using these techniques, we first measured dendritic spine turnover across the course of several weeks. We found approximately 15.0% fluctuation in turnover, with spine density peaking during periods of high estradiol. To understand how these structural changes affected the functional properties of the circuit, we tracked place cell responses across environments defined by differential visual cues. The mice were first introduced to environment A, then transferred to environment B, then finally reintroduced to environment A (A > B > A’). The degree of hippocampal remapping between environments A and B was greatest during periods of elevated estradiol and synaptic density, while the stability of place fields between environments A and A’ was not significantly different across days. Shifts in dendritic spine turnover along with place cell remapping during periods of high estradiol suggest that endocrine state modulates both the structural and functional plasticity of the hippocampal network.",
        "url": "https://www.world-wide.org/cosyne-23/dynamic-endocrine-factors-shape-hippocampal-60eb4149"
    },
    "Machine Learning Approaches Reveal Prominent Behavioral Alterations and Cognitive Dysfunction in a Humanized Alzheimer Model": {
        "title": "Machine Learning Approaches Reveal Prominent Behavioral Alterations and Cognitive Dysfunction in a Humanized Alzheimer Model",
        "authors": "Stephanie Miller, Nick Kaliss, Pranav Nambiar, Jorge Palop, Kevin Luxem, Yuechen Qiu, Catherine Cai, Kevin Shen, Takashi Saito, Takaomi Saido, Alexander Pico, Reuben Thomas, Stefan Remy",
        "date": "Thursday, 9 March 2023",
        "location": "I-013",
        "abstract": "Behavioral manifestations define neurological disorders, but our knowledge of disease-induced behavioral alterations is incomplete and largely limited to standard domain-specific behavioral approaches. New humanized App knock-in (KI) models of Alzheimer’s disease (AD) mimic disease mechanisms better than transgenic overexpression, but fail to display consistent behavioral alterations in standard behavioral tests despite severe AD-related neuropathological changes. To address this technological barrier in AD modeling, we used the machine learning platforms DeepLabCut and VAME to test the hypothesis that deconstructing full sequences of spontaneous mouse behavior into canonical behavioral units (motifs) will better capture AD-induced brain dysfunction in App-KI mice. Indeed, we found that humanized AppNL-G-F/NL-G-F mice have robust impairments in spontaneous behavior as evidenced by prominent alterations in motif use and motif transitions. This phenotype is consistent with cognitive dysfunction, including blunted novelty response, impaired habituation and sensitization, and disorganized behavioral sequences. We conclude that machine learning approaches provide a direct and unbiased measure of AD-related mechanisms of brain dysfunction.",
        "url": "https://www.world-wide.org/cosyne-23/machine-learning-approaches-reveal-prominent-9cf421cc"
    },
    "Excitatory-inhibitory cortical feedback enables efficient hierarchical credit assignment": {
        "title": "Excitatory-inhibitory cortical feedback enables efficient hierarchical credit assignment",
        "authors": "Will Greedy, Heng Wei Zhu, Joseph Pemberton, Jack Mellor, Rui Ponte Costa",
        "date": "Thursday, 9 March 2023",
        "location": "I-014",
        "abstract": "The error-backpropagation (backprop) algorithm remains the most common solution to the credit assignment problem in artificial neural networks. In neuroscience, it remains unclear whether the brain could be adopting a similar strategy to modify its synapses. Recent models have attempted to bridge this gap while being consistent with a range of experimental observations. However, these models are either ineffective at propagating error signals through several brain areas or require a multi-phase learning process, neither of which are reminiscent of learning in the brain. Here, we build upon prior work introducing Bursting Cortico-Cortical Networks (BurstCCN), a model which solves these issues by integrating biologically-plausible bursting, dendritic feedback and cell-type specific functional connectivity. BurstCCN uses a burst-dependent synaptic plasticity rule and connection-type-specific short-term synaptic plasticity to enable burst multiplexing. In addition, it relies on apical dendrite-targeting (SST) interneurons to maintain E/I balance and facilitate the encoding of error signals. First, we demonstrate that the BurstCCN can effectively backpropagate errors through multiple layers using a single-phase learning process. Next, we demonstrate that the BurstCCN is capable of learning non-trivial image classification tasks (MNIST and CIFAR-10) as well as a reinforcement learning task (CartPole). Finally, we show how Dalean constraints can be introduced, proposing a role for both inhibitory (SST, PV, NDNF) and disinhibitory (VIP) cell-types. Overall, our work suggests that specific excitatory-inhibitory cortico-cortical connectivity with both short- and long-term synaptic plasticity, jointly underlie single-phase efficient deep learning in the brain.",
        "url": "https://www.world-wide.org/cosyne-23/excitatory-inhibitory-cortical-feedback-3c00fb1b"
    },
    "Brain-wide Representations of Behavior Spanning Multiple Timescales and States in C. elegans": {
        "title": "Brain-wide Representations of Behavior Spanning Multiple Timescales and States in C. elegans",
        "authors": "Adam Atanas, Jungsoo Kim, Ziyu Wang, Eric Bueno, McCoy Becker, Di Kang, Jungyeon Park, Cassi Estrem, Talya Kramer, Saba Baskoylu, Vikash Mansingkha, Steven Flavell",
        "date": "Thursday, 9 March 2023",
        "location": "I-015",
        "abstract": "Changes in an animal’s behavior and internal state are accompanied by widespread changes in activity across its brain. However, how neurons across the brain encode behavior and how this is impacted by state is poorly understood. We recorded brain-wide activity and the diverse motor programs of freely-moving C. elegans and built probabilistic models that explain how each neuron encodes quantitative features of the animal’s behavior. By determining the identities of the recorded neurons, we created, for the first time, an atlas of how the defined neuron classes in the C. elegans connectome encode behavior. Many neuron classes have conjunctive representations of multiple behaviors. Moreover, while many neurons encode current motor actions, others encode recent actions. Changes in behavioral state are accompanied by widespread changes in how neurons encode behavior, and we identify these flexible nodes in the connectome. Our results provide a global map of how the cell types across an animal’s brain encode its behavior.",
        "url": "https://www.world-wide.org/cosyne-23/brain-wide-representations-behavior-159c8d83"
    },
    "The shared geometry of biological and recurrent neural network dynamics": {
        "title": "The shared geometry of biological and recurrent neural network dynamics",
        "authors": "Arthur Pellegrino & Angus Chadwick",
        "date": "Thursday, 9 March 2023",
        "location": "I-016",
        "abstract": "Recent studies have proposed that the activity of both recurrent and biological neural networks is constrained to a task manifold. This manifold is often intrinsically lower dimensional than the full neural state space, and its geometry is directly related to task computations. In parallel, there has been a surge of interest in training RNNs to solve behavioural tasks in order to generate testable hypotheses regarding the computations employed by neural circuits. However, means of using task-trained RNNs to test hypotheses regarding the geometry of neural data manifolds are currently lacking. In the present work, we develop a method to address this need. Our method consists of aligning the RNN and neural data manifolds, while accounting for trial-to-trial variability in trajectories on the data manifold by controlling and time-warping the trajectories of the RNN. We apply our method to two large-scale datasets. First, using recordings from prefrontal cortex during a contextual decision making task, we show that our method uncovers task-relevant structure in the neural data that is otherwise hidden in the high-dimensional data. Second, using motor and premotor cortical activity in a delayed center-out reach task, we demonstrate that by varying the architecture of the RNN and the design of the task it is trained on, distinct hypotheses can be generated regarding the origin of motor preparatory activity and rotational dynamics that can be tested in the neural data. Together, our results illustrate how hypotheses regarding the latent computations employed by neural circuits to solve behavioural tasks can be framed and tested by comparing the geometry of recurrent and biological neural network activity.",
        "url": "https://www.world-wide.org/cosyne-23/shared-geometry-biological-recurrent-fbf1771d"
    },
    "Neural-astrocyte interaction enables contextually guided circuit dynamics": {
        "title": "Neural-astrocyte interaction enables contextually guided circuit dynamics",
        "authors": "Giacomo Vedovati, Thomas J. Papouin, ShiNung Ching",
        "date": "Thursday, 9 March 2023",
        "location": "I-017",
        "abstract": "Recurrent neural networks, a ubiquitous construct in machine intelligence, have become a powerful hypothesis-generating tool in theoretical neuroscience. Such networks can be used to examine potential circuit mechanisms associated with a variety of cognitive functions. Here, we use recurrent networks to engage a new theoretical question: the potential role of astrocytes in neural computation. Astrocytes are highly abundant cells in the cortex that are capable of modulating many facets of neural dynamics, including excitability, synaptic efficacy and plasticity. However, despite this modulatory capability, astrocytes are generally disregarded in models of neural computation, perhaps due to their much slower time-scale and seeming lack of specificity in their neural targets, and because of a lack of general theories of astrocytes contribution to neural circuit activity. Here, we explore a potential computational function of astrocytes: the contextual guidance of synaptic efficacy for rapid switching between previously learned tasks, inspired by the latest conceptual leap in the field of astrocyte biology. We build a recurrent neuro-astrocyte network in which each astrocyte modulates the efficacy of a subset of synapses, motivated by astrocytic tiling of neural space. Astrocytes in the model are sensitive to the association rule or context and propagate, in essence, a low-rank perturbation to the synaptic weights of the neural network. We show that fast learning can converge in the presence of these perturbations, leading to a single context-dependent network able to quickly switch contexts without relying on re-learning. Critically, astrocytic perturbation need only exist and be context-dependent for this mechanism to succeed; there is no transport of synaptic weights to `design' astrocytic modulation. This work suggests a potential computational role for astrocytic modulation in neural circuits, and new frameworks in multiple time-scale recurrent neural networks.",
        "url": "https://www.world-wide.org/cosyne-23/neural-astrocyte-interaction-enables-cf0da327"
    },
    "Efficient connectome analyses for identifying bottleneck neurons in behaviorally-relevant pathways": {
        "title": "Efficient connectome analyses for identifying bottleneck neurons in behaviorally-relevant pathways",
        "authors": "Ishani Ganguly, Rudy Behnia, Ashok Litwin-Kumar",
        "date": "Thursday, 9 March 2023",
        "location": "I-018",
        "abstract": "The availability and scale of synapse-resolution connectomes containing the wiring of neural systems has grown rapidly in recent years. In order to exploit these rich datasets and extract neural circuit mechanisms underlying behavior, scalable connectome analysis tools capable of predicting information routing principles in circuit pathways are necessary. Current methods to extract neurons mediating information flow only consider a limited set of pathway lengths and do not scale to large connectome datasets. Here, we develop an efficient framework to identify such bottlenecks in pathways between arbitrary source and target neurons. We define an influence metric that quantifies the strength of pathways of arbitrary length from sources to targets and develop an algorithm that extracts the smallest group of neurons that account for a specified proportion of this total influence, which we term \"bottleneck neurons\". To validate our methods, we deploy them on the Drosophila hemibrain connectome to recover several well-studied neural pathways from sensory input to descending motor output. By varying a gain parameter that penalizes longer neural pathways when computing influence, we can prioritize neurons that are involved in longer or shorter pathways in these ground truth circuits. We then apply our framework to explore the subset of bottleneck neurons that mediate information flow from the sensory periphery to the functionally and anatomically distinct compartments of the mushroom body, the primary learning center in the insect brain. Extending our methods to other regions may elucidate which neurons are best suited for experimental manipulation and shed light on large-scale organizational principles of neural circuits.",
        "url": "https://www.world-wide.org/cosyne-23/efficient-connectome-analyses-identifying-a16b6822"
    },
    "Mesolimbic dopamine release conveys causal associations": {
        "title": "Mesolimbic dopamine release conveys causal associations",
        "authors": "Huijeong Jeong, Annie Taylor, Joseph Floeder, Martin Lohmann, Stefan Mihalas, Brenda Wu, Mingkang Zhou, Dennis Burke, Vijay Mohan K Namboodiri",
        "date": "Thursday, 9 March 2023",
        "location": "I-019",
        "abstract": "Learning to predict rewards based on environmental cues is essential for survival. It is widely believed that animals learn to predict rewards by updating predictions whenever the outcome deviates from expectations. Such violations of predictions are called reward prediction errors (RPEs). RPEs are the critical teaching signal in the most widely accepted model for associative learning—temporal difference reinforcement learning (TDRL). As TDRL RPE has been successful at explaining the activity dynamics of dopamine, it has become the dominant theory of dopamine’s role as the critical regulator of learning. An alternative approach to learn cue-reward associations is to infer the cause of meaningful outcomes such as rewards. Since causes must precede outcomes, a viable approach to infer whether a cue causes reward is to learn whether the cue consistently precedes reward. This approach is advantageous in the real world where cues often outnumber the meaningful outcomes (e.g., rewards). Using this intuition, here we propose a causal inference algorithm that infers whether a cue is a cause of reward. Based on this algorithm, we denote stimuli (cues or rewards) whose cause should be learned by the animal as “meaningful causal targets” and propose that mesolimbic dopamine signals whether a current event is a meaningful causal target. We found that our model makes similar predictions as RPEs under commonly studied experimental settings. Hence, to distinguish between the two hypotheses (RPEs or causal associations), we performed experimental tests by measuring dopamine release in nucleus accumbens core. We found that mesolimbic dopamine is consistent with signaling causal associations but not RPE in every case, thereby challenging the dominant theory of reward learning in the brain. Our results provide a new conceptual and biological framework for associative learning.",
        "url": "https://www.world-wide.org/cosyne-23/mesolimbic-dopamine-release-conveys-9b811f77"
    },
    "Spatiotemporal patterns of adaptation-induced slow oscillations in a whole-brain model of slow-wave sleep": {
        "title": "Spatiotemporal patterns of adaptation-induced slow oscillations in a whole-brain model of slow-wave sleep",
        "authors": "Caglar Cakan, Cristiana Dimulescu, Liliia Khakimova, Daniela Obst, Agnes Flöel, Klaus Obermayer",
        "date": "Thursday, 9 March 2023",
        "location": "I-020",
        "abstract": "During slow-wave sleep, the brain is in a self-organized regime in which slow oscillations (SOs) between up- and down-states travel across the cortex. While an isolated piece of cortex can produce SOs, the brain-wide propagation of these oscillations are thought to be mediated by the long-range axonal connections. We address the mechanism of how SOs emerge and recruit large parts of the brain using a whole-brain model constructed from empirical connectivity data in which SOs are induced independently in each brain area by a local adaptation mechanism. Using an evolutionary optimization approach, good fits to human resting-state fMRI data and sleep EEG data are found at values of the adaptation strength close to a bifurcation where the model produces a balance between local and global SOs with realistic spatiotemporal statistics. Local oscillations are more frequent, last shorter, and have a lower amplitude. Global oscillations spread as waves of silence across the brain, traveling from anterior to posterior regions. These traveling waves are caused by heterogeneities in the brain network in which the connection strengths between brain areas determine which areas transition to a down-state first, and thus initiate traveling waves across the cortex. Our results demonstrate the utility of whole-brain models for explaining the origin of large-scale cortical oscillations and how they are shaped by the connectome. Combined with a modern optimization pipeline, our work expands the scope of biophysically realistic whole-brain models to investigating brain activity beyond the awake resting-state.",
        "url": "https://www.world-wide.org/cosyne-23/spatiotemporal-patterns-adaptation-induced-801deb7d"
    },
    "Robust multiband drift estimation in electrophysiology data": {
        "title": "Robust multiband drift estimation in electrophysiology data",
        "authors": "Charlie Windolf, Angelique C Paulk, Yoav Kfir, Eric Trautmann, Samuel Garcia, Domokos Meszéna, William Munoz, Irene Caprara, Mohsen Jamali, Julien Boussard, Ziv Williams, Sydney Cash, Liam Paninski, Erdem Varol",
        "date": "Thursday, 9 March 2023",
        "location": "I-021",
        "abstract": "High-density electrophysiology probes have opened new possibilities for systems neuroscience in human and non-human animals, but probe motion poses a challenge for downstream analyses, particularly in human recordings. We improve on the state of the art for tracking this drift with four major contributions. First, we extend previous decentralized methods to use multiband information, leveraging the local field potential (LFP) and current source density (CSD) as well as spikes. Second, we show that the CSD-based approach enables subsecond drift tracking. Third, we introduce an efficient online algorithm, enabling the method to scale to longer and higher-resolution recordings, which could facilitate real-time applications. Finally, we improve the robustness of the approach by accounting for the nonstationarities that occur in real data and by automating parameter selection. Together, these advances enable fully automated scalable registration of challenging datasets from both human and mouse.",
        "url": "https://www.world-wide.org/cosyne-23/robust-multiband-drift-estimation-electrophysiology-6c23740c"
    },
    "Learning orthogonal working memory representations protects from interference in a dual task": {
        "title": "Learning orthogonal working memory representations protects from interference in a dual task",
        "authors": "Alexandre Mahrach, Xian Zhang, Da Li, Chengyu Li, Albert Compte",
        "date": "Thursday, 9 March 2023",
        "location": "I-022",
        "abstract": "Working memory (WM) is a cognitive function that allows for the short-term maintenance and manipulation of information when no longer accessible to the senses. It relies on temporarily storing stimulus features in the neuronal activity. However, the mechanisms protecting WM from task-irrelevant influences are unknown. Recent studies involving WM tasks have suggested that neural activity before and after distractors can be decomposed into two orthogonal subspaces, one invariant across distraction, thus protecting WM from interferences. However, whether orthogonalization is a general mechanism for WM preservation remains an open question, and the network mechanisms supporting it are unclear. Here, we investigated WM representations in calcium imaging data from the prelimbic cortex (PrL) in mice learning to perform a recently developed olfactory dual task. The task consists of an outer delayed paired-association task (DPA) combined with an inner Go-NoGo task. We studied how PrL reflected the process of learning to protect the memory representation of DPA sample odors against Go/NoGo distractor odors. We evaluated the activity overlap with the low-dimensional encoding manifold of the sample/distractor odors as the mouse learned. In the first training days, we found that PrL early delay activity overlapped with both sample and distractor axes, but the overlap with the distractor axis vanished in the late training phase. We give a mechanistic account of these PrL activity overlaps in a spiking network model of strongly recurrent neurons with low-rank connectivity and short-term facilitation. Our model associates learning with (1) orthogonalization of sample and distractor representations and (2) orthogonalization of WM representations with corresponding irrelevant sensory representations. We confirmed both predictions with the help of photoinhibition of the Anterior Cingulate Cortex (ACC) to PrL inputs. Altogether, our results suggest that rotations of WM representations in PrL play a fundamental role in preserving WM from interfering tasks.",
        "url": "https://www.world-wide.org/cosyne-23/learning-orthogonal-working-memory-representations-c2664ae2"
    },
    "Behavioral and neural mechanisms of optimal sensory discrimination": {
        "title": "Behavioral and neural mechanisms of optimal sensory discrimination",
        "authors": "Daniel Hulsey, Lia Papadopoulos, Kevin Zumwalt, Suhyun Jo, Santiago Jaramillo, David McCormick, Luca Mazzucato",
        "date": "Thursday, 9 March 2023",
        "location": "I-023",
        "abstract": "Recent studies show that behaving animals transition between discrete strategies during sensory decision-making and that arousal modulates task performance. However, it remains a challenge to understand (i) the relationships between arousal and task strategy during sensory discrimination and (ii) the neural mechanisms underlying optimal performance states. To address these topics, we combined behavioral, neurophysiological, and computational approaches to uncover the neural mechanisms underlying arousal-dependent sensory discrimination. We implemented two-alternative-choice tasks, prompting mice to categorize auditory or visual stimuli as they traverse a range of arousal levels. We show that mice transition between minutes-long optimal, sub-optimal, and disengaged performance states, and selectively maintain persistent optimal states. We also find that the likelihood of optimal state occupancy exhibits a robust inverted-U relationship with pupil diameter, and that transitions into the optimal state are accompanied by marked decreases in the trial-to-trial variability of multiple arousal measures. These relationships hold in both auditory and visual tasks, though mice performing the visual task have larger optimal pupil sizes than their auditory counterparts, suggesting modality-dependent arousal modulation. To test whether arousal-induced performance modulations occur at early stages of the cortical hierarchy, we analyzed Neuropixels recordings from auditory cortex of passively-behaving mice presented with pure tones. We show that tone frequency is best decoded from population activity during periods of intermediate pupil size, suggesting that optimal performance states extracted from the behavioral task may be underpinned by arousal-regulated neural representations that are formed even in passive settings. Using a circuit model, we then explain how arousal could modulate neural dynamics in a manner consistent with the observed inverted-U relationship between sound discriminability and pupil size. Taken together, our findings show that the regulation of arousal helps to establish optimal neural and behavioral performance states for sensory discrimination.",
        "url": "https://www.world-wide.org/cosyne-23/behavioral-neural-mechanisms-optimal-2d8f1fc8"
    },
    "Task switching differentially perturbs neural geometry in the human frontal and temporal lobes": {
        "title": "Task switching differentially perturbs neural geometry in the human frontal and temporal lobes",
        "authors": "Hristos Courellis, Araceli Cardenas, Marielle Darwin, John Thompson, Taufik Valiante, Adam Mamelak, Ralph Adolphs, Ueli Rutishauser",
        "date": "Thursday, 9 March 2023",
        "location": "I-024",
        "abstract": "The process of switching between tasks is cognitively taxing, and gives rise to a task switching cost (TSC), an increase in reaction time immediately after switching [1]. While robust in humans, the presence of TSC in other animals is debated, being absent from some species entirely, thus necessitating study in humans [2,3]. The neurophysiological basis of TSC is also debated, with two competing explanations involving reconfiguration of medial frontal cortical (MFC) activity for the current task, or lack of inhibition of the previous task. To disambiguate between these explanations, we conducted single-unit recordings in epilepsy patients who were instructed to alternate between cognitive tasks. Our objective was to identify population-level neural signatures that explain TSC and arbitrate between the reconfiguration and inhibition models of task switching. We recorded 1023 neurons in 10 patients (15 sessions) from medial frontal and temporal structures. We found that MFC neurons form a strong hierarchical representation of task context, unlike neurons in the prefrontal cortex and temporal lobe. Furthermore, we identify two orthogonal context-encoding subspaces within MFC that are present during pre-stimulus baselines. One subspace emerges immediately after switching but is transiently present, and is not predictive of TSC magnitude. The other subspace persistently encodes task context. However, while switching, even after the instructions, this subspace retains a representation of the previous task, and updates to the current task after the first trial. The degree of previous-task representation in this persistent subspace after a switch is predictive of switching costs. These findings provide a population level explanation for both reconfiguration and inhibition, with reconfiguration entailing transfer of context information out of the transient and into the persistent subspace, and a lack of appropriate inhibition reflected in the previous-task-encoding in the persistent subspace after switching, which explains TSC magnitude.",
        "url": "https://www.world-wide.org/cosyne-23/task-switching-differentially-perturbs-d217c421"
    },
    "Predicting proprioceptive cortical anatomy and neural coding with topographic autoencoders": {
        "title": "Predicting proprioceptive cortical anatomy and neural coding with topographic autoencoders",
        "authors": "Max Grogan, Lee Miller, Kyle Blum, Yufei Wu, Aldo Faisal",
        "date": "Thursday, 9 March 2023",
        "location": "I-025",
        "abstract": "Proprioception is fundamental for the control of movement, its loss producing profound motor deficits. Yet basic questions of how pose and movement are represented, as well as how these representations are arranged across the somatosensory cortex, are unclear. To this end, we adopt a task-driven modelling approach, using a spiking variational autoencoder to approximate a population of cortical neurons. We optimize the model to encode natural movement stimuli derived from recordings of human kinematics and impose biological constraints which we hypothesise to be important for reproducing characteristics of proprioceptive neural coding, namely, enforcing a spike-based code and implementing lateral effects between neighbouring neurons in the model to drive topographical structure in neural tuning. To evaluate the effectiveness of these principles at reproducing empirical observations in neural data (without directly fitting to neural data), we task our model with encoding movement kinematics during a centre-out reaching task and compare activity in modelled neurons to recorded neurons in area 2 of monkeys performing the same task. The model reproduces several key features of neural tuning at both the level of individual neurons, and the spatial organisation of their tuning across the cortical surface. Furthermore, we demonstrate the importance in training on data from the true distribution of natural behaviour, with the model failing to reproduce key properties of the empirical data when trained on stereotyped reaching behaviour only. We then highlight two testable predictions made by the model: 1. The arrangement of directional tuning across the cortex has a blob-and-pinwheel-type geometry. 2. Few neurons encode just a single joint. In summary, the topographic VAE (Author et al, XXXX) provides a principled basis for understanding sensorimotor representations and their spatial organisation in cortex. These basic scientific principles may have application to the restoration of sensory feedback in brain-computer interfaces (Weber et al, 2012).",
        "url": "https://www.world-wide.org/cosyne-23/predicting-proprioceptive-cortical-f38f425e"
    },
    "Approximate inference through active computation accounts for human categorization behavior": {
        "title": "Approximate inference through active computation accounts for human categorization behavior",
        "authors": "Xiang Li, Luigi Acerbi, Wei Ji Ma",
        "date": "Thursday, 9 March 2023",
        "location": "I-026",
        "abstract": "Bayesian computations are intractable and expensive, but this is rarely accounted for in existing Bayesian observer models. In this work, we propose that a) the brain can only compute imprecise (noisy) estimates of likelihoods and posteriors, and, b) since computations are expensive, the brain actively chooses which computations to perform to refine such estimates. We call our framework approximate inference through active sampling (AIAS) and study its implications in N-alternative categorization. While it is common in Bayesian observer models to assume that the agent makes noisy measurements of a state of the world, here we introduce an additional noise at a higher level in the computation. We assume that the true (ideal-observer) likelihoods and posteriors of the categories are unknown to the agent. The agent sequentially makes noisy measurements of those likelihoods – each “sample” representing a unit of computation –, one category at a time, thus refining their beliefs over the true likelihoods and their belief over the true posterior probabilities. The brain simulates to decide whether to sample and which category to sample. AIAS accounts for several empirical findings. First, we find that the average number of measurements grows approximately logarithmically with N, as per Hick's law. Second, we account for a puzzling recent finding that decision confidence follows the difference between the two highest posteriors, rather than the highest posterior itself. AIAS not only provides better fits of choice and confidence data in this categorization task, but yields a parameter-free prediction of response times. Third, we show that AIAS is able to explain how categorization behavior changes when the visual contrast varies. Overall, AIAS provides a novel approach to explain human categorization by casting approximate inference as an active-sampling process with imprecise computations.",
        "url": "https://www.world-wide.org/cosyne-23/approximate-inference-through-active-8fad936d"
    },
    "Globally gated deep linear networks": {
        "title": "Globally gated deep linear networks",
        "authors": "Qianyi Li & Haim Sompolinsky",
        "date": "Thursday, 9 March 2023",
        "location": "I-027",
        "abstract": "Gating represents multiplicative interactions in neural systems, and are well known motifs of biological neural circuits. Recently neural networks with gating have attracted increased attention. Gated Linear Networks (GLNs) have been studied for their interesting capabilities such as biologically plausible learning and reduced forgetting in sequential learning. The network has also been shown to mimic some aspects of cerebellar architecture and plasticity. However, there has been virtually no theoretical understanding of the capabilities and limitations of GLNs. To close this gap, we introduce Globally Gated Deep Linear Networks (GGDLNs) where gating units are shared among all processing units in a given layer, decoupling the architectures of the nonlinear, unlearned gating and the learned linear processing motifs. This allows for rigorous theoretical analysis of these interesting systems. We derive exact equations for performance of GGDLNs. We find that the statistics of the network outputs after learning can be expressed in terms of the input similarity matrix and the inner product of the gating units which undergoes modification through a task-dependent matrix. Interestingly, this matrix is directly related to the covariance of the readout weights, generating experimentally verifiable predictions of network connectivity given specific tasks. Using our theory, we study several aspects of the network. We show that GGDLNs with sufficient gating units behave similarly to fully trained nonlinear networks. We found that the network can achieve feature selection by adjusting the task-dependent matrix to select important gating units for the relevant tasks. Additionally, we evaluate the network’s ability for context-dependent learning by incorporating task-relevant information into the gating units, mimicking top-down contextual signals from the mossy fiber pathway. In summary, we derive exact theoretical predictions of performance and connectivity in GGDLNs trained on any specified tasks, providing insights for understanding learning with dendritic gating architectures in the brain.",
        "url": "https://www.world-wide.org/cosyne-23/globally-gated-deep-linear-networks-11c74f9b"
    },
    "Computation of abstract context in the midbrain reticular nucleus during perceptual decision-making": {
        "title": "Computation of abstract context in the midbrain reticular nucleus during perceptual decision-making",
        "authors": "Jordan Shaker, Dan Birman, Nicholas Steinmetz",
        "date": "Thursday, 9 March 2023",
        "location": "I-028",
        "abstract": "Perceptual decision-making is crucial for survival, requiring the integration of dynamic sensory evidence from the environment with internal state variables (e.g. context, priors, value) to choose an appropriate action plan. Neural correlates of perceptual decisions are more distributed than once thought, having been found within the cortex, striatum, and superior colliculus (SC). Recent work has suggested a potentially novel node in this network - the midbrain reticular nucleus (MRN) - which was one of the few regions that encoded visual and action selection signals in a brain-wide survey of 2-alternative forced choice (2AFC) task-related activity in mice. To characterize the functional properties of MRN, we have conducted extensive recordings throughout MRN while both task-naive and trained mice passively view a variety of task stimuli. Recordings performed thus far have revealed topographic organization of sensory/motor coding in MRN and increased visual responses after task training. Additionally, we sought to assess whether the MRN, in addition to containing action selection signals, contains internal state signals required to compute the abstract decision. We have successfully designed and trained a novel reverse contingency task for mice wherein the computation of context can be measured. Identical visual stimuli require opposing motor reports for reward depending on the task block. In preliminary Neuropixels 2.0 recordings during task performance, we found contextual modulation of visual and action-related responses in canonical decision-making regions including secondary motor cortex (MOs), caudoputamen, and SC as well as in the MRN. Analyzing the population activity structure, we find evidence for a computation in which context alters the integration of evidence by shifting the attractor landscape. Together, these findings suggest that the MRN may be a novel node in the distributed network underlying the computation of abstract contextual information related to perceptual decisions.",
        "url": "https://www.world-wide.org/cosyne-23/computation-abstract-context-midbrain-aa07ef7e"
    },
    "Dynamic gating of perceptual flexibility by non-classically responsive cortical neurons": {
        "title": "Dynamic gating of perceptual flexibility by non-classically responsive cortical neurons",
        "authors": "Blake Sidleck, Jack Toth, Priya Agarwal, Olivia Lombardi, Danyall Saeed, Dylan Leonard, Abraham Eldo, Badr Albanna, Michele Insanally",
        "date": "Thursday, 9 March 2023",
        "location": "I-029",
        "abstract": "The ability to flexibly respond to sensory cues in dynamic environments is essential to adaptive auditory-guided behaviors such as navigation and communication. How do neural circuits flexibly gate sensory information to select appropriate behavioral strategies based on sensory input and context? Auditory neural responses during behavior are diverse, ranging from highly-reliable ‘classical’ responses (i.e. robust, frequency-tuned cells) to irregular or seemingly random ‘non-classically responsive’ firing patterns (i.e., nominally non-responsive cells) that fail to demonstrate any significant trial-averaged responses to sensory inputs or other behavioral factors. While classically responsive cells have been extensively studied for decades, the contribution of non-classically responsive cells to behavior has remained underexplored despite their prevalence. Recent work has shown that non-classically responsive cells in auditory cortex (AC) and secondary motor cortex (M2) contain significant stimulus and choice information and encode flexible task rules. While it has been shown that both classically and non-classically responsive units are essential for asymptotic task performance their role during learning is unknown. Here, we explore how diverse cortical responses emerge and evolve during flexible behavior. We recorded single-unit responses from AC while mice performed a reversal learning task. Cortical response profiles during learning were highly heterogeneous spanning the continuum from classically to non-classically responsive. Strikingly, we found that the proportion of task-encoding non-classically responsive neurons significantly increased during late learning when the largest behavioral improvements occur demonstrating that non-classically responsive neurons are preferentially recruited during learning. To identify the role of top-down feedback on AC circuits during key learning phases we optogenetically silenced M2→AC projection neurons while recording AC spiking responses. Remarkably, silencing M2 inputs preferentially modulated non-classically responsive cells and impaired behavioral performance during post-reversal learning. Our findings demonstrate that task-encoding non-classically responsive cells are preferentially recruited during learning by top-down inputs enabling neural and behavioral flexibility.",
        "url": "https://www.world-wide.org/cosyne-23/dynamic-gating-perceptual-flexibility-664ffec5"
    },
    "Familiarity-modulated synapses model cortical microcircuit novelty responses": {
        "title": "Familiarity-modulated synapses model cortical microcircuit novelty responses",
        "authors": "Kyle Aitken, Marina Garrett, Shawn R. Olsen, Stefan Mihalas",
        "date": "Thursday, 9 March 2023",
        "location": "I-030",
        "abstract": "Since environments are constantly in flux, the brain’s ability to identify novel stimuli that fall outside its own internal representation of the world is crucial for an organism’s survival. Within the mammalian neocortex, inhibitory microcircuits are proposed to regulate activity in an experience-dependent manner and different inhibitory subtypes exhibit distinct novelty responses. Discerning the function of diverse neural circuits and their modulation by experience can be daunting unless one has a biologically plausible novelty mechanism that is both understandable and flexible. Here we introduce a simple novelty mechanism, familiarity modulated synapses (FMSs), which exhibit synaptic changes following exposure to a stimulus via unsupervised, local modulations. FMSs stand apart from other familiarity mechanisms in their simplicity: they require no separated training and testing phases, no specialized connectomics, and can distinguish novelty without relying on slow recurrent convergence. Implementing FMSs within a model of a cortical microcircuit that includes multiple inhibitory subtypes, we simultaneously reproduce three distinct novelty effects recently observed in experimental data from visual cortical circuits in mice. This includes oddball and omission responses as well as novelty effects that occur over drastically different time scales. The model demonstrates how experimentally-observed microcircuit structure give rise to qualitatively distinct novelty responses across the various cell populations. Altogether, our findings highlight the flexibility of FMSs and opens the door to computationally and theoretically investigating how distinct synapse modulations can lead to a variety novelty responses in a simple, understandable, and biologically plausible setup.",
        "url": "https://www.world-wide.org/cosyne-23/familiarity-modulated-synapses-model-f856f467"
    },
    "Cortical dopamine enables deep reinforcement learning and leverages dopaminergic heterogeneity": {
        "title": "Cortical dopamine enables deep reinforcement learning and leverages dopaminergic heterogeneity",
        "authors": "Jack Lindsey & Ashok Litwin-Kumar",
        "date": "Thursday, 9 March 2023",
        "location": "I-031",
        "abstract": "Midbrain dopamine (DA) activity is implicated in reinforcement learning (RL). DA activity is observed to signal reward prediction error (RPE), a key quantity in many RL algorithms used to modulate updates to state-reward and state-action associations. How the state representations underlying these associations are themselves learned is typically outside the scope of RL models of the basal ganglia. However, modern RL algorithms in machine learning typically employ deep RL, in which state representations are learned as part of the RL algorithm, to attain state-of-the-art performance. In this work, we investigate the requirements for biologically plausible deep RL by studying a model in which DA projections to cortical regions upstream of the striatum drive state representation learning. We show that coarse, global DA projections are sufficient to enable effective representation learning, provided there exist two classes of cortical neurons that undergo DA-modulated plasticity according to learning rules with opposite signs (as experimental evidence suggests is the case for D1 and D2 receptor-expressing neurons). We next apply our model to an open question in the field: recent experimental evidence suggests DA population activity does not uniformly signal RPE, but rather heterogeneously encodes higher-dimensional information about an animal’s state. While prior work has proposed interpretations of this phenomenon, it remains unclear whether such heterogeneity serves a useful function in the context of RL. We show that although DA heterogeneity provides no benefit in classic RL models without state representation learning, it improves learning performance in our model. We develop a theoretical framework that explains this performance improvement and enables predictions about the optimal set of DA signals for a given task. We describe a key prediction of our model, that cortical representations of state should change over the course of learning to carry more of the same information as DA activity.",
        "url": "https://www.world-wide.org/cosyne-23/cortical-dopamine-enables-deep-reinforcement-cfa7e942"
    },
    "Perturbed population states: neuron loss and the recovery of behavioral performance": {
        "title": "Perturbed population states: neuron loss and the recovery of behavioral performance",
        "authors": "Stephen Clarke, Iliana Bray, Paul Nuyujukian",
        "date": "Thursday, 9 March 2023",
        "location": "I-032",
        "abstract": "Brain networks have the remarkable ability to adapt to neuron loss; however, little is known about how population spiking activity is affected quantitatively and even less is known about how populations adapt to restore behavior. Here, we analyzed the impact of neuron loss on population correlation structure using numerical simulations, a spiking neural network model, and in vivo spiking data from a lesion technique in which focal neuron loss is created through chronically implanted electrode arrays in awake-behaving animals. This easily-repeated perturbation allows neuroscientists to track the affected neuron population, before and after injury, establishing causal links between models of recorded activity and skilled task behaviors. The extent of perturbation to the largest 10 eigenvalues of the population spike count covariance matrix was significantly correlated with the extent of behavioral impairment, both in the model and in vivo. Despite the loss of individual neurons, correlation structure in the population returned alongside recovery of reaching behavior. These same correlations also provided a way to estimate neuron loss, using only small recorded sub-samples of the true underlying population. The results are anticipated to foster discussion among both systems and computational neuroscientists that are interested in population state models of cortex, and those interested in reverse engineering neural networks by building upon null network models to produce recovery patterns observed in vivo.",
        "url": "https://www.world-wide.org/cosyne-23/perturbed-population-states-neuron-loss-2b1a962c"
    },
    "Can a conserved transcriptomic axis predict state modulation of cortical interneurons?": {
        "title": "Can a conserved transcriptomic axis predict state modulation of cortical interneurons?",
        "authors": "Joram Keijser, Loreen Hertäg, Henning Sprekeler",
        "date": "Thursday, 9 March 2023",
        "location": "I-033",
        "abstract": "Inhibitory interneurons in cortex consist of many subtypes that differ in, e.g., connectivity and physiology. Recently, it was shown that —in layers 1-3 of mouse primary visual cortex— interneuron subtypes differ systematically in their modulation with an animal’s behavioural state, and that this state modulation can be predicted from the first principal component (PC) of the gene expression matrix (Bugeon et al. 2022). Here, we ask if this link between transcriptome and state-dependent processing is a general principle that extends across layers, areas, and species. To this end, we analysed 6 publicly available single-cell RNA sequencing (scRNA-seq) datasets collected from mouse, human, songbird, and turtle forebrains. All data sets contain a similar set of interneurons. In spite of this conservation at the level of cell types, we found clear differences between transcriptomic PCs, with larger differences between evolutionarily distant species. Further analyses revealed two factors underlying these differences: Divergence in gene expression within conserved cell types, and —to a lesser extent— divergence in cell type abundance. We confirm that cross-species differences are much larger than within-species differences, and show that within-species differences are mainly due to the presence or absence of deep-layer subtypes in the dataset. Finally, we study the cross-species expression of cholinergic receptors, thought to causally link transcriptome and state modulation (e.g. Muñoz et al. 2017, Bugeon et al. 2022). We find that many cholinergic receptors correlating with state modulation in mouse interneurons are not expressed in interneurons of other species, suggesting two hypotheses for future work: (1) Interneurons are similarly state-modulated across species but via different pathways, indicating adaptive significance; (2) Interneurons are differentially state-modulated across species, indicating evolutionarily divergent control of information flow. Overall, our work leverages genomic data to test the universality of findings from the mouse as an accessible model organism.",
        "url": "https://www.world-wide.org/cosyne-23/conserved-transcriptomic-axis-predict-0747486c"
    },
    "A biophysically detailed model of retinal degeneration": {
        "title": "A biophysically detailed model of retinal degeneration",
        "authors": "Aiwen Xu & Michael Beyeler",
        "date": "Thursday, 9 March 2023",
        "location": "I-034",
        "abstract": "Understanding the retina in health and disease is a key issue for neuroscience and neuroengineering applications such as retinal prostheses. Although the processing of visual information in the healthy retina has been studied in detail, no comprehensive computational model exists that captures the many cell-level and network-level biophysical changes common to retinal degenerative diseases. To address this challenge, we developed a biophysically detailed model of the retinal circuitry and simulated the network-level response to both light and electrical stimulation. The model included 11,138 cells belonging to nine different cell types (cone photoreceptors, horizontal cells, ON/OFF bipolar cells, ON/OFF amacrine cells, and ON/OFF ganglion cells) confined to a 300 × 300 × 210 µm patch of the parafoveal retina. After verifying that the model reproduced seminal findings about the light response of retinal ganglion cells (RGCs), we systematically introduced anatomical and neurophysiological changes to the network and studied their effect on network activity. In early phases of degeneration, we found that cone outer segment truncation and cone cell death differentially affected ON and OFF RGC firing: whereas the light response of ON RGCs diminished more quickly than that of OFF RGCs, the spontanenous firing rate of OFF RGCs steadily increased. In late phases of degeneration, we found that migration and progressive death of inner retinal neurons led to a steady increase in electrical activation thresholds of both ON and OFF RGCs, especially for epiretinal stimulation. Our findings demonstrate how biophysical changes associated with retinal degeneration affect retinal responses to both light and electrical stimulation. A detailed model of the retina in health and disease has the potential to further our understanding of visual processing in the retina as well as inform the design of retinal prostheses.",
        "url": "https://www.world-wide.org/cosyne-23/biophysically-detailed-model-retinal-2860ef79"
    },
    "Model-guided discovery of a retinal chromatic feature detector that signals visual context changes": {
        "title": "Model-guided discovery of a retinal chromatic feature detector that signals visual context changes",
        "authors": "Larissa Höfling, Philipp Berens, Thomas Euler, Klaudia P. Szatko, Christian Behrens, Yongrong Qiu, David Klindt, Zachary Frazier Jessen, Gregory William Schwartz, Timm Schubert, Matthias Bethge, Katrin Franke, Alexander Ecker",
        "date": "Thursday, 9 March 2023",
        "location": "I-035",
        "abstract": "The retina transforms patterns of light into visual feature representations supporting behaviour. In the mouse, these representations are distributed across more than 30 types of retinal ganglion cells (RGCs), whose spatial and temporal tuning properties have been studied extensively. However, a systematic approach for linking the often nonlinear retinal transformations of natural visual inputs to specific ethological purposes is lacking. Here, we trained a convolutional neural network model (CNN) on large-scale functional two-photon recordings of RGC responses to natural mouse movies, and then used this model to search in-silico for stimuli that maximally excite distinct types of RGCs. This procedure predicted centre colour-opponency in transient Suppressed-by-Contrast RGCs (tSbC), a cell type whose function is being debated. We confirmed experimentally that these cells indeed responded very selectively to Green-OFF, UV-ON contrasts, which we found to be characteristic of transitions in the visual scene from ground to sky, as might be elicited by head- or eye-movements across the horizon. Indeed, we found that tSbC reliably detected these transitions. Based on these findings, we suggest a role for tSbC RGCs in providing contextual information (i.e., sky or ground) necessary for the selection of appropriate behavioural responses to other stimuli, such as looming objects. Beyond these specific results, our approach sketches a fast-forward path towards a better understanding of the feature channels encoded by the retina by creating a continuous link from natural stimulus to feature selectivity to ethological relevance.",
        "url": "https://www.world-wide.org/cosyne-23/model-guided-discovery-retinal-chromatic-d03a598d"
    },
    "Information correlations reduce the accuracy of pioneering normative decision makers": {
        "title": "Information correlations reduce the accuracy of pioneering normative decision makers",
        "authors": "Zachary Kilpatrick, Megan Stickler, Bhargav Karamched, William Ott, Krešimir Josić",
        "date": "Thursday, 9 March 2023",
        "location": "I-036",
        "abstract": "Decision making is essential to cognition, often requiring the integration of sequences of observations over time. Choice rules trigger decisions once sufficient evidence is acquired for a choice. Models often describe single accumulation-to-bound processes, but organisms often decide in groups or accumulate multiple information streams. A better understanding of naturalistic decision making thus requires probing the neural computations and behaviors of evidence accumulation processes involving the integration of multiple information streams. Normative models of information-sharing in multi-agent systems reveal recursive processes that prevent overcounting knowledge received from neighbors, building on log likelihood ratio (LLR) update models arising from sequential analysis [3,4]. Here, we consider a complementary question: How do correlations in the information collected by individual members of a group shape the relative accuracy of their decisions? Our main finding is that individuals that make earlier decisions than other group members are less accurate when the evidence the members gather is correlated, even when all agents have identical decision criteria requiring the same total evidence. As a result, an agent's level of accuracy is ordered inversely by their decision time order (i.e., the nth decider is the nth least accurate). Joint dependence of each decider's accuracy on their own LLR and decision order arises due to correlations between the agents' evidence streams. This effect does not occur when agents make independent measurements of their environment, and is thus not due simply to early deciders having accumulated less evidence. The common evidence increment shared by all agents results in early decisions that are more likely to be based on faulty evidence. This finding reveals the importance of considering how information correlations common in nature impact decision accuracy. Our results give a normative account of reduced accuracy of hasty deciders even when all group members have identical decision criteria.",
        "url": "https://www.world-wide.org/cosyne-23/information-correlations-reduce-accuracy-8347f976"
    },
    "Maturing neurons and dual structural plasticity enable flexibility and stability of olfactory memory": {
        "title": "Maturing neurons and dual structural plasticity enable flexibility and stability of olfactory memory",
        "authors": "Bennet Sakelaris & Hermann Riecke",
        "date": "Thursday, 9 March 2023",
        "location": "I-037",
        "abstract": "The capacities to learn and to store memories are two of the most important functions of the brain, but these abilities are inherently at odds with each other. On one hand, a neuronal network must be flexible enough to quickly store new information, but on the other it must be stable enough to prevent old memories from being constantly overwritten. Metaplasticity in which the timescale of synaptic modifications made by an individual neuron changes could resolve this flexibility-stability tradeoff. We propose that this strategy may be implemented in the olfactory bulb (OB). A striking, characteristic feature of olfaction is that throughout adulthood new, initially highly plastic adult-born interneurons (abGCs) are added to the OB, while others are removed through well-controlled apoptosis. The computational benefit of this expensive form of plasticity is still poorly understood. Here, we use a biophysically inspired computational model of the rodent OB to show explicitly how neurogenesis, apoptosis, and established properties of abGCs, particularly their transiently enhanced excitability and structural plasticity, combine to enable the flexible formation of stable odor memories. The model demonstrates that all three components, neurogenesis, apoptosis and transient properties of abGCs, are necessary to achieve this goal. Moreover, in line with experiments, we show how memories are encoded by young abGCs, how these memories are briefly vulnerable to interference from a new stimulus, how re-learning a lost memory is faster than learning a new memory, and how the OB can learn several odors at the same time. The model predicts that odor exposure leads to the formation of birthdate-dependent, odor-specific subnetworks in the OB.",
        "url": "https://www.world-wide.org/cosyne-23/maturing-neurons-dual-structural-plasticity-b32ea314"
    },
    "Recording Multi-Neuronal Activity in Unrestrained Animals with 3D Random-Access 2-Photon Microscopy": {
        "title": "Recording Multi-Neuronal Activity in Unrestrained Animals with 3D Random-Access 2-Photon Microscopy",
        "authors": "Akihiro Yamaguchi, Rui Wu, Paul McNulty, Doycho Karagyozov, Mirna Mihovilovic Skanata, Marc Gershow",
        "date": "Thursday, 9 March 2023",
        "location": "I-038",
        "abstract": "To study the neural correlates of naturalistic behaviors, we seek to record neural activity in unrestrained animals. Due to behavior-induced motion artifacts, such recordings are particularly challenging for two-photon fluorescence microscopy. Studying multi-neuronal activity in the central nervous system in moving larval Drosophila, whose brain is translated, rotated, and deformed in 3D, has been a great challenge. To overcome the challenges, we developed a method capable of calcium recording from multiple neurons in a brain of a freely moving Drosophila larva with extremely low latency (100 μsec) while simultaneously recording the animal’s posture and locomotion. We combined a resonant ultrasonic lens as a fast axial scanner and two acousto-optic deflectors as a lateral scanner that allows inertia-free relocation of the excitation beam at constant time. This method allows continuous recording from fluorescently labeled neurons while correcting the scanning position to sub-micron precision in real-time. With this method, we recorded calcium activities from a diverse set of neurons: pre-motor neurons, visual interneurons, and descending neurons in the VNC and brain of unrestrained crawling Drosophila larvae. We showed a correlation between the natural activation of mooncrawler descending neuron (MDN) and the larva’s backward crawling behavior, confirming a previous study using optogenetic activation and CaMPARI (Calcium-Modulated PhotoActivatable Ratiometric Integrator) to establish causation and correlation (Carreira et al. 2018). Our multi-neuronal recording of pre-motor neurons also revealed sequential activation during forward crawling; a result essential to understand how timed activation for locomotion is generated in a moving animal. Our technique can also be extended beyond moving larvae to stabilize recordings in a variety of moving substrates and expand the repertoire of neural activity that can be studied in cellular-resolution.",
        "url": "https://www.world-wide.org/cosyne-23/recording-multi-neuronal-activity-unrestrained-28e4fb05"
    },
    "Novelty drives human exploration even when it is suboptimal": {
        "title": "Novelty drives human exploration even when it is suboptimal",
        "authors": "Alireza Modirshanechi, He A. Xu, Wei-Hsiang Lin, Michael H. Herzog, Wulfram Gerstner",
        "date": "Thursday, 9 March 2023",
        "location": "I-039",
        "abstract": "How do humans explore environments with sparse rewards? Recent studies in computational neuroscience have proposed an answer by integrating intrinsic reward signals into traditional reinforcement learning models of human behavior. However, different choices of intrinsic reward result in fundamentally different exploration strategies. Here, we focus on three representative intrinsic reward signals (novelty, surprise, and information-gain) and ask which one explains human exploration best. We design an experimental paradigm for multi-step decision-making where the three representative intrinsic rewards make different predictions: Participants search for a goal state in a complex environment with 59 states and 3 actions per state that, importantly, includes a large sub-region (50 states) with highly stochastic transitions. This sub-region mimics the main features of a noisy TV as in the infamous 'noisy TV problem'. We show via simulations that exploration driven by different reward signals exhibits different levels of attraction to this stochastic sub-region. Simulated agents driven by information-gain eventually lose their interest in stochasticity when they realize that there is no information to gain, agents driven by novelty exhibit a persistent attraction to stochasticity and the ones driven by surprise a detrimentally increasing attraction. Performing the same experiment on human participants shows that human participants who are optimistic about the availability of goal states of higher value than those already known exhibit a persistent attraction to stochasticity. We show that this behavior is both qualitatively and quantitatively consistent with that of novelty-driven agents and not with those driven by surprise or information-gain – despite the evident efficiency of information-gain in dealing with stochasticity. Our work provides evidence for novelty-driven reinforcement learning algorithms as models of human exploration and suggests that humans use suboptimal but computationally cheap policies for exploration in complex environments.",
        "url": "https://www.world-wide.org/cosyne-23/novelty-drives-human-exploration-even-dc437a95"
    },
    "A rate code for position error in a ring attractor model of path integration": {
        "title": "A rate code for position error in a ring attractor model of path integration",
        "authors": "Gorkem Secer, Ravikrishnan P. Jayakumar, Manu Madhav, James J. Knierim, Noah Cowan",
        "date": "Thursday, 9 March 2023",
        "location": "I-040",
        "abstract": "Path integration is an internal computation of position by integrating velocities over time. In the absence of external landmarks, path integration accumulates error, causing the internal representation of position to drift relative to the external world [1,2]. In addition to the well-established role of landmarks in correcting this error, recent experiments identified a new role of landmarks: recalibrating the path-integration gain, a factor mapping the animal’s movement through space to an updating of position in its internal representation [3]. Here, we set out to understand the mechanisms by which landmarks recalibrate the path-integration gain while correcting position errors. To garner theoretical insight, we derived an expression for the path-integration gain as a function of synaptic weights of a ring attractor model and analyzed the stability of dynamics when these weights were tuned via Hebbian plasticity. This analysis revealed a necessary condition that the firing rates of some neurons must change monotonously with the error in positional representation. As a preliminary test of this prediction, we analyzed an existing dataset of place cells that were recorded during the recalibration of path-integration gain by rotating landmarks as a function of the rat’s movement [3]. In 248/400 cells from five rats, firing rates were correlated with the positional error, estimated by drift in firing locations relative to landmarks in each experimental session. Across sessions, the slope of this relationship was negatively correlated with the total error accumulated in a session. Finally, we revisited the model and modified its extrinsic connectivity to reproduce both roles of landmarks—gain recalibration and error correction—via a rate code of the error, exhibiting the same negative correlation between slope and total error. Our results suggest a mechanism recruiting a rate code of the position error as a neural substrate of the interaction between landmarks and path integration.",
        "url": "https://www.world-wide.org/cosyne-23/rate-code-position-error-ring-attractor-5fc5b66e"
    },
    "Dissecting multi-population interactions across cortical areas and layers": {
        "title": "Dissecting multi-population interactions across cortical areas and layers",
        "authors": "Evren Gokcen, Anna Jasper, Alison Xu, Byron Yu, Christian Machens, Adam Kohn",
        "date": "Thursday, 9 March 2023",
        "location": "I-041",
        "abstract": "The functional organization of cerebral cortex comprises several motifs, including feedforward, feedback, and horizontal interactions across areas and layers. Modern recording techniques now allow us to record from many neurons across these populations. However, especially as we consider multiple (more than two) populations, new conceptual and statistical frameworks are needed to reveal the population-level nature of these organizational motifs and how they contribute to brain function. Here, we advance the use of the dimensionality reduction approach group factor analysis (GFA), alongside large-scale electrophysiological recordings, to dissect multi-dimensional interactions across visual cortical areas and layers. GFA automatically determines not only the number of latent dimensions across a collection of neuronal populations, but also which subset of populations each latent involves. We first validated GFA's ability to recover multi-population interactions in synthetic data and in spiking neural activity since, to our knowledge, this work is the first such application of GFA. GFA not only performed well on realistic-scale simulated neural activity, but also reproduced key results from a prior study of areas V1 and V2: that the two areas interact via a communication subspace. We then used GFA to study interactions across select laminar compartments of macaque visual areas V1, V2, and V3d, recorded simultaneously with multiple Neuropixels probes. We found that (1) Laminar compartments of V1 share activity patterns with each other that are distinct from those shared with V2, consistent with the presence of distinct inter-areal and inter-laminar signaling pathways; and (2) V1-V2 and V1-V3d share unique activity patterns, consistent with the presence of distinct signaling pathways from V1 to these two downstream areas. The presence of unique inter-areal activity patterns depended on retinotopic alignment. This work establishes a framework for dissecting the multi-population interactions that underlie nearly all sensory, cognitive, and motor functions.",
        "url": "https://www.world-wide.org/cosyne-23/dissecting-multi-population-interactions-681e30e0"
    },
    "The least-control principle for local learning at equilibrium": {
        "title": "The least-control principle for local learning at equilibrium",
        "authors": "Alexander Meulemans, Nicolas Zucchet, Seijin Kobayashi, Johannes von Oswald, João Sacramento",
        "date": "Thursday, 9 March 2023",
        "location": "I-042",
        "abstract": "A widely-accepted tenet of neuroscience is that learning relies on synaptic plasticity. Because plasticity is thought to be governed by local, activity-dependent rules, it is a longstanding mystery how synapses change in concert so that behavioral output improves. This problem is aggravated by the recurrent and multilayered architecture of the cortex, which makes it hard to determine the effects of a given synaptic modification. Here we present a novel principle for learning rooted in optimal control theory, which yields local plasticity rules for any neural dynamics which reaches an equilibrium, thus encompassing both multilayered and recurrent neural networks. Our principle casts learning as a least-control problem, where we first introduce an optimal controller to lead the dynamics towards a solution state, and then define learning as reducing the amount of control needed to reach such a state. We derive a gradient-following, activity-dependent plasticity rule for control minimization, and establish conditions under which it optimizes behavioral performance. Furthermore, we provide conditions for a network state to be optimally-controlled, and we design neural control circuits of varying complexity that meet our optimality conditions either approximately or exactly. Critically, unlike previous gradient-based cortical learning theories we do not require the control feedback to be vanishingly small, an assumption that is problematic in noisy circuits and at odds with experimental reports showing that feedback connections can influence cortical processing. We conduct a series of benchmarking experiments and find that our principle leads to strong performance matching that of backpropagation-of-error, currently the gold standard for deep learning. Finally, we establish a duality between control minimization and a probabilistic technique known as free-energy minimization. This connection allows interpreting an influential family of cortical models which fall under the umbrella of predictive processing as instantiations of our least-control principle.",
        "url": "https://www.world-wide.org/cosyne-23/least-control-principle-local-learning-f587aeb2"
    },
    "Distinct mechanisms for evidence accumulation and choice memory explain diverse neuronal dynamics": {
        "title": "Distinct mechanisms for evidence accumulation and choice memory explain diverse neuronal dynamics",
        "authors": "Thomas Luo, Carlos Brody, Timothy Kim, Brian DePasquale*",
        "date": "Thursday, 9 March 2023",
        "location": "I-043",
        "abstract": "A computation that is thought to underlie many decisions is the gradual accumulation of noisy evidence over time until a bound is reached, which triggers the commitment to a choice. The integration-to-bound framework captures the behavior in many decisions, as well as the pooled responses across neurons in many brain regions, suggesting that choices are formed based on the accumulated evidence encoded in neuronal firing rates. However, the correspondence between accumulated evidence and neuronal dynamics is only on aggregate. The choice-related dynamics of individual neurons are heterogeneous and appear inconsistent with representing a single bounded integration process. It is unclear how the diversity of choice dynamics might be reconciled with an integration-to-bound framework. Here we show that heterogeneous choice dynamics can be explained by state-dependent representations of accumulated evidence, before and after the commitment to a choice–which is implied by distinct mechanisms for integrating evidence and for maintaining the memory of the choice. We recorded from hundreds of neurons simultaneously using Neuropixels probes from five frontal brain regions in rats performing a task that requires the gradual accumulation of auditory evidence. We developed a statistical approach that models spike trains with state-dependent Poisson generalized linear models whose encoding of accumulated evidence depends on whether a bound has been reached. State-dependent encoding of accumulated evidence well predicts the diverse choice dynamics of individual neurons, better than models with stationary encoding. Moreover, we found that rat frontal regions, in particular the medial prefrontal cortex, represent accumulated evidence more strongly before than after the commitment to a choice, indicating that frontal circuits are differentially engaged during evidence accumulation and during choice memory. These findings suggest that the diversity of choice dynamics results from a single multi-staged decision process.",
        "url": "https://www.world-wide.org/cosyne-23/distinct-mechanisms-evidence-accumulation-28bac565"
    },
    "Learning predictive neural representations by straightening natural videos": {
        "title": "Learning predictive neural representations by straightening natural videos",
        "authors": "Xueyan Niu, Cristina Savin, Eero Simoncelli",
        "date": "Thursday, 9 March 2023",
        "location": "I-044",
        "abstract": "Recent experiments demonstrate that the brain transforms visual inputs into representations that follow straighter temporal trajectories than their initial photoreceptor encoding, facilitating prediction by linear extrapolation (Hénaff et al 2019; 2021). Can the brain use this principle to learn visual representations? Here, we develop an objective that quantifies straightening, augment it with a regularizer to prevent collapse to trivial solutions, and use it to train deep feedforward neural networks on video sequences. Decoding of the learned representation with a separately trained readout network reveals that the representation preserves visual information in video frames, and can make good next-frame predictions. Separate SVM decoders reveal that the representation has isolated visual and physical identities in videos, including object category, position, shape, and types of motion. When the straightening objective is applied at different levels of the hierarchy and corresponding temporal scales, the same learning procedure yields hierarchical temporal representations that can predict future inputs at multiple time scales. The local, fast representations learned by our model encode and predict fine details of local motion, while the global and slow representations encode visual aspects that persist for longer durations. Overall, our model provides a potential mechanism by which the visual system can partition and represent features at different spatial and temporal resolutions along the visual hierarchy.",
        "url": "https://www.world-wide.org/cosyne-23/learning-predictive-neural-representations-bfb2a3d0"
    },
    "Infinite storage in quasi-memory: a cryptographic principle underlining caching behavior in animals": {
        "title": "Infinite storage in quasi-memory: a cryptographic principle underlining caching behavior in animals",
        "authors": "Oren Forkosh",
        "date": "Thursday, 9 March 2023",
        "location": "I-045",
        "abstract": "The brain's extraordinary abilities are often associated with its ability to learn and adapt. But memory and plasticity, in general, have their limitations, especially when faced with the tasks such as retrieving hundreds of thousands of items, such as in the case of scatter-hoarding animals. Here, we present a brain mechanism that works by utilizing cryptographic principles in lieu of plasticity. Rather than memorizing the locations of their caches, as previously suggested, we propose that cache-hoarding animals use a single cryptographic-like mechanism for both caching and retrieval. The model we developed functions similarly to hippocampal spatial cells, which respond to an animal’s positional attention. We know that the region that activates each spatial cell remains consistent across subsequent visits to the same area but not between areas. This remapping, combined with the uniqueness of cognitive maps, produces a persistent crypto-hash function for both food caching and retrieval. We show that our model is consistent with previous observations, such as animals’ ability to prioritize food items that are perishable or by their nutritional value. While focusing here on scatter-hoarding, the mechanism we present might be utilized by the brain in other ways providing essentially infinite retention capacity for structured data.",
        "url": "https://www.world-wide.org/cosyne-23/infinite-storage-quasi-memory-cryptographic-8e8ab6a9"
    },
    "Hippocampal place codes reflect the compressibility of sensory experience": {
        "title": "Hippocampal place codes reflect the compressibility of sensory experience",
        "authors": "James Priestley, Lorenzo Posani, Marcus Benna, Attila Losonczy, Stefano Fusi",
        "date": "Thursday, 9 March 2023",
        "location": "I-046",
        "abstract": "Neurons in the rodent hippocampus appear to encode the position of the animal in physical space during movement. Individual ``place cells'' fire in restricted sub-regions of an environment, a feature often taken as evidence that the hippocampus encodes a map of space that subserves navigation. But these same neurons exhibit complex responses to many other variables that defy explanation by position alone, and the hippocampus is known to be more broadly critical for memory formation. Here we elaborate and test a theory of hippocampal coding which produces place cells as a general consequence of efficient memory coding. We constructed neural networks that actively exploit the correlations between memories in order to learn compressed representations of experience. Place cells readily emerged in the trained model, due to the correlations in sensory input between experiences at nearby locations. Notably these properties were highly sensitive to the compressibility of the sensory environment, with place field size and population coding level in dynamic opposition to optimally encode the correlations between experiences. The effects of learning were also strongly biphasic: nearby locations are represented more similarly following training, while locations with intermediate similarity become increasingly decorrelated, both distance-dependent effects that scaled with the compressibility of the input features. Using virtual reality and 2-photon functional calcium imaging in head-fixed mice, we recorded the simultaneous activity of thousands of hippocampal neurons during virtual exploration to test these predictions. Varying the compressibility of sensory information in the environment produced systematic changes in place cell properties that reflected the changing input statistics, consistent with the theory. We similarly identified representational plasticity during learning, which produced a distance-dependent exchange between compression and pattern separation. These results motivate a more domain-general interpretation of hippocampal computation, one that is naturally compatible with earlier theories on the circuit's importance for episodic memory formation.",
        "url": "https://www.world-wide.org/cosyne-23/hippocampal-place-codes-reflect-compressibility-58254aca"
    },
    "Two types of locus coeruleus norepinephrine neurons drive reinforcement learning": {
        "title": "Two types of locus coeruleus norepinephrine neurons drive reinforcement learning",
        "authors": "Zhixiao Su & Jeremiah Cohen",
        "date": "Thursday, 9 March 2023",
        "location": "I-047",
        "abstract": "To make decisions in a dynamic world, animals adjust their behavior in response to environmental feedback. To understand how this flexibility is achieved, we seek to understand how the nervous system learns from choice outcomes. Theories proposed that norepinephrine (NE) neurons in the locus coeruleus (LC) modulate learning from reinforcement. We tested this hypothesis by measuring activity from identified mouse LC-NE neurons during a behavioral task requiring ongoing learning from reward prediction errors (RPE). Mice were trained to make choices to lick leftward or rightward for reward with changing probabilities. Because reward probabilities were unknown to the animals, they used reward history to make future choices. We made electrophysiological recordings from identified LC-NE neurons by “tagging” channelrhodopsin-2-expressing LC-NE neurons in Dbh-Cre mice. We found two types of biophysically distinct LC-NE neurons featuring different action potential shapes, dorsal-ventral distribution, and excitability. These two types of neurons also responded differently to decision outcomes. Type I neurons were excited by positive RPE while type II neurons were excited by lack of reward. To test the hypothesis that LC-NE neurons modulate learning from decision outcomes, we silenced their activity using the inhibitory opsin GtACR2. The inactivation caused increased probability of switching choices on the trials following no reward, which can be captured by modeling inhibition as a negative shift of RPE. Our data indicate biophysically and anatomically distinct modules in LC and reveal a function for LC-NE neurons in modulating learning from experience.",
        "url": "https://www.world-wide.org/cosyne-23/types-locus-coeruleus-norepinephrine-219e5266"
    },
    "Dynamical mechanisms of flexible pattern generation in spinal neural populations": {
        "title": "Dynamical mechanisms of flexible pattern generation in spinal neural populations",
        "authors": "Lahiru Wimalasena, Chethan Pandarinath, Nicholas Au Yong",
        "date": "Thursday, 9 March 2023",
        "location": "I-048",
        "abstract": "Recent investigations into the coordinated activity of neuronal populations in motor circuits have revealed low-dimensional dynamical features hypothesized to support the generation of patterned motor output. However, such studies have typically relied on vast simplifications - trial-averaging, heavy smoothing - and are often far removed from muscle activity, the true output of the motor system. Thus, it is unclear whether the uncovered dynamical features are primarily useful for intuition-building, or reflect computational mechanisms that operate at the temporal precision of motor control. Here we investigated the neural population closest to motor output - spinal interneurons - and tested the degree and temporal precision with which low-dimensional spinal dynamical features reflect the generation of muscle activity. We studied lumbar intermediate zone interneuronal population activity and bilateral, multi-muscle intramuscular EMG recorded in two decerebrated T9 spinalized cats performing air-stepping. We uncovered dynamical features using AutoLFADS [1], an unsupervised deep learning method to infer latent dynamics from neural and muscle population recordings. Spinal population dynamics were highly predictive of multi-muscle activity on individual gait cycles on a millisecond timescale. However, the reverse was not true: the spinal activity was higher dimensional than muscle activity and contained features not directly related to muscle output. We hypothesized that spinal populations may use these higher dimensions to separate internal timing mechanisms from motor output. Specifically, we investigated extensor burst duration during the gait cycle, which varied step to step based on locomotion speed. We uncovered oscillatory dynamics within the spinal population activity, and found that the duration spent within the oscillator was highly predictive of single-gait cycle variations in extensor burst duration, precise to within tens of milliseconds. These results reveal low-dimensional dynamical features in spinal interneuron activity that may be integral in enabling flexible pattern generation and for precisely controlling timing variations in motor output.",
        "url": "https://www.world-wide.org/cosyne-23/dynamical-mechanisms-flexible-pattern-472cd8bb"
    },
    "Neuroformer: A Transformer Framework for Multimodal Neural Data Analysis": {
        "title": "Neuroformer: A Transformer Framework for Multimodal Neural Data Analysis",
        "authors": "Antonis Antoniades, Yiyi Yu, Spencer LaVere Smith",
        "date": "Thursday, 9 March 2023",
        "location": "I-049",
        "abstract": "Systems neuroscience experiments generate multimodal data streams, including neuronal activity, stimuli, movement, and behavior events. In analysis, it can be beneficial to avoid hypothesis-driven models and instead take a data-driven approach. For this, we need a general purpose framework to handle the diverse data, and identify relationships across space, time, and modalities in a computationally efficient manner. In this work, we introduce such a framework. Our model, called the Neuroformer, can simulate neuronal populations, and jointly process an arbitrary number of additional modalities (stimuli, movement, etc.). To validate its performance, we analyzed a simulated neuronal circuit and showed that the inferred network was accurate in structure and directionality of connections. To demonstrate its utility, we used the Neuroformer to analyze large scale, multimodal data from a 2-photon calcium imaging experiment and inferred relationships between visual stimuli and neuronal activity. The Neuroformer is a flexible data-driven tool for modeling and analysis in systems neuroscience. We provide an open-source codebase for replicating and extending this work.",
        "url": "https://www.world-wide.org/cosyne-23/neuroformer-transformer-framework-multimodal-9f89afa4"
    },
    "Revealing and reshaping attractor dynamics in large networks of cortical neurons": {
        "title": "Revealing and reshaping attractor dynamics in large networks of cortical neurons",
        "authors": "Chen Beer & Omri Barak",
        "date": "Thursday, 9 March 2023",
        "location": "I-050",
        "abstract": "Attractors play a key role in a wide range of processes including learning, memory, decision making and navigation. Due to recent innovations in recording methods, there is increasing evidence for the existence of attractor dynamics in the brain. Yet, our understanding of how these attractors emerge or disappear in a biological system is lacking. In vitro cultured cortical neurons have been used extensively as a realistic experimental tool to understand the underlying mechanisms in neuronal assemblies. One of the main characteristics of the activity of such networks are the spontaneous synchronized bursts, in which a large fraction of the neurons fire almost simultaneously within several hundreds of milliseconds. We follow the spontaneous activity of such networks and identify these bursting events. We create a vocabulary of spatiotemporal patterns and show that they function as discrete attractors in the network dynamics. We then repeatedly trigger specific attractors via electrical stimulation. We find that the targeted attractors are eliminated from the spontaneous vocabulary, while they are robustly evoked by the electrical stimulation. This seemingly paradoxical finding can be explained by a Hebbian-like strengthening of specific pathways into the attractors, at the expense of weakening non-evoked pathways into the same attractors. We verify this hypothesis, provide a mechanistic explanation for the underlying changes supporting this effect. To our knowledge, this work provides the first direct evidence for discrete multi-stability in a biological neural network. In addition, the plasticity principles we describe improve our understanding on how attractors in a biological system evolve.",
        "url": "https://www.world-wide.org/cosyne-23/revealing-reshaping-attractor-dynamics-3ce94d8b"
    },
    "Representational drift from a population view of memory consolidation": {
        "title": "Representational drift from a population view of memory consolidation",
        "authors": "Denis Alevi, Felix Lundt, Henning Sprekeler",
        "date": "Thursday, 9 March 2023",
        "location": "I-051",
        "abstract": "In the classical views of systems memory consolidation, memories are transferred from the hippocampus to cortex and between cortical areas for long-term storage [1]. But with the advance of neuronal recording techniques, it has become apparent that most variables of the outside world are learned and represented in multiple brain regions simultaneously. In some brain regions, these representations change dynamically while the behavior of the animal remains stable [2]. Here, we propose a population perspective on memory consolidation that reproduces many features of this “representational drift”. We develop an analytically tractable model that is inspired by the structure of insect mushroom bodies and an earlier model of working memory [3], in which memories are not transferred between brain regions but rather redistributed across or within regions. Memories remain stable during consolidation by confining synaptic plasticity to the null space of a memory readout. The resulting changes in population activity are in agreement with the systematic changes observed in vivo. Neuronal tuning curves show a diversity of changes, including stability, gradual drifts in the preferred stimulus, abrupt remapping, and a loss or gain of tuning. Decoders trained on a single session show limited generalization over time, while multi-day decoders reveal invariant subspaces in population activity. Finally, the model shows that a varying degree of plasticity across neurons can lead to a largely linear increase in the squared deviation of population activity from a reference day, although the changes in tuning are deterministic and not driven by diffusion. In summary, we present a model of systems memory consolidation which combines the classical view of memory consolidation as a memory transfer mechanism with the modern view of highly distributed memory representations. [1] Roxin & Fusi 2013 [2] Driscoll et al. 2017 [3] Goldman 2009",
        "url": "https://www.world-wide.org/cosyne-23/representational-drift-from-population-e6333b77"
    },
    "Task interference underlies the task switch cost in perceptual decision-making": {
        "title": "Task interference underlies the task switch cost in perceptual decision-making",
        "authors": "Cheng Xue, Sol Markman, Marlene Cohen, Ruoyi Chen, Lily Kramer",
        "date": "Thursday, 9 March 2023",
        "location": "I-052",
        "abstract": "To survive in the uncertain world, humans and animals must pick the right task to perform in each situation and flexibly switch between tasks when they infer that the environment has changed. Yet such flexibility comes at a cost. Task performance decreases when the relevance of the task is uncertain. Here we present multiple lines of evidence from monkey electrophysiology, human psychophysics, and artificial neural networks demonstrating a neuronal mechanism that inflicts a cost of flexibility. In a behavioral paradigm designed to measure and manipulate subjects’ belief about the relevance of either of two perceptual tasks, we found that human and monkey subjects make less accurate perceptual decisions under task uncertainty. To generate hypotheses about a neuronal basis for the task switching cost, we compared two recurrent neural networks (RNNs), trained to produce the correct choice or to reproduce the choices of monkey subjects. The ‘correct-choice’ RNN learned to flexibly switch tasks without incurring a task switch cost, while the ‘monkey-choice’ RNN displayed the expected cost of task switching. The different activity of the recurrent layers of the two models suggested a mechanism that produces the task switch cost. The relevant subspaces for the two tasks remained separate for the ‘correct-choice’ model, but collapsed together for the ‘monkey-choice’ model, leading to interference between tasks especially when task is uncertain. We confirmed predictions of the model in further behavioral and physiological experiments, demonstrating that behavior and neural activity shows signs of task interference under uncertain task conditions. These results provide a neuronal mechanism for flexible decision-making in neurotypical subjects, as well as its dysfunction in common neurological disorders. They support the general, tantalizing hypothesis that limits in cognitive capacity arise from interference between the neural representations of different stimuli, tasks, or memories.",
        "url": "https://www.world-wide.org/cosyne-23/task-interference-underlies-task-switch-390758dd"
    },
    "Dynamics-neutral growth of stochastic stabilized supralinear networks": {
        "title": "Dynamics-neutral growth of stochastic stabilized supralinear networks",
        "authors": "Puria Radmard, Wayne WM Soo, Máté Lengyel",
        "date": "Thursday, 9 March 2023",
        "location": "I-053",
        "abstract": "Recurrent neural networks have been trained to perform a wide variety of experimental tasks in order to understand the underlying dynamics employed by the brain to solve those tasks. However, some of the most commonly trained network architectures have not been biologically realistic, typically limiting their analogy with the brain to the level of abstract dynamical motifs. For example, they had noiseless dynamics or no separation of excitatory and inhibitory cells. The stochastic stabilized supralinear network (SSN) incorporates these features, as well as a rectified-superlinear activation function representative of cortical neurons (instead of common choices such as tanh or ReLU). Yet, the same features that make the SSN biologically realistic also make it challenging to train, as it is prone to runaway excitation through the reverberation of expansive non-linear activations. Here, we present a method to train SSNs that avoids dynamical instabilities during training. We start by randomly initializing a smaller network, and then alternate between optimizing the network and growing it by adding more neurons to it. Specifically, we add neurons in a (theoretically-motivated) dynamics-neutral way that preserves network stability. We demonstrate the effectiveness of this approach by training SSNs on: (1) the standard MNIST classification task; (2) amortized sampling-based probabilistic inference under a Gaussian scale mixture-model with a rich set of V1-like receptive fields that can sufficiently reconstruct CIFAR-10 natural images (an unachievable target for previous methods); and (3) a working memory-guided saccade task with eight different stimuli. In all examples, we find that it is nearly impossible to randomly initialize stable networks at their full sizes with similar activity levels as our trained networks, thereby highlighting the necessity of our approach. These results pave the way to training SSNs for other tasks and to understanding the circuit mechanisms of neural computations at a single cell resolution.",
        "url": "https://www.world-wide.org/cosyne-23/dynamics-neutral-growth-stochastic-dcdd2153"
    },
    "Normative modeling of auditory memory for natural sounds": {
        "title": "Normative modeling of auditory memory for natural sounds",
        "authors": "Bryan Medina & Josh McDermott",
        "date": "Thursday, 9 March 2023",
        "location": "I-054",
        "abstract": "Auditory memory is critical for nearly every daily task we perform involving sounds. However, memory is also imperfect, and the reasons for memory errors remain poorly understood. We probed auditory memory using a sound recognition experiment: sounds were presented serially, with some repeating, and participants judged whether each stimulus had occurred previously. Recognition was well above chance but decreased with the number of intervening stimuli between the first and second presentations of repeated sounds (the interstimulus interval; ISI). Some sounds were mistakenly judged to be novel when they had in fact repeated, and others were mistakenly judged to have repeated when they did not. To understand these effects in normative terms, we replicated them with auditory texture stimuli, whose internal representation is believed to be well explained by statistics of standard auditory filter cascades modeled after the auditory system. We then developed an ideal observer model using this statistical representation. The model encodes experiences as memory traces whose noise grows with time, and then decides whether a subsequent stimulus is more likely to have come from the distribution of stimuli implied by these memory traces or from the prior distribution over all textures. We estimated the prior from statistics measured from a large set of natural textures. The model qualitatively mirrored human performance trends and replicated human judgements on an item-by-item basis, predicting both false memories (stimuli incorrectly judged to have repeated) and misses (repeated stimuli that were incorrectly judged to be novel). The results suggest that memory errors can be predicted to a large extent from the statistics of natural stimuli and provide a framework for understanding the successes and failures of memory for natural stimuli.",
        "url": "https://www.world-wide.org/cosyne-23/normative-modeling-auditory-memory-natural-96ff08a2"
    },
    "Representational drift leads to sparse activity solutions that are robust to noise and learning": {
        "title": "Representational drift leads to sparse activity solutions that are robust to noise and learning",
        "authors": "Maanasa Natrajan & James Fitzgerald",
        "date": "Thursday, 9 March 2023",
        "location": "I-055",
        "abstract": "Memories are thought to be stored in synapses between neurons, but these connections in the hippocampus show complete turnover within a fortnight[1]. Dynamics have also been seen at the representational level, as the cells responding to a particular position change across days even when the animal isn’t overtly learning or forgetting[2]. While some researchers consider representational dynamics to be an inevitable consequence of ongoing learning, others suggest that drift may be beneficial. For instance, theoretical work by Kappel et al.,[3] suggests that if initial learning leads the system to a locally optimal performance solution then drift would enable the brain to not get stuck there and instead find globally optimal solution. This requires drop in performance when the system is exploring low-performance regions between the optima. If there is incomplete exploration of solution space and representations explored by drift are equivalent in performance, then it isn’t known if the solutions explored by drift are in any way better than initially learned solution. Here we modeled drift as uniform sampling of weight solution space and showed that drift leads to sparse activity solutions, which are robust to noise and suitable for continual learning. A threshold-linear activation function produces more weights corresponding to a sparse activity solution than to a dense activity solution[4]. Thus, in simulations drift quickly led to sparse representations with few active neurons for each position in the environment. These sparse activity solutions found by drift expanded the solution space of weights, so they were more robust to noise and could easily learn new information when compared to equally well performing dense activity solutions. Our results demonstrate that sparsity can be a natural consequence of drift, and drift can be used in biological and artificial agents to help learn new memories while retaining old ones.",
        "url": "https://www.world-wide.org/cosyne-23/representational-drift-leads-sparse-aa4563b3"
    },
    "Drift dynamics interact with a confirmation bias in visual working memory": {
        "title": "Drift dynamics interact with a confirmation bias in visual working memory",
        "authors": "Hyunwoo Gu, Joonwon Lee, Hyang-Jung Lee, Heeseung Lee, Minjin Choe, Sungje Kim, Dong-Gyu Yoo, Jaeseob Lim, Jun Hwan Ryu, Sukbin Lim, Sang-Hun Lee",
        "date": "Thursday, 9 March 2023",
        "location": "I-056",
        "abstract": "Committing to a decision tends to bias future behaviors, a phenomenon dubbed “confirmation bias”. Daily life requires us to make decisions on remembered past experiences; still, the understanding of confirmation bias in working memory remains sparse. Here, we show that the stimulus-specific drift dynamics should be incorporated into any viable account of confirmation bias in working memory. We crafted a paradigm where participants view a grating briefly, make a binary decision on it, and estimate its orientation, with varying delays between those epochs. We developed a dynamical model wherein decision and drifting memoranda mutually affect each other in determining eventual mnemonic estimates. This model accounted for the key dynamic features of behavior reports and BOLD responses in the visual cortex, including (i) the decision-time-dependent stimulus-specific and decision-consistent biases and (ii) the relation between pre- and post-decision biases. Furthermore, these dynamic features of confirmation bias naturally emerged from recurrent networks trained to the above experimental paradigm, suggesting an interplay between the winner-take-all decision-making mechanism and the drift-driven working memory dynamics. The work presented here highlights drift dynamics as a novel link mediating an interplay between decision-making and working memory.",
        "url": "https://www.world-wide.org/cosyne-23/drift-dynamics-interact-with-confirmation-c73b58b1"
    },
    "Experience, Not Time, Determines Representational Drift in the Hippocampus": {
        "title": "Experience, Not Time, Determines Representational Drift in the Hippocampus",
        "authors": "Dorgham Khatib, Aviv Ratzon, Mariell Sellevoll, Genela Morris, Omri Barak, Dori Derdikman",
        "date": "Thursday, 9 March 2023",
        "location": "I-057",
        "abstract": "Memories of past events can be recalled long after the event, indicating stability. But new experiences are also integrated into existing memories, indicating plasticity. In the hippocampus, spatial representations are known to remain stable, but have also been shown to drift over long periods of time. We hypothesized that experience, more than the passage of time, is the driving force behind memory plasticity. We compared the stability of place cells in the hippocampus of mice traversing two similar, familiar tracks for different durations. We found that the more time spent in an environment, the greater the representational drift, regardless of the total elapsed time. Our results suggest that spatial representation is a dynamic process, related to the ongoing experiences within a specific context, and is related to the accumulation of new memories rather than to passive forgetting.",
        "url": "https://www.world-wide.org/cosyne-23/experience-time-determines-representational-92db3ea6"
    },
    "Brain wide distribution of prior belief constrains neural models of probabilistic inference": {
        "title": "Brain wide distribution of prior belief constrains neural models of probabilistic inference",
        "authors": "Felix Hubert, Charles Findling, Berk Gerçek, Brandon Benson, Matthew Whiteway, Christopher Krasniak, Anthony Zador, The International Brain Lab The International Brain Lab, Peter Dayan, Alexandre Pouget",
        "date": "Thursday, 9 March 2023",
        "location": "I-058",
        "abstract": "Despite numerous studies, the neural basis of Bayesian inference during decision-making remains unclear. To address the question of where and how prior knowledge about a task is combined with sensory observations, we examine brain-wide neural recordings collected by the International Brain Lab (IBL). In the IBL task, mice indicate the location of a visual grating stimulus (left or right). Crucially, the prior probability that the stimulus appears on the left flips between 20% and 80% in blocks of variable length. The mice leveraged the block structure to improve their decision accuracy, notably performing better than chance (using the prior) when the grating contrast is set to zero. Using IBL’s complete dataset of Neuropixels electrophysiological recordings and wide-field cortical calcium imaging, we decoded the Bayes optimal prior estimate from most of the brain regions in the Allen atlas (N ~ 160 regions). We establish in both electrophysiology and wide-field imaging that the prior is widely represented throughout the mouse brain in a pre-stimulus epoch. In agreement with previous work, we find it present in particular in high level cortical areas such as ACC or OFC. However, it is also seen throughout substantial portions of the rest of the brain, including early sensory cortical and subcortical regions, such as primary visual cortex and lateral geniculate nucleus, as well as motor-related regions such as M1 and the cerebellum. This widespread representation of the prior argues for a neural model of inference involving loops between areas, as opposed to a model in which prior information is incorporated only in decision making areas, thus shedding light on a critical aspect of Bayesian inference in neural circuits. This study offers the first brain-wide perspective on prior encoding, underscoring the importance of using large scale recordings on a single standardized task.",
        "url": "https://www.world-wide.org/cosyne-23/brain-wide-distribution-prior-belief-e4ccace7"
    },
    "Reward prediction error neurons implement an efficient code for value": {
        "title": "Reward prediction error neurons implement an efficient code for value",
        "authors": "Wei Ji Ma, Dongjae Kim, Heiko Schuett",
        "date": "Thursday, 9 March 2023",
        "location": "I-059",
        "abstract": "Dopaminergic reward prediction error neurons in the midbrain are the most prominent reward representation in the brain. To understand why these neurons represent rewards the way they do when stochastic rewards are encountered, we derive the optimal population of neurons to encode rewards drawn from a given distribution. To do so, we extend an existing framework for efficient coding to decouple the density of neurons from their slopes. We compare the optimally efficient population to measurements of reward prediction error neurons. We find three aspects of the optimized population confirmed: First, RPEN thresholds cover the range of the distribution with an emphasis on higher thresholds. Second, RPENs with higher thresholds have higher gains. And third, the asymmetry of RPENs' responses around their thresholds depends on their threshold switching from concave to convex with growing threshold. The shift of the thresholds compared to the reward distribution and the increase of gain with threshold were not explained so far. The change in curvature around threshold was recently used as evidence for distributional reinforcement learning, but is explained by efficient coding as well. Thus, reward prediction error neurons may broadcast an efficient reward signal.",
        "url": "https://www.world-wide.org/cosyne-23/reward-prediction-error-neurons-implement-a2e6d65a"
    },
    "State Space Models for Classifying Grid Cell Spatial Sequences": {
        "title": "State Space Models for Classifying Grid Cell Spatial Sequences",
        "authors": "Lavonna Mark, Andrew Warrington, Emily Jones, Isabel Low, Lisa Giocomo, Scott Linderman",
        "date": "Thursday, 9 March 2023",
        "location": "I-060",
        "abstract": "To navigate accurately, the brain requires an internal map of the external spatial world. The entorhinal cortex (EC) is thought to play an important role in the generation of this internal map, as it contains grid cells that fire periodically in space. However, grid cells are also active at rest, replaying grid cell spike sequences that reflect spatial sequences observed during mobility [1,2,3]. Replay events are thought to play an important role in memory and planning. Little is known, however, on the spatial structure of entorhinal replay, limiting our understanding of how grid cells participate in these higher-order cognitive functions. A challenge of studying replay is that the animal’s imagined position is not experimentally accessible, and thus relies on statistical methods for inferring the imagined position sequence. The discovery of spatial sequences is therefore sensitive to assumptions about their expected structure–previous methods in EC have assumed linear trajectories or constant velocities [1,2,3]. Recent probabilistic state space models (SSMs) provide a more flexible way of parameterizing and comparing spatial sequences [4,5]. A major challenge lies in applying these models to grid cells. Compared to place cells, where these models have been applied, grid cells have multiple spatial fields, rather than single spatial fields, and are often multimodal (encoding position, speed etc.), not unimodal [6]. Here, we investigate the ability of SSMs to correctly infer the underlying spatial dynamics of grid cell activity. We find that we can classify spatial sequences using grid cell activity over a range of realistic tuning parameters. We quantify the sensitivity of inferences to noisy and multimodal coding, and the ability of models to decode real-life trajectories. Our study provides groundwork for testing hypotheses on entorhinal replay, allowing for better understanding the role of grid cells in higher-order cognition. [1] Ólafsdóttir, H., et al. Nat Neuroscience (2016). [2] Ólafsdóttir, H., et al. Neuron (2017). [3] O’Neill, J., et al. Science (2017). [4] Krause, E. and Drugowitsch, J. Neuron (2022). [5] Denovellis, E., et al. Elife (2021). [6] Hardcastle, K., et al. Neuron (2017).",
        "url": "https://www.world-wide.org/cosyne-23/state-space-models-classifying-grid-cell-bce91186"
    },
    "Thoughtful faces: Using facial features to infer naturalistic cognitive processing across species": {
        "title": "Thoughtful faces: Using facial features to infer naturalistic cognitive processing across species",
        "authors": "Alejandro Tlaie Boria, Katharine Shapcott, Muad Abd el Hay, Berkutay Mert, Pierre-Antoine Ferracci, Robert Taylor, Iuliia Glukhova, Martha Nari Havenith, Marieke Schölvinck",
        "date": "Thursday, 9 March 2023",
        "location": "I-061",
        "abstract": "Understanding how internally driven cognitive processes (COPs) give rise to behavior in different species is one of the key challenges in systems neuroscience. Traditionally, neuroscience has aimed to isolate individual COPs by simplifying sensory stimuli and behavioral readouts. Yet in natural behavior, several COPs can co-occur, often with overlapping neural representations. The dynamics of such superimposed COPs are yet to be understood, as well as the extent to which they generalize across species. To tackle this question, we developed a naturalistic Virtual Reality setup in which two species (mice and macaques) engage in the same visual foraging task. To infer underlying COPs in a data-driven manner, we employed a recently developed approach that extends Hidden Markov Models (HMMs) by allowing their probabilities to vary according to Generalized Linear Models (GLMs). We exploited the richness of a wide range of facial features extracted from video recordings to train a GLM-HMM. By doing so, we identified, on a single-trial basis, a set of internal states that predicted whether animals could proficiently perform the task. In both species, facial features just before the animal’s decision were most predictive of trial outcome, and could be distilled into a low number of internal states. While internal states mapped onto specific trial outcomes in both species, these states did not rely on the same raw facial features in monkeys and mice. Transitions between internal states were frequent, precluding convergence onto one dominant state. However, in mice slower state transitions improved model performance, while this association was reversed for macaques. This suggests that in mice, behaviorally relevant internal states evolve on a slower time scale than in monkeys. With this framework, we were able to flexibly and agnostically track the dynamics of several ongoing COPs, identifying general principles of naturalistic cognitive processing across species.",
        "url": "https://www.world-wide.org/cosyne-23/thoughtful-faces-using-facial-features-d41cce8b"
    },
    "Complex computation from developmental priors": {
        "title": "Complex computation from developmental priors",
        "authors": "Dániel Barabási, Taliesin Beynon, Nicolas Perez-Nievas, Ádám Katona",
        "date": "Thursday, 9 March 2023",
        "location": "I-062",
        "abstract": "Artificial Intelligence (AI) research has provided key insights into the mechanics of learning complex tasks. However, AI models have long overlooked innateness: how strong pressures for survival lead to the encoding of complex behaviors in the nascent wiring of a brain. Although innate neural solutions have inspired AI approaches from layered architectures to ConvNets, the underlying neuroevolutionary search for novel heuristics has not been successfully systematized. In this manuscript, we examine how neurodevelopmental principles can inform the discovery of useful inductive biases. We begin by considering the weight matrix of a neural network to be emergent from well-studied rules of neuronal compatibility. Rather than updating the network's weights directly, we improve task fitness by updating the neurons' wiring rules, thereby mirroring evolutionary selection on brain development. We find that the resulting framework can not only achieve high performance on standard machine learning (ML) tasks, but does so with a fraction of the full network's parameters. Further, we show that developmentally-inspired techniques have higher and more stable performance on metalearning tasks than the standard models they encode. In summary, by introducing realistic developmental considerations into ML frameworks, we not only model the emergence of innate behaviors, but also define a discovery process for structures that promote complex computations.",
        "url": "https://www.world-wide.org/cosyne-23/complex-computation-from-developmental-bdb88e1a"
    },
    "Brain-wide Hierarchical Encoding of Working Memory": {
        "title": "Brain-wide Hierarchical Encoding of Working Memory",
        "authors": "Huangao Zhu, Chengyu Li, Peiyuan Li",
        "date": "Thursday, 9 March 2023",
        "location": "I-063",
        "abstract": "The brain is efficient to categorize continuous sensory inputs into discrete perceptions to aid efficient action. The brain-wide neural mechanism underlying this sensory-to-categorical transformation remains elusive. Here we recorded brain-wide neuronal activity by Neuropixels probes in mice performing a two-alternative forced choice (2AFC) odor categorization task, using different combinations of odor mixtures. Mixtures of two pure odors were delivered at different ratios, and the left or right lick decision after a delay period should be based on the category defined by the dominant odor. Mice showed lower performance in the trials with smaller difference in odor concentration. We recorded more than 30,000 neurons from over 100 regions in 14 mice (Figure 1). Based on the dynamics of the regional proportion of neurons with information-coding ability, we could group the 29 recorded regions (with more than 100 recorded neurons) into three region clusters. Cluster 1 was composed of sensory areas for olfactory, cluster 2 included many association areas, whereas cluster 3 included motor-related regions (Figure 2B). From region clusters 1 to 3, we observed progressive increase from more sensory （sample ratio） to more categorical encoding. We also observed temporal progression for this sensory to categorical transformation, especially during the later delay period and lick-action periods. In the error trials, neurons showed reduced but correct encoding of sensory information during the delay period, whereas reversed encoding of categorical information during the action period (Figure 3). Spike correlogram revealed strong directional functional coupling at ten-millisecond time scale in the neuronal pairs, especially those showing congruent odor selectivity. The cross-region functionally coupling showed differential dynamics in three region clusters, in a manner correlated with information-maintenance ability (Figure 4, 5). Our results revealed the brain-wide dynamics in sensory-to-category transformation in the brain and further underscored the importance of information-specific functional coupling in cognition.",
        "url": "https://www.world-wide.org/cosyne-23/brain-wide-hierarchical-encoding-working-8d4a1c4e"
    },
    "Mechanisms underlying flexible, context-dependent timing in medial entorhinal cortex": {
        "title": "Mechanisms underlying flexible, context-dependent timing in medial entorhinal cortex",
        "authors": "Erin Bigus, Hyun-Woo Lee, James Heys",
        "date": "Thursday, 9 March 2023",
        "location": "I-064",
        "abstract": "The nervous system must perceive and learn durations to guide adaptive behavior. Prior work to investigate the neural substrates of interval timing has focused largely on relatively simple timing tasks whereby subjects learn to discriminate and reproduce the duration of events occurring at a single fixed interval. Although episodic memory requires accurate temporal coding and is mediated by structures in the medial temporal lobe (MTL), including the medial entorhinal cortex (MEC), a well-established role for MTL circuits in interval timing behavior is conspicuously lacking. MEC seems well-suited to perform timing via continuous attractor network dynamics. However, the role of MEC in timing remains unclear, perhaps because existing timing tasks do not require the type of flexible learning that MTL circuits have likely evolved to mediate. We therefore aim to establish the precise contribution of MEC to interval timing by testing the hypothesis that MEC is necessary for flexible interval timing behavior, which is driven by regular patterns of sequential neural activity. To test this hypothesis, we first developed a novel temporal delayed nonmatch to sample (tDNMS) task that requires mice to flexibly learn and compare the relative durations of pairs of stimuli. Chemogenetic inhibition of MEC completely abolished mice from learning to respond appropriately in each trial type, or temporal context, showing a clear necessity of MEC in flexible timing behavior. As hypothesized, cellular-resolution Ca2+ imaging revealed that populations of MEC neurons fire in regular, time-locked sequences across trials. Interestingly, many time cells display context-dependent timing activity that emerges with learning and supports task performance. Together, findings demonstrate that MEC is necessary to learn flexible, context-dependent timing, which is mediated by sequential activity of MEC time cells. We are now using these results to test circuit-level models, including that MEC time cell activity is driven by a continuous attractor network.",
        "url": "https://www.world-wide.org/cosyne-23/mechanisms-underlying-flexible-context-dependent-9b029fd4"
    },
    "A predictive plasticity rule entails the anticipation of multiple spike sequences": {
        "title": "A predictive plasticity rule entails the anticipation of multiple spike sequences",
        "authors": "Matteo Saponati & Martin Vinck",
        "date": "Thursday, 9 March 2023",
        "location": "I-065",
        "abstract": "Intelligent behavior depends on the brain’s ability to anticipate future events. Experimental evidence shows reliable temporal sequences in the neural activity, suggesting a functional role of sequences for the association and subsequent anticipation of events in time. However, how neurons can predict temporal patterns and fire ahead of sensory inputs remains largely unknown. We propose a plasticity rule based on predictive processing, where neurons learn a low-rank model of the synaptic input dynamics in their membrane potential. Neurons thereby amplify those synapses that maximally predict other synaptic inputs based on their temporal relations. We show that neurons predict sequences over long timescales and shift their spikes toward the first inputs in a sequence. Moreover, we show how the predictive plasticity rule entails the prediction of multiple sequences in a recurrent neural network. Neurons in the network selectively anticipate sequences in the input spike trains via a recurrent inhibition mechanism. In sum, our results indicate prediction as a guiding principle for the anticipation of multiple spike sequences in both single neurons and recurrent neural networks. Our model shows that the existence of reliable spike sequences can be explained by predictive mechanisms at the single-neuron level.",
        "url": "https://www.world-wide.org/cosyne-23/predictive-plasticity-rule-entails-anticipation-58111943"
    },
    "A causal inference model of spike train interactions in fast response regimes": {
        "title": "A causal inference model of spike train interactions in fast response regimes",
        "authors": "Zachary Saccomano & Asohan Amarasingham",
        "date": "Thursday, 9 March 2023",
        "location": "I-066",
        "abstract": "The idea of estimating synaptic connectivity and strength from parallel spike trains has been entertained since the late 1960s, but the last few years have seen a resurgence in proposed methods. A majority of model-free techniques estimate synaptic coupling via a “separation of timescales” (SOT) principle applied to the cross-correlogram (CCG). That is, a joint distribution is implicitly specified on paired spike trains where it is common to include a fast timescale component (modeling synaptic coupling) and a coarse timescale component (modeling network effects). Such models provide insights into the problem and recent experimental perturbations (e.g., optogenetics) in vivo support SOT. However, simple thought experiments suggest that the CCG is insufficient to isolate causation from correlation when synaptic and network terms have non-trivial dependence structure. By employing concepts from causal inference and nonstationary time series analysis, here we develop a model of spike train coupling that is couched in terms of local (i.e., in time) probabilistic computations, yielding causal inferences in the midst of complex, time-varying dependencies between coupling and network states. The approach combines a nonparametric model of point processes with a causal potential outcomes framework. Under the model, we prove theorems for unbiased point estimation and exact confidence intervals for excitatory and inhibitory coupling. Building on insights from this more rigorous analysis, we proceed to develop a heuristic approach to estimate fractional common cause inputs. Inferences are demonstrated in point process simulations with nonstationarity and dependence structure that maximally conflates correlation and causation.",
        "url": "https://www.world-wide.org/cosyne-23/causal-inference-model-spike-train-interactions-ccb14876"
    },
    "The role of the entorhinal cortex in reward-guided spatial navigation": {
        "title": "The role of the entorhinal cortex in reward-guided spatial navigation",
        "authors": "John Issa, Brad Radvansky, Feng Xuan, Daniel Dombeck",
        "date": "Thursday, 9 March 2023",
        "location": "I-067",
        "abstract": "The concept of a cognitive map posits that the brain maintains an internal representation of space. This map is represented in cells of the hippocampus and entorhinal cortex, which carry information about the animal’s location in an environment. These representations are adaptable to changes in the environment; for example, the number of hippocampal place cells that encode a particular location will increase if a reward is delivered at that location. We aimed to investigate what information the two regions of the entorhinal cortex – medial and lateral – may contribute during reward-guided spatial navigation. To this end, we compared activity across populations of neurons from three regions (CA1 of the hippocampus, MEC: medial entorhinal cortex, and LEC: lateral entorhinal cortex) during a spatial navigation task. As expected, we found an enrichment in the number of CA1 place cells at the rewarded location of the track. In stark contrast, however, we found little to no preference of MEC cells for the rewarded location but a dramatic increase in the number of LEC cells active near the reward location. Moreover, we found that the reward representation in the LEC is stable across locations and environments. These results establish a dichotomy between the entorhinal cortices in spatial navigation. Further, they provide a possible framework for the types of information and behavior they may be involved in. While the MEC has a well-established role in encoding spatial locations, our results indicate that the LEC provides a more dynamic, contextual representation that interfaces information from goals and rewards with the spatial navigation system in a flexible manner.",
        "url": "https://www.world-wide.org/cosyne-23/role-entorhinal-cortex-reward-guided-12533f12"
    },
    "Robustness of PFC networks under inter and intra-hemispheric patterned microstimulation perturbations": {
        "title": "Robustness of PFC networks under inter and intra-hemispheric patterned microstimulation perturbations",
        "authors": "Joana Soldado Magraner, Yuki Minai, Matthew Smith, Byron Yu",
        "date": "Thursday, 9 March 2023",
        "location": "I-068",
        "abstract": "A central problem in neuroscience is to understand how the dynamics of neural populations support computation. These dynamics are created both by the local neural circuitry as well as the inputs to that circuit from other brain regions. Hence, characterizing how inputs drive different population responses is key to understanding how brain circuits are modulated to flexibly produce different behaviors. To this end, we developed a patterned microstimulation (uStim) protocol that allowed us to finely manipulate the activity of a neural population in a given area by directly stimulating the same population, or alternatively, by stimulating the activity of a second population in a different area. To achieve this, we implanted two macaques with either one or two 96-channel Utah arrays and electrically stimulated combinations of electrodes. We used our protocol to study how population dynamics in the prefrontal cortex (PFC), a high-order cognitive area that displays persistent memory encoding, is influenced by both inter and intra-hemispheric inputs. For this, we assessed the impact that different uStim patterns applied to the right-hemisphere PFC (PFCR) had on the contralateral PFC (PFCL) during a memory task. We also measured the effect of direct stimulation in the PFCL. We found that both inter and intra-hemispheric stimulation patterns pushed the PFCL activity in different directions and triggered transient responses lasting hundreds of milliseconds with diverse relaxation dynamics. The relaxation brought back the responses to an attractor state which encoded the different memory conditions. Thus, PFC activity displayed robustness to a wide range of inter and intra-hemispheric input perturbations. Patterned uStim might be an important causal tool to probe the dynamics of neural populations to understand brain computation.",
        "url": "https://www.world-wide.org/cosyne-23/robustness-networks-under-inter-intra-hemispheric-c7fa9e8d"
    },
    "Cortical-bulbar feedback supports behavioral flexibility during rule reversal": {
        "title": "Cortical-bulbar feedback supports behavioral flexibility during rule reversal",
        "authors": "Diego Eduardo Hernández Trejo, Andrei Ciuparu, Pedro Garcia da Silva, Cristina Velázquez, Raul Mureşan, Dinu Albeanu",
        "date": "Thursday, 9 March 2023",
        "location": "I-069",
        "abstract": "Animals flexibly adjust their behavior to adapt to environmental changes. Mice excel at recognizing odorants in complex sensory conditions; however, little we know about: (1)how sudden changes in stimulus contingency modify odorant representations and (2)how changes in odorant representations causally relate to behavioral adjustments. The olfactory bulb(OB) relays odor-triggered information to higher olfactory areas, including the piriform cortex(PCx). The PCx receives input from association areas(e.g., orbitofrontal cortex) and sends dense feedback that selectively modulates one of the OB output channels(mitral cells). Therefore, PCx is in an ideal position to integrate sensorial input and behavioral contingencies and modulate the OB output in tune with the animal behavioral goals. To study the role of cortical-bulbar feedback in supporting flexible behaviors, we trained mice in a Go/No-Go task with rule reversal guided by odorant and sound-tone cues. Within the same session, reward contingencies were reversed across blocks of contiguous trials, rewarding either the odorant or tone cues depending on the block rule and animal decision(report lick). Using multiphoton microscopy, we monitored cortical-bulbar feedback bouton responses(GCaMP5/7b) of anterior PCx(aPCx) neurons from mice engaged in the task. Cortical-bulbar feedback boutons exhibited dense and diverse responses aligned with different trial epochs. Cortical-bulbar feedback activity changes mirror the task block structure and display a high correlation for the same behavioral contingency. The response changes observed after each rule reversal slightly lagged in updating accordingly to the behavioral switch. Multilayer perceptrons trained to decode stimulus identity and behavioral contingency rapidly increased their performance during cue delivery and before the animal’s decision. Optogenetic suppression experiments(Jaws) of cortical-bulbar feedback suggest that mice rely on cortical feedback to adapt their behavior after each rule switch. Our results indicate that cortical-bulbar feedback multiplexes information about stimulus identity and behavioral contingency and is rapidly re-formatted according to changes in contingency rules.",
        "url": "https://www.world-wide.org/cosyne-23/cortical-bulbar-feedback-supports-behavioral-58799bf6"
    },
    "Switching autoregressive low-rank tensor (SALT) models for neural dynamics": {
        "title": "Switching autoregressive low-rank tensor (SALT) models for neural dynamics",
        "authors": "Hyun Dong Lee, Joshua I. Glaser, Andrew Warrington, Vladislav Susoy, Aravinthan D.T. Samuel, Liam Paninski, Scott Linderman",
        "date": "Thursday, 9 March 2023",
        "location": "I-070",
        "abstract": "Switching linear dynamical system (SLDS) models are widely used for modeling neural and behavioral time series data [Glaser et al., 2020, Linderman et al., 2019, Nair et al., 2022, Zoltowski et al., 2022]. These models characterize high-dimensional time series through a combination of discrete and continuous latent states. The continuous states offer a low-dimensional representation of the data, while the discrete state defines how the continuous states evolve over time. Together, they provide quantitative and interpretable summaries of multidimensional time series. Unfortunately, fitting these models requires a complex and computationally expensive optimization. We propose an alternative approach called switching autoregressive low-rank tensor (SALT) models. SALT models decompose observed data into a similar representation, defined through discrete states and continuous dynamics, with simpler optimization. Indeed, we can show that SALT models closely approximate SLDS models. The key technical insight is that when you integrate over the continuous states of an SLDS you obtain an autoregressive hidden Markov model (ARHMM) with low-rank dynamics tensors. Rather than fitting the SLDS, we fit the low-rank ARHMM directly. We demonstrate SALT models via an application to whole-brain recordings of male C. elegans during mating [Susoy et al., 2021]. Mating is the worms’ most complex behavior: it requires several distinct sub-behaviors to be enacted in a coherent sequence, where each sub-behavior involves continuous control of movement. We show that SALT extracts discrete states that reflect expert annotations of behavioral state. We also inspect the learned low-rank tensors, which provide an alternative route for investigating the continuous dynamics within each behavioral state. These analyses highlight the value of SALT models as an alternative to switching linear dynamical systems, offering a similar decomposition while using simpler and computationally cheaper inference procedures.",
        "url": "https://www.world-wide.org/cosyne-23/switching-autoregressive-low-rank-tensor-559ecd22"
    },
    "Abstract deliberation by visuomotor neurons in prefrontal cortex": {
        "title": "Abstract deliberation by visuomotor neurons in prefrontal cortex",
        "authors": "Julie Charlton & Robbe Goris",
        "date": "Thursday, 9 March 2023",
        "location": "I-071",
        "abstract": "During visually guided behavior, the prefrontal cortex plays a pivotal role in mapping sensory inputs onto appropriate motor plans. When the sensory input is ambiguous, this involves deliberation. It is not known whether the deliberation is implemented as a competition between possible stimulus interpretations or between possible motor plans. Here we study neural population activity in prefrontal cortex of macaque monkeys trained to flexibly report categorical judgments of ambiguous visual stimuli. The subjects judged whether a visual stimulus presented near the central visual field was oriented clockwise or counterclockwise from vertical. They communicated their judgment with a saccade to one of two peripheral visual targets. The meaning of the response options was signaled by the targets’ orientation (clockwise vs counterclockwise), and was unrelated to their spatial position (one target was placed in the neurons’ estimated motor response field, the other on the opposite side of the fixation mark). Because the spatial configuration of the choice targets varied randomly from trial-to-trial, our task design allowed for the dissociation of neural predictors of the upcoming categorical choice and the upcoming motor response used to report this choice. We find that the population activity initially represents the level of commitment to a categorical choice before transitioning into the stereotypical representation of the motor plan. We show that stimulus strength and prior expectations both bear on the formation of the categorical choice, but not on the formation of the action plan. These results reveal that prefrontal circuits involved in action selection are also used for the deliberation of abstract propositions, divorced from a specific motor plan, thus providing a crucial mechanism for abstract reasoning.",
        "url": "https://www.world-wide.org/cosyne-23/abstract-deliberation-visuomotor-neurons-2abc2954"
    },
    "Violations of transitivity disrupt relational inference in humans and reinforcement learning models": {
        "title": "Violations of transitivity disrupt relational inference in humans and reinforcement learning models",
        "authors": "Thomas Graham & Bernhard Spitzer",
        "date": "Thursday, 9 March 2023",
        "location": "I-072",
        "abstract": "Humans are capable of generalising local pairwise relations to transitively infer global relationships between items, states or events. Recent research has shown that asymmetric learning, where beliefs about only the winners (or losers) of local comparisons are updated, is well-suited to allow human and artificial agents to infer relational structures from sparse feedback. However, less is known about how already-acquired knowledge and subsequent learning policies are impacted by experiences that violate the inferred monotonic ordering of items, such as when agents learn that A is greater than B and B is greater than C, but then are later told that C is greater than A. Here, we show that introducing a single such ‘uroboros’ relation into a monotonically ordered set of items disrupted humans’ inferred relational knowledge about the remaining items. Fitting simple reinforcement learning (RL) models to human participant data replicated the asymmetries previously observed in inferential learning, but also captured the uroboros-induced ‘unlearning’ of transitive relations. Despite this disruption to the learned value structure, direct (non-transitive) relational learning of neighbouring items was preserved. This effect was captured by augmenting asymmetric RL with an episodic memory-like process that learns directly experienced pair relations. In explorative analyses, we find no conclusive evidence for a learning policy change in response to the uroboros relation, e.g. in terms of learning rate changes. Our results indicate that asymmetric RL of item values, complemented by direct pair-level memory, not only accounts for efficient inference of latent relational structure, but also for rapid unlearning of inferred relations in response to surprising feedback.",
        "url": "https://www.world-wide.org/cosyne-23/violations-transitivity-disrupt-relational-49b4e0d4"
    },
    "Divisive normalization as a mechanism for hierarchical causal inference in motion perception": {
        "title": "Divisive normalization as a mechanism for hierarchical causal inference in motion perception",
        "authors": "Boris Penaloza, Sabyasachi Shivkumar, Gabor Lengyel, Linghao Xu, Gregory DeAngelis, Ralf Haefner",
        "date": "Thursday, 9 March 2023",
        "location": "I-073",
        "abstract": "Causal inference (CI) has been proposed as a universal computational motif in the brain [Shams & Beierholm 2020]. However, its neural implementation is unclear. Likewise, Divisive Normalization (DN) has been proposed as a canonical circuit motif [Heeger 2011], but there are competing theories about the computations that DN implements (gain control, attention). In this work, we unified both by showing how an extended DN model can account for neural predictions made by a CI model [Shivkumar et al. 2022] in the context of hierarchical motion perception. Specifically, we generated CI predictions for neural responses to a center-surround stimulus. CI makes interesting predictions for neural responses encoding two latent variables in the model: retinal and relative velocities. These predictions (supported by preliminary data) resemble the responses of two previously described classes of neurons in area MT: those with antagonistic or integrative surround [Born & Bradley 2005]. We investigated whether DN could be a potential mechanism that implements CI computations by fitting it to the CI predictions. Classic DN postulates that each neuron’s response is divisively modulated by pooling the activity of neighboring neurons. We analytically showed that a normalization pool that only incorporates the activities of neurons responding to center and surround stimuli alone cannot explain the complex CI responses. Instead, we found that a normalization pool that additionally includes multiplicative interactions between the center and surround activities can explain our CI predictions. We used tuning properties of MT neurons [DeAngelis & Uka 2003] to generate both: (a) biologically-realistic CI predictions and (b) a realistic normalization pool. We showed that the same DN model can explain CI neural predictions across different center-surround speeds. Our results suggest that an extended DN architecture, with interaction terms in the normalization pool, may serve as a mechanism to implement CI at the neural circuit level.",
        "url": "https://www.world-wide.org/cosyne-23/divisive-normalization-mechanism-hierarchical-2384e90b"
    },
    "Connectome-constrained cortical circuits optimized for visual function and working memory tasks": {
        "title": "Connectome-constrained cortical circuits optimized for visual function and working memory tasks",
        "authors": "Wayne WM Soo & Xiao-Jing Wang",
        "date": "Thursday, 9 March 2023",
        "location": "I-074",
        "abstract": "Recurrent neural networks (RNNs) trained on working memory (WM) tasks have been the subject of extensive study. These networks typically contain one or more aspects of biological-implausibility, such as the adoption of saturating output functions (tanh), violation of Dale's Law or introduction of artificial elements (LSTM). They also have over-simplistic input pathways such as binary cues, which are insufficient to represent the rich dynamics found in sensory brain areas. In particular, the role of inter-areal communication between sensory and association areas for WM has been critically underrepresented in these models. Here, we address these problems by constructing RNNs comprising of 15 sensory or association brain areas. We differentiate them by constraining network weights to match experimental inter-areal connectomic data while also constraining single-area recurrent weights to follow a biologically-motivated gradient of synaptic excitation. Stimulus is presented to the network through information-maximized Gabor receptive fields of V1 excitatory cells. We identified an approximate dorsal and ventral stream from these areas and trained them to determine the location and shape of stimuli respectively. Concurrently, each network is also trained on one of 11 WM tasks with a common set of readout weights shared across all networks. We find that sensory areas in trained networks exhibit higher-dimensional dynamics compared to association areas and have similar activities regardless of task. Based on behaviors that emerged from our networks during training, we propose generalizations to two theories that originated from analyzing handcrafted models: (1) counterstream inhibitory bias, where inter-areal excitatory-inhibitory feedback connections are stronger than excitatory-excitatory connections; and (2) bifurcation in space, where sensory and association areas produce functionally-distinct dynamics at all stages of WM tasks. Our approach represents a new direction for task-optimized RNNs, where regular functions are incorporated into multi-area networks under a single architecture in order to meaningfully analyze within-class inter-areal dynamics.",
        "url": "https://www.world-wide.org/cosyne-23/connectome-constrained-cortical-circuits-8182fc2c"
    },
    "Heterogeneity in normalization and attentional modulation in a circuit model": {
        "title": "Heterogeneity in normalization and attentional modulation in a circuit model",
        "authors": "Deying Song & Chengcheng Huang",
        "date": "Thursday, 9 March 2023",
        "location": "I-075",
        "abstract": "The size of a neuron’s receptive field increases along the visual hierarchy. Neurons in higher-order visual areas integrate information through a canonical mechanism called normalization, where neurons respond sublinearly to multiple stimuli in the receptive field (Carandini & Heeger, 2012). Neurons in visual cortex exhibit highly heterogeneous degrees of normalization, which can be measured by normalization index, defined as the sum of a neuron’s firing rate to each one of two stimuli divided by its firing rate when both stimuli are presented. Interestingly, it has been demonstrated that the heterogeneity in normalization is also strongly associated with the heterogeneity in attentional modulation in firing rates (Ni et al., 2012). However, the circuit mechanism underlying such heterogeneity is still unclear. In this work, we adopt a two-layer spiking neuron circuit model, modeling V1 and V4 areas, to capture the effects of normalization and attentional modulation on both trial-average and trial-variable responses of a neural population. Our circuit model naturally produces a wide distribution of normalization indexes across neurons. The normalization index of each neuron is highly correlated with the magnitude of the inhibitory current it receives. In addition, we find that the pairwise correlation between two neurons is related to their normalization indexes. Specifically, neurons with similar normalization indexes have higher correlation than those with different indexes, consistent with a recent experimental finding (Ruff et al., 2016). Further, our modeled attention improves the communication from the attended V1 location to V4 neurons. In particular, V4 neurons with larger normalization indexes are better predicted by V1 neurons from the attended location. Together, our model captures several experimental findings on normalization and attentional modulation in visual cortex, and we identify inhibition to be the main determinant of the heterogeneity in these modulations.",
        "url": "https://www.world-wide.org/cosyne-23/heterogeneity-normalization-attentional-270d3143"
    },
    "Brainstem serotonin neurons selectively gate retinal information flow to thalamus": {
        "title": "Brainstem serotonin neurons selectively gate retinal information flow to thalamus",
        "authors": "Mark Andermann, Andrew Lutas, Liang Liang, Jesseba Fernando, Jasmine Reggiani, Melanie Barbini, Qiufen Jiang, Fei Deng, Jinxia Wan, Yulong Li, Chinfei Chen",
        "date": "Thursday, 9 March 2023",
        "location": "I-076",
        "abstract": "Retinal ganglion cell (RGC) types relay parallel streams of visual feature information. We hypothesized that neuromodulators might efficiently control which visual information streams reach the cortex, by selectively gating transmission from specific RGC axons in the thalamus. Using fiber photometry recordings, we found that optogenetic stimulation of serotonergic axons in primary visual thalamus of awake mice suppressed ongoing and visually evoked calcium activity and glutamate release from RGC boutons. Two-photon calcium imaging revealed that serotonin axon stimulation suppressed RGC boutons that responded strongly to global changes in luminance more than those responding only to local visual stimuli, while the converse was true for suppression induced by increases in arousal. Converging evidence suggests that differential expression of the 5-HT1B receptor on RGC presynaptic terminals, but not differential density of nearby serotonin axons, may contribute to the selective serotonergic gating of specific visual information streams before they can activate thalamocortical neurons. We hope this work inspires new computational models of the impact of dynamic, early-stage filtering of visual information channels.",
        "url": "https://www.world-wide.org/cosyne-23/brainstem-serotonin-neurons-selectively-d03fdd02"
    },
    "Neural network dynamics underlying context-dependent perceptual decision making": {
        "title": "Neural network dynamics underlying context-dependent perceptual decision making",
        "authors": "Yuxiu Shao, Srdjan Ostojic, Manuel Molano-Mazon, Ainhoa Hermoso-Mendizabal, Lejla Bektic, Jaime de la Rocha",
        "date": "Thursday, 9 March 2023",
        "location": "I-077",
        "abstract": "In perceptual judgments, sensory information is typically combined with contextual information which can determine the prior statistics. In a previously developed 2AFC auditory categorization task in which the stimulus sequence included two different statistical contexts, rats can capitalize on the context information but only in after-correct trials; in after-error trials, they consistently deviate from optimal behavior by waiving the accumulated context evidence (Hermoso-Mendizabal et al. 2020). Recently, it has been shown that Recurrent Neural Networks (RNNs) pre-trained in a naturalistic task presenting more than two possible choices reproduce the animal’s suboptimal behavior in the 2AFC, which has been termed after-error reset strategy (Molano-Mazón et al. 2021). To what extent the neuronal mechanisms underlying the representation of sequential trial statistics and the reset strategy are shared between these pre-trained RNNs and animals, remains an open question. To address this question, we performed a population analysis of pre-trained RNNs and found that they formed an accurate representation of the statistical context independent of the previous outcome. After error trials, the reset was implemented nonetheless by dynamically decoupling the network’s decisions from the predictions based on the context evidence. We conducted the same analysis using neural recordings from the dorsomedial striatum (DMS) and frontal orienting field (FOF) of rats performing the task. The statistical context was encoded in the DMS, but at output-level, this encoding did not affect the rats’ choices in after-error trials. However, unlike in the RNNs where the previous choices were always well encoded, there was a loss of information in the rats’ neural activity concerning the previous incorrect choices. The FOF in contrast showed only a weak encoding of context. Our comparative population analysis in RNNs and rats' striatal activity provides an integrated insight into the neural computational mechanisms that support flexible behavior in context-dependent perceptual tasks.",
        "url": "https://www.world-wide.org/cosyne-23/neural-network-dynamics-underlying-context-dependent-65bf87b9"
    },
    "Ensemble remodeling supports memory-updating": {
        "title": "Ensemble remodeling supports memory-updating",
        "authors": "Austin Baggetta, Denise Cai, William Mau, Denisse Morales-Rodriguez, Zhe (Phil) Dong, Brian Sweis, Zachary Pennington, Taylor Francisco, Mark Baxter, Tristan Shuman",
        "date": "Thursday, 9 March 2023",
        "location": "I-078",
        "abstract": "Memory-updating is critical in dynamic environments because updating memories with new information promotes versatility. However, little is known about how memories are updated with new information. To study how neuronal ensembles might support memory-updating, we used a hippocampus-dependent spatial reversal task to measure hippocampal ensemble dynamics when mice switched navigational goals. Using Miniscope calcium imaging, we identified neuronal ensembles (co-active neurons) in dorsal CA1 that were spatially tuned and stable across training sessions. When reward locations were moved during a reversal session, a subset of these ensembles decreased their activation strength, correlating with memory-updating. These “fading” ensembles were a result of weakly-connected neurons becoming less co-active with their peers. Middle-aged mice were impaired in reversal learning, and the prevalence of their remodeling ensembles correlated with their memory-updating performance. Therefore, we have identified a mechanism where the hippocampus breaks down ensembles to support memory-updating.",
        "url": "https://www.world-wide.org/cosyne-23/ensemble-remodeling-supports-memory-updating-c78c711b"
    },
    "The space of finite ring attractors: from theoretical principles to the fly compass system": {
        "title": "The space of finite ring attractors: from theoretical principles to the fly compass system",
        "authors": "Tirthabir Biswas, Angel Stanoev, Sandro Romani, James Fitzgerald",
        "date": "Thursday, 9 March 2023",
        "location": "I-079",
        "abstract": "A cognitive compass is a critical component of spatial navigation and path integration. Experiments in the fruit fly and recent theoretical work show that an accurate compass can be built from a handful of neurons. Many previous models have used ring attractors to model head direction systems. However, these models relied on hand-designed neural network connectivity patterns, and we lack a principled methodology for quantitatively relating connectomics data to theoretical ring attractor models. Here we introduce a novel theoretical framework for analyzing the space of threshold-linear ring attractor networks. Under the assumption that neural activity in the compass system is self-sustained, we derive predictions that link asymmetric bumps of neural activity to symmetric patterns of neural network connectivity. We also provide a recipe for using neural activity measurements and connectomics data to test these predictions in the fly's compass system. Our framework thus allows us to incorporate connectomics data to build data-driven ring attractor models that are as close to the biology as possible.",
        "url": "https://www.world-wide.org/cosyne-23/space-finite-ring-attractors-from-theoretical-850a38e9"
    },
    "Influence of neuromodulators on brain state transitions in larval zebrafish": {
        "title": "Influence of neuromodulators on brain state transitions in larval zebrafish",
        "authors": "Antoine Légaré, Sandrine Poulin, Vincent Boily, Mado Lemieux, Patrick Desrosiers, Paul De Koninck",
        "date": "Thursday, 9 March 2023",
        "location": "I-080",
        "abstract": "With the rapid growth of optical imaging technologies, the simultaneous observation of brain-wide activity and behavior in small organisms offers a unique opportunity to study how distributed neuronal networks interact to process sensory information and generate behavior. While neuromodulators have been shown to grant flexible state-switching mechanisms to circuits, their influence on global network dynamics is poorly characterized. Using resonant-scanning two-photon microscopy, we measured brain-wide calcium dynamics in head-restrained larval zebrafish while monitoring tail movements to investigate how dopamine, norepinephrine and serotonin drive neuronal and behavioral states. We first developed an unsupervised clustering approach to extract recurrent regional activation patterns, or brain states, across all fish and recording sessions. The approach identifies short-lived states, as well as states lasting over tens of seconds, the majority of which having no behavioral manifestation. The spatial distribution of state activity is modular and constrained by structural communities of strongly interconnected regions. Transition probabilities between states are conserved across the population, while state dwell times vary. Interestingly, the identity of individual fish is recovered across imaging sessions using a subset of fingerprint states. To investigate how neuromodulators might be driving these states and individual differences, we use post hoc immunolabeling and image registration to identify cell types of interest in calcium imaging datasets, from which we extract neuromodulatory signaling. Robust correlations are observed between tail movements and the firing of dopaminergic/noradrenergic cells, recapitulating their well-studied role in driving locomotor networks. Our current framework will be expanded to different sensorimotor contexts using visual stimulation, while controlling neuromodulators with pharmacology. The receptor distributions will be characterized with fluorescence in situ hybridization to constrain recurrent neural network models with neuromodulatory interactions. We aim to give a brain-wide description of how neuromodulators interact and lead to the emergence of recurrent macroscopic states, hallmarks of multiple imaging modalities.",
        "url": "https://www.world-wide.org/cosyne-23/influence-neuromodulators-brain-state-14e10b1d"
    },
    "Non-stationary recurrent neural networks for reconstructing computational dynamics of rule learning": {
        "title": "Non-stationary recurrent neural networks for reconstructing computational dynamics of rule learning",
        "authors": "Max Ingo Thurm, Georgia Koppe, Eleonora Russo, Florian Bähner, Daniel Durstewitz",
        "date": "Thursday, 9 March 2023",
        "location": "I-081",
        "abstract": "Updating behavioral policies in novel environments or upon shifting action-outcome contingencies is essential for survival. A number of studies have identified the medial prefrontal cortex (mPFC) as a key player in cognitive flexibility, rule learning and uncertainty detection. Animals learning a new behavioral paradigm, or switching between rules, show abrupt changes in their performance, accompanied by sharp transitions in neuronal population dynamics. However, the precise mechanisms regulating behavioral flexibility remain unclear. Here we aim to extract the computational mechanisms behind these behavioral and neurophysiological phenomena through dynamical systems reconstruction, employing an interpretable non-stationary piecewise-linear recurrent neural network (PLRNN) for this purpose. Our approach enables to model neuronal adaptation to changing environmental contingencies with trial-specific connectivity matrices regularized by smoothness and continuity priors. We train our model to reconstruct the non-stationary neuronal dynamics from multiple-single unit (MSU) recordings of the rodent's mPFC on a trial-by-trial basis while animals performed a probabilistic rule-shifting task. After model training, 1) the non-stationary PLRNN can accurately generate a variety of single-unit firing rate profiles, 2) task-related events can be decoded as well from the PLRNN’s latent space as from the original MSU activity, 3) change points identified in the PLRNN-generated activity and the original MSU recordings across trials tightly correlate, and 4) PLRNN-simulated trial-to-trial trajectories for both rules closely match those directly obtained from the data. Thus, after PLRNN training on the neural recordings, its behavioral and dynamical characteristics closely mimicked those observed in the real data. Moreover, we show that trial-specific connectivity matrices allow for highly accurate decoding of rule-type, but are not influenced by other task events. Hence, changes in the animal’s behavior appear to be based on alterations in the underlying functional connectivity. In conclusion, the non-stationary PLRNN offers a novel framework for investigating time-variant, neuro-dynamical phenomena during learning, plasticity, and development.",
        "url": "https://www.world-wide.org/cosyne-23/non-stationary-recurrent-neural-networks-487cb607"
    },
    "Learning Cortical Hierarchies With Temporal Hebbian Updates": {
        "title": "Learning Cortical Hierarchies With Temporal Hebbian Updates",
        "authors": "Matilde Tristany Farinha, Pau Vilimelis Aceituno, Reinhard Loidl, Benjamin Grewe",
        "date": "Thursday, 9 March 2023",
        "location": "I-082",
        "abstract": "A key driver of mammalian intelligence is the ability to represent sensory inputs at different levels of abstraction. In deep learning, hierarchical neural networks learn such abstractions through top-down signals that drive synaptic plasticity. This is commonly done with backpropagation, an algorithm that is considered biologically implausible. In this work, we present a novel dynamic target propagation framework for hierarchical learning that uses Differential Hebbian (DH) updates, a rate-based version of Spike-Time-Dependent Plasticity. Our framework is based on the Deep Feedback Control (DFC) model and one of its extensions, where top-down feedback is used to shape neural activity, and learning relies on a prediction error calculated locally in each neuron. In contrast to the original DFC and similar bio-plausible learning models, our DH learning framework relays on experimentally observed learning rules, rather than on the comparison of somatic and dendritic activity which has not -- to the best of our knowledge -- been observed and its possible biological implementation remains unclear. Both our DH framework and DFC are consistent with predictive coding, where learning is based on encoding predictions and errors. However, in contrast to standard predictive coding, our framework does not require explicit encoding of errors, as errors are encoded implicitly by the change of activity within the same unit. Relaxing this need for error encoding is relevant from an experimental neuroscience perspective since error encoding is a key source of criticism of predictive coding due to its lack of interpretability in experimental settings. In summary, we propose a new framework that allows learning in multilayer networks with temporal Hebbian updates. We test our DH framework on a modest computer-vision benchmark (MNIST), showing competitive performance to backpropagation and its original multi-compartment DFC model. Finally, we discuss how the assumptions of our model relate to observations in experimental neuroscience.",
        "url": "https://www.world-wide.org/cosyne-23/learning-cortical-hierarchies-with-temporal-41935f3b"
    },
    "Adaptive coding efficiency through joint gain control in neural populations": {
        "title": "Adaptive coding efficiency through joint gain control in neural populations",
        "authors": "Lyndon Duong, David Lipshutz, David Heeger, Dmitri Chklovskii, Eero Simoncelli",
        "date": "Thursday, 9 March 2023",
        "location": "I-083",
        "abstract": "Efficiently transmitting information from dynamic environments necessitates sensory systems that rapidly and reversibly adapt to changes in input statistics. Single neurons adjust their input-output gains to adaptively normalize their stimulus-driven response variance (Fairhall et al. 2001). In neural populations, statistical whitening and related adaptations have been observed (Dan et al. 1996; Benucci et al. 2013; Wanner and Friedrich 2020), whereby joint statistics of neurons are decorrelated in addition to being re-scaled to have equal variance. Existing models of neural population adaptation rely on synaptic plasticity mechanisms, which, while more flexible, are unlikely to operate as transiently or reversibly as gain control. In this study, we develop a novel circuit which generalizes single-neuron adaptive gain control to the level of a population. We derive a normative adaptive whitening algorithm which regulates joint second-order statistics of a neural population by adjusting the marginal statistics of an overcomplete auxiliary population. The algorithm operates online, and can be mapped onto a recurrent neural network comprising principal cells and gain-modulating interneurons. Remarkably, the interneurons adjust gains using only local signals, and feed back onto principal cells to achieve a globally statistically white output. Our framework can be generalized to handle biophysical constraints, and we demonstrate its use in statistically whitening local image patches using convolutional weights. Finally, we compare our model to experimental observations of adaptation in early sensory systems.",
        "url": "https://www.world-wide.org/cosyne-23/adaptive-coding-efficiency-through-joint-7485fd18"
    },
    "Signatures of belief representations in recurrent neural networks and prefrontal cortex": {
        "title": "Signatures of belief representations in recurrent neural networks and prefrontal cortex",
        "authors": "Jay Hennig, Sandra Romero Pinto, Scott Linderman, Naoshige Uchida, Samuel Gershman",
        "date": "Thursday, 9 March 2023",
        "location": "I-084",
        "abstract": "A popular model of the basal ganglia uses the theory of reinforcement learning (RL), where phasic dopamine activity encodes reward prediction errors to drive the learning of reward associations. In contrast to classical RL, however, where relevant state information is always provided to the agent, animals must find optimal behaviors using only incomplete state information. One theoretical observation is that animals (or agents) can solve these partially observable tasks by forming \"beliefs,\" or optimal Bayesian posterior estimates of the state of the task. However, it is unknown whether animals could truly learn these theoretical constructs directly from experience, nor is it clear what signatures we might look for in neural data to know whether the brain truly uses a belief representation. To tackle this, we developed a two-pronged approach for linking the theory of beliefs with analyses. Using recurrent neural networks (RNNs), we can build brain-like model systems that must solve the task of estimating value given the same observations as animals. We then use these model systems to develop statistical analyses that determine whether or not the neural representations are consistent with beliefs. Using these analyses, we find that RNNs trained to estimate value do indeed discover belief-like representations. Tentative analysis of neural population activity from mouse cortex suggests cortex also exhibits similar dynamical structure as beliefs and RNNs.",
        "url": "https://www.world-wide.org/cosyne-23/signatures-belief-representations-recurrent-88d4885b"
    },
    "The geometry and role of sequential activity in olfactory processing": {
        "title": "The geometry and role of sequential activity in olfactory processing",
        "authors": "Jonathan V. Gill, Mursel Karadas, Shy Shoham, Dmitry Rinberg",
        "date": "Thursday, 9 March 2023",
        "location": "I-085",
        "abstract": "Animals depend on their senses for survival. Mice, who rely on olfaction to navigate the world, can rapidly identify odors within a single sniff across a wide range of concentrations. In the mouse olfactory bulb (OB), mitral and tufted cells (MTCs) respond to odors by changing both the rate and timing of spikes relative to inhalation, resulting in reliable, odor specific sequences that evolve over a single sniff. However, it remains unknown how sequential MTC activity is organized. Specifically, what defines the order in which MTCs fire, and what information is encoded in these sequences? To address this, we performed 2-photon (2P) calcium imaging of hundreds of MTCs expressing the fast calcium indicator jGCaMP8f, permitting us to monitor the sub-sniff timing of responses to a battery of odors. We constructed a space of MTC tuning using the pairwise correlations between MTC odor responses averaged over a single sniff. We then analyzed the propagation of sequences in this space and discovered that sequences originated in a set of similarly tuned neurons and propagated to more distantly tuned neurons, so that the latency of MTC activation was linearly related to distance in tuning space. Analyzing the concentration dependence of sequence propagation, we found that the early part of the sequences carried information that was concentration invariant, while later MTC responses were inconsistent across concentrations. Finally, inspired by the discovery that similarly tuned MTCs are activated sequentially across odors, we constructed and analyzed a computational model for sequence-based unsupervised training of synapses from MTCs to the piriform cortex, which revealed that sequential activity across the entire sniff permits perceptual generalization for novel odors.",
        "url": "https://www.world-wide.org/cosyne-23/geometry-role-sequential-activity-olfactory-54bb96d0"
    },
    "Functional Subtypes of Synaptic Dynamics Revealed by Model-based Classification": {
        "title": "Functional Subtypes of Synaptic Dynamics Revealed by Model-based Classification",
        "authors": "John Beninger, Julian Rossbroich, Katalin Toth, Richard Naud",
        "date": "Thursday, 9 March 2023",
        "location": "I-086",
        "abstract": "Synapses show preferential responses to particular temporal patterns of activity. Across synapses, however, there is a large degree of response heterogeneity that is routinely and tacitly separated into classes. Furthermore, feedforward neural networks incorporating simple models of these dynamic responses outperform similar recurrent neural network (RNN) models in several neuroscience related tasks. Here we combined a kernel-based model and machine learning techniques to infer biologically grounded, and functionally distinct classes of short-term synaptic dynamics in data from the Allen Institute Synaptic Physiology data set. To identify the presence of classes of synaptic dynamics, we independently performed unsupervised clustering of model parameters and supervised subclass prediction followed by inspection of functional classes used in prediction. In rodent data, we found a remarkable convergence onto six functional classes. Three of these groups corresponded to different types of increasing synaptic strength and were labelled “strongly facilitating”, “depressing then facilitating”, and “short duration facilitating”. The other three groups corresponded to different intensities of strength decrease and “no plasticity” synapses. Application of the same clustering methods in human data inferred the same classes. Next we examined to what extent our inferred groups corresponded to high level transcriptionally defined clusters in rodent data. Better prediction of transcriptomic subclass can be achieved by using model parameters than by using standard electrophysiological features, and suggests that our functionally defined clusters align with specific predicted pre- or post-synaptic transcriptomic subclasses. We propose that these functional types of synaptic dynamics shape the connectivity of the brain and that, paired with our model fits, will be useful as readily available, biologically plausible building blocks for computational simulations.",
        "url": "https://www.world-wide.org/cosyne-23/functional-subtypes-synaptic-dynamics-9338520d"
    },
    "Decoding stress susceptibility from activity in amygdala-ventral hippocampal network": {
        "title": "Decoding stress susceptibility from activity in amygdala-ventral hippocampal network",
        "authors": "Frances Xia, Valeria Fascianelli, Nina Vishwakarma, Frances Ghinger, Stefano Fusi, Mazen Kheirbek",
        "date": "Thursday, 9 March 2023",
        "location": "I-087",
        "abstract": "Mood disorders are characterized by behavioral changes arising from network-level alterations, with the amygdala (AMY)-ventral hippocampus (vHPC) pathway being a central component. Anhedonia, the reduced ability to feel pleasure, is a core feature of mood disorders. However, how stress-induced changes in motivation to seek and consume rewards are represented in the activity patterns in the AMY and vHPC remains unclear. Furthermore, how these activity patterns can inform pathway-specific manipulations to rescue anhedonic behavior remains to be explored. Here, we used Neuropixels probes to record AMY and vHPC single units in mice following chronic social defeat stress (CSDS) to assess how stress modulates representations of reward choice and reward-seeking behavior. First, we explored whether anhedonia is linked to reduced discriminability of reward values in vHPC and AMY. Surprisingly, we found that vHPC and AMY neurons in CSDS mice showed enhanced reward choice sensitivity in comparison to controls. Furthermore, we could decode future reward choices from vHPC and AMY activity in mice susceptible to CSDS, seconds before mice made their choice, suggesting inflexibility in reward representations. This was accompanied by reduced sensitivity to reward delivery. We next explored how neural activity differs between groups before mice were task-engaged. We found that the neural representations in AMY of susceptible mice have higher embedding dimensionality with fewer correlated states, suggesting that even in the absence of behavior, AMY activity patterns can differentiate mice of varying stress susceptibility levels. Inter-regionally, AMY-vHPC coordinated activity was correlated with sucrose preference, suggesting that reduced AMY-vHPC interaction may underlie anhedonia. To correct this, we chemogenetically activated the vHPC-AMY pathway, which enhanced vHPC-AMY correlated activity and rescued anhedonic behavior. Together, our results show that reward choice representations in the AMY and vHPC are altered in susceptible mice, and these changes may be responsible for ultimately driving anhedonic behavior following stress.",
        "url": "https://www.world-wide.org/cosyne-23/decoding-stress-susceptibility-from-7639bf67"
    },
    "Directly comparing fly and mouse visual systems reveals algorithmic similarities for motion detection": {
        "title": "Directly comparing fly and mouse visual systems reveals algorithmic similarities for motion detection",
        "authors": "Caitlin Gish, Damon Clark, Juyue Chen, James Fransen, Emilio Salazar-Gatzimas, Bart Borghuis",
        "date": "Thursday, 9 March 2023",
        "location": "I-088",
        "abstract": "Evolution has equipped vertebrates and invertebrates with neural circuits that selectively encode visual motion. In both flies and mice, early visual circuits separately detect the movement of light and dark edges. Strong parallels have been noted between the two systems in their anatomy, circuitry, and the suite of computations that they perform. However, because their direction-selective cells have different morphologies and employ different neurotransmitters and receptors, the similarities between them exist not at the molecular level, but at the algorithmic level. While similarities in the computations performed by these circuits in mouse and fruit fly have been noted, direct experimental comparisons have been lacking. Mouse retinal physiologists and fly visual neuroscientists use largely non-overlapping sets of visual stimuli, making direct comparisons between the systems difficult. Here, we have directly compared motion encoding in these two species at the algorithmic level, using matched stimuli and focusing on a pair of analogous neurons: the mouse ON-starburst amacrine cell (ON-SAC) and Drosophila T4. Our analysis shows that the cells have similarly shaped spatiotemporal receptive fields, respond sensitively to fast spatiotemporal correlations, and are similarly tuned to sinusoidal drifting gratings, but they differ in their response to apparent motion stimuli. Interestingly, both neuron types show a response to summed sinusoids that deviates from models for motion processing in these cells, underscoring the similarities in their processing and identifying response features that remain unexplained. Flies and mice diverged many hundred million years ago, implying these similarities are likely the result of convergent evolution. This suggests strong selective pressure on motion detection to employ what may be a limited number of solutions within the anatomical and biophysical constraints of nervous systems and the statistical properties of natural visual input.",
        "url": "https://www.world-wide.org/cosyne-23/directly-comparing-mouse-visual-systems-d13e4236"
    },
    "An RNN model of planning explains hippocampal replay and human behavior": {
        "title": "An RNN model of planning explains hippocampal replay and human behavior",
        "authors": "Kristopher Jensen, Marcelo Mattar, Guillaume Hennequin",
        "date": "Thursday, 9 March 2023",
        "location": "I-089",
        "abstract": "When interacting with complex environments, humans can rapidly adapt their behavior to changes in task or context. This flexibility has been suggested to result from fast recurrent dynamics in the prefrontal network, acquired through a process of meta-reinforcement learning (Wang et al., 2018). However, these models fail to capture an important aspect of human behavior: when adapting to new information, we spend variable and often long periods of time contemplating possible futures before acting. For such planning to be rational, its benefits to future behavior must at least compensate for the time spent thinking. Here, we capture these properties of human behavior by developing a neural network model where not only actions, but also planning itself, are controlled by prefrontal cortex. The model consists of a meta-reinforcement learning agent augmented with the ability to perform ‘simulation-based planning’ in the form of policy rollouts. Our results demonstrate that the agent learns to plan when planning is beneficial, explaining the empirical variability in human thinking times. Intriguingly, the patterns of policy rollouts employed by the artificial agent, and their effect on behavior, closely resemble patterns of rodent hippocampal replays in a spatial navigation task studied by Widloski et al. (2022). Our work suggests that the brain implements simulation-based planning through prefrontal-hippocampal interactions, where hippocampal replays are triggered by - and in turn adaptively affect - prefrontal dynamics.",
        "url": "https://www.world-wide.org/cosyne-23/model-planning-explains-hippocampal-2b051cb4"
    },
    "Efficient coding explains neural response homeostasis and stimulus-specific adaptation": {
        "title": "Efficient coding explains neural response homeostasis and stimulus-specific adaptation",
        "authors": "Edward Young & Yashar Ahmadian",
        "date": "Thursday, 9 March 2023",
        "location": "I-090",
        "abstract": "Neurons are typically sensitive to a small fraction of possible stimuli in sensory space. If the environment changes, making certain stimuli more prevalent, neurons sensitive to those stimuli respond more often and therefore have a higher average firing rate. Prolonged exposure to such an environment often causes such neurons to adapt by responding less vigorously. If adaptation consistently returns the average firing rate to its value prior to environmental shift, it is termed firing-rate homeostasis. We present a normative explanation of firing-rate homeostasis grounded in the Infomax principle. Homeostasis arises as the optimal solution to a trade-off between coding fidelity and metabolic cost, understood as the average population spike count. Our framework gives quantitative conditions necessary for the optimality of homeostasis, and predicts how adaptation should deviate from homeostasis when these conditions are violated. Based on biological estimates of relevant parameters, we show that these conditions hold in areas of cortex where homeostatic adaptation has been observed. Another feature of adaptation within sensory cortex is stimulus specific adaptation, under which neurons not only change their responsiveness, but also the shape of their tuning curves. This often takes the form of repulsion of preferred stimuli away from an adaptor stimulus. We demonstrate how homeostatic coding, coupled with Bayesian theories of neural representation, can explain such stimulus-specific adaptation effects (e.g., in V1), which we show can be implemented by divisive normalisation with adaptive weights. Furthermore, our framework gives a computational interpretation to the feedforward inputs and weights of the divisive normalisation operation. In summary, we show analytically that homeostasis is the optimal solution to maximising the informational content of population responses with limited energetic resources, irrespective of the computations encoded by the population.",
        "url": "https://www.world-wide.org/cosyne-23/efficient-coding-explains-neural-response-e3c9196d"
    },
    "Online contrastive PCA with Hebbian / anti-Hebbian plasticity": {
        "title": "Online contrastive PCA with Hebbian / anti-Hebbian plasticity",
        "authors": "Tiberiu Tesileanu, Siavash Golkar, David Lipshutz, Dmitri Chklovskii",
        "date": "Thursday, 9 March 2023",
        "location": "I-091",
        "abstract": "Living organisms receive an immense amount of information per unit time, but much of it is of little relevance for behavior. A simple approach to process this high-dimensional input is to focus on a lower-dimensional subspace and ignore the directions that are less informative. Principal component analysis (PCA) achieves this by discarding the directions with low variance. Such an approach is, however, inefficient in cases where the irrelevant directions are very noisy, thus having greater variance than the relevant ones. If we have access to representative samples of variability in irrelevant directions (\"negative samples\"), we can achieve better efficiency by using a contrastive variant of PCA, as in Abid et al. (2017). Contrastive PCA (cPCA) finds the subspace of highest relevant variance, associated with positive samples, while minimizing the variance associated with irrelevant information, as inferred from negative samples. Here we build an online, biologically plausible variant of cPCA, which we call cPCA*, and show that it has a number of realistic features. In particular, cPCA* can be implemented as a circuit comprised of two-compartment neurons. The feedforward connectivity undergoes Hebbian or anti-Hebbian plasticity depending on whether it is processing a positive or a negative sample. We posit that positive and negative samples arrive via the same pathway and propose that the indication of which samples are positive or negative can be done either explicitly (e.g., using neuromodulatory signals) or implicitly (e.g., based on temporal ordering). Altering the sign of the plasticity in relation to the order in which signals arrive suggests a possible relation to Spike Timing Dependent Plasticity (STDP).",
        "url": "https://www.world-wide.org/cosyne-23/online-contrastive-with-hebbian-anti-hebbian-da7b6341"
    },
    "Learning in neural networks with brain-inspired geometry": {
        "title": "Learning in neural networks with brain-inspired geometry",
        "authors": "Jonathan Cornford, Arna Ghosh, Gauthier Gidel, Blake Richards",
        "date": "Thursday, 9 March 2023",
        "location": "I-092",
        "abstract": "There are many differences between artificial and biological neural networks. However, some of those less frequently considered are the differences between their respective weight distributions and dynamics. Here, we take inspiration from neuroscience and train networks with a multiplicative update algorithm called exponentiated gradient descent (EG). In comparison to gradient descent (GD), this corresponds to changing geometries and measuring parameter differences with the un-normalised relative entropy function instead of Euclidean distance. In line with biology, the multiplicative updates prescribed by EG are unable to change weight polarity, and as such we show a feed-forward inhibition-inspired “Dale’s ANN” (DANN) architecture learns better with EG than standard networks. Furthermore, DANN networks trained with EG are only slightly worse on standard image classification benchmarks than baseline models, and perform much better for tasks in which task-relevant inputs are sparse. Finally, we show networks trained with EG learn heavy-tailed weight distributions that are more similar to observed biological weight distributions, and provide preliminary evidence that they perform better than GD-trained networks at higher weight-sparsity levels.",
        "url": "https://www.world-wide.org/cosyne-23/learning-neural-networks-with-brain-inspired-ac8744e3"
    },
    "Cell-specific mechanisms of medial frontal theta during error monitoring": {
        "title": "Cell-specific mechanisms of medial frontal theta during error monitoring",
        "authors": "Beatriz Herrera, Amirsaman Sajad, Steven P. Errington, Jeffrey D. Schall, Jorge J. Riera",
        "date": "Thursday, 9 March 2023",
        "location": "I-093",
        "abstract": "Theta oscillations in dorsomedial frontal cortex (DMFC) are prominent signatures of cognitive control and error monitoring (Cavanagh and Frank, Trends Cogn. Sci., 2014; Cohen, Trends Neurosci., 2014). Yet, the neuronal mechanisms generating these signals remain uncertain. Here, we study whether neocortical pyramidal neurons alone can induce frontal theta during error monitoring by combining electrophysiological data and biophysical modeling. We recorded neuronal spiking and local field potentials (LFPs) across all layers of DMFC from two macaque monkeys performing a saccade countermanding stop-signal task. In this task, subjects were required to generate a saccade to a peripheral target, but to inhibit this planned saccade when a stop-signal appeared. Errors occurred when monkeys generated a saccade despite the appearance of a stop-signal. We utilized the recorded error-related spiking activity of putative L3 and L5 pyramidal neurons to estimate the pre-synaptic inputs of these neurons in realistic biophysical neuronal models around the saccade onset time (L3 model: Eyal et al., Front. Cell. Neurosci., 2018; L5 model: Hay et al., PLoS Comput. Biol., 2011). We focused on reproducing the spiking activity of correct and error trials and considered only excitatory synaptic inputs (AMPA and NMDA synapses). After estimating the pre-synaptic inputs onto these neurons, we simulated the LFPs produced by the activity of a population of L3 and L5 error neurons at 16 equally spaced (150 μm) vertically aligned points located at the center of the cortical column. Recorded LFPs showed an increase in theta power across cortical layers around saccade onset, which was more pronounced in L3 and L5, and significantly larger in error versus correct trials. Simulated LFPs showed a similar increase in the laminar time-varying theta power around saccade onset, which was also significantly larger in error versus correct trials. Simulations indicate that L5 error pyramidal neurons, but not L3 contributed to the increase in the laminar theta power around saccade onset.",
        "url": "https://www.world-wide.org/cosyne-23/cell-specific-mechanisms-medial-frontal-68e1d748"
    },
    "Computational and behavioral mechanisms underlying selecting, stopping, and switching of actions": {
        "title": "Computational and behavioral mechanisms underlying selecting, stopping, and switching of actions",
        "authors": "Shan Zhong & Vasileios Christopoulos",
        "date": "Thursday, 9 March 2023",
        "location": "I-094",
        "abstract": "How actions are regulated based on environmental changes is a fundamental neurobiological question. A key component of action regulation is action inhibition, which when abnormal contributes to various neuropsychiatric disorders. We explored the mechanism of action regulation by recruiting healthy adults (n=15, ages 21-42) to perform reaches towards targets presented on a computer screen using a joystick. The experiment includes: decision-making task, in which subjects were instructed to reach towards one target or freely choose between two targets; stop-signal task, in which a stop signal appeared in some trials of the decision-making task, forcing subjects to stop; and switch task, in which subjects had to switch towards an unknown or known target location in some trials of the decision-making task. We found that the reaction time for one-target trials is always shorter than that of two-target trials, regardless of the task (two-sample t-test, p<0.001). In the stop-signal task, the probability of successfully stopping is inversely correlated with the stop signal delay. However, subjects could stop an action easier when they choose between two targets than when they are instructed to move towards one target. They also delayed their response when anticipating a stop signal, suggesting an inhibitory mechanism during planning to ensure a successful stop. Importantly, subjects did not delay their response when they anticipated a switch signal, suggesting that an inhibitory mechanism in not engaged to prepare for switching. In addition, they had slower responses to switch ongoing actions when the new target location was known (two- target trials) than when it was unknown (one-target trials) prior to movement initiation. To better understand the mechanism of action regulation, we designed a neurocomputational framework and showed that selecting and switching actions towards locations that are known prior to movement initiation could be implemented through action competition, without engaging an inhibitory mechanism.",
        "url": "https://www.world-wide.org/cosyne-23/computational-behavioral-mechanisms-1c011cf9"
    },
    "Parsing neural dynamics with infinite recurrent switching linear dynamical systems": {
        "title": "Parsing neural dynamics with infinite recurrent switching linear dynamical systems",
        "authors": "Victor Geadah & Jonathan W. Pillow",
        "date": "Thursday, 9 March 2023",
        "location": "I-095",
        "abstract": "Unsupervised segmentation of behavior and neural activity into simpler alternating states is providing unprecedented insights onto the neural underpinnings of decision-making. Recurrent Switching Linear Dynamical Systems (rSLDS) models use observations or continuous latent activity to guide the switching in states, providing significant advantages in capturing important temporally and spatially sequential dependencies. In trying to allow for unbounded complexity in the discrete states, most approaches have focused on Dirichlet Process (DP) mixture models. Such non-parametric Bayesian models restrict the distribution over dynamical states to be invariant under permutations (i.e. exchangeable) —a challenging assumption in the modeling of sequential data, and incompatible with recurrent connections. In this work, we leverage nonexchangeable parsing processes to extend the rSLDS model to infinite capacity distributions over dynamical state partitions. Common Pólya-gamma augmentation techniques can be used to provide tractable Bayesian inference, but at a considerable computational cost. We instead leverage partial differential equations (PDE) theory to derive an efficient, semi-parametric formulation for discrete state dynamical sufficient statistics in the infinite rSLDS model class. Finally, we demonstrate the flexibility and synthesizing properties of our model class on synthetic data and mice electrophysiological data during decision-making. For the latter, we present early evidence towards the model’s abilities to uncover slow non-stationary motifs in the discrete state distribution underlying baseline neural activity.",
        "url": "https://www.world-wide.org/cosyne-23/parsing-neural-dynamics-with-infinite-2975a898"
    },
    "Noradrenergic Modulation of Whole Brain Energy Landscape Mediates Perceptual Switches": {
        "title": "Noradrenergic Modulation of Whole Brain Energy Landscape Mediates Perceptual Switches",
        "authors": "Christopher Whyte, Brandon Munn, Gabriel Wainstein, Kaylena Ehgoetz Martens, Eli Müller, Vicente Medel, Britt Anderson, Elisabeth Stöttinger, James Danckert, James Shine",
        "date": "Thursday, 9 March 2023",
        "location": "I-096",
        "abstract": "Visual perception relies on a distributed thalamocortical network whose modes of interaction are governed by the neuromodulatory systems. Here we set out to test the hypothesis that bursts of noradrenaline from the locus coeruleus help to facilitate shifts in perception by increasing neural gain across the cortex and flattening the whole brain ‘energy landscape’. In line with our hypothesis, shifts in the perceptual interpretation of an ambiguous image were associated with peaks in pupil diameter – a correlate of adrenergic tone. We trained a recurrent neural network (RNN) to perform an analogous task, then manipulated the gain of the RNN to mimic the effect of noradrenaline. We observed an earlier perceptual shift as a function of noradrenaline heightened gain. Leveraging a dimensionality reduced readout of the dynamics, and a measure of the energy landscape traversed by the dynamics, we developed two predictions: perceptual switches should co-occur with peaks in low-dimensional brain state velocity and with a flattened energy landscape. We used whole-brain fMRI data to test these predictions in humans, thus, confirming the role of the adrenergic system in the large-scale network velocity and flattened energy landscape topography signatures of the brain during perceptual switches.",
        "url": "https://www.world-wide.org/cosyne-23/noradrenergic-modulation-whole-brain-da323502"
    },
    "Predicting sensory modulation of precise spike timing for motor control": {
        "title": "Predicting sensory modulation of precise spike timing for motor control",
        "authors": "Usama Sikandar, Hannah Choi, Joy Putney, Hengye Yang, Silvia Ferrari, Simon Sponberg",
        "date": "Thursday, 9 March 2023",
        "location": "I-097",
        "abstract": "Animals from flying insects to running humans thrive in uncertain and noisy environments. They smoothly navigate, swiftly track targets and escape predators because their sensorimotor systems are precisely fine-tuned for these tasks. Millisecond-precise spike timing codes, prevalent in both sensory and motor systems, can prompt large changes in muscle forces especially when several muscles coordinate to control a biomechanical action. Such coordinated spike timing changes, modulated by task-relevant sensory encoding over long timescales, can significantly contribute to the effectiveness of motor control. However, how does this modulation play into goal-directed control of motor action? A critical step in determining this is predicting motor spike timing changes from sensory encoding. Some existing algorithms can predict spike timings by training spiking neurons to spike within precise time windows. Yet their applicability is limited to simulated data on feedforward two-layered networks only. Therefore, to predict the motor spike timings in a biologically meaningful way, we need computational frameworks based on physiology and experimental data that combine sensing models with coordinated motor program prediction models. A hawkmoth, with its millisecond-precise motor control, serves as an excellent model organism here because the information required to build its visuomotor models based on a comprehensive motor program is readily available. Here, we propose a model of the hawkmoth visuomotor circuit which sequentially predicts precise timings of coordinated motor spikes from the visual encoding of an oscillating flower’s motion. Our model is based on event-based motion detection, coupled with a compound eye model, and an artificial recurrent neural network (RNN) that predicts the hawkmoth’s comprehensive spike-resolved motor program (precise spike timings of 10 major flight muscles). Besides being trained on the experimental data, our model features a motion detection mechanism inspired by a compound eye as well as signal compression and expansion ratios in hawkmoth’s sensorimotor neural circuits.",
        "url": "https://www.world-wide.org/cosyne-23/predicting-sensory-modulation-precise-e8752502"
    },
    "Olfactory bulb network computations underlie concentration invariant odor identification": {
        "title": "Olfactory bulb network computations underlie concentration invariant odor identification",
        "authors": "Mursel Karadas, Jonathan V. Gill, Sebastian Ceballo, Shy Shoham, Dmitry Rinberg",
        "date": "Thursday, 9 March 2023",
        "location": "I-098",
        "abstract": "Odors evoke distinct patterns of neural activity across different concentrations, both at the input level of olfactory sensory neurons (OSN) and glomeruli, as well as the next level, mitral/tufted cells (MTCs). What features of these patterns carry invariant information about odor identity and what are the neural mechanisms defining these features? To address this question, we designed an all-optical system to monitor the activity of many glomeruli and MT cells with high temporal resolution and developed an optogenetic method for establishing functional connectivity between glomeruli and MTCs. We combined two photon Ca2+ imaging with one photon patterned optogenetics in mice expressing a fast calcium indicator (GCaMP6f) in glomeruli and MTCs, and a light-sensitive opsin (ChR2) in OSNs. We found that the earliest activity of glomeruli and MTCs most reliably represented odor identity across concentrations. We found that MTCs connected to early activated glomeruli exhibited stereotypic excitatory responses following their parent glomeruli. At the same time, the odor responses of MTCs connected to later activated glomeruli were strongly affected by the inhibitory network evoked by earlier activated glomeruli. We probed the responsiveness of MTCs to glomerular activation using short optogenetic pulses in the presence of odor stimuli and found that MTCs can effectively transmit glomerular signals to the cortex only in a short temporal window at the beginning of the sniff cycle. Beyond this window, MTC responses were strongly suppressed by inhibition evoked by the presented odor. These findings reveal potential mechanisms for concentration invariant odor coding, and support the primacy model for olfactory information processing, wherein the earlier-activated glomeruli carry odor identity information.",
        "url": "https://www.world-wide.org/cosyne-23/olfactory-bulb-network-computations-cc76e876"
    },
    "Topography of multisensory convergence throughout the mouse cortex": {
        "title": "Topography of multisensory convergence throughout the mouse cortex",
        "authors": "Kinjal Pravinbhai Patel, Avery Ryoo, Stefan Mihalas, Bryan Tripp",
        "date": "Thursday, 9 March 2023",
        "location": "I-099",
        "abstract": "Information about an animal's surroundings reaches the brain through multiple sensory modalities. Multimodal information is integrated at multiple stages, including subcortically, and in primary-sensory and higher-order cortical areas. A basic and functionally important feature of multisensory convergence is its topography. For example, in the superior colliculus, visual, auditory, and tactile information converge in register, producing a two-dimensional map that drives saccades. Many studies have demonstrated multimodal convergence elsewhere in the brain, but beyond the superior colliculus, the topography of this convergence is less clear. In this study, we use a model of 100um-voxel-wise connection strengths in the mouse, which is based on 428 tracer injections, to estimate the dimensions of multisensory maps in all isocortex areas. The first step in this process is to propagate 2D cortical coordinates of the voxels of six primary sensory areas through the connection model, resulting in a 12D coordinate for each voxel in the isocortex. We then use singular value decomposition to calculate the explained variance of dimension-reduced coordinates, and report for each area the dimension that accounts for 90% of the variance. Across the isocortex, these dimensions range nearly from one to six. Higher-dimensional multisensory convergence tends to occur in areas that are higher in the cortical hierarchy. These dimensions do not simply reflect the number of converging modalities, because any number of modalities can converge into a lower-dimensional map if some dimensions are either correlated with others or not topographically organized. These results have implications for modelling neural systems. In particular, they suggest a need for higher-dimensional topography in multisensory models.",
        "url": "https://www.world-wide.org/cosyne-23/topography-multisensory-convergence-2b4af3a6"
    },
    "Population encoding and decoding of frontal cortex during natural communication in marmosets": {
        "title": "Population encoding and decoding of frontal cortex during natural communication in marmosets",
        "authors": "Jingwen Li, Mikio Aoi, Vladimir Jovanovic, Cory Miller",
        "date": "Thursday, 9 March 2023",
        "location": "I-100",
        "abstract": "Communication is an inherently interactive behavior involving the coordinated exchange of social signals between two or more individuals. Studies exploring the neural basis of communication in the primate brain have traditionally focused on how these signals are processed or produced, leaving many facets of vocal behavior largely unexplored. One challenge has been limitations of traditional analyses for quantifying the often variable, dynamic nature of natural communication behaviors, such as conversational exchanges. Here we recorded the activity of single neurons in prefrontal and premotor cortex as freely behaving marmosets engaged in natural conversational exchanges. We applied different analysis approaches to determine how these substrates encode the various facets of this vocal behavior. Using peri-stimulus time histograms (PSTHs), we observed neurons responding to hearing calls and neurons showing a compensatory decrease when producing calls. We further performed a generalized linear model (GLM) based analysis. The predicted spike rate from GLM recapitulates observed PSTHs and the GLM kernels and coefficients yield more neurons in the population having a significant change in spike rate for communication events as well as state-related neurons that are modulated by the internal behavior states. By performing dimensionality reduction and clustering analysis on the GLM kernels and coefficients, we observed distinctive clusters in the population playing different functional roles: one cluster driving marmoset call production; one responding to only conversational calls; one responding to hearing calls. Last, we used the GLM framework to decode the animal’s communicating behavior from the neural activities. These results show that the GLM analysis applied here to a continuous natural vocal behavior revealed elements of primate frontal cortex activity that were not evident using more traditional analyses, and suggests that this method may be a powerful tool to better understand the neural basis of communication in the primate brain and other naturally occurring behaviors.",
        "url": "https://www.world-wide.org/cosyne-23/population-encoding-decoding-frontal-76863d7a"
    },
    "Simultaneous brain control of two cursors enabled by online-robust neural networks": {
        "title": "Simultaneous brain control of two cursors enabled by online-robust neural networks",
        "authors": "Darrel Deo, Francis Willett, Donald Avansino, Leigh Hochberg, Krishna Shenoy, Jaimie Henderson",
        "date": "Thursday, 9 March 2023",
        "location": "I-101",
        "abstract": "Advancements in machine learning and artificial intelligence have given rise to promising neural network-based models of the complex nonlinear relationships between movement intention and neural activity. In particular, recurrent neural networks (RNNs) are one commonly used algorithm for brain-computer interface (BCI) control, due to their ability to learn temporal dependencies within the training data. However, most BCI training data contains highly stereotyped temporal and behavioral structure to which RNNs can overfit, causing poor performance in online settings when behavior and temporal characteristics differ from the offline task used for RNN calibration. To solve this problem, we developed a data augmentation technique that dilates/compresses small snippets of training data in time and randomizes the order of these snippets, helping RNN decoders trained on temporally stereotyped open-loop data generalize to the closed-loop setting. We demonstrate this technique in the context of simultaneous two-cursor control via RNN decoders, in a person with paralysis enrolled in the BrainGate2 pilot clinical trial. We show that decoders trained with our data augmentation technique outperform linear decoders and non-augmented RNNs, even though augmented RNNs perform worse on the training data. This suggests that prior work demonstrating very high performance on stereotyped data may not be representative of how performance will translate to online settings. Our approach of hardening neural networks to online settings makes it possible to achieve high-performance control of multiple effectors at the same time, since multi-effector movement is coded in a nonlinear way that benefits from nonlinear decoding approaches. Insights gained developing neural decoders to accurately restore this multi-effector motion may help future BCIs to restore physical whole-body motion using exoskeletons or muscle stimulation to carry out acts of daily living.",
        "url": "https://www.world-wide.org/cosyne-23/simultaneous-brain-control-cursors-enabled-a7aac94d"
    },
    "Alternating inference and learning: a thalamocortical model for continual and transfer learning": {
        "title": "Alternating inference and learning: a thalamocortical model for continual and transfer learning",
        "authors": "Ali Hummos & Guangyu Robert Yang",
        "date": "Thursday, 9 March 2023",
        "location": "I-102",
        "abstract": "Animals thrive in a constantly changing environment and leverage the temporal structure to learn well-factorized causal representations. In contrast, traditional neural networks have no representation of these changes and suffer from forgetting. In the prefrontal-thalamic circuit, reciprocal feedback connections produce a compressed thalamic representation of the computations performed in the prefrontal cortex. In inspiration, we use a neural network with a separate latent task representation and introduce a simple algorithm that uses optimization to rapidly infer and generate representations of the current task. The algorithm alternates between updating the neural network weights and the latent task embedding, allowing the agent to parse the stream of temporal experience into discrete tasks and organize learning about them. The algorithm achieves competitive end average accuracy on a continual learning benchmark, but importantly, by requiring the model to adapt through inferring tasks (latent updates), it organizes task knowledge into structures and the thalamic task embedding becomes a cognitive interface to control them. Tasks later in the sequence can be solved through knowledge transfer as they become reachable within the well-factorized thalamic latent space. The algorithm adapts to a stream of unlabeled tasks through task inference, rather than re-learning, consistent with accounts of animal behavior, and proposes feedback control as a fundamental computation in the corticothalamic projections in the brain.",
        "url": "https://www.world-wide.org/cosyne-23/alternating-inference-learning-thalamocortical-dcd915e1"
    },
    "Synaptic-type-specific clustering optimizes the computational capabilities of balanced recurrent networks": {
        "title": "Synaptic-type-specific clustering optimizes the computational capabilities of balanced recurrent networks",
        "authors": "Emmanouil Giannakakis, Anna Levina, Victor Buendia, Sina Khajehabdollahi",
        "date": "Thursday, 9 March 2023",
        "location": "I-103",
        "abstract": "The specific topology of biological neural networks is believed to be one of the most important ingredients of the nervous system's computational capabilities. Furthermore, multiple experimental studies have demonstrated that neural connectivity is highly inhomogeneous, following different patterns between different regions and neuron types. In particular, the presence of clusters of highly interconnected neurons is one of the most well-established connectivity patterns across multiple brain areas. Still, the functional implications of such brain connectivity features, especially for the performance of specific tasks remain largely unknown. Here, we use a reservoir computing model to link diverse, synaptic type-specific levels of clustering in balanced recurrent networks with the ability to process multiple uncorrelated complex inputs simultaneously. We construct a balanced recurrent network of rate neurons, which we use as a reservoir that simultaneously predicts the trajectory of two chaotic attractors. Predicting the dynamics of a single chaotic system is a commonly used task. For the more challenging simultaneous prediction, we split the network into two clusters, each responsible for processing one attractor. We investigate whether synaptic connections between the two clusters can benefit the reservoir's performance. In particular, we hypothesize that different probabilities of connection within and between clusters for different types of synapses could improve the network's ability to process complex dynamics. Thus, we use approximate Bayesian computation to estimate the distribution of synapse type-specific clustering levels that lead to optimal network performance. We find that localized excitation, combined with more spread-out inhibition (a pattern observed in cortical networks), boosts the network's performance. Our findings suggest that contrary to common intuition, overlapping connectivity between sub-networks performing different tasks can lead to beneficial dynamics that enhance task performance. Thus, commonly observed connectivity patterns in the brain could have a functional role in the parallel processing of multiple signals.",
        "url": "https://www.world-wide.org/cosyne-23/synaptic-type-specific-clustering-c13afeba"
    },
    "Dissecting cortical and subcortical contributions to perception with white noise optogenetic inhibition": {
        "title": "Dissecting cortical and subcortical contributions to perception with white noise optogenetic inhibition",
        "authors": "Jackson Cone, Autumn Mitchell, Rachel Parker, John Maunsell",
        "date": "Thursday, 9 March 2023",
        "location": "I-104",
        "abstract": "During visually guided behaviours, hundreds of milliseconds or more can elapse between stimulus onset and a behavioural response. How spikes occurring at different times and in different brain areas are read out to generate perception and guide behaviour remains elusive. To explore temporal relationships between sensory input, neuronal spiking, and behaviour, we recently adapted reverse correlation approaches for optogenetic inhibition. We delivered white noise pulse trains of optogenetic stimulation to excite ChR2-expressing inhibitory neurons in the primary visual cortex (V1) or superior colliculus (SC) of head-fixed mice while they performed a visual detection task. We computed neuronal-behavioral kernels (NBK) based on a reverse correlation of the optogenetic stimuli aligned to stimulus onset after sorting those stimuli based on task outcomes (hit, miss). The NBK provides an unbiased, temporally-precise estimate of how suppression of spiking at different moments during a trial affects behavioural detection of visual stimuli. Because visual stimulus preferences in V1 and SC differ, we hypothesized that spike weighting dynamics differ between SC and V1 depending on the identity of the visual stimulus (e.g., luminance versus contrast). SC NBKs revealed that spikes in the earliest portion of mouse SC visual responses contribute to detection of visual contrast as well as luminance. However, while early V1 spikes are strongly weighted for detecting contrast stimuli, there is little sign of V1 contributions to luminance detection. Optogenetic perturbations outside of the initial 100 ms after the onset of visual stimuli had little impact on performance in either area or condition. Electrophysiological recordings in SC and V1 revealed no long-lasting circuit level effects in response to white noise optogenetic stimulus trains. These data suggest that V1 and SC make concurrent contributions to detection of visual contrast, while detecting changes in luminance depends more strongly on the SC.",
        "url": "https://www.world-wide.org/cosyne-23/dissecting-cortical-subcortical-contributions-572a5501"
    },
    "Anisotropy in visual crowding is reflected in inter-laminar interactions of macaque V1": {
        "title": "Anisotropy in visual crowding is reflected in inter-laminar interactions of macaque V1",
        "authors": "Xize Xu, Anirvan Nandy, Monika Jadi, Mitchell Morton",
        "date": "Thursday, 9 March 2023",
        "location": "I-105",
        "abstract": "Spatial vision is the ability to perceive visual objects within 3-dimensional space, and its dysfunction is detrimental to our ability to interact with the visual world. Our visual experience is a result of the concerted activity of neuronal ensembles in the sensory hierarchy. How the organization of objects in space influences interactions in this hierarchy is poorly understood. We investigated this question in the inter-laminar interactions in the visual cortex, a canonical motif of hierarchical information processing. We analyzed laminar electrophysiological recordings in cortical area V1 while monkeys viewed stimuli in isolation or with flanking stimuli at various spatial configurations that are known to exert a “crowding” effect on perception. Visual crowding is thought to be the primary limitation on object perception in peripheral vision, and the psychophysically identified “crowding zone” of impaired object identification is highly anisotropic. Employing reduced rank regression techniques, we assessed the extent to which trial-to-trial variability in the superficial layer could be predicted by the input layer. We found that the overall prediction accuracy in the inter-laminar communication subspace was weaker in the presence of crowding stimuli. Furthermore, the prediction accuracy was worst when the flanking stimuli were in the visual subspace that causes the strongest perceptual crowding effects. When we quantified the temporal dynamics of the prediction accuracy, the overall degradation due to crowding had a latency of ~45ms after the onset of visual responses in superficial layers of V1. The degradation specific to the visual subspace with the strongest crowding effects had an additional latency of ~14-18ms. Our results suggest a model in which perceptual impairment under crowding is mediated by visual context integration in the superficial layer of V1. The delays suggest that contextual inputs are conveyed through feedback pathways, and that the anisotropy in contextual inputs is the neural substrate of perceptual experience.",
        "url": "https://www.world-wide.org/cosyne-23/anisotropy-visual-crowding-reflected-401bced3"
    },
    "Place Field Dynamics as a Window on Synaptic Plasticity in the Hippocampus": {
        "title": "Place Field Dynamics as a Window on Synaptic Plasticity in the Hippocampus",
        "authors": "Antoine Madar & Mark Sheffield",
        "date": "Thursday, 9 March 2023",
        "location": "I-106",
        "abstract": "Although changes in synaptic efficacy are widely thought to be a substrate for memory storage in the brain, the rules of synaptic plasticity are difficult to assess in vivo and thus remain unclear. We considered the dynamics of hippocampal representations as an indirect indicator of ongoing plasticity during memory formation and familiarization. Using calcium imaging data from mice navigating virtual tracks, during which CA1 or CA3 neurons were recorded, we tracked the evolution of the spatial modulation of their activity (place fields) lap by lap. During exploration of a novel environment, 50% of CA1 place fields shifted, mostly backwards. The shift speed and proportion of shifting place fields was lower in CA3. To determine the mechanisms supporting these shifting dynamics, we simulated spiking place cells with plastic synapses following different plasticity rules. In contrast to early models, we found that classic Hebbian spike-timing-dependent-plasticity (STDP) is ill-suited to produce strong backward shifting when realistic firing rates and place field properties are maintained. Including inputs shifting like observed in CA3 was not sufficient to explain the shifts in CA1. Behavioral Timescale Synaptic Plasticity (BTSP), recently discovered in CA1, is an alternative candidate mechanism. Our new model of BTSP combined with homeostatic synaptic normalization points to BTSP, not STDP, as the main plasticity mechanism underlying the dynamics of spatial representations in CA1. It also suggests that BTSP occurs in CA3, albeit with phenomenological differences. Exploration of our model’s parameter space and mining of the experimental data for BTSP signatures further shows that the probability of BTSP-triggering events is dynamic: it decreases after place field onset and with familiarity to the environment. Overall, our study supports BTSP as a prominent type of plasticity in vivo, provides new insights in its phenomenology and new ways to incorporate it in computational models of spiking neurons.",
        "url": "https://www.world-wide.org/cosyne-23/place-field-dynamics-window-synaptic-d7c4b3f8"
    },
    "Vector production via mental navigation in the entorhinal cortex": {
        "title": "Vector production via mental navigation in the entorhinal cortex",
        "authors": "Sujaya Neupane, Ila Fiete, Mehrdad Jazayeri",
        "date": "Thursday, 9 March 2023",
        "location": "I-107",
        "abstract": "Cognitive maps are hypothesized memory systems that organize sensory experience into knowledge that can be used flexibly in novel scenarios, such as finding new routes during navigation. Evidence for this hypothesis has been largely limited to experiments with fully observable sensory information. However, to serve as a genuine internal source of knowledge, cognitive maps should also be able to support mental computations in the absence of external cues. To test this hypothesis, we developed a mental navigation task in which monkeys must produce vectors that correspond to moving between pairs of randomly selected start and target positions along a fixed and previously experienced sequence of landmarks without visual feedback. Animals succeeded in this task and generalized to unseen landmark pairs, suggesting that they relied on a cognitive map of the landmark sequence. We next recorded from the entorhinal cortex (EC), as a hypothesized substrate for the cognitive map. We found that neurons in a subregion of EC were task modulated and exhibited a periodicity matching the inter-landmark interval. Some EC neurons additionally showed ramping activity with distance-dependent end states, consistent with path integration. We found that neuron pairs with high periodicity scores showed trial- and context-invariant cross-correlation structure, a signature of grid cell continuous attractor network (CAN) states. We thus built a CAN model of entorhinal grid cells augmented with a Hebbian learning mechanism for memorizing the landmark sequence. Attractor states in the model constrained mental navigation such that internally learned landmark inputs transiently slowed the dynamics, acted as local resets, and reduced the overall variability of path integration. Consistent with the predictions from the CAN model, animals’ behavioral variability was captured by a dynamic process punctuated by landmark-induced reset events. Our work thus connects the neural phenomenon of EC periodic neurons to the ability to perform mental navigation.",
        "url": "https://www.world-wide.org/cosyne-23/vector-production-mental-navigation-a66818ec"
    },
    "Resilience to sensory uncertainty in the primary visual cortex": {
        "title": "Resilience to sensory uncertainty in the primary visual cortex",
        "authors": "Hugo Ladret, Nelson Cortes, Lamyae Ikan, Frederic Chavane, Christian Casanova, Laurent Perrinet",
        "date": "Thursday, 9 March 2023",
        "location": "I-108",
        "abstract": "Our daily endeavors occur in a complex visual environment, whose intrinsic variability shapes the way we integrate information to make decisions. By processing thousands of parallel sensory inputs, our brain is theoretically able to compute the uncertainty of its environment, which would allow it to perform Bayesian integration of its internal representations and its new sensory inputs to drive optimal inference. While there is convincing evidence that humans do compute this sensory uncertainty to guide their behavior, the actual neurobiological and computational principles on which uncertainty computations rely are still poorly understood. Here, we generated naturalistic stimuli of controlled uncertainty and performed a model-based analysis of their electrophysiological correlates in the primary visual cortex. Firstly, we report two layer-specific neuronal responses : infragranular layer neurons were vulnerable to increments of uncertainty, contrarily to supragranular neurons who were resilient, to the point of sometimes reducing uncertainty from the input. Secondly, we used neural decoding to show that these two responses have two different functional population roles: vulnerable neurons encode only the sensory feature (here, orientation) of the input, while resilient neurons co-encode both the sensory feature and its uncertainty. Finally, we implemented a recurrent leaky integrate-and-fire neural network to mechanistically demonstrate that these different types of responses to uncertainty can be explained by different types of recurrent connectivity between cortical neurons. Overall, we provide neurobiological and computational evidences which pinpoint recurrent interactions as the neural substrate of computations on sensory uncertainty. This fits theoretical considerations on canonical microcircuit in the cortex, potentially establishing uncertainty computations as a new general role for local recurrent cortical connectivity.",
        "url": "https://www.world-wide.org/cosyne-23/resilience-sensory-uncertainty-primary-88600879"
    },
    "Modularity emerges in neural networks trained to perform context-dependent behavior": {
        "title": "Modularity emerges in neural networks trained to perform context-dependent behavior",
        "authors": "W. Jeffrey Johnston & Stefano Fusi",
        "date": "Thursday, 9 March 2023",
        "location": "I-109",
        "abstract": "Humans and other animals often perform similar actions in different contexts. For instance, we use different criteria when judging whether an apple or avocado are ripe, but use very similar motor actions to move the fruit into our basket if we select it. We hypothesize that this ability to context switch is facilitated by functional modularity within brain regions, such as the specialization of a subpopulation of inferotemporal cortex neurons for face relative to non-face features. However, the link between this functional modularity and context-dependent behavior is not fully understood. Here, we show that functional modularity emerges in feedforward neural networks when they are trained to perform context-dependent tasks, even without any metabolic or anatomical constraints. In this setting, the network always uses the same output dimensions -- analogous to different motor actions -- but must learn to use a unique decision rule for each context, as in the case above. First, we analyze the representational geometry within the modules developed by the network and show that the representations are both abstract (or, disentangled) and flexible. That is, they enable generalization across different conditions even within a single module and they enable novel, nonlinear tasks to be learned with a simple linear readout. Next, we show that these modular representations emerge due to the geometry of the output and the known implicit bias of feedforward networks for shared representational structure. In particular, we show that the modular solution to the tasks has more shared structure than non-modular solutions. This work makes predictions for when and where modular structure will be observed in neural populations. In particular, we predict that modular structure will emerge when the same outputs are used in conflicting behavioral contexts. We are working to connect these results to experimental data that does, and does not, show modularity.",
        "url": "https://www.world-wide.org/cosyne-23/modularity-emerges-neural-networks-trained-01304d4a"
    },
    "A hypothalamic circuit underlying dynamic control of instinctive social need": {
        "title": "A hypothalamic circuit underlying dynamic control of instinctive social need",
        "authors": "Ding Liu, Mostafizur Rahman, Autumn Johnson, Nicolai Pena, Catherine Dulac",
        "date": "Thursday, 9 March 2023",
        "location": "I-110",
        "abstract": "Social interaction is a fundamental and evolutionarily conserved need. Social grouping decreases the risk of predation, reduces energy consumption and leads to mutually beneficial behaviors such as parenting and group foraging. By contrast, social isolation leads to a range of mental and physical problems in both human and animals. However, how the brain controls instinctive social need and what neuronal populations and circuits are involved, remain unknown. In this study, we report the identification of novel populations of hypothalamic neurons in the medial preoptic nucleus (MPN) in mice that are activated by either social isolation (MPN-isolation neurons) or social reunion (MPN-reunion neurons) and form a unique local excitation-inhibition microcircuit regulating a dynamic balance between social seeking and social satiety. Using micro-endoscopic Ca2+ imaging in freely behaving animals, we uncovered the sustained activation of MPN-isolation neurons during social isolation and their persistent inhibition during social reunion, therefore serving as a social state indicator. Using functional circuit mapping approaches, we found that local GABAergic neurons that are activated by social interaction have direct inhibitory input onto MPN-isolation neurons and thus likely provide social satiety signal. The functional contributions of these neurons to social need were causally assessed by optogenetic approaches. Moreover, cell type-specific viral-mediated neural tracing uncovered the connectivity between these neuronal populations and brain areas associated with emotional state, social reward as well as metabolism, offering an overarching understanding of the brain regulation of social need. Finally, we have identified social touch as an important sensory input modulating social need and social satiety. By monitoring population activity, manipulating cell-type specific neuronal activity and mapping brain-wide connectivity, this study uncovers local and global circuit mechanisms underlying social homeostasis.",
        "url": "https://www.world-wide.org/cosyne-23/hypothalamic-circuit-underlying-dynamic-95dd998a"
    },
    "Differential effects of positive versus negative drug reinforcement on contextual coding": {
        "title": "Differential effects of positive versus negative drug reinforcement on contextual coding",
        "authors": "Yanjun Sun & Lisa Giocomo",
        "date": "Thursday, 9 March 2023",
        "location": "I-111",
        "abstract": "Re-exposure to drug-associated spatial contexts often provokes drug craving and relapse. The hippocampus plays a critical role in drug associative learning, with a recent study reporting that drug-context associations were encoded in a specific group of CA1 place cells1. In addition to position (P) coding, both head direction (H) and speed (S) coding in the hippocampus2,3 were shown for encoding a given context. These navigational variables can be encoded conjunctively in place cells to support the acquisition of context-specific memories3,4. Contexts associated with either drug rewards or withdrawal can lead to drug-seeking behavior. However, it is unknown how these opposing drug effects change the contextual coding of the hippocampus through multiple navigational variables. To address this question, we performed morphine (MO) conditioned place preference (CPP) and conditioned place aversion (CPA) to model the contextual association with drug reward and withdrawal, meanwhile imaged the Ca2+ activity of individual CA1 neurons using miniscopes. To dissociate neural coding from correlated navigational variables, we used a linear-non-linear Poisson (LN) model5 to account for deceptive correlations and unbiasedly identify neurons that encode single vs. mixed navigational variables. These variables include position (P), head direction (H), speed (S) and all their possible combinations (mixed selectivity, i.e., PH, PS, HS, and PHS). As a result, we found drug rewards (CPP) primarily decreased the number of position coding only place cells, leaving mixed selective place cells unaffected, whereas drug withdrawal (CPA) primarily increased the number of mixed selective place cells but not position coding only place cells. Neither effect was seen in a sucrose CPP experiment, despite the same behavioral change. Together, using an LN model, our work revealed the distinct impact of opposing drug reinforcement on the contextual coding in the hippocampus, providing insights into how hippocampal computations support the transition from voluntary to compulsive drug use.",
        "url": "https://www.world-wide.org/cosyne-23/differential-effects-positive-versus-01b0b2a1"
    },
    "Human Spinal Epidural Neuromodulation Modeling and Stimulation Effect Prediction": {
        "title": "Human Spinal Epidural Neuromodulation Modeling and Stimulation Effect Prediction",
        "authors": "Hongda Li & Yanan Sui",
        "date": "Thursday, 9 March 2023",
        "location": "I-112",
        "abstract": "Spinal neuromodulation via epidural electrical stimulation is a promising therapy for motor function restoration of patients with spinal cord injury. By applying specific sequences of electrical stimulation to the spinal cord through the electrode array, the patient can achieve multiple movements. However, one of main difficulties of this therapy is that the mapping between stimulation parameters and body motions is complex and ambiguous. To achieve specific actions, it often requires a large number of experiments to tune stimulation parameters. Individual differences of functional innervation and huge stimulation parameter space make the parameter-tuning process more challenging. It is also important to prevent potential damage to the patient while exploring new parameters. To better understand human spinal neuromodulation process and predict the effect of epidural electrical stimulation, we developed a personalized hybrid model with finite element method and biophysical neural computation. The high-precision finite element model of the spinal cord and electrode array was build based on CT and MRI of a spinal cord injured patient. Biophysical axon models were embedded in dorsal column, afferent and efferent nerve roots to calculate neural activities. The neural activation matrix was imported into a neural network to obtain the normalized activity intensity of targeted muscles. Learning from a small amount of stimulating parameters together with surface electromyography (EMG) data of the patient, our model can predict muscle activities of new stimulation parameters with high accuracy rate. The hybrid model can give reliable predictions whether a specific muscle would be strongly activated or not activated, which is very important for filtering out unsafe or ineffective parameters. The model could serve as a safe agent which computationally evaluate and predict effective stimulation parameters for motor function restoration. The model can also help with the optimization of the electrode array and revealing the mechanism of epidural spinal neuromodulation.",
        "url": "https://www.world-wide.org/cosyne-23/human-spinal-epidural-neuromodulation-a7864aab"
    },
    "Manifold representation in continuous attractor neural networks: a general constructive approach": {
        "title": "Manifold representation in continuous attractor neural networks: a general constructive approach",
        "authors": "Federico Claudi, Sarthak Chandra, Ila Fiete",
        "date": "Thursday, 9 March 2023",
        "location": "I-113",
        "abstract": "Low dimensional attractor dynamics have now been established as a core mechanism by which neural populations represent, remember, and compute with continuous-valued external variables. Arriving at this state in the field has relied on the intuition-guided construction of neural circuit models with continuous attractor dynamics that led to population-level predictions about dynamics, followed by validation from large-scale recordings. Recent deep learning approaches require less intuition but extensive training to generate networks with continuous attractor and integrator dynamics, however extracting the essential components of the circuit that support their functionality (interpretibility) is challenging. Here we consider whether it is possible to take an alternative approach to these methods, and directly construct neural circuits that generate continuous attractor dynamics and velocity integration functionality appropriate for a given external variable with arbitrary topology. We first provide a general theory characterizing which variables and topologies can be faithfully mapped onto which manifolds and topologies. Second, we provide a direct and generic method for building neural networks whose dynamics lie on an arbitrary desired manifold, which we call the MADE (Manifold Attractor Direct Engineering) method. Third, we show how neural circuits can be directly and generically structured by MADE to perform path integration on the manifold. Just as the Hopfield prescription showed how to embed prespecified discrete states as discrete fixed points in a neural circuit, this work provides a prescription for how to embed prespecified continuous states as a continuous attractor manifold in a neural circuit. Thus, our theoretical work furthers our understanding of the relationship between neural manifold topologies and computation. The MADE general modeling framework provides a tool for directly building clearly interpretable and predictive circuit models of how the brain might represent and integrate arbitrary continuous variables for which we did not yet possess models.",
        "url": "https://www.world-wide.org/cosyne-23/manifold-representation-continuous-f281faf3"
    },
    "Musculoskeletal skill learning with curriculum-based Static to Dynamic Stabilization": {
        "title": "Musculoskeletal skill learning with curriculum-based Static to Dynamic Stabilization",
        "authors": "Nisheet Patel, Pablo Tano, Alberto Silvio Chiappa, Alex Pouget, Alexander Mathis",
        "date": "Thursday, 9 March 2023",
        "location": "I-114",
        "abstract": "Building realistic models for complex and skilful motor tasks such as dexterous object manipulation is hampered by two key challenges: the need for physiologically-detailed musculoskeletal models and powerful algorithms that are able to tackle such high-dimensional problems. The newly released MyoSuite ecosystem provides such musculoskeletal models and is 4000x faster than previous simulators, thereby enabling us to develop and test algorithms for agile object manipulation. Combining ideas from stochastic optimal control and reinforcement learning (RL), we develop a training curriculum called Static to Dynamic Stabilization (SDS). The SDS curriculum first learns stable static solutions at several intermediate points along the desired object trajectory and gradually relaxes them to yield dynamically stable movement motifs. Akin to coaching techniques for skill-learning in humans, SDS allows the agent to experience intermediate configurations before learning a policy that reaches those configurations from the default initial state of the task at hand. We trained a policy gradient method using the SDS curriculum on the Baoding Balls task which involves rotating two balls in the hand. The task is extremely challenging since the environment is noisy, unstable, partially observable, and involves a time-varying decision-making component. Our model beat all SOTA baselines by a wide margin and won the MyoChallenge, a NeurIPS 2022 competition hosted by Meta AI. To the best of our knowledge, our model is the first successful example of fully-learned musculoskeletal control in a highly skilled object manipulation task. This highlights the usefulness of the SDS curriculum to develop realistic, high-performance sensorimotor models, thereby paving the way to compare and contrast artificial and biological control systems performing arbitrarily complex motor skills.",
        "url": "https://www.world-wide.org/cosyne-23/musculoskeletal-skill-learning-with-ca556563"
    },
    "maskNMF: a denoise-sparsen-detect pipeline for demixing dense imaging data faster than real time": {
        "title": "maskNMF: a denoise-sparsen-detect pipeline for demixing dense imaging data faster than real time",
        "authors": "Amol Pasarkar, Liam Paninski, Pengcheng Zhou, Melissa Wu, Ian Kinsella, Daisong Pan, Jiang Lan Fan, Zhen Wang, Lamiae Abdeladim, Darcy Peterka, Hillel Adesnik, Na Ji",
        "date": "Thursday, 9 March 2023",
        "location": "I-115",
        "abstract": "In recent years, many calcium and voltage imaging methods have been developed in pursuit of a central goal of systems neuroscience: to study the function of large populations of neurons. Projective imaging methods, such as Bessel imaging, are a promising class of approaches in pursuit of this goal. These methods simultaneously record neural activity at a wide range of depths in the brain, effectively allowing scientists to image a volume of brain tissue. However, this added capability comes with a trade-off: all observed signals from the volume are projected onto a 2D imaging plane. Therefore, these signals must be computationally demixed to recover the desired neural activity. Furthermore, these large-scale recordings demand computationally fast analyses. We address these needs with a GPU accelerated algorithm, maskNMF, which can demix hour-long Bessel data within minutes. The key strategy in maskNMF is to first estimate the spatial profiles of the neurons, and use these estimates as a starting point for spatially and temporally demixing the entire dataset. To that end, we begin by registering and compressing the imaging video. This has the added benefit of denoising the data. Next, we use a deconvolution operation on the compressed data to temporally sparsen the imaging video. The result typically contains spatially isolated neurons in each frame. We use a neural network trained automatically on simulated calcium imaging data to detect these isolated neural shapes. We then use these spatial shapes to initialize a constrained nonnegative matrix factorization model (NMF) to perform signal demixing. Our method can accurately demix denser data than was previously feasible, enabling imaging of larger neural populations. We have validated this method on both real and simulated data and provide a detailed comparison of how state-of-the-art methods compare to maskNMF as imaging density increases.",
        "url": "https://www.world-wide.org/cosyne-23/masknmf-denoise-sparsen-detect-pipeline-aef225e4"
    },
    "The combinatorial code and the graph rules of Dale networks": {
        "title": "The combinatorial code and the graph rules of Dale networks",
        "authors": "Nikola Milicevic & Vladimir Itskov",
        "date": "Thursday, 9 March 2023",
        "location": "I-116",
        "abstract": "Relating connectivity features to the function of a recurrent neuronal network is a longstanding problem that still remains at large. To this end we describe the combinatorics of equilibria and steady states of neurons in recurrent networks that satisfy the Dale’s law. It turns out that the combinatorial code of a Dale network can be characterized in terms of two properties: (i) the network connectivity graph, and (ii) a spectral condition on the synaptic matrix. We find that in the weak coupling regime the combinatorial code depends only on the connectivity graph, and not on the particulars of the synaptic strengths. Moreover, we prove that the combinatorial code of a weakly coupled network is a sublattice, and we provide a learning rule for learning a sublattice in such a network. Neural activity in sensory areas of the brain is shaped both by the stimulus and by the internal neural dynamics. Receptive fields of individual neurons are convex in a number of brain regions (such as the hippocampus, and the visual cortex). Not any combinatorial code is compatible with convex receptive fields. This raises a natural question: how do recurrent networks produce convex codes? Surprisingly, we find that the architecture of a Dale network “enforces” convex code output, both in weak and strong coupling regimes.",
        "url": "https://www.world-wide.org/cosyne-23/combinatorial-code-graph-rules-dale-networks-545336eb"
    },
    "Synaptic low-rank modulation facilitates adaptation in cortical networks": {
        "title": "Synaptic low-rank modulation facilitates adaptation in cortical networks",
        "authors": "Ivan Bulygin, James Ferguson, Tim Vogels",
        "date": "Thursday, 9 March 2023",
        "location": "I-117",
        "abstract": "The human brain quickly adapts to a rapidly changing environment, often faster than what is thought to be possible by way of synaptic plasticity. Real-time control adaptation can only be achieved through faster processes such as neuromodulation. A number of neuromodulation models based on gain regulation have been proposed recently. But most of them utilize neuron-wide regulation and can not accommodate the simultaneous impact of different types of neurotransmitters on different parts of the dendritic tree. Models of synaptic gating and connectivity-tuning demonstrate that using enough additional parameters, one can mold a desired task into the network. Nevertheless, the relationship between the minimal amount of modulation and dimensionality of the task variation is not understood. Here, we address both of these questions using tractable representations of synaptic neuromodulation in recurrent neural networks (RNNs). Consistent with the experimental findings, modulation is performed by an external network of modulatory neurons, adapting their strengths and direction of modulation in response to the task variation. We introduce fixed synaptic masks, representing susceptibilities of the individual synapses to the neurotransmitter release from each modulatory neuron. These masks form a scaffold for neuromodulation patterns that can be applied to the network through activation of corresponding modulatory neurons. We observe that appropriate combination of masks can effectively mold network connectivity, adapting it to the changed environment. Specifically, we demonstrate how synaptic modulation can facilitate performance of the network on varying tasks of pattern discrimination and detection and link the (minimum) number of modulatory controls to the degrees of freedom in task variation. Our approach creates a useful framework for improving the mechanistic understanding of rapid adaptation in neural circuits. We shift the focus from synaptic plasticity as learning mechanism for one task to flexible neuromodulation that fits an entire subspace of tasks.",
        "url": "https://www.world-wide.org/cosyne-23/synaptic-low-rank-modulation-facilitates-8d47a6e9"
    },
    "Stable geometry is inevitable in drifting neural representations": {
        "title": "Stable geometry is inevitable in drifting neural representations",
        "authors": "Evan Schaffer",
        "date": "Thursday, 9 March 2023",
        "location": "I-118",
        "abstract": "In many brain regions, the stimulus tuning of neurons is stable on a timescale of hours but not on a timescale of weeks, a phenomenon often called ‘representational drift’. For example, in piriform cortex, which is commonly considered primary olfactory cortex, the cells responsive to a given odor are completely uncorrelated with those activated by the same odor two weeks later (Schoonover et al., 2021). This would seem to imply that piriform cortex, like other brain regions whose activity appears to drift, is useless for the retrieval of associative memories learned several weeks prior. However, decoding approaches have demonstrated that stable decoding of drifting representations is possible (Rule et al., 2020). While these previous computational results offer a very plausible resolution to the paradox of how the brain operates with drifting representations, we lack a deep understanding of why this works. Here, we offer a very general mathematical understanding of why stable decoding from drifting representations is possible. We demonstrate that under very weak assumptions, the downstream layer in a two-layer network is guaranteed to act as a tight frame for the representation space of the upstream layer. A tight frame shares many features of an orthogonal basis, including preserving the geometry of relationships between input patterns. Drifting representations that have stable geometry are decodable; thus, the ability to decode from drifting representations is essentially inevitable. Finally, we reconcile these theoretical results with empirical results that appear to show a lack of stable geometry in drifting representations by showing that the discrepancy is due to the number of simultaneously recorded neurons.",
        "url": "https://www.world-wide.org/cosyne-23/stable-geometry-inevitable-drifting-becbbdc0"
    },
    "Developmentally structured coactivity and plasticity in the hippocampal trisynaptic loop": {
        "title": "Developmentally structured coactivity and plasticity in the hippocampal trisynaptic loop",
        "authors": "Roman Huszar, Dhananjay Huilgol, Jiaxi Liu, Josh Huang, György Buzsáki",
        "date": "Thursday, 9 March 2023",
        "location": "I-119",
        "abstract": "Research into the hippocampus has long emphasized its plasticity (McClelland et al., 1995), though recent reports have highlighted its remarkably stable firing patterns (Mizuseki et al., 2013). How plasticity updates networks maintaining their dynamics remains an open question, largely due to a lack of experimental access points into network stability. Development may provide one such access point. We previously showed that CA1 pyramidal neurons of the same embryonic birthdate exhibit prominent cofiring across different brain states and overlapping place tuning during behavior (Author et al., 2022). Prior anatomical work showed that same birthdate neurons across hippocampal subregions (DG-CA3, CA3-CA1) are synaptic partners (Deguchi et al., 2011). This suggests developmentally installed, functionally relevant circuit motifs throughout the entire hippocampal trisynaptic loop. Here, we investigate this hypothesis by monitoring activity of same birthdate excitatory neurons across all hippocampal subregions and study how it updates with learning. First, neural ensembles of the dentate gyrus (DG) and CA3 were monitored with high density silicon probes, and birthdate-defined populations expressing ChR2 were identified in vivo with short-pulse optogenetics. Same birthdate DG granule cells displayed prominent coactivity in dentate spikes, a population pattern triggered by entorhinal input. Furthermore, CA3 neurons that co-discharged upon mossy-fiber stimulation tended to cofire during spontaneous activity bursts. This suggests that same birthdate granule cells shape the activity of downstream CA3 partners, consistent with their synaptic interconnectedness (Deguchi et al., 2011). To directly explore the interactions and plasticity of same birthdate populations across synaptically connected areas, we birthdated populations of CA3 and CA1 neurons and monitored their joint activity during a hippocampus dependent learning task requiring plasticity (Dupret et al., 2010). Same birthdate CA1 and CA3 pyramidal neurons exhibited overlapping place fields, which remapped together with learning. This indicates that plasticity-dependent synaptic modifications are subject to a developmental circuit constraint.",
        "url": "https://www.world-wide.org/cosyne-23/developmentally-structured-coactivity-e3c13a82"
    },
    "Neural representation and predictive processing of dynamic visual signals": {
        "title": "Neural representation and predictive processing of dynamic visual signals",
        "authors": "Pierre-Étienne Fiquet & Eero Simoncelli",
        "date": "Thursday, 9 March 2023",
        "location": "I-120",
        "abstract": "All organisms make temporal predictions, and their evolutionary fitness level generally scales with the accuracy of these predictions. In visual perception, observer motion and continuous deformations of objects and textures imbue our visual input with distinct temporal structures, enabling partial prediction of future inputs from past ones. Inspired by recent hypotheses that primate visual representations support prediction by ``straightening'' the temporal trajectories of naturally-occurring input (Henaff et. al., 2019), we formulate an architecture for image representation that facilitates prediction by linearizing the temporal trajectories of frames of natural video. To facilitate this goal, we note that many deformations can be described as linear advances in the phase of a complex-valued representation. The most well-known example is that of the Fourier transform, whose complex coefficients have constant amplitude and shifting phase under translational motion, but the concept generalizes to all compact commutative Lie groups. We train a network to optimize next-frame predictions over large natural video datasets and show that it achieves performance on par with (or better than) that of traditional motion compensation and conventional deep networks while remaining interpretable and fast. The learned filters come in conjugate phase-shifted pairs and are selective for orientation and scale, which is reminiscent of the models used to describe selectivity of primary visual cortex neurons. Our results demonstrate the potential of a principled video processing framework for modeling visual processing and eventually linking behavioral performance with neural computations.",
        "url": "https://www.world-wide.org/cosyne-23/neural-representation-predictive-processing-2f7b22ab"
    },
    "Pre-training artificial neural networks with spontaneous retinal activity improves image prediction": {
        "title": "Pre-training artificial neural networks with spontaneous retinal activity improves image prediction",
        "authors": "Lilly May, Alice Dauphin, Julijana Gjorgjieva",
        "date": "Thursday, 9 March 2023",
        "location": "I-121",
        "abstract": "The processing of natural visual environments rich with motion is central to animal survival. Many aspects of perceiving and detecting visual motion are already mature before the onset of visual experience. How the visual system develops to enable these functions in the absence of external stimuli remains unclear. A prominent transient feature of developing circuits is the ability to generate complex spatiotemporal patterns of spontaneous activity, even before sensory organs mature. For example, before vision onset in the mammalian retina, activity propagates in the form of spatiotemporally structured patterns known as waves, which have been implicated in the refinement of different aspects of circuit connectivity and function. This includes the formation of gross retinotopic maps and the refinement of receptive fields in downstream visual areas like the thalamus, superior colliculus, and visual cortex. Recent work showed that retinal waves in mice contain statistical features of real-world visual stimuli such as optic flow (Ge et al., 2021), suggesting they could also play an important role in preparing the visual system for motion processing. While recent biologically-constrained networks implicate retinal waves in network connectivity refinements, we wondered whether state-of-the-art artificial neural network (ANN) models trained on natural movies show improved performance if pre-trained with retinal waves. Indeed, we found that pre-training ANNs with retinal waves significantly improves the processing of real-world visual stimuli and temporarily accelerates learning. We further investigated how other aspects of retinal waves, such as their propagation bias, may influence the learning speed and network performance on both retinal wave and natural movie datasets. Overall, our work sheds light on the functional role of spatiotemporally patterned spontaneous activity in the processing of motion in natural scenes, suggesting that they provide a training signal to prepare the developing visual system for adult visual processing.",
        "url": "https://www.world-wide.org/cosyne-23/pre-training-artificial-neural-networks-c01bd545"
    },
    "Learning representations of environmental priors in visual working memory": {
        "title": "Learning representations of environmental priors in visual working memory",
        "authors": "Tahra Eissa & Zachary Kilpatrick",
        "date": "Thursday, 9 March 2023",
        "location": "I-122",
        "abstract": "Experience helps us learn the structure of the environment. Such learning can be described by statistical inference models in which environmental priors adapt to new information across time and influence future estimates. For instance, we may learn that certain colors are overrepresented in the world (e.g., I will see more greens and browns if I am in a forest), leading to cognitive biases in favor of more common environmental features. Humans display systematic biases when retaining estimates of an object's features in working memory, which may reflect learned priors of object feature values. However, the neural mechanisms that support inferring the environmental prior and producing biases in working memory have not been identified. We build on observations from human response data that show systematic biases in a delayed-estimation task of color reports to determine if humans modulate their biases based on their experience. Considering subject responses when task stimuli (colors) were drawn from heterogeneous distributions that did not necessarily correspond with reported population biases, we confirm that most subjects’ response distributions are better described by models that learn feature distributions than those that do not. We also found that a neural circuit model that infers the environmental prior via long-term potentiation and homeostatic plasticity could replicate these behavioral findings and represent experienced stimulus history. Changes to synaptic connectivity shape the persistent and collective neural activity that encodes the stimulus estimate in working memory, producing neural activity attractors are aligned to common stimulus values and mechanistically implementing probabilistic priors. This work suggests that systematic limitations in working memory reflect efficient representations of inferred environmental structure, providing new insights into how humans integrate environmental knowledge into their cognitive strategies.",
        "url": "https://www.world-wide.org/cosyne-23/learning-representations-environmental-f36960dd"
    },
    "Flexible boolean computation by auditory neurons": {
        "title": "Flexible boolean computation by auditory neurons",
        "authors": "Grace Ang & Andriy Kozlov",
        "date": "Thursday, 9 March 2023",
        "location": "I-123",
        "abstract": "Neurons have rich input-output functions for pooling and transforming inputs, owing to dendritic nonlinearities and adaptation. These nonlinearities are also flexible, adapting to accomodate changes in stimulus statistics (Młynarski and Hermundstad, 2021) or to extract different features from sensory space (Deny et al., 2017). Thus far, our understanding of the complex transformations by neurons has been largely informed by experiments which directly activate synaptic inputs on dendrites. However, these do not consider how natural and complex stimuli map to neuronal inputs. Our study uses ethologically-relevant and real-world sensory stimuli to probe neuronal integration functions. In auditory cortex in mice, we record extracellular single unit spikes to pairs of ultrasonic mouse vocalization (USV) syllables, which were selected and combined according to the neuron's responses. Many stimulus pairs produced a summation response (quantified by the summation index, SmI) that resembled the MAX operation: a pair of superimposed syllables evoked a response that was similar to the response to each syllable presented in isolation, instead of a linear summation, in agreement with Kozlov and Gentner (2014). To investigate the changes in integration behaviour to simple input transformations, we pitch-shifted syllables of a pair. Summation did not depend on the spectral separation between syllables in a pair. Instead, summation became more OR-like for pitch-shifted versions (of the same syllable pair) that were preferred by the neuron. When summation was more AND-like, we observed an increase in spike temporal precision to superimposed syllables, which could indicate increased selectivity. This flexibility in neuronal computation contrasts with neural activation functions artificial networks, which are limited to a prescribed set and fixed across units and time. Recent work has suggested that adopting flexible biological nonlinear activation functions improve task performance of artificial neural networks (Geadah et al, 2020). Examining how single neurons multiplex different computations may have interesting functional implications for network computation.",
        "url": "https://www.world-wide.org/cosyne-23/flexible-boolean-computation-auditory-ee4372ab"
    },
    "Improved estimation of latent variable models from calcium imaging data": {
        "title": "Improved estimation of latent variable models from calcium imaging data",
        "authors": "David Zoltowski, Adam Charles, Jonathan W. Pillow, Stephen Keeley",
        "date": "Thursday, 9 March 2023",
        "location": "I-124",
        "abstract": "Calcium imaging (CI) has emerged as a prominent method for recording neural population activity. Therefore, CI recordings are prime candidates for the application of latent variable models designed to identify latent neural states and dynamics. However, in CI experiments spiking events are measured only indirectly via calcium ions that rapidly enter a cell during action potentials and then slowly seep back out. To analyze CI data, per-neuron fluorescence time-traces are typically either de-convolved to approximate spiking events or analyzed directly. The former approach, although enabling many methods developed for spiking data to be trivially applied to CI, can introduce errors via mis-estimation of spikes. Alternatively, direct modeling typically relies on Gaussian observation models, despite the mismatch to autoregressive calcium dynamics. Here, we develop accurate yet tractable models for characterizing the latent structure of neural population activity directly from CI data. We augment three standard neural population models, Gaussian Process Factor Analysis (GPFA), hidden Markov Models (HMMs), and latent dynamical systems, with a CI observation model (Ganmor et al. 2016). The CI observation model has autoregressive calcium dynamics with spike count influxes driven by a latent Poisson variable, and therefore can address both of the shortcomings of deconvolution and Gaussian observation approaches. To fit the models, we develop inference methods using variational and Laplace approximations. We demonstrate that using a more accurate CI observation model improves latent variable inference and model fitting on both CI generated using state-of-the-art biophysical simulations, as well as imaging data recorded in an experimental setting. Finally, we also propose extensions to the CI observation model to account for nonlinear relationships between spiking activity and the calcium influx. We expect the developed methods to be widely applicable for analysis of CI recordings.",
        "url": "https://www.world-wide.org/cosyne-23/improved-estimation-latent-variable-ae43e0fb"
    },
    "Decreased interictal EEG slowing is consistent with increased multiple timescale neural adaptation": {
        "title": "Decreased interictal EEG slowing is consistent with increased multiple timescale neural adaptation",
        "authors": "Brian Lundstrom & Thomas Richner",
        "date": "Thursday, 9 March 2023",
        "location": "I-125",
        "abstract": "Human invasive EEG recordings are used to guide clinical decision-making for epilepsy patients and offer an opportunity to better understand underlying neurophysiology. However, the relationship between macroscale electrophysiological recordings and underlying neural networks mechanisms remain unclear. Lundstrom et al [1,2] have shown that interictal (between-seizure) low frequency EEG activity (<1 Hz) is decreased at the seizure onset zone (SOZ), while higher frequency activity (1-50 Hz) is increased. These changes result in interictal power spectral densities (PSDs) with flattened slopes near the SOZ, which are areas of increased neural excitability. We hypothesized that these observations are consistent with changes in short-term plasticity, or adaptation, within the neural circuit. We used filter-based neural mass models and conductance-based models that incorporated short-term plasticity, including spike frequency adaptation and synaptic depression. We focused on multiple timescales of adaptation, which can approximate fractional dynamics, a form of calculus related to power laws and history dependence that is related to neural adaptation [3,4]. We found that when multiple timescale adaptation approximates fractional dynamics, PSDs retain a linear form with a decreased slope, similar to experimental findings. Coupled with input changes, short-term plasticity changed circuit responses in unexpected ways. For example, although increased input typically increases broadband power, increased input with synaptic depression may decrease power. The effects of adaptation were most pronounced for low frequency activity (< 1Hz). Increased input combined with a loss of adaptation yielded reduced low frequency activity and increased higher frequency activity, consistent with clinical EEG observations near the SOZ. Modeling supports increased multiple timescale adaptation as a reasonable explanation for decreased interictal EEG slowing near the SOZ. Changes in neural adaptation and short-term plasticity may be evident in macroscale electrophysiological recordings and provide a window to assessing and understanding neural circuit excitability.",
        "url": "https://www.world-wide.org/cosyne-23/decreased-interictal-slowing-consistent-ac95b73c"
    },
    "Conditioning in hetero-associative neural networks trained with three-factor predictive plasticity": {
        "title": "Conditioning in hetero-associative neural networks trained with three-factor predictive plasticity",
        "authors": "Pantelis Vafidis & Antonio Rangel",
        "date": "Thursday, 9 March 2023",
        "location": "I-126",
        "abstract": "Animals learn from experience the value of environmental stimuli and adjust their behavior accordingly. At the core of animal conditioning lies the capacity to associate a neural activity pattern induced by an unconditioned stimulus (US) with the pattern arising in response to a conditioned stimulus (CS). Reward-modulated associative synaptic plasticity has been successful in explaining conditioning when the neural representations of behavioral stimuli are unmixed. However, this assumption is inconsistent with the fact that neurons --- particularly in high-level, cognitive areas --- display mixed selectivity. Inspired by experimental findings on the associative power of single cortical pyramidal neurons, we propose a computational model that achieves generic pattern-to-pattern mappings at the population level. Our model incorporates a local learning rule operating in compartmentalized neurons, which mirrors the capacity of cortical pyramidal neurons to implement predictive learning through coincidence detection. These properties confer crucial advantages over three-factor Hebbian plasticity in point neurons and allow our model to account for a wide gamut of conditioning phenomena, including trace and delay conditioning, extinction, reported neuromodulator dynamics, the S-shaped acquisition curve characteristic of animal conditioning and the drop in conditioning effectiveness with larger delays between the CS and the US. Allowing for the simultaneous presentation and competition of CSs naturally gives rise to phenomena like blocking, overshadowing, saliency effects and overexpectation. Finally, examining the impact of CS contingency on conditioning we find that the model offers a reductionist mechanism for causal inference by resolving the post hoc fallacy, which states that when event Y occurs after event X, then X is considered its cause. The model makes testable predictions about the evolution of neural mixed representations during conditioning experiments that might prove useful to understand existing datasets and guide future experiments. In phychological terms, it corresponds to the stimulus substitution component of classical conditioning.",
        "url": "https://www.world-wide.org/cosyne-23/conditioning-hetero-associative-neural-8a21c0a5"
    },
    "Place Cells are Clustered by Field Location in CA1 Hippocampus": {
        "title": "Place Cells are Clustered by Field Location in CA1 Hippocampus",
        "authors": "Hannah Wirtshafter & John Disterhoft",
        "date": "Thursday, 9 March 2023",
        "location": "I-127",
        "abstract": "Both modern and historic neuroscience have been challenged by achieving an understanding of neuron cir-cuits, and determining the computational and organizational principles underlying these circuits. Deeper un-derstanding of the organization of brain circuits and cell types, including in the hippocampus, is required for neuroscience advances and understanding governing principles of the brain. In this manuscript, we pioneer a new mathematical method to analyze the spatial clustering of active neurons in the hippocampus. We use cal-cium imaging and a rewarded navigation task to record from 1000s of place cells in the CA1 of freely moving rats. We then use statistical techniques in widespread use in geographic mapping studies, global Moran’s I and local Moran’s I, to demonstrate that cells that code for similar spatial locations tend to form small spatial clusters. We show that these clusters are primarily formed by cells that have place fields around previously rewarded locations. That said, there is no obvious topographic mapping of environmental location onto the hippocampus. Insights into hippocampal organization, as in this study, can elucidate mechanisms underlying motivational behaviors, spatial navigation, and memory formation.",
        "url": "https://www.world-wide.org/cosyne-23/place-cells-clustered-field-location-cc1b1f61"
    },
    "Neural mechanisms of stream formation during active listening in the ferret auditory cortex": {
        "title": "Neural mechanisms of stream formation during active listening in the ferret auditory cortex",
        "authors": "Jules Lebert, Carla Griffiths, Joseph Sollini, Jennifer Bizley",
        "date": "Thursday, 9 March 2023",
        "location": "I-128",
        "abstract": "Listening in the real world involves making sense of mixtures of multiple overlapping sounds. The brain decomposes such scenes into individual objects, and a sequence of related auditory objects forms a stream. We are investigating the role of the auditory cortex in the formation and maintenance of auditory streams. The temporal coherence theory has provided one explanation for stream formation, postulating that the brain creates a multidimensional representation of sounds along different feature axes, and groups them based on their temporal coherence, to form streams. However, this theory has yet to be tested at the neural population level with naturalistic sounds. To investigate this question, we trained ferrets to detect a target word in a stream of random distractor words, spoken by the same talker, played in the presence of a spatially separated noise stream (speech-shaped noise). Neural data were collected in the auditory cortex of behaving ferrets. We found that the neural encoding of words is unaffected by the location of the stream in a single-stream task (p > 0.05). However, in the presence of a spatially separated competing stream, encoding of the words in the contralateral stream was significantly better than in the ipsilateral stream (p = 0.034). Interestingly, early in the trial, the ipsilateral stream decoding is at chance level, whereas towards the end of the trial it approaches that of the contralateral stream. These findings suggest that, in the presence of a competing noise stream, auditory cortical neural populations may quickly adapt to switch from representing the contralateral stream to representing the attended stream.",
        "url": "https://www.world-wide.org/cosyne-23/neural-mechanisms-stream-formation-during-0844bc93"
    },
    "Learning a visual representation by maximizing manifold capacity": {
        "title": "Learning a visual representation by maximizing manifold capacity",
        "authors": "Thomas Yerxa, Yilun Kuang, Eero Simoncelli, SueYeon Chung",
        "date": "Thursday, 9 March 2023",
        "location": "I-129",
        "abstract": "Biological visual systems learn complex representations of the world that support a wide range of cognitive behaviors without using a large number of labelled examples. The efficient coding hypothesis suggests that this is accomplished by adapting the sensory representation to the statistics of the input signal, i.e. in a way that facilitates redundancy reduction. Visual signals have several clear sources of redundancy. They evolve slowly in time, since temporally adjacent inputs typically correspond to different views of the same scene, which in turn are usually more similar than views of distinct scenes. Moreover, the variations within individual scenes often correspond to variations in a small number of parameters, such as those controlling viewing and lighting conditions. Motivated by these observations, we seek to learn a function that represents different views of the same scene with compact, low dimensional manifolds while simultaneously maximizing the separation between manifolds representing distinct scenes. Recent theoretical advances describe how these two notions of extent (dimensionality and size) can be combined in order to measure “manifold capacity”, a measure of the number of manifolds that can be linearly separated from each other in the representation space. In this work we demonstrate that optimizing a network for manifold capacity results in a representation that supports near state-of-the-art object recognition on several datasets, and is robust to adversarial stimulus perturbations. Both results are consistent with biological networks, since (1) performance on object classification has been shown to be correlated with fits to neural data and (2) vulnerability to adversarial stimulus perturbations is one of the hallmark differences between artificial and biological perception. This is an important first step demonstrating that coding efficiency can serve as a normative principle underlying robust object recognition.",
        "url": "https://www.world-wide.org/cosyne-23/learning-visual-representation-maximizing-a72e079f"
    },
    "Learning parsimonious dynamics for state abstraction and navigation": {
        "title": "Learning parsimonious dynamics for state abstraction and navigation",
        "authors": "Tankred Saanum & Eric Schulz",
        "date": "Thursday, 9 March 2023",
        "location": "I-130",
        "abstract": "Cognitive maps associate complex, high-dimensional stimuli, such as visual percepts, with abstract latent variables, such as spatial locations. It has been argued that animals use these abstract spatial features to navigate and infer novel shortcuts in their environments. Employing information theory, we present a simple computational account of how such abstract spatial representations may emerge from interactions with high-dimensional stimuli: We show that learning world models in which the dynamics are parsimonious and apply (approximately) independently of the state in an abstract state space give rise to spatial concepts, improved performance in navigation tasks and neural representations of space found in humans and rodents. Specifically, we show that artificial agents equipped with such world models i) outperform agents with non-parsimonious world models in planning tasks where they need to extrapolate about the dynamics of novel parts of the environment, and ii) learn latent state spaces that afford faster policy learning. By constructing latent spaces in which a small set of dynamical laws hold independently of where the agent may be in this space, our model uses a simple computational principle to explain how geometric representations of high- dimensional worlds emerge. Additionally, these parsimonious world models allow for systematic generalization about transition dynamics in a way reminiscent of those of animals, and provide an information-theoretic account of the emergence of the neural representations associated with these abilities.",
        "url": "https://www.world-wide.org/cosyne-23/learning-parsimonious-dynamics-state-31ee0754"
    },
    "Apparently high-dimensional spontaneous neural activity is locally low-dimensional in time": {
        "title": "Apparently high-dimensional spontaneous neural activity is locally low-dimensional in time",
        "authors": "Pranjal Gupta, Trevor Alston, John Pearson",
        "date": "Thursday, 9 March 2023",
        "location": "I-131",
        "abstract": "It has been commonly reported across species and brain regions that neural population dynamics are low-dimensional, leading to a broad range of theories on the significance of this structure [1, 2]. However, several recent studies have reported that spontaneous activity in rodent sensory regions is high-dimensional [3], presenting a challenge to explanations which posit low-dimensional dynamics as integral to neural computations. Here we hypothesized that the observation of high-dimensional population dynamics in these datasets results from neural activity progressing through a series of low-dimensional manifolds. That is, dynamics which seem to explore a high-dimensional subspace over a long period of time may be better described as dynamics which explore many low-dimensional subspaces over many short periods of time, where the high-dimensional space is composed of the union of the low-dimensional subspaces. We developed a novel statistical model and algorithm termed SPLAT to quantify the time-local dimensionality of neural population activity, defined as the number of active latent neural patterns during a small segment of time. We first established in synthetic data how SPLAT correctly recovers temporally sparse low-dimensional structure that appears high-dimensional when analyzed by PCA. We then applied this method to mouse V1 neurophysiology recordings from the Allen Brain Visual Behavior Neuropixels dataset [4], finding that SPLAT infers a small number of meaningful latent variables whose dynamics directly capture the temporally sparse stimulus structure of intermittent flashes of light in between periods of darkness. Finally, we found that these population recordings show evidence of local low dimensionality, with PCA estimating that 32 dimensions capture 85% of the variance, while SPLAT infers no more than 6 patterns are active during any given 10 ms bin. Together, these results suggest that apparently high- dimensional activity may represent passage through a sequence of low-dimensional neural computations.",
        "url": "https://www.world-wide.org/cosyne-23/apparently-high-dimensional-spontaneous-53283ffe"
    },
    "Calcium imaging-based brain-computer interface for investigating long-term neuronal code dynamics": {
        "title": "Calcium imaging-based brain-computer interface for investigating long-term neuronal code dynamics",
        "authors": "Linor Balilti Turgeman, Yaniv Ziv, Or Pinchasov, Nitzan Geva, Alon Rubin",
        "date": "Thursday, 9 March 2023",
        "location": "I-132",
        "abstract": "Brain-computer interfaces (BCI) have important applications both in medicine and as a research tool. In recent years the field of calcium imaging based BCIs has been accelerating1–4. Calcium imaging has the advantages of recording hundreds of cells simultaneously, and tracking the same neurons over many days, allowing a longitudinal analysis of neural code development and dynamics5. The collected data usually requires post experiment offline processing to extract single cells’ activity. Yet, emerging techniques for real-time processing of imaging data offer the potential for novel BCI experiments, in which closed-loop feedback is triggered at short latency in response to neural population activity3,6. Here, we present a proof-of-concept for a closed-loop BCI that allows longitudinal readout of neuronal activity from tens to hundreds of neurons in freely behaving mice, and enables the activation of external hardware based on real-time detection of specified activity patterns. Our system is modular, comprising several hardware and software components, which allows customization according to experimental needs. The hardware components are a head-mounted miniature fluorescence microscope, an overhead camera for tracking the mouse behavior, and an Arduino-controlled system for feedback within the behavioral arena. The software components include code for online processing of acquired recordings, aligning region of interest (ROI), fluorescence trace extraction and event detection, matching activity patterns, and animal’s tracking. With this system, we trained mice to run back and forth along a linear track, to attain water rewards at the track’s edges, upon activation of the same neuronal population activity pattern in hippocampal CA1. Mice maintained a stable level of reward across 6 recording days, demonstrating the ability to track and activate a BCI with the same set of cells across days. In the future, such a system could facilitate longitudinal interrogation of neural code dynamics.",
        "url": "https://www.world-wide.org/cosyne-23/calcium-imaging-based-brain-computer-fd3719b9"
    },
    "A neural network model of sequential memory retrieval during free recall": {
        "title": "A neural network model of sequential memory retrieval during free recall",
        "authors": "Moufan Li, Kristopher Jensen, Marcelo Mattar",
        "date": "Thursday, 9 March 2023",
        "location": "I-133",
        "abstract": "Humans exhibit highly structured patterns of memory recall. For example, when recalling a previously studied sequence of items, two patterns are often observed. First, after recalling any given item, the next recall tends to be an item studied in temporal proximity to the just-recalled item. Second, items tend to be recalled in the same order they were studied. To explain these findings, a prominent computational model called Temporal Context Model (TCM) posits the existence of a slowly-drifting temporal context that mediates encoding and retrieval of item sequences. While this model uses a handcrafted linear rule for updating the temporal context, here we study if and how a dynamic neural system might learn a context-like representation to support sequential retrieval. We developed a memory model with recurrent dynamics and trained it on a free-recall task to investigate what patterns of recall emerged after learning. We found that the model had a propensity to recall items in forward order, even though our training process had no built-in bias for forward recall. Our model learns a joint representation of the temporal context and item-related information, allowing the hidden state of the network to evolve in the same way during recall as it does during encoding. Our findings provide a possible answer to how the neural system can encode temporal context information and perform sequential memory retrieval. Importantly, the enhanced flexibility of our model over TCM allows it to be employed in tasks other than free-recall such as decision making.",
        "url": "https://www.world-wide.org/cosyne-23/neural-network-model-sequential-memory-44873492"
    },
    "Semi-supervised quantification and interpretation of undirected human behavior": {
        "title": "Semi-supervised quantification and interpretation of undirected human behavior",
        "authors": "Zhanqi Zhang, Yichi Yang, Timothy Sheehan, Chi Chou, Holden Rosberg, William Perry, Jared Young, Arpi Minassian, Gal Mishne, Mikio Aoi",
        "date": "Thursday, 9 March 2023",
        "location": "I-134",
        "abstract": "Undirected behavior reflects cognitive functions and provides insights for diagnosing psychiatric conditions such as bipolar disorder (BD) (McReynolds, 1962). Open-field animal behaviors have been well-studied for this purpose; however, a corresponding human subject paradigm is still lacking, and quantifying complex spontaneous human behaviors is challenging. Here, we demonstrate a semi-supervised model to quantify undirected human behavior, differentiate subtle hallmark behavioral features of BD, and create a natural language generative model to provide nuanced interpretations of behaviors with context information. We collected videos of BD (n=12) and control (n=12) human participants freely interacting in an unexplored room with each video manually annotated into 6 categories (e.g., walk). We used DeepLabCut (Mathis et al, 2018) to track the spatiotemporal postures of the participants coupled with the VAME latent variable model (Luxem et al, 2021) to encode pose sequences into latent representations. We then clustered the latent representations into 10 behavioral motifs. To interpret these motifs, we independently described example clips using natural language. Using these descriptions, we created a novel transformer-based model that generated interpretable descriptions for each cluster. We found the dwell time of motif “approach, inspect, move along” is significantly lower in the BD population compared with controls (two sample t-test, p-value: 0.04), while no significance was found from manually annotated categories. We then used transition matrices to characterize how participants transitioned between motifs. We found BD to have sparser transition matrices in the second half of the video which reflected more stereotyped behavior and a smaller behavioral repertoire. We quantified this using the entropy of the transition matrix and found BD patients to have significantly different entropy between the first and the second half of the video (F test for equal variances, p-value: 0.01). Our analysis identifies fine-resolution behavioral motifs that can distinguish BD using undirected human behavior.",
        "url": "https://www.world-wide.org/cosyne-23/semi-supervised-quantification-interpretation-8ade3e70"
    },
    "Exploring the role of image domains in self-supervised DNN models of the rodent brain": {
        "title": "Exploring the role of image domains in self-supervised DNN models of the rodent brain",
        "authors": "Aaditya Prasad, Uri Manor, Talmo Pereira",
        "date": "Thursday, 9 March 2023",
        "location": "I-135",
        "abstract": "Biological visual systems have evolved around the efficient coding of natural image statistics in order to support recognition of complex visual patterns. Recent work has shown that deep neural networks are able to learn similar representations to those measured in visual areas in animals, suggesting they may serve as models for the brain. Varying network architectures and loss functions has been shown to modulate the biological similarity learned representations, however the extent to which this results from exposure to natural image statistics during training has not been fully characterized. Here, we use self-supervised learning to train neural network models across a range of data domains with different image statistics and evaluate the similarity of the learned representations to neural activity of the mouse visual cortex. We find that networks trained on different domains also exhibit different responses when shown held-out natural images. Furthermore, we find that the degree of biological similarity of the representations generally increases as a function of the naturalness of the data domain used for training. Our results provide evidence for the idea that that the training data domain is an important component when modeling the visual system using deep neural networks.",
        "url": "https://www.world-wide.org/cosyne-23/exploring-role-image-domains-self-supervised-c6649c77"
    },
    "NeuralPlayground: A Standardised Environment for Evaluating Models of Hippocampus and Entorhinal Cortex": {
        "title": "NeuralPlayground: A Standardised Environment for Evaluating Models of Hippocampus and Entorhinal Cortex",
        "authors": "Clementine Domine, Rodrigo Carrasco-Davis, Andrew Saxe, Luke Hollingsworth, Caswell Barry",
        "date": "Thursday, 9 March 2023",
        "location": "I-136",
        "abstract": "The abstract representation of space has been extensively studied in the hippocampus and entorhinal cortex. Yet while a growing variety of theoretical models have been proposed to capture the rich neural and behavioral phenomenology associated with these regions, it remains difficult to compare these theories systematically against each other using the full range of empirical data. To address this gap, we built an open-source standardised software framework, named NeuralPlayground, to facilitate comparisons of hippocampus and entorhinal cortex models. This Python software package offers a reproducible way to compare models consistently against a centralised library of published experimental results, including neural recordings and animal behavior. The framework currently contains implementations of three Agents, including a excitatory/inhibitory plasticity agent and the Tolman-Eichenbaum machine (TEM), three Experiments providing simple interfaces to publicly available neural and behavioral data; a customizable 2-dimensional Arena (continuous and discrete) able to produce common experimental environments such as T-maze, circular and dynamical arenas which the agents can move in and interact with, and a Comparison tool to facilitate systematic comparisons by enabling users to pick from any Agent, Arena, Experiments, and metrics to produce a comparison of the results between artificial agents and experimental measurements. As a result, we hope to generate new insights into the model theory and implementation, illuminating the strengths and weaknesses of each model. We hope our framework, available at github.com/anonymous, offers a foundation that the community will build upon, toward a shared computational understanding of the hippocampus and entorhinal cortex.",
        "url": "https://www.world-wide.org/cosyne-23/neuralplayground-standardised-environment-0528f1fc"
    },
    "Revealing sudden transitions from goal-directed to habitual behavior during learning in mice": {
        "title": "Revealing sudden transitions from goal-directed to habitual behavior during learning in mice",
        "authors": "Sharlen Moore, Zyan Wang, Ruolan Sun, Ziyi Zhu, Angel Lee, Adam Charles, Kishore Kuchibhotla",
        "date": "Thursday, 9 March 2023",
        "location": "I-137",
        "abstract": "The transition from goal-directed to habitual decision-making during learning is thought to be gradual, yet permanent. Current approaches for distinguishing between the two decision processes require discrete ‘test’ sessions that preclude assessment of the nature and timing of the transition. Here, we devised a naturalistic devaluation approach to assess the underlying decision mode en passant, without discrete ‘test’ sessions. We hypothesized that by shifting a need for plain water, to a preference, we would favor action rate variability in animals during the goal-directed phase, unmasking transitions towards habitual behavior, expected to be characterized by a reduction in action rate variability. Mice received ad libitum non-palatable water in the home cage but received small plain water droplets for correct actions during an auditory stimulus recognition task. These mice exhibited naturalistic fluctuations in the cue-driven response rate during discriminative instrumental training. Then, abruptly and overnight, this variability ceased, and mice transitioned to a high and stable response rate despite no measurable changes in weight or general motivation. An HMM-GLM model revealed that animal’s choices pre-transition rapidly switched between two states (Go-biased/NoGo-Biased) while choices post-transition were dominated by one persistent Go-biased state. Pre-transition performance was sensitive to outcome devaluation (a hallmark of goal-directed behavior) but insensitive afterwards (a feature of habitual behavior). The sudden transition was accompanied by signatures of automaticity in lick microstructure and pupillary dynamics. Surprisingly, some animals reverted to goal-directed mode after several sessions in habit mode suggesting that transitions to habitual decision-making are not permanent. Lesioning the dorso-lateral striatum (area essential for habit formation) impaired the appearance of a transition. Thus, this naturalistic devaluation paradigm provides a powerful en passant approach to study habit formation and shows that transitions to habitual decision-making are strikingly abrupt, but also reversible, suggesting that control of decision-making is more agile than previously thought.",
        "url": "https://www.world-wide.org/cosyne-23/revealing-sudden-transitions-from-goal-directed-0411545a"
    },
    "Uncovering relationships between neural network activation changes and parameter dynamics during learning": {
        "title": "Uncovering relationships between neural network activation changes and parameter dynamics during learning",
        "authors": "Nanda H. Krishna, Colin Bredenberg, Alexandre Payeur, Guillaume Lajoie",
        "date": "Thursday, 9 March 2023",
        "location": "I-138",
        "abstract": "Learning in neural circuits manifests via slow changes in activity driving behaviour changes. Uncovering how the coordination of plasticity mechanisms found in the brain leads to such changes is a difficult problem, chiefly because we do not have access to the synaptic parameters underlying neural computation. Nevertheless, as neural population recording techniques improve and experiments track changes in neural dynamics over long durations, finer details about plastic changes could be inferred by observing and characterizing changes in neural activity. In this work, we present a step towards this goal and describe an effort to extract a data-driven mapping between neural activity space and neural network parameter space during learning. We present in silico experiments with recurrent neural networks (RNNs) trained for single and multi-objective tasks and explore the relationship between the dynamics of network parameters and activity over the course of training. We consider two tasks: (i) classification of one or both digits from an image containing two digits; and (ii) a center-out cursor control task with cursor position and size targets. Using simple classifiers and linear dimensionality reduction tools, we show that: (1) changes in the neural activations are representative of the corresponding changes in parameters over the course of training; and (2) it is possible to reliably distinguish single and multi-objective task settings based on activation representations during learning. Our experiments pave the way for more latent space design that could reveal key features of connectivity plasticity dynamics from those of neural activities recorded during learning. We posit that similar techniques can be used in longitudinal systems neuroscience experiments and in experiments using brain-computer interfaces which promote and require targeted learning.",
        "url": "https://www.world-wide.org/cosyne-23/uncovering-relationships-between-neural-d4304ea1"
    },
    "Opposing functional influence of cortical L5 neurons on functionally distinct subpopulations of L2/3": {
        "title": "Opposing functional influence of cortical L5 neurons on functionally distinct subpopulations of L2/3",
        "authors": "Anna Vasilevskaya & Georg Keller",
        "date": "Thursday, 9 March 2023",
        "location": "I-139",
        "abstract": "Inferring the mappings between actions and sensory feedback is a fundamental aspect of brain function. These mappings are described by two types of internal models – one that transforms motor signals into predictions of sensory feedback (forward model), and one that transforms sensory goals onto the motor commands necessary to achieve those goals (inverse model). One promising theoretical framework that provides computational ground for learning and maintaining these mappings, is that of predictive processing. The functional implementation of this algorithm in cortex implies two computational modules that interact with each other – a comparator circuit and an internal representation circuit. The key functional component of the comparator circuit – prediction-error neurons – has been previously identified in layer 2/3 across multiple cortical areas. The internal representation circuit remains enigmatic and has been hypothesized to reside in layer 5. Elucidating interactions between functional subpopulations of layer 5 and layer 2/3 becomes key for identifying prospective populations of internal representation neurons and testing the framework. To test the circuit model’s predictions on functional influence of internal representation neurons on prediction-error neurons, we used two-photon calcium imaging in combination with cell-type specific optogenetic manipulations while mice were engaged in visuomotor behavior in a virtual reality environment. We found that optogenetic activation of Tlx3-positive layer 5 intratelencephalically projecting neurons in V1 resulted in opposing functional influence on layer 2/3 positive and negative prediction-error neurons: positive prediction-error neurons exhibited an increase in activity upon stimulation, while negative prediction-error neurons, exhibited a decrease. The observed functional connectivity in combination with other known properties of Tlx3-positive layer 5 neurons suggests that these neurons could either carry a role of inverse internal representation neurons in V1 (thus, being involved in maintaining an inverse internal model), or function as a type of internal representation neuron under a hierarchical predictive processing model.",
        "url": "https://www.world-wide.org/cosyne-23/opposing-functional-influence-cortical-49b427b1"
    },
    "Dynamical Neural Computation in Predictive Sensorimotor Control": {
        "title": "Dynamical Neural Computation in Predictive Sensorimotor Control",
        "authors": "Yun Chen, Yiheng Zhang, He Cui",
        "date": "Thursday, 9 March 2023",
        "location": "I-140",
        "abstract": "How does the motor cortex function in predictive sensorimotor control? This is important for understanding neural control of movement, but dauting for the tangling of high-dimensional sensory and motor information. To address this question, we recorded neural population activity from the motor cortex while the monkeys were performing a manual interception task. Interestingly, on the neural states of single trials, we observed a low-dimensional ring-like neural geometry. This geometry, featured with ordered reach-direction clusters and tilted target-speed rings, also emerges in a three-layer RNN with appropriate inputs. Such a standard RNN, however, falls short of the capability in disentangling the sensorimotor interaction due to its homogenous hidden-units. Therefore, to scrutinize the interplaying process, we build another modular RNN to induce the neuronal tuning properties that may be relatively more sensory or motor. This RNN consists of two modules in the hidden-layer, one with adjustable connection weights and another with fixed ones. By making only the latter connected with the output nodes, these two modules work as ‘planning module’ and ‘execution module’, correspondingly. It turns out that the geometry of states from different modules differs as expected: the target-speed rings remain titled in the ‘planning module’ but go overlapped in the ‘execution module’, implying a divergence of involvement of sensory information. In addition, this model enables interception trials with the same endpoint and reversible inactivation, which so far can hardly be done in animals. The simulation results of short-term blocking target-location input suggest that sensory information to the ‘execution module’ is also necessary for accurate behavior. The present work reveals a specific geometric structure in neural space, and becomes an instance where models keep abreast with experiment: while the network’s reproduction supports the motor cortex as a dynamical system, the refined manipulation within network modules might provide further mechanical insights.",
        "url": "https://www.world-wide.org/cosyne-23/dynamical-neural-computation-predictive-cbde35ee"
    },
    "AI-driven cholinergic theory enables rapid and robust cortex-wide learning": {
        "title": "AI-driven cholinergic theory enables rapid and robust cortex-wide learning",
        "authors": "Maija Filipovica, Kevin Kermani Nejad, Will Greedy, Heng Wei Zhu, Rui Ponte Costa",
        "date": "Friday, 10 March 2023",
        "location": "II-001",
        "abstract": "The cholinergic system has been associated with learning, but also with cognitive decline in dementia, aging and injury. Yet, to date, no computational models have been put forward to explain how the cholinergic system contributes to both learning and cognitive decline. Here we introduce a model that combines a recently proposed model of cortex-wide credit assignment with a cholinergic adaptive module based on adaptive deep learning rules. According to this model, the cholinergic system opens a cortex-wide gate for learning, but its end effect is controlled by local adaptive processes. Using a multi-class perceptual discrimination task we show that cholinergic adaptive learning leads to rapid cortex-wide learning when compared with non-adaptive models. Such cholinergic adaptive modulation results in a constant redistribution of learning across the cortex making task-encoding sparser. Consequently, we show that the network becomes more robust to perturbations such as simulated cell death. Moreover, we demonstrate that in order to obtain such rapid and robust learning, global mechanisms are not sufficient, suggesting the need for a tight cholinergic interaction with local cortical circuits. Overall, our work provides a novel theoretical framework for cellular-systems neuroscience with which to link cholinergic cortical modulation to health and disease.",
        "url": "https://www.world-wide.org/cosyne-23/ai-driven-cholinergic-theory-enables-6f63fd89"
    },
    "A predictive learning model for cognitive maps that generate replay": {
        "title": "A predictive learning model for cognitive maps that generate replay",
        "authors": "Daniel Levenstein, Adrien Peyrache, Blake Richards",
        "date": "Friday, 10 March 2023",
        "location": "II-002",
        "abstract": "The hippocampus maintains an online representation of an animal’s situation in the environment which supports navigation, and generates offline simulations of plausible trajectories in that environment which are used for recall, imagination, planning, and the consolidation of memories. A leading theory is that these capacities rely on an attractive neuronal manifold, or cognitive map, in CA3, with topological correspondence to space. Supporting this idea, continuous attractor neural networks (CANNs) show place cell-like tuning for spatial locations, and can be used to simulate plausible trajectories in the environment in the absence of input. However, these networks require specific wiring between units with pre-assigned spatial locations or learning from inputs or outputs with preexisting spatial tuning, and it’s unclear how such a network can be learned from sensory information alone. Recently, it’s been found that self-supervised predictive learning - learning to predict subsequent or held-out sensory observations - can produce networks with spatially tuned cells, suggesting that predictive learning may be a plausible mechanism to develop a cognitive map in hippocampal circuits. Here we show that predictive learning can form a cognitive map which can autonomously generate offline replay. However, we find that the presence of spatially-tuned cells is insufficient to indicate the presence of a continuous attractor. While recurrent neural nets trained to predict next time step observations reliably develop spatially-tuned units, they don’t produce a neural manifold with topological correspondence to space, and as a result, do not produce coherent replay in the absence of sensory input. These fundamental properties of a cognitive map emerge only when the network is trained using a learning algorithm in which recurrent connections are used to project multiple timesteps ahead of the agent. Once learned, this cognitive map can autonomously generate behaviorally plausible “replay” trajectories offline, including those not taken by the agent during wakefulness.",
        "url": "https://www.world-wide.org/cosyne-23/predictive-learning-model-cognitive-09872de8"
    },
    "Basal ganglia-dependent expression of recent song learning in the juvenile finch": {
        "title": "Basal ganglia-dependent expression of recent song learning in the juvenile finch",
        "authors": "Drew Schreiner, Samuel Brudner, John Pearson, Richard Mooney",
        "date": "Friday, 10 March 2023",
        "location": "II-003",
        "abstract": "Many of our most impressive skills, from speech to music, evolve across many dimensions and are learned spontaneously without external reinforcement. While we know much about how the basal ganglia contribute to learning low-dimensional, externally reinforced behaviors like lever pressing, their contribution to learning high-dimensional behaviors is less clear. Birdsong learning is a paradigmatic example of high-dimensional learning. Juvenile songbirds vary many acoustic dimensions as they learn to copy their tutor’s song, a spontaneous process that evolves without external reinforcement. While songbirds possess a song-specialized basal ganglia nucleus (the sBG) necessary for song copying, nearly all of what we know about the sBG derives from studies in adult birds that examine a unidimensional, externally reinforced type of “vocal lever pressing.” We combined sophisticated computational analyses with closed-loop optogenetic suppression to directly test the hypothesis that sBG activity is acutely necessary to express recently learned changes during juvenile song copying. The high dimensionality of birdsong is one major challenge to testing this hypothesis. To address this challenge, we applied a variational autoencoder to compress high-dimensional vocal data into a low-dimensional latent space, then developed a feed forward neural network that predicted the age of production for every syllable rendition based on these latent dimensions. In this way, we identified learning-relevant dimensions in the vocal data. We combined this with closed-loop optogenetic suppression of sBG activity in juvenile zebra finches as they copied their tutor’s song. sBG suppression induced a regression in song learning immediately and transiently (i.e., only on targeted renditions), erasing on average the previous 8 hours of learning. This indicates that, during juvenile song copying, the sBG functions to express recently acquired learning on a rendition-to-rendition basis. Our work is of broad relevance to understanding how the basal ganglia help solve high-dimensional learning problems, even without external reinforcement.",
        "url": "https://www.world-wide.org/cosyne-23/basal-ganglia-dependent-expression-3cd89981"
    },
    "The tradeoff between fine-tuning and accurate angular integration in small networks": {
        "title": "The tradeoff between fine-tuning and accurate angular integration in small networks",
        "authors": "Marcella Noorman, Brad Hulse, Vivek Jayaraman, Sandro Romani, Ann Hermundstad",
        "date": "Friday, 10 March 2023",
        "location": "II-004",
        "abstract": "Flexible navigation requires animals to form accurate and persistent internal representations of continuous spatial variables. Such representations—e.g., those carried by head direction (HD), grid, and place cells—can guide behavior even in the absence of localizing sensory cues. Theories of mammalian HD cells propose that such representations can be realized in a special class of networks that maintain a localized bump of activity via structured recurrent connectivity, and that shift this bump of activity via angular velocity input. These so-called ring attractor networks have historically relied on large numbers of neurons to generate continuous internal representations that persist without input and accurately respond to changes in input. Surprisingly, in the fly, an HD representation is maintained by a network whose dynamics and connectivity resemble those of a ring attractor network, but with far fewer neurons than required theoretically. In 2020, Noorman et al. showed that such small networks can generate continuous ring attractor solutions if coupling strengths are appropriately tuned. Using the existence of such solutions as a starting point, we sought to characterize performance as a function of network size and tuning. We first analytically derive the optimal coupling strengths that mathematically flatten the energy of the dynamical system and enable optimal performance. For threshold linear networks, the resulting ring attractor manifold emerges as a discrete set of line attractor manifolds that are ``stitched together'' to form a ring. We then analytically characterize performance away from these optimal tunings in dynamical regimes that are governed by discrete sets of stable and unstable fixed points. Finally, we quantify tradeoffs between network size and tuning precision needed to achieve the same performance, which reveals that more strongly coupled networks require less fine-tuning.",
        "url": "https://www.world-wide.org/cosyne-23/tradeoff-between-fine-tuning-accurate-73cfddfb"
    },
    "Thalamic maintenance of a complex sequential learned behavior: birdsong": {
        "title": "Thalamic maintenance of a complex sequential learned behavior: birdsong",
        "authors": "Nader Nikbakht, Michale Fee, Derek Sederman, Yevhen Tupikov, Dezhe Jin",
        "date": "Friday, 10 March 2023",
        "location": "II-005",
        "abstract": "Performing learned behaviors requires animals to produce precisely timed motor sequences. Birdsong is an excellent natural example of a complex, learned and precisely timed behavior. In the zebra finch we asked how thalamocortical input contributes to song dynamics. Birdsong is controlled by a brainstem-thalamocortical feedback loop. The premotor cortical region HVC (proper name) contains projection neurons that produce precisely timed, highly reliable and ultra-sparse spike burst sequences that underlie song dynamics. The origin of these bursts is debated. One model posits that bursts are generated locally in HVC through a synaptic chain mechanism. Alternatively, the thalamic nucleus Uveaformis (Uva), could drive HVC bursts as part of the brainstem-thalamocortical distributed network. Despite its importance, single unit recordings from Uva during singing have never been reported and consequently, the exact circuit-level function of this nucleus is unknown. We developed a lightweight (~1 g) microdrive for juxtacellular recordings and with it performed the very first extracellular single unit recordings in Uva during song. Recordings revealed HVC-projecting Uva neurons contain timing information during the song, but compared to HVC neurons, fire densely in time and are much less reliable. Computational models of Uva-driven HVC neurons estimated that a high degree of synaptic convergence is needed from Uva to HVC to overcome the inconsistency of Uva firing patterns. However, traced axon terminals of single Uva neurons showed low convergence within HVC such that each HVC neuron receives input from only 2-3 Uva neurons. These results suggest that Uva maintains sequential cortical activity during song but does not provide unambiguous timing information. Our observations are consistent with a model in which the brainstem-thalamocortical feedback loop acts at the syllable timescale (~100 ms) and does not support a model in which the brainstem-thalamocortical feedback loop acts at fast timescale (~10 ms) to generate sequences within cortex.",
        "url": "https://www.world-wide.org/cosyne-23/thalamic-maintenance-complex-sequential-a95a1746"
    },
    "Unveiling the structure of the grid cell code in novel environments": {
        "title": "Unveiling the structure of the grid cell code in novel environments",
        "authors": "Ben Sorscher, Surya Ganguli, John Wen, Lisa Giocomo",
        "date": "Friday, 10 March 2023",
        "location": "II-006",
        "abstract": "Understanding how the brain builds maps of novel environments on behavioral timescales (seconds-minutes) is a fundamental question for neuroscience. Theoretical works posit a Hebbian plasticity mechanism for integrating novel landmarks [1]. Drosophila have been shown to use such a mechanism to integrate novel landmarks on timescales of minutes [2,3]. However, current evidence suggests that plasticity in the medial entorhinal cortex (MEC) operates on the timescale of days [4] — leaving open the question of how the mammalian brain maps novel environments on behavioral timescales. Here we investigate this question using Neuropixels recordings of hundreds of neurons in mice navigating diverse virtual reality (VR) environments. We find that MEC is capable of building stable, consistent maps of novel environments after just a single exposure (one-shot). Novel spectral analyses reveal that this is accomplished by visual landmarks driving a bump of neural activity onto stable periodic trajectories on a toroidal attractor. However, visual landmarks also distort the grid cell code so that distances in real space are no longer proportional to distances on the neural manifold. Nevertheless these distortions are predictable, leading to an underlying structure which persists across diverse environments. Remarkably, this structure is sufficiently rigid that a simple 2-D dynamical model allows us, for the first time, to predict grid cell responses in a novel environment before the animal enters that environment. Together, these results point to a picture of MEC as learning through the dynamics of a fixed circuit, capable of one-shot mapping novel environments at the cost of susceptibility to distortions and spontaneous remapping. Despite these distortions, we show in behavioral assays that rapidly generated MEC maps enable mice to one- or few-shot learn to navigate to hidden rewards in novel environments. These results lend credence to the promise of “learning through dynamics” to subserve flexible behavior.",
        "url": "https://www.world-wide.org/cosyne-23/unveiling-structure-grid-cell-code-novel-c56eacd9"
    },
    "Representational dissimilarity metric spaces for stochastic neural networks": {
        "title": "Representational dissimilarity metric spaces for stochastic neural networks",
        "authors": "Jingyang Zhou, Lyndon Duong, Josue Nassar, Jules Berman, Jeroen Olieslagers, Alex Williams",
        "date": "Friday, 10 March 2023",
        "location": "II-007",
        "abstract": "Comparing high-dimensional neural response patterns across different animals or artificial deep networks is a fundamental problem in computational neuroscience. There are now many methods for quantifying representational dissimilarity including canonical correlations analysis (CCA), centered kernel alignment (CKA), representational similarity analysis (RSA), shape metrics, and so on. Intuitively, these measures quantify similarity in the geometry of neural responses while removing expected forms of invariance across networks (e.g. permutations over arbitrary neuron indices). However, these methods only compare deterministic representations of external stimuli. Biological networks are essentially never deterministic in this fashion. In fact, the variance of a stimulus-evoked neural response is often larger than its mean, and influential theoretical work has shown that the structure of noise correlations can limit the information capacity of neural circuits. Stochastic responses also arise in the deep learning. literature in many contexts, such as in deep generative modeling or to provide regularization (e.g. dropout). We currently lack rigorous methods to compare representations across these stochastic networks, beyond using their trial-average response (which ignores stochasticity entirely). To fill the gap in the literature, we generalize previously proposed shape metrics to quantify differences in stochastic representations. Stochastic shape metrics are proper metrics – they are non-negative, symmetric, and satisfy triangle inequality, and thus can be used as a rigorous basis for many supervised and unsupervised analyses. Leveraging this novel framework, we find that the stochastic geometries of neurobiological representations of oriented visual gratings and naturalistic scenes respectively resemble untrained and trained deep network representations. Further, we are able to more accurately predict certain deep network attributes (e.g. training hyperparameters) from its position in stochastic (versus deterministic) shape space.",
        "url": "https://www.world-wide.org/cosyne-23/representational-dissimilarity-metric-a52fcc0e"
    },
    "Striatal dopamine encodes movement and value at distinct time points": {
        "title": "Striatal dopamine encodes movement and value at distinct time points",
        "authors": "Heejae Jang, Andrew Mah, Christine Constantinople",
        "date": "Friday, 10 March 2023",
        "location": "II-008",
        "abstract": "Midbrain dopamine (DA) neurons are thought to be critical for reinforcement learning as well as motor control. One important target for DA neurons is the striatum where different subregions are innervated by different midbrain DA neurons. A wealth of evidence suggests that DA release in the ventral striatum acts as a reward prediction error (RPE) to support cue-outcome associations while DA manipulations in the dorsolateral striatum produce gross effects on movement. The dorsomedial striatum (DMS), located between the ventral and dorsolateral striatum, may represent an intermediate position along the continuum of value to action coding in the striatum and its associated DA innervation. To address how value and action are represented by DA in DMS, we trained rats on a novel value-based decision-making task that includes reward-and motor-related components at distinct points in time that facilitates relating DA to different aspects of behavior. Fiber photometry measurement of DA release in DMS reveals phasic DA responses at multiple task events, only some of which are accompanied by movement. The amplitude of these movement DA signals predicts the vigor of the upcoming contralateral movement. In the absence of movement, phasic DA release signals RPE by conveying reward magnitude and probability. Bilateral muscimol or DREADDs inhibition of DMS impaired rats’ ability to adapt their choices depending on the current reward context. To address which aspect of value processing is impaired, we simulated behavioral data with a Bayesian-inference-based model with softmax policy. We find that the qualitative features of inactivation data are captured by a high softmax parameter, suggesting that DMS inactivation renders policy more explorative. These data suggest that the heterogeneous DA signal in DMS supports value-based decision-making by promoting movement and learning at distinct timepoints for action policies.",
        "url": "https://www.world-wide.org/cosyne-23/striatal-dopamine-encodes-movement-value-1d789785"
    },
    "A stable sensory map emerges from neurons with unstable tuning properties": {
        "title": "A stable sensory map emerges from neurons with unstable tuning properties",
        "authors": "Dominik Aschauer, Anna Chambers, Jens-Bastian Eppler, Matthias Kaschube, Simon Rumpel",
        "date": "Friday, 10 March 2023",
        "location": "II-009",
        "abstract": "Primary sensory cortices are functionally organized according to topographic principles, such as the tonotopic map of auditory cortex. Recently, chronic recordings of neuronal activity have revealed that single cell stimulus tuning can undergo continuous remodeling, which appears to be in conflict with the stability of sensory maps. Using longitudinal two-photon imaging in the auditory cortex of 12 mice (21.506 neurons), we attempt to reconcile the conflicting observations of unstable single-cell tuning properties and stable population-level topographic maps. Using intrinsic imaging and chronic two-photon calcium imaging, we assess tuning properties to pure tones (PT) and more naturalistic, complex sounds (CS). We find that responses to complex sounds, but also topographically organized pure tones are highly volatile and many neurons gain and lose responsiveness regularly over time. We modeled the transitions between four different states of responsiveness (unresponsive, CS-responsive, PT-responsive, CS&PT-responsive) as a discrete-time Markov chain. This simple Markov chain was able to capture the dynamics of responsiveness over a 9-day period, indicating that the turnover is predominantly stochastic and memoryless. The structure of the tonotopic map is nevertheless upheld throughout the experiment by shifting subpopulations of neurons. Assessing the model’s long-term predictions, we found that within 100 days the vast majority of neurons would become responsive to the set of sounds used in our study, at least transiently. This provides an interesting twist on the common observation that it is difficult to evoke a sensory response in a neuron: It may not have been the wrong stimulus, but the wrong day.",
        "url": "https://www.world-wide.org/cosyne-23/stable-sensory-emerges-from-neurons-with-487ba317"
    },
    "The logic of recurrent circuits in the primary visual cortex": {
        "title": "The logic of recurrent circuits in the primary visual cortex",
        "authors": "Gregory Handy, Ian Oldenburg, Will Hendricks, Hillel Adesnik, Brent Doiron",
        "date": "Friday, 10 March 2023",
        "location": "II-010",
        "abstract": "Although most synapses within the neocortex are recurrent, the functional impact of this recurrence remains unclear. Prior experimental and theoretical work in the primary visual cortex (V1) suggests that recurrent excitation amplifies responses when signals are weak in order to optimize detection, while recurrent inhibition suppresses responses when signals are strong to optimize discrimination. Deepening our understanding of the logic for when recurrent activity facilitates cooperation among cortical ensembles and when it mediates competition beyond these initial results is fundamental to understanding cortical computation. A major challenge to addressing this logic is parsing the impact of local recurrence within the circuit from that of feedforward and feedback inputs. To overcome this obstacle, we used multiphoton holographic optogenetics to activate ensembles of neurons in Layer 2/3 of V1 in the absence of any external stimulus. Leveraging the spatial specificity of two-photon holographic optogenetics, we find that both the spatial and stimulus preference organization of the ensemble affect the recruited activity. While these two organizing principles interact to produce non-intuitive population responses, with the strongest effects occurring within 30 µm of a stimulated cell, the sign of this interaction for individual responding neurons is dictated by their relative tuning to the ensemble. Specifically, compact (i.e., densely packed) co-tuned ensembles are able to recruit nearby iso-tuned neurons, while suppressing others. Computational modeling suggests that a combination of highly local recurrent excitatory connectivity and the selective convergence of co-tuned excitatory neurons onto local inhibitory neurons can give rise to these principles of recurrent activity. Further, the model calls attention to the previously undervalued trade-off occurring between the excitatory E→E and suppressive E→I→E recurrent pathways. This combination of in vivo and in silico circuit interrogation explain how recurrent cortical circuits selectively amplify or suppress cortical activity depending on the precise pattern of co-active neurons.",
        "url": "https://www.world-wide.org/cosyne-23/logic-recurrent-circuits-primary-visual-436e469d"
    },
    "A Large Dataset of Macaque V1 Responses to Natural Images Revealed Complexity in V1 Neural Codes": {
        "title": "A Large Dataset of Macaque V1 Responses to Natural Images Revealed Complexity in V1 Neural Codes",
        "authors": "Shang Gao, Tianye Wang, Xie Jue, Daniel Wang, Tai Sing Lee, Shiming Tang",
        "date": "Friday, 10 March 2023",
        "location": "II-011",
        "abstract": "Natural visual environments are full of complex and diverse patterns. Recent neurophysiological experiments based on artificial patterns have suggested that macaque V1 neurons’ receptive fields are more complex and diverse in feature selectivity (Tang et al 2017) rather than just oriented Gabor filters. However, that finding was based on extensive parametric artificial stimuli used and might be biased. Hence, the nature of the neural codes of macaque V1 neurons remains controversial. To resolve this question, we performed 2-photon calcium imaging on three macaque monkeys to obtain 1689 V1 neurons’ responses to 30K-50K natural images. This dataset allows us to characterize the neural code of V1 neurons more generally and comprehensively. Fitting CNN models to this dataset, we found: (1) data size matters – CNN models trained with a larger set of data can generalize better for predicting responses to images that are not in the training set, and more importantly, the receptive fields recovered become more complex and diverse with more and more data; (2) natural images matters – using the CNN models, we showed that complex and diverse tunings can be revealed by testing with natural images, but not easily with white noise stimuli, even at an extremely large sample size; (3) over-completeness better – we showed that overcomplete sparse coding theory, which predicts the development of more diverse and complex tunings, yields filters that fit V1 neurons’ responses better than that provided by standard sparse coding theory. These findings suggest that with big data, V1 neurons’ CNN models capture more accurately the neural code of V1 neurons, providing compelling evidence in support of the complexity and diversity of the neural codes, and overcomplete sparse coding theory. The results also demonstrate that these models can potentially be used as V1 neurons-in-silico for investigating the neural codes and processes in V1.",
        "url": "https://www.world-wide.org/cosyne-23/large-dataset-macaque-responses-natural-3ac1c59a"
    },
    "Explaining the coexistence of neural oscillations and avalanches in resting human brain": {
        "title": "Explaining the coexistence of neural oscillations and avalanches in resting human brain",
        "authors": "Fabrizio Lombardi, Gašper Tkačik, Selver Pepic, Oren Shriki, Daniele De Martino",
        "date": "Friday, 10 March 2023",
        "location": "II-012",
        "abstract": "Neurons in the brain are wired into adaptive networks that exhibit a range of collective dynamics. Oscillations, for example, are paradigmatic synchronous patterns of neural activity with a defined temporal scale. Neuronal avalanches, in contrast, do not show characteristic spatial and temporal scales, and are often considered as evidence of brain tuning to quasi-criticality. While models have been developed to account for oscillations or neuronal avalanches separately, they typically do not explain both phenomena, are too complex to analyze analytically, or intractable to infer from data rigorously. Here we propose a non-equilibrium feedback-driven Ising-like class of neural networks that simultaneously and quantitatively captures scale-free neuronal avalanches and scale-specific oscillations. In the most simple yet fully microscopic model version we can analytically compute the phase diagram and make direct contact with human brain resting-state activity recordings via tractable inference of the model's two essential parameters. The inferred model quantitatively captures the dynamics over a broad range of scales, from single sensor oscillations and collective behaviors of nearly-synchronous extreme events on multiple sensors, to neuronal avalanches unfolding over multiple sensors across multiple time bins. Importantly, the inferred parameters correlate with model-independent signatures of \"closeness to criticality\", indicating that the coexistence of scale-specific (neural oscillations) and scale-free (neuronal avalanches) dynamics in brain activity occurs close to a non-equilibrium critical point at the onset of self-sustained oscillations.",
        "url": "https://www.world-wide.org/cosyne-23/explaining-coexistence-neural-oscillations-90b99553"
    },
    "Neural circuitry underlying cortical control of vocalization-driven maternal behavior": {
        "title": "Neural circuitry underlying cortical control of vocalization-driven maternal behavior",
        "authors": "Amy LeMessurier, Ayat Agha, Robert Froemke",
        "date": "Friday, 10 March 2023",
        "location": "II-013",
        "abstract": "Perception of vocalizations is critical for many species. In mammals, the central auditory pathway is highly interconnected, with corticofugal feedback projections from auditory cortex (AC) to the auditory midbrain that rival the density of feed-forward auditory input. These projections support sound localization, feature coding, and noise invariance. Because vocalizations are acoustically complex and carry social significance, we hypothesize that feedback projections from AC enable behavioral responses. Infant vocalizations that elicit parental care are highly conserved in mammals. In mice, experienced caretakers find and retrieve isolated pups into the nest when pups emit ultrasonic vocalizations (USVs). Virgin females generally don’t retrieve pups until they gain experience, for example by co-housing with a dam and litter. The onset of retrieval behavior is correlated with heightened sensitivity to USVs in left AC. To test whether corticofugal projections are required for retrieval, we chemogenetically silenced activity in left AC layer 5 (L5) – where most projections originate – during a pup retrieval assay. In experts, retrieval was greatly impaired. However, silencing a subset of L5 neurons projecting to striatum had no effect, suggesting that cortical modulation of specific projection targets may be preferentially involved in behavior. We used 2-photon calcium imaging in awake mice to compare USV responses in neurons projecting to striatum and inferior colliculus. Corticocollicular neurons in expert retrievers exhibited sustained increases in activity during USV playback compared to pure tones, while activity was equivalent during USV and tone presentation in corticostriatal neurons. This was corroborated by in vivo patch-clamp recordings in optotagged projection neurons. This sustained activity may reflect increased excitability in a network of recurrently-linked cortical and subcortical areas. To examine whether this activity develops with experience, we imaged corticocollicular neurons over co-housing. Tracking activity in corticocollicular neurons across days revealed a diversity of response profiles and changes in responsiveness to USVs.",
        "url": "https://www.world-wide.org/cosyne-23/neural-circuitry-underlying-cortical-a718fbd3"
    },
    "V2 builds a generalizable texture representation": {
        "title": "V2 builds a generalizable texture representation",
        "authors": "Abhimanyu Pavuluri & Adam Kohn",
        "date": "Friday, 10 March 2023",
        "location": "II-014",
        "abstract": "Decades of work has attempted to explain how the representation of visual information is transformed across stages of the cortical processing stream. In some cases, these transformations have been elucidated by insights into how the receptive field properties of individual neurons differ across areas. But the view provided by single neuron selectivity has struggled to explain the transformations occurring from early to mid-level cortex. An alternative, complementary approach is to study the representational geometry of neuronal populations. Though derived from individual neuronal selectivity, population geometry can reveal encoding strategies difficult to infer from single neurons. Recent work in artificial networks has shown the trade-offs of different visual representational geometries. For instance, discriminability is favored by high-dimensional representations; generalizability is favored by low-dimensional, systematic embedding of image statistics. To understand the representational strategy in the visual cortex, we compared the population geometry for synthetic, naturalistic textures in primary visual cortex (V1) and area V2 of macaque monkeys. We simultaneously measured neuronal population activity in both areas, and determined their sparsity, dimensionality, discriminability, latent embedding, and generalizability performance, for an ensemble of textures. V2 populations showed evidence of an emerging latent representation of image statistics, affording better generalizability in predicting responses to new textures. This latent representation also allowed for improved discriminability between textures. Analysis of pre-trained deep net (AlexNet and VGG-16) responses to the same stimulus ensemble did not replicate the representational geometry observed in cortex. We conclude that there is a shift in the representational geometry between V1 and V2 to a latent representation of image statistics. Our results show that assessing representational geometry can provide important insights into the transformations that occur across successive stages of visual processing.",
        "url": "https://www.world-wide.org/cosyne-23/builds-generalizable-texture-representation-a2013697"
    },
    "The role of inhibition in shaping memory-encoding hippocampal sequences": {
        "title": "The role of inhibition in shaping memory-encoding hippocampal sequences",
        "authors": "Jiannis Taxidis, Blake Madruga, Michael Lin, Peyman Golshani",
        "date": "Friday, 10 March 2023",
        "location": "II-015",
        "abstract": "Hippocampal pyramidal (PY) spiking sequences link temporally contiguous memories by encoding sensory cues as well as temporal intervals between them, constructing trajectories across ‘memory-space’. But what is the role of inhibition – particularly parvalbumin (PV) and somatostatin expressing (SST) interneurons (INs) - in shaping such sensory and temporal representations? We pioneered longitudinal, high-frequency voltage imaging in vivo on the CA1 of PV-Cre and SST-Cre mice while they performed an odor-cued delayed non-match-to-sample task (DNMS), shown to yield odor-specific PY sequences during the odors and ensuing delays. We recorded action potentials and membrane dynamics from PV and SST cells during untrained trial exposure as well as during trained performance, following the same cells across multiple days or before and after training. Roughly half of PV and SST cells exhibited a significant firing field during the odor-cue presentation (‘odor-cells’). Unlike PYs, these neurons responded to both odors similarly, and practically no cells encoded any delay timepoints, yielding no delay-sequences. The number of odor-cells was stable per day, with a fixed cell-turnover, whereas some INs retained stable odor-fields for days, even throughout DNMS training. Surprisingly, at the odor onset, cells exhibited a sharp delta-frequency hyperpolarization which was triggered by a short burst seen only in PV cells. It briefly reset the intracellular theta phase of INs and condensed the rebound odor-spiking into a single theta-cycle. Such pronounced and fine-timed inhibition should silence many PYs during odors. Indeed, through in vivo 2-photon calcium imaging in transgenic mice under the same setup, we found that roughly half PYs were inhibited during odors. We thus propose that the role of this very fine-timed but non-specific and behaviorally-independent inhibition, is to silence background activity during a cue and thus increase the signal-to-noise-ratio of the few PYs that encode the cue presentation and initiate the ensuing spiking sequence.",
        "url": "https://www.world-wide.org/cosyne-23/role-inhibition-shaping-memory-encoding-04bd4d93"
    },
    "Hidden synaptic structures control collective network dynamics": {
        "title": "Hidden synaptic structures control collective network dynamics",
        "authors": "Lorenzo Tiberi, David Dahmen, Moritz Helias",
        "date": "Friday, 10 March 2023",
        "location": "II-016",
        "abstract": "A common approach to model local neural circuits is to assume random connectivity. But how is our choice of randomness informed by known network properties? And how does it affect the network's behavior? Previous approaches have focused on prescribing increasingly sophisticated statistics of synaptic strengths and motifs. However, experimental data on parallel dynamics of neurons is more readily accessible than their microcircuitry. We therefore propose a paradigm shift, specifying connectivity in the space that directly controls the dynamics – the space of eigenmodes. We develop a theory for a novel ensemble of large random matrices, whose eigenvalue distribution can be chosen arbitrarily. We show analytically how varying such distribution induces a diverse range of collective network behaviors. We discover a critical point whose nature is shaped by the distribution of oscillation frequencies of near-critical modes: correlation and response functions can be tuned from an exponential to a power-law decay in time. Their decay exponents slow down proportionally to the density of near-critical eigenvalues. Above a critical density, the network furthermore shows a sharp transition from high to low dimensional activity. Which synaptic strengths statistics control such diverse range of behaviors? We prove it to be the structure of subleading order statistics. At leading order in the number of neurons, instead, synapses only show simple correlations between reciprocal connections. The richer structures at subleading order are effectively hidden in synaptic space. Yet, their collective effect is macroscopically observable in the space of neuronal dynamics. Our novel approach provides a largely extended ensemble of connectivity matrices, with which to explore a wider space of possible network dynamics. As an application, we expose novel behaviors whose origin is hardly detectable in synaptic space alone and establish a solid analytical link between observable neuronal dynamics – correlations, responses and dimensionality – and connectivity.",
        "url": "https://www.world-wide.org/cosyne-23/hidden-synaptic-structures-control-collective-f8589b81"
    },
    "Drosophila detects negative visual evidence against self-motion": {
        "title": "Drosophila detects negative visual evidence against self-motion",
        "authors": "Ryosuke Tanaka, Baohua Zhou, Margarida Agrochao, Bara Badwan, Braedyn Au, Natalia Castelo Branco Matos, Damon Clark",
        "date": "Friday, 10 March 2023",
        "location": "II-017",
        "abstract": "Sensory inputs available to animals are often open to multiple interpretations. When evaluating the likelihood of a certain interpretation, it is important that they consider not only evidence confirming that interpretation, but also evidence against it. Human reasoning often fails to appropriately weigh negative evidence, a phenomenon termed confirmation bias. However, since behaving based on false beliefs is costly, animals may detect negative evidence better in the context of innate, naturalistic behaviors. An example of such behaviors is visual course stabilization. Existing models assume that animals perform template matching over the vector field of local visual motion to detect optic flow and estimate self-motion. However, template matching overlooks an entire class of alternative scene interpretations: that the observer is stationary and external objects are moving consistently with optic flow templates. A potentially useful visual cue to detect the absence of self-rotation is visual patterns that are stationary on the retina. Because all visible features of the world move in the same direction during genuine observer rotation, stationary visual patterns strongly argue against the existence of self-rotation. Here, we demonstrate that the fruit fly Drosophila suppresses its rotational course stabilization behavior in the presence of stationary visual patterns, a manifestation of negative evidence detection. In parallel in silico experiments, we show artificial neural networks trained to distinguish self- and world-motion also learn to exploit stationary visual patterns, supporting the functional interpretation of the fly behavior. Using genetic manipulations and measurements of neural activity, we constrain microcircuit mechanisms of stationary pattern detection, which we find to include a visual neuron type called Mi4. Overall, our results exemplify how the compact brain of flies takes negative evidence into account to improve its heading stability, exploiting geometrical constraints of the visual world.",
        "url": "https://www.world-wide.org/cosyne-23/drosophila-detects-negative-visual-evidence-708822e2"
    },
    "Controlled generation of functional human neural circuits": {
        "title": "Controlled generation of functional human neural circuits",
        "authors": "Johannes Striebel, Rouhollah Habibey, Volker Busskamp",
        "date": "Friday, 10 March 2023",
        "location": "II-018",
        "abstract": "Biological neural networks show an inherent structure and connections that are reproduced across individuals. It is still largely unknown how the structure of such networks is correlated with their observed functional dynamics and computational output. Detailed investigation of network structure and its functional implications is challenging. For instance, in vivo studies do not allow for isolated analysis of network motifs. As basic elements of neuronal systems, these motifs need careful consideration. In contrast, the main obstacle in vitro is to create defined network structures down to the single cell level. This lack of control is hindering reproducible experimental research on small-scale circuits. Thus, precise study of functional features inherent to structural motifs is hardly possible. Here, we present a method to generate predefined 2D neural networks by placing neurons in a scaffold atop a multielectrode array (MEA). We have built a setup for printing single human induced pluripotent stem cell (hiPSC)-derived neurons with µm precision. Microchannels help to guide neurites growth direction and generate predefined neuronal connections. It is possible to incorporate multiple neuronal cell types in one circuit. Our approach can be extended to incorporate precise stimulation of neurons by MEA electrodes or optogenetic actuators. Using our method, we engineer first and second order network motifs which are abundant in biological neural systems like the retina. Advanced control over neuronal network formation facilitates to compare computational predictions to experimental results and might therefore help refining existing models. Insights into structure-function relationships could potentially aid a more detailed understanding of large neuronal systems.",
        "url": "https://www.world-wide.org/cosyne-23/controlled-generation-functional-human-5ca8914c"
    },
    "The scale-invariant covariance spectrum of brain-wide activity in larval zebrafish": {
        "title": "The scale-invariant covariance spectrum of brain-wide activity in larval zebrafish",
        "authors": "Zezhen Wang, Weihao Mai, Yuming Chai, Chen Shen, Kexin Qi, Yu Hu, Quan Wen",
        "date": "Friday, 10 March 2023",
        "location": "II-019",
        "abstract": "A quantitative characterization of brain-wide activity imposes strong constraints on mechanistic models that link neural circuit connectivity, brain dynamics, and behavior. Here, we analyze whole-brain calcium activity in larval zebrafish captured by fast light-field volumetric imaging during hunting behavior. We found that the brain-wide activity is distributed across many principal component dimensions described by the covariance spectrum. Intriguingly, this spectrum shows an invariance to spatial subsampling. That is, the distribution of eigenvalues of a smaller and randomly sampled cell assembly is statistically similar to that of the entire brain. We propose that this property can be understood in the spirit of multidimensional scaling (MDS): pairwise correlation between neurons can be mapped onto a distance function between two points in a low-dimensional functional space. We numerically and analytically calculated the eigenspectrum in our model and identified three key factors that lead to the experimentally observed scale-invariance: (i) the slow decay of the distance-correlation function, (ii) the high dimension of the functional space, and (iii) the heterogeneity of neural activity. Our model can quantitatively recapitulate the scale-invariant spectrum in our zebrafish data and multi-area electrode recordings in mice. Our results provide new insights and interpretations of brain-wide neural activity and offer clues on circuit mechanisms for coordinating global neural activity patterns.",
        "url": "https://www.world-wide.org/cosyne-23/scale-invariant-covariance-spectrum-a11ce1e0"
    },
    "Visual representation of different levels of abstraction along the mouse visual hierarchy": {
        "title": "Visual representation of different levels of abstraction along the mouse visual hierarchy",
        "authors": "Benjie Miao, Peng Jiang, Joshua H. Siegle, Shailaja Akella, Peter Ledochowitsch, Hannah Belski, Severine Durand, Shawn R. Olsen, Xiaoxuan Jia",
        "date": "Friday, 10 March 2023",
        "location": "II-020",
        "abstract": "The functional visual hierarchy has been widely studied in primates but was only recently revealed in mice. It is thus unclear whether different areas along the mouse visual hierarchy also represent distinct levels of visual abstraction. To address this question, we carefully designed a visual stimulus set consisting of natural images of diverse objects, synthetic textures, and corresponding noise from a range of families. We acquired and analyzed a novel electrophysiology dataset with ~13,000 neurons recorded across six visual cortical regions along the visual hierarchy in awake mice using Neuropixels probes, while presenting those images. By evaluating the performance of decoding tasks at three different levels (category, subcategory and exemplar levels), we evaluated visual information representation with different spatial granularity, i.e., whether a region prefers fine-grained features or coarse-grained global information. We found that the decoding accuracy of areas V1, LM and AL were consistently higher than areas RL, PM and AM for different levels of tasks, suggesting a potential separation of two processing streams. Within each stream, the early areas perform better in decoding exemplar-level image information, indicating that they are better at local feature extraction. On the other hand, higher visual regions perform better in categorization of texture families and objects, suggesting an abstraction of global information. Interestingly, decoding performance was significantly higher for textures than for natural objects, which implied a limitation of natural object representation in mice as compared to primates. To explain the change of representation granularity, we compared the representation of different visual areas with the pre-trained artificial neural networks (ANN) and observed an increased similarity between neuronal and ANN’s representations across convolutional layers. The overall results shed light on visual information representation at different levels of abstraction in the mouse visual hierarchy and provide a framework to study visual information transformation in mice.",
        "url": "https://www.world-wide.org/cosyne-23/visual-representation-different-levels-4a27d542"
    },
    "Dissecting the Functional Organization of the Serotonergic System at Whole-Brain Scale in C. elegans": {
        "title": "Dissecting the Functional Organization of the Serotonergic System at Whole-Brain Scale in C. elegans",
        "authors": "Di Kang, Ugur Dag, Ijeoma Nwabudike, Matthew Gomes, Eric Bueno, Jungsoo Kim, Adam Atanas, Cassi Estrem, Sarah Pugliese, Ziyu Wang, Emma Towlson, Steven Flavell",
        "date": "Friday, 10 March 2023",
        "location": "II-021",
        "abstract": "Serotonin signaling is evolutionarily ancient and controls many aspects of behavior. The principles by which serotonin acts on its diverse types of receptors to modulate neural circuit activity and resultant behavior is poorly understood. Here, we examine how serotonin released from a food-responsive neuron in C. elegans alters neural activity at whole-brain scale to induce adaptive behaviors, such slow locomotion and increased pharyngeal pumping. A comprehensive in vivo genetic analysis of the six C. elegans serotonin receptors identifies three core serotonin receptors that sense serotonin release with different temporal kinetics to induce slow locomotion upon serotonin release. By expressing stereotypical combinations of fluorophores across all the neurons, we map out the exact sites of serotonin receptor expression in the connectome. Receptor swap experiments show that the behavioral responses to serotonin is attributable to the unique sites where these receptors are expressed. Brain-wide calcium imaging during food-triggered serotonin release reveals widespread neural dynamics that are significantly correlated moment-to-moment with the activity of the serotonergic neuron, which impacts different behavioral networks in different ways. The exact sites of receptor expression partially predict their correlation strength with the serotonergic neuron as it releases serotonin to the neuropil. In addition, we observe that serotonin-associated brain dynamics extend much more broadly than predicted from the structural connectome. These results provide a global view of how serotonin acts on specific receptors at defined sites in a connectome to modulate circuits and behavior in response to changes in the sensory environment.",
        "url": "https://www.world-wide.org/cosyne-23/dissecting-functional-organization-2f932bb5"
    },
    "A probabilistic framework for task-aligned intra- and inter-area neural manifold estimation": {
        "title": "A probabilistic framework for task-aligned intra- and inter-area neural manifold estimation",
        "authors": "Edoardo Balzani, Jean-Paul Noel, Pedro Herrero-Vidal, Dora Angelaki, Cristina Savin",
        "date": "Friday, 10 March 2023",
        "location": "II-022",
        "abstract": "Low dimensional neural manifolds provide a compact characterization of population activity and shared co-variability across brain areas. Nonetheless technical limitations restrict the applicability of these tools to experimental designs without explicit trial structure, and thus cannot be used to understand neural responses during naturalistic behavior. Here we propose a novel probabilistic framework that allows for interpretable partitioning of population variability within and across areas in the context of naturalistic behavior. Our approach for task aligned manifold estimation (TAME-GP) explicitly partitions variability into private (to an area) and shared (across areas) sources, which can each be aligned to task-relevant axes. Furthermore, it uses biologically-appropriate Poisson noise, and introduces temporal smoothing of latent trajectories in the form of a Gaussian Process prior. This TAME-GP graphical model allows for robust estimation of task-relevant variability in local population responses, and of shared co-variability between brain areas. We demonstrate the efficiency of our estimator on simulated data. We also apply it to several datasets of neural population recordings in multiple species, areas and behavioral tasks. Overall, our results demonstrate the capacity of TAME-GP to capture meaningful intra- and inter-area neural variability with single trial resolution.",
        "url": "https://www.world-wide.org/cosyne-23/probabilistic-framework-task-aligned-dcfce16d"
    },
    "A common neural mechanism mediates microsaccades and covert spatial attention": {
        "title": "A common neural mechanism mediates microsaccades and covert spatial attention",
        "authors": "Priyanka Gupta, Sanchit Gupta, Sridharan Devarajan",
        "date": "Friday, 10 March 2023",
        "location": "II-023",
        "abstract": "Microsaccades are small (<1°) fixational eye movements. Spatial biases in microsaccade direction reflect the focus of covert attentional selection [1]. Yet, whether microsaccades and covert attention are mediated by shared, or distinct, neural mechanisms remains actively debated [2-4]. For example, a recent study suggested that attentional modulations of neural activity in visual area V4 occur only when accompanied by microsaccades [2]. Yet, other studies have shown that behavioral and neural effects of attention occur regardless of microsaccades [3-4]. Here, we present novel evidence that reconciles these disparate findings and demonstrates a compelling mechanistic link between microsaccades and lateralized alpha-band (8-12 Hz) synchronization, a widely reported signature of functional inhibition during attention [5]. We analyzed microsaccades and scalp electroencephalography (EEG) data from n=23 participants performing a visual working memory task (1200 trials each) [4]. We observed a consistent increase in alpha-band synchronization (phase-locking value / PLV) [5], from ~200 ms preceding each microsaccade and lasting well (>300 ms) afterwards (Fig. 1D-E). Surprisingly, this increase was substantially more pronounced over the hemisphere ipsilateral, rather than contralateral, to the microsaccade (p<0.001, permutation test). Demonstrating the robustness of this association, we replicated this finding in two independently acquired datasets comprising n=38 participants performing spatial attention tasks (Fig. 1F-G). We synthesized these findings in a computational model of the superior colliculus (SC), a midbrain structure implicated in eye-movements and attention [6] (Fig. 2). We modeled the lateralized increase in alpha-band PLV via a local inhibitory mechanism that drives microsaccades ipsilaterally through a threshold-mediated disinhibitory motif (Fig. 2A-B). Model simulations readily reconciled puzzling disconnects between microsaccades and attention-related modulations of both behavior and SC neural activity, reported recently [3]. In sum, alpha-band synchronization may represent a common neural mechanism that mediates both microsaccades and attention, motivating the need for detailed characterization of the underlying neural circuitry.",
        "url": "https://www.world-wide.org/cosyne-23/common-neural-mechanism-mediates-microsaccades-89e91d61"
    },
    "Sequence decoding with millisecond precision in the early olfactory system": {
        "title": "Sequence decoding with millisecond precision in the early olfactory system",
        "authors": "Robin Blazing & Kevin Franks",
        "date": "Friday, 10 March 2023",
        "location": "II-024",
        "abstract": "In all sensory systems, arrays of receptors respond to stimuli over both space and time. Whether and how the precise temporal pattern of receptor activation impacts the activity of downstream brain regions remains unclear. In the olfactory system, odors activate stereotyped spatiotemporal sequences of olfactory bulb (OB) glomeruli, whose responses reflect the activity of olfactory receptor neurons. These glomeruli project via OB mitral and tufted (M/T) cells to downstream piriform cortex (PCx), forming a shallow circuit through which to assess how temporal patterns of receptor activity are encoded at each stage of processing from the periphery to cortex. Using targeted patterned optogenetic stimulation of glomeruli in awake, head-fixed mice while recording from large populations of PCx neurons, we have revealed that neural population responses in PCx are exquisitely sensitive to the specific timing with which glomeruli are sequentially stimulated throughout a single sniff cycle (~150ms). We hypothesized that this temporal selectivity is conferred by cortical inhibitory circuits. We therefore stimulated sequences of glomeruli while optogenetically suppressing PCx inhibitory interneurons. Suppressing cortical inhibition substantially increased the magnitude of PCx responses but, surprisingly, had little effect on temporal selectivity. Instead, we found that OB M/T cells also exhibit temporally selective responses, suggesting that sequence selectivity is computed by OB circuits and then relayed to downstream cortical networks. Together, our findings provide novel insights into the computational principles and mechanisms that govern neural sequence readout in cortical circuits.",
        "url": "https://www.world-wide.org/cosyne-23/sequence-decoding-with-millisecond-precision-2ce11ae9"
    },
    "A Biophysical Mechanism for Changing the Threat Sensitivity of Escape Behavior": {
        "title": "A Biophysical Mechanism for Changing the Threat Sensitivity of Escape Behavior",
        "authors": "Yaara Lefler, Yeqing Wang, Goncalo Ferreira, Tiago Branco",
        "date": "Friday, 10 March 2023",
        "location": "II-025",
        "abstract": "Animals faced with predatorial threats innately react by escaping to safety. Although escape is instinctive, it is also flexible enough to adapt to dynamic changes in the environment. For example, animals adapt to the risk of predation by increasing escape probability when there is a higher incidence of predator attacks. This flexibility is critical for maximizing the adaptiveness of behavioural choices, but the underlying mechanisms are unknown. It has recently been shown that activation of neurons in the dorsal periaqueductal gray (dPAG) is the main step for commanding escape initiation. Here we hypothesized that changing the excitability of dPAG neurons is a mechanism for implementing experience-dependent adaptations of escape behavior. To investigate this hypothesis, we developed a new paradigm for performing whole-cell recordings from dPAG neurons of mice escaping from threatening stimuli. Head-restrained mice navigate between a shelter and a threat zone and are exposed to threatening stimuli that cause escape-to-shelter responses. To modulate escape behavior we presented repeated stimuli, which caused an increase in the probability and vigor of escape, indicating a decrease in the escape threshold. Using this sensitization paradigm and whole-cell recordings we studied the cellular mechanisms of escape threshold modulation. We found that repeated presentation of escape-eliciting stimuli causes a subthreshold sustained depolarization that lasts for several minutes. This depolarization is large enough to reduce the amount of synaptic input needed to reach the action potential threshold. Consequently, subsequent threatening stimuli are more likely to elicit action potentials and therefore escape initiation. We further propose that the sustained depolarization arises from a local disinhibitory mechanism. Our findings present a cellular mechanism for rapid experience-dependent modulation of instinctive escape behavior. We suggest that this biophysical process at the level of single midbrain neurons may be a general mechanism for modulating behavior initiation in dynamic environments.",
        "url": "https://www.world-wide.org/cosyne-23/biophysical-mechanism-changing-threat-bee7f4ab"
    },
    "The desire to know: representations of information value in mouse orbitofrontal cortex during information seeking": {
        "title": "The desire to know: representations of information value in mouse orbitofrontal cortex during information seeking",
        "authors": "Jennifer Bussell, Ethan Bromberg-Martin, Richard Axel, Larry Abbott",
        "date": "Friday, 10 March 2023",
        "location": "II-026",
        "abstract": "Animals often seek knowledge of no apparent extrinsic value, suggesting that knowledge is a source of intrinsic value. Therefore, the desire to acquire information may be an innate motivational drive. We have developed a task in mice to study the neural mechanisms that compute the value of informative stimuli that drive information seeking. Mice are provided with odor cues in a center port that dictate entry into one of two side ports. The side ports offer water reward with identical probability and differ only in whether they provide an information odor cue that reveals the reward outcome. We found that mice strongly preferred the information port and also traded water reward to obtain information. We performed calcium imaging with miniature microscopes in orbitofrontal cortex, a brain region that represents value and task variables and has been previously implicated in information seeking. Decoding analysis and dimensionality reduction revealed a population representation predictive of information that emerged in orbitofrontal cortex during learning. We not only observed a representation predictive of information, we also observed a representation upon the receipt of information. The population response was largely shared between the side port water- and no water-predicting odors, suggesting that information is an unconditioned stimulus that reinforces the representation of information-predicting odor. Moreover, the representation predictive of information was distinct from the representation predictive of water reward. Thus, mice seek information of no extrinsic value, and the value of information is encoded in a distinct representation in the orbitofrontal cortex.",
        "url": "https://www.world-wide.org/cosyne-23/desire-know-representations-information-012a959f"
    },
    "Coordinating behavioral sequencing and sidedness": {
        "title": "Coordinating behavioral sequencing and sidedness",
        "authors": "Xinping Li, Kyle Thieringer, Elise Ireland, Mala Murthy",
        "date": "Friday, 10 March 2023",
        "location": "II-027",
        "abstract": "Most animals evolved with bilateral symmetry. Yet, many behaviors, from tying shoelaces to playing sports, require asymmetric motions and frequent transitions between the use of different sides of the body. Sidedness (whether the movement is produced on the right or left side of the body) therefore constitutes a critical aspect of the behavior, in addition to the sequence of actions that compose a behavior. We do not know how neural circuits coordinate these two aspects of behavior in any system. To solve this problem, we take advantage of a quantifiable, yet complex behavior produced by Drosophila melanogaster that involves both motor sequencing and sidedness. During courtship, male flies vibrate one wing at a time to produce a highly dynamic song that they pattern into sequences of distinct syllables in response to sensory cues from the female. Using novel behavioral methods, we show that males seamlessly switch between wings during the ongoing song, choosing the one closest to the female, without disruption or alteration of the song sequence. Moreover, we show that female location is highly predictive of male wing choice in their monocular zone (when the male fly sees the female with only one eye). Wing choices become stochastic in the binocular zone, when the position of the female becomes ambiguous. Additionally, we show that sensory information across modalities play different roles in mediating wing usage. Furthermore, using genetic manipulations, optogenetics, and patch-clamp electrophysiology, we explore the roles of individual neurons in wing choices and song patterning. Our ongoing study focuses on the computational rules and circuit mechanisms by which ongoing sensory information patterns song sequences and mediates wing choices simultaneously. Our work ultimately seeks to uncover general principles of neural circuit function that will inform how the nervous system implements behavioral flexibility in more complex systems.",
        "url": "https://www.world-wide.org/cosyne-23/coordinating-behavioral-sequencing-9b8c7ec8"
    },
    "Understanding Auditory Cortex with Deep Neural Networks": {
        "title": "Understanding Auditory Cortex with Deep Neural Networks",
        "authors": "Bilal Ahmed, Brian Malone, Joseph Makin",
        "date": "Friday, 10 March 2023",
        "location": "II-028",
        "abstract": "Recent work [Yamins 2014, Bashivan 2019, Bao 2020] has shown that the initial responses of individual neurons in the ventral stream of visual cortex can be predicted with high accuracy by deep neural networks trained on challenging visual classification problems. Similar results have been obtained for voxels of auditory cortex with fMRI [Kell 2018]. But the relatively poor time resolution of fMRI precludes capturing temporal structure below about 1 Hz, which is known to be an important characteristic of auditory processing [Downer 2020]. Here we investigate the relationship between sequences of neural spiking activity, in response to audio stimuli, in the auditory cortex of squirrel monkeys; and sequences of hidden-layer representations in a deep neural network (DNN) trained to convert speech audio to text. We show: (1) Layers of the trained—but not the untrained—DNN can explain the activity of neurons in core and belt areas of auditory cortex, at temporal frequencies of 50 Hz and higher, and with noise-corrected correlations as high as 0.94. (2) Different regions of auditory cortex correlate well with different layers of the DNN model, suggesting the existence of topographic organization not based strictly on tonotopy. (3) The DNN can be used to generate “optimal” audio inputs—i.e., that maximize the predicted neural response [Bashivan 2019]—which in some cases turn out to resemble chirps, a common call of the squirrel monkey. The success of this method has important implications for understanding the computational basis of auditory cortex, since the “object-space” of non-primary auditory areas is unknown.",
        "url": "https://www.world-wide.org/cosyne-23/understanding-auditory-cortex-with-deep-ce42322d"
    },
    "Beyond task-optimized neural models: constraints from eye movements during navigation": {
        "title": "Beyond task-optimized neural models: constraints from eye movements during navigation",
        "authors": "Akis Stavropoulos, Kaushik Lakshminarasimhan, Dora Angelaki",
        "date": "Friday, 10 March 2023",
        "location": "II-029",
        "abstract": "Generic neural networks optimized for task performance are often successful in predicting neural activity in animals. However, neural mechanisms dictate not only the task performance but also how a particular task is solved. Can we deduce mechanisms from cognitive strategies? To find out, we asked humans and monkeys to perform a challenging task in which they steered to a remembered goal location by integrating self-motion in a virtual environment lacking position cues. Although this task requires only mentally tracking one’s position relative to the goal, subjects physically tracked this latent task variable with their gaze. Restraining eye movements worsened task performance suggesting that embodiment plays a computational role. Above findings are well explained by a neural model with tuned bidirectional connections between oculomotor and sensory input circuits. In contrast to other task-optimized models, this model correctly predicted that leading principal components of the monkey posterior parietal cortex activity should encode their position relative to the goal. These results explain the computational significance of motor signals in evidence-integrating circuits and suggest that plasticity between those circuits might enable efficient learning of complex tasks.",
        "url": "https://www.world-wide.org/cosyne-23/beyond-task-optimized-neural-models-1eb8e466"
    },
    "Locally coupled oscillatory recurrent networks learn traveling waves and topographic organization": {
        "title": "Locally coupled oscillatory recurrent networks learn traveling waves and topographic organization",
        "authors": "Andy Keller & Max Welling",
        "date": "Friday, 10 March 2023",
        "location": "II-030",
        "abstract": "Complex spatio-temporal neural population dynamics such as traveling waves are known to exist across multiple brain regions (Lubenov & Siapas, 2009; Muller et al., 2014), and have been hypothesized to play diverse roles from information transfer (Sato et al., 2012) to long-term memory consolidation (Muller et al., 2016). To-date, however, the empirical validation of these computational hypotheses has been hindered by the lack of a flexible and efficiently trainable model of such behavior. In this work, we introduce the Locally Coupled Oscillatory Recurrent Neural Network (LocoRNN), and show that it indeed learns to leverage traveling waves, and other well known coordinated dynamics of coupled oscillators (Kuramoto, 1975), in the service of structured sequence modeling. However, unlike previous models of such dynamics, we show that our model remains a flexible, trainable, sequence model competitive with state of the art on benchmarks such as the Hamiltonian Dynamics Forecasting Suite (Botev et al., 2021). Furthermore, when trained to model simple image sequences such as simulated retinal waves, we see that the orientation selectivity of hidden neurons becomes topographically organized, while such organization is absent when trained on unstructured noise. The resulting organization is reminiscent of orientation columns observed in the visual cortex and in line with prior work on activity-dependent organization in the visual system during development (Ackman et al, 2012). Due to local connectivity, our model is both more biologically plausible and parameter efficient than its globally coupled counterpart, the coRNN (Rusch & Mishra, 2021), while also being substantially more amenable to gradient-based training than recent spiking neural network counterparts (Davis et al, 2021) due to provably bounded gradients. Overall, we believe our results highlight the value of the LocoRNN as a novel tool for investigating the diversity of hypothesized roles of synchronous neural dynamics and their impact on computation.",
        "url": "https://www.world-wide.org/cosyne-23/locally-coupled-oscillatory-recurrent-1e889d08"
    },
    "Multi task representations of RNNs show a simplicity bias": {
        "title": "Multi task representations of RNNs show a simplicity bias",
        "authors": "Elia Turner & Omri Barak",
        "date": "Friday, 10 March 2023",
        "location": "II-031",
        "abstract": "Recently, both experimental and theoretical work has expanded from studying neural systems with one task at a time to studying them while performing multiple tasks. An open question is understanding how a brain area, a population of inter-connected neurons, can carry on different computations depending on the context. Computations can either share the neural population code, share some activity modes, be entirely separated in activity space, or anything in between. To study this theoretically, it is possible to train RNNs on multiple tasks and study the emerging hidden representations. The challenge is that tasks that are typically used in Neuroscience are composed of multiple sensory, cognitive, and motor primitives, and traditional task-similarity is multidimensional, which makes it difficult to know which computational component influenced the final representations. To overcome that, we develop a framework that disambiguates cognitive computation from sensory and motor processes, by designing all tasks to operate on identical input and output statistics. The framework naturally leads to simple mathematical measures of task-similarity. We train multiple RNN instances on a large set of tasks of two types (1-back and 2-back memory), with various architectural choices. We find that networks are \\textit{simplicity-biased}, in the sense that they will form the minimal dynamical objects necessary to solve the task. We demonstrate the interaction between this bias and the external forces -- task-similarity, input and output architecture, and context signals -- shape the joint representation.",
        "url": "https://www.world-wide.org/cosyne-23/multi-task-representations-rnns-show-0122c895"
    },
    "Large scale neural dynamics that govern normal and disrupted breathing": {
        "title": "Large scale neural dynamics that govern normal and disrupted breathing",
        "authors": "Nicholas Bush & Jan-Marino Ramirez",
        "date": "Friday, 10 March 2023",
        "location": "II-032",
        "abstract": "Breathing is a vital sensorimotor behavior maintained throughout life that must be concurrently robust and flexible. Despite the relative simplicity of this behavior, the neural circuits that drive and maintain breathing are distributed throughout a large population of anatomically distributed and molecularly diverse neural population that compose the rostro-caudally extended Ventral Respiratory Column (VRC) The rhythmic properties of individual VRC nuclei are well known, yet technical challenges have limited the interrogation of the entire VRC population simultaneously. Here we introduce an experimental preparation that allows for large-scale electrophysiological recordings along the rostrocaudal extent of the medulla We combine recordings from Neuropixel probes with optogenetic tagging and 3D histological reconstructions to detail the respiratory-related activities of VRC populations in intact, freely breathing mice. We apply dimensionality reduction techniques to the activity of simultaneously recorded VRC populations to show that dynamics of these populations evolve along a continuous, rotational, low-dimensional trajectory that is consistent across animals and recordings. Inspiratory and expiratory activity can be well described as an alternation between disjoint, but intersecting, linear dynamical systems governed by unstable fixed points. Notably, the offset of inspiration forms an attractive target in neural population space, expanding the classical idea of the “inspiratory off-switch” to the population dynamics of the entire VRC. We further test how these rotational dynamics are disrupted by systemic perturbations to respiratory dynamics: opioids and hypoxia. We show that opioids cause myriad diverse changes in single unit spiking activity across the VRC. However, the underlying low-dimensional structure is preserved, but evolution through low-dimensional trajectories is slowed, suggesting that there are redundant network solutions to preserve respiratory function in response to such perturbations. In contrast, during hypoxia induced gasping, the rotational dynamics observed during normal breathing (eupnea) collapse to form ballistic all-or-nothing efforts.",
        "url": "https://www.world-wide.org/cosyne-23/large-scale-neural-dynamics-that-govern-25c3697e"
    },
    "Hippocampal Planning: Linking Actions and Outcomes to Guide Behavior": {
        "title": "Hippocampal Planning: Linking Actions and Outcomes to Guide Behavior",
        "authors": "*Sarah Jo Venditto, Kevin Miller, Nathaniel Daw, Carlos Brody**",
        "date": "Friday, 10 March 2023",
        "location": "II-033",
        "abstract": "Humans and animals construct internal models linking actions with their likely outcomes, and use these models to guide behavior. Such model-based cognition is often referred to as planning, and its neural mechanisms remain poorly understood (Miller & Venditto, 2021). The hippocampus, known for its role in spatial learning and memory, is necessary for planning (Miller et al., 2017; Vikbladh et al., 2019). Specifically, hippocampal sequences, which “sweep out” nonlocal trajectories both during active behavior (“theta sequences”) and at rest (“sharp-wave ripple sequences”; SWR), have been proposed to link actions to subsequent outcomes in a manner suitable for planning (Mattar & Daw, 2018; Pezzulo et al., 2019). Here, we investigate the role of these sequences in detail using Neuropixel 2.0 probes (Steinmetz et al., 2021) to record many simultaneous units while rats perform a multi-step decision task that elicits planned behavior (Miller et al., 2017). We find that hippocampus encodes states of the task with periods of action and outcome co-representation. We find action-outcome links during theta sequences before trial initiation, biased towards upcoming choices and previously experienced outcomes, and during theta sequences approaching outcomes, biased towards previous choices. Choices paired with unexpected outcomes have increased representation of non-chosen actions, reflecting knowledge of the task’s transition structure and suggesting credit assignment towards relevant, non-chosen actions. SWR sequences between trials are biased towards previously rewarded outcomes but show no significant choice modulation. These results suggest that theta sequences, but not SWR sequences, support choice evaluation and model-based credit assignment.",
        "url": "https://www.world-wide.org/cosyne-23/hippocampal-planning-linking-actions-2d1d920c"
    },
    "Transforming a head direction signal into a goal-oriented steering command": {
        "title": "Transforming a head direction signal into a goal-oriented steering command",
        "authors": "Elena Westeinde, Emily Kellogg, Paul Dawson, Jenny Lu, Lydia Hamburg, Benjamin Midler, Shaul Druckmann, Rachel Wilson",
        "date": "Friday, 10 March 2023",
        "location": "II-034",
        "abstract": "To navigate, we must continuously estimate the direction we are headed in, and we must use this information to guide our path toward our goal (Schöne, 2014). Direction estimation is accomplished by ring attractor networks in the head direction system (Knierim et al., 2012, Hulse et al., 2020). However, we do not understand how the sense of direction is used to guide action. Drosophila connectome analyses (Rayshubskiy et al., 2020, Hulse et al., 2021) recently revealed two cell types (PFL2 and PFL3) that connect the head direction system to the locomotor system. These populations also receive almost all the same inputs, including those that may constitute a goal signal. Here we show how both cell types combine an allocentric head direction signal with an internal goal signal to produce an egocentric motor drive. We used 2-photon calcium imaging and electrophysiology to monitor their activity as flies navigated in a virtual reality environment toward a goal stored in memory. Strikingly, PFL2 and PFL3 populations are both modulated by deviation from the goal direction, but with opposite signs. The amplitude of PFL2 activity is highest when the fly is oriented away from its goal; chemogenetically activating these cells destabilizes the current orientation and drives turning. By contrast, total PFL3 activity is highest around the goal; these cells generate directional turning to correct small deviations from the goal. Our data support a model where the goal is stored as a sinusoidal pattern whose phase represents direction, and whose amplitude represents salience. Variations in the amplitude of this internal goal signal can explain observed transitions between goal-oriented navigation and exploration. Together, these results show how the sense of direction is used for feedback control of locomotion.",
        "url": "https://www.world-wide.org/cosyne-23/transforming-head-direction-signal-into-e6ee56b1"
    },
    "Embryonic layer 5 pyramidal neurons form earliest recurrent circuits with correlated activity": {
        "title": "Embryonic layer 5 pyramidal neurons form earliest recurrent circuits with correlated activity",
        "authors": "Arjun Bharioke, Martin Munz, Georg Kosche, Verónica Moreno-Juan, Alexandra Brignall, Alexandra Graff-Meyer, Talia Ulmer, Tiago Rodrigues, Simone Picelli, Cameron Cowan, Botond Roska",
        "date": "Friday, 10 March 2023",
        "location": "II-035",
        "abstract": "Layer 5 pyramidal neurons (L5 PNs) are a major cortical output. Their connectivity approximates a recurrent neural network (RNN), with the majority of inputs coming from other L5 PNs. These neurons may underlie anesthesia-induced unconsciousness, by restricting information output from cortex. Therefore, understanding the formation of the L5 PN circuitry, from the time at which L5 PNs first enter cortex, would provide insight into how a biological RNN can be constructed. However, this is technically challenging because, in mice, L5 PNs first enter cortex at embryonic day (E) 13.5, five days before birth. Hence, we developed a method of two-photon imaging from cortical neurons, in living embryos, connected to the dam. Applying this para-uterine imaging method, we observed a structured, bimodal pattern of increased activity in embryonic L5 PNs. Surprisingly, they showed an early peak of activity only a day after migrating into the nascent cortex, at E14.5, followed by a decrease from E15.5 to E16.5, and then a second increase from E17.5 onwards. Further, the neurons responded to glutamatergic agonists. Performing visually-guided patch clamp recordings in living embryos, we found that embryonic L5 PNs showed tetrodotoxin-sensitive active conductances during both periods of increased activity. Together, these results suggest that embryonic activity is mediated similarly as in the adult. Intriguingly, activity across pairs of embryonic L5 PNs was correlated greater than expected by chance. This suggests that embryonic L5 PNs form recurrent circuits with other L5 PNs, as early as E14.5. However, these correlations were independent of distance, and did not form waves. Throughout embryonic development, the precise temporal variation in activity in L5 PNs coincided with changes in circuit organization. This suggests that correlated activity serves a specific function. The para-uterine imaging method gives us all-optical access to characterizing this function and, thereby, to understanding this biological RNN’s construction.",
        "url": "https://www.world-wide.org/cosyne-23/embryonic-layer-pyramidal-neurons-form-06e55d04"
    },
    "Dendritic modulation for multitask representation learning in deep feedforward networks": {
        "title": "Dendritic modulation for multitask representation learning in deep feedforward networks",
        "authors": "Willem Wybo, Viet Anh Khoa Tran, Matthias Tsai, Bernd Illing, Jakob Jordan, Walter Senn, Abigail Morrison",
        "date": "Friday, 10 March 2023",
        "location": "II-036",
        "abstract": "Feedforward sensory processing in the brain is generally construed as proceeding through a hierarchy of layers, each constructing increasingly abstract and invariant representations of sensory inputs. This interpretation is at odds with the observation that activity in sensory processing layers is heavily modulated by contextual signals, such as cross modal information or internal mental states. While it is tempting to assume that such modulations bias the feedforward processing pathway towards detection of relevant input features given a context, this induces a dependence on the contextual state in hidden representations at any given layer. The next processing layer in the hierarchy thus has to be able to extract relevant information for each possible context. For this reason, most machine learning approaches to multitask learning apply task-specific output networks to context-independent representations of the inputs, generated by a shared trunk network. Here, we show that a network motif, where a layer of modulated hidden neurons targets an output neuron through task-independent feedforward weights, solves multitask learning problems, and that this network motif can be implemented with biophysically realistic neurons that receive context-modulating synaptic inputs on dendritic branches. The dendritic synapses in this motif evolve according to a Hebbian plasticity rule modulated by a global error signal. We then embed such a motif in each layer of a deep feedforward network, where it generates task-modulated representations of sensory inputs. To learn feedforward weights to the next layer in the network, we apply a contrastive learning objective that predicts whether representations originate either from different inputs, or from different task-modulations of the same input. This self-supervised approach results in deep representation learning of feedforward weights that accommodate a multitude of contexts, without relying on error backpropagation between layers.",
        "url": "https://www.world-wide.org/cosyne-23/dendritic-modulation-multitask-representation-6cb4d73b"
    },
    "Ranking and serial thinking: evidence of a geometrical solution in premotor cortex": {
        "title": "Ranking and serial thinking: evidence of a geometrical solution in premotor cortex",
        "authors": "Gabriele Di Antonio, Sofia Ragio, Emiliano Brunamonti, Stefano Ferraina, Maurizio Mattia",
        "date": "Friday, 10 March 2023",
        "location": "II-037",
        "abstract": "Serial thinking is a cognitive function underpinning almost any of our daily actions. Our brain continuously encodes and learns ordered sequences that we can remember, process and replay as in motor planning and language production. Despite the pervasiveness of such computation, a full understanding of the neuronal machinery underpinning this function is still lacking. Psychophysical evidence suggests that the ordering of learned information can be solved resorting to a linear mental workspace, namely the mental line, in which the relevant items are mapped according to their arbitrary assigned rank. Here, we prove that a “geometric” mental line (GML) exists and it can be encoded as a suited linear combination of the item representations in the neuronal state space of cortical networks, as long as their independence can be assumed. In associative cortices, such independence is known to be guaranteed by quasi-randomly projecting sensory information in the high-dimensional space of neuronal activity. Accordingly, we found that abstract symbols involved in a transitive inference task, were represented in the dorsal premotor (PMd) cortex of two rhesus monkeys as independent and almost orthogonal engrams. Indeed, the multi-unit activity (MUA) recorded in the left PMd from a 96-channel microelectrode array displayed mixed selectivity to the symbols and their locations. The monkeys were required to learn the ordinal position of a set of seven visual abstract symbols (A, B, C, …), arbitrarily rank ordered. In trials and error sessions they first learned that A > B and B > C, subsequently accomplishing the task request to transitively infer the never experienced relationship A > C. Composing the GML based on the decoded representations, we show that PMd activity projected on this linear subspace is predictive of the motor decision, eventually mapping the symbols in adjacent positions along this mental line.",
        "url": "https://www.world-wide.org/cosyne-23/ranking-serial-thinking-evidence-geometrical-6a2f496e"
    },
    "Coregistration of heading and visual inputs in retrosplenial cortex": {
        "title": "Coregistration of heading and visual inputs in retrosplenial cortex",
        "authors": "Kevin Sit & Michael Goard",
        "date": "Friday, 10 March 2023",
        "location": "II-038",
        "abstract": "Spatial cognition depends on an accurate representation of orientation within an environment. Head direction cells in distributed brain regions receive a range of sensory inputs, including proprioceptive, vestibular, and somatosensory information, but visual input is particularly important for aligning their responses to environmental landmarks. To investigate how population-level heading responses are aligned to visual input, we recorded from the retrosplenial cortex (RSC) of head-fixed mice in a moving environment using two-photon calcium imaging. RSC receives strong inputs from both visual and spatial regions, and lesions result in drift of heading direction cell tuning away from environmental landmarks. First, we show that RSC neurons are tuned to the animal’s relative orientation in the environment, even in the absence of head movement, exhibiting the same functional properties as previously defined head-direction cells. Next, we imaged axonal terminals in RSC, revealing that RSC receives functionally distinct projections from visual and thalamic areas. The information carried by these projections combine in RSC to form functional subclasses of neurons, two of which faithfully mirror RSC inputs, representing visually-biased or heading-biased information. However, a newly discovered class coregisters these visual and thalamic signals, combining them into a novel response profile only found in RSC. Finally, decoding analyses reveal unique contributions to heading representations from each subclass of RSC neurons. Whereas heading-biased cells contribute in both light-on and light-off conditions, visually-biased cells drive high decoder performance in light-on conditions only. The final class of cells utilizes information from both sources, resulting in improved decoding in light-on conditions while retaining information in light-off conditions. Together, our results indicate a circuit in RSC that contributes to anchoring heading representations to environmental visual landmarks.",
        "url": "https://www.world-wide.org/cosyne-23/coregistration-heading-visual-inputs-f4b1726f"
    },
    "How Symmetry and Self-Coupling Shape Dynamics and Trainability of Recurrent Neural Networks": {
        "title": "How Symmetry and Self-Coupling Shape Dynamics and Trainability of Recurrent Neural Networks",
        "authors": "Matthew Ding & Rainer Engelken",
        "date": "Friday, 10 March 2023",
        "location": "II-039",
        "abstract": "The connectivity between neurons plays a major role in the dynamics and function of all neural systems. Here, we investigate the joint effects of two previously reported connectivity motifs, partial symmetry and self-coupling, on the dynamics of recurrent neural networks (RNNs). Both motifs can be thought of as statistical deviations from i.i.d. connectivity. In particular, we define self-coupling as the values of diagonal entries and partial symmetry as the correlations across the diagonals of coupling matrices. We calculate the full Lyapunov spectrum to characterize the stability of perturbations in multiple directions of phase space. We identify two regimes in which symmetry and self-coupling affect dynamics. In the first regime, there is a small variance in the synaptic currents from recurrent input. In this regime, increasing the strength of symmetry or self-coupling results in greater dimensionality of the network dynamics. In the second regime, there is a large variance of synaptic currents, and increasing motif strength results in lower dimensionality and decreased chaos. To assess the functional implications of the effects of partial symmetry and self-coupling on dimensionality, we initialize RNNs with these motifs and train them on a multidimensional integration task. RNNs initialized with a wide range of motif strengths have variable performance. However, nonchaotic initialization as defined by an initial maximum Lyapunov exponent less than zero is the main predictor of training success across all values of initial motif strength. Our results complement previous work by considering the full Lyapunov spectrum and describing the combined effects on dynamics and trainability of different types of connectivity motifs present together. As statistical connectivity data from neural systems becomes increasingly available, we anticipate that our work will be relevant to developing new tools to find the functional and dynamical implications of these network descriptions.",
        "url": "https://www.world-wide.org/cosyne-23/symmetry-self-coupling-shape-dynamics-f5086cd3"
    },
    "Descending control of turning during walking": {
        "title": "Descending control of turning during walking",
        "authors": "Helen Yang, Quinn Vanderbeck, Rachel Wilson, Laia Serratosa Capdevila, Anna Li, Jasper Phelps, Brandon Mark, Zetta AI Llc, John Tuthill, Wei-Chung Lee",
        "date": "Friday, 10 March 2023",
        "location": "II-040",
        "abstract": "To understand how the brain controls behavior, we need to understand the neural code for movement. Descending neurons (DNs) represent a bottleneck for motor control signals, and so provide an opportunity to study neural coding in a compact form. In Drosophila, almost all DNs are uniquely identifiable in the connectome of the central nervous system and targetable with specific genetic drivers, allowing us to study their connectivity and physiology in parallel. Previous studies have concluded that these DNs generate high-level motor commands, such as “stop” or “turn”, leaving the detailed implementation to the circuitry of the ventral nerve cord. Here, we challenge this conclusion. First, we use two-photon imaging to show that there are many DNs whose activity correlates with turning during walking. To understand their potential specializations, we focused on two of these cells, DNa02 and DNg13. We found that they have distinct synaptic inputs in the brain connectome and also distinct synaptic outputs in the ventral nerve cord connectome; this implies they can be recruited independently and that they drive different features of movement. We found that directly activating DNa02 shortens the stride on the inside of a turn, while activating DNg13 lengthens the stride on the outside of a turn. Using electrophysiological recordings in walking flies, we found that DNa02 is mainly active during fast turns that arrest forward movement, whereas DNg13 is more broadly active, spiking during fast and slow turns regardless of forward movement. Moreover, DNa02 is recruited abruptly, whereas DNg13 is recruited gradually. Together, these results clearly show that DNs specify limb movements, rather than merely issuing high-level commands, and that different DNs are specialized to independently control different limb movement features. Our work illustrates how DNs can be recruited to execute a complex motor output with flexible kinematics and vigor.",
        "url": "https://www.world-wide.org/cosyne-23/descending-control-turning-during-walking-d83ed50b"
    },
    "Homeostatic synaptic scaling optimizes learning in network models of neural population codes": {
        "title": "Homeostatic synaptic scaling optimizes learning in network models of neural population codes",
        "authors": "Jonathan Mayzel & Elad Schneidman",
        "date": "Friday, 10 March 2023",
        "location": "II-041",
        "abstract": "Studying and understanding the code of large neural populations hinges on learning accurate models of population activity. Statistical models that are based on sparse nonlinear Random Projections (RP) of the population proved to be highly accurate, efficient, and scalable. Interestingly, this class of models has a straightforward biologically-plausible implementation as a shallow neural circuit. Here we extend the RP models, and learn them by optimizing or ``reshaping\" the random projections themselves. The reshaping of projections is akin to changing synaptic connections in the neural circuit implementation of RP models. Applied to recordings of tens of cortical neurons from behaving monkeys, we show that these Reshaped Random Projections models are more accurate and efficient than RP models and on par with backpropagation models. We explore the biological plausibility of RP models, by adding biological features to the circuit models. We find, surprisingly, that learning reshaped RP models with Homeostatic synaptic scaling results in even more efficient and accurate models. We further show that Homeostatic Reshaped RP models that rely on sparse and random connectivity are superior to fully connected network models. Our results therefore offer an accurate and highly efficient class of models for large populations codes. And, importantly, they suggest that beyond regulating network activity, homeostatic synaptic scaling may have a key computational role in neural circuits -- optimizing their performance and efficiency.",
        "url": "https://www.world-wide.org/cosyne-23/homeostatic-synaptic-scaling-optimizes-e591cbff"
    },
    "Optogenetic inhibition reveals large-scale intracortical interactions in the developing cortex": {
        "title": "Optogenetic inhibition reveals large-scale intracortical interactions in the developing cortex",
        "authors": "Deyue Kong, Haleigh Mulholland, Matthias Kaschube, Gordon Smith",
        "date": "Friday, 10 March 2023",
        "location": "II-042",
        "abstract": "In ferret visual cortex, spontaneous activity prior to eye-opening is organized into large-scale, modular patterns in the absence of long-range horizontal projections. This correlated activity reveals endogenous networks that predict aspects of future orientation selectivity [1]. Previous modelling works have shown that the long-range correlations observed in these networks can arise from purely locally connected neurons through multi-synaptic interactions [1][2]. Here we seek to explicitly map the structure of cortical lateral interactions through localized perturbations in vivo. We first constructed a linear recurrent neural network model of strongly coupled excitatory and inhibitory units with effective local heterogeneous Mexican hat connections, finding that perturbing a small region of inhibitory neurons exerts a spatially extended influence on the pattern of ongoing activity. Notably, the influence is modular, partially similar in structure to spontaneous activity, and the strength of influence depends on stimulation location. To test these predictions, we virally expressed GCaMP6s in excitatory neurons and Chrimson-ST in inhibitory neurons in layer 2/3 of young ferret visual cortex, allowing us to optogenetically activate small regions (~500μm diameter) of inhibitory neurons and simultaneously record widefield calcium activity. In line with model predictions, local optogenetic inhibitory perturbations propagate through the entire network and induce a reorganization of activity even in areas up to 2mm away from stimulation site. The degree of disruption to the structure of correlations in activity depends on the perturbation location, and can be predicted from stimulation site’s overlap with the leading spontaneous principal components (PCs). The variance in optogenetically-perturbed activity patterns only partially overlaps with spontaneous activity space, suggesting a different activity manifold with local disruption. Our results are consistent with the presence of strongly coupled E and I networks in early cortex, and demonstrate that network behaviour is an emergent property with local activity exerting specific and global influences.",
        "url": "https://www.world-wide.org/cosyne-23/optogenetic-inhibition-reveals-large-scale-6e3ed926"
    },
    "Control of locomotor statistics by contralateral inhibition in a pre-motor center": {
        "title": "Control of locomotor statistics by contralateral inhibition in a pre-motor center",
        "authors": "Hannah Gattuso, Jonathan Victor, Bard Ermentrout, Katherine Nagel",
        "date": "Friday, 10 March 2023",
        "location": "II-043",
        "abstract": "During foraging, changes in sensory cues such as food odor drive changes in locomotor statistics, shifting animal behavior from dispersal to local search. While cue-evoked changes in locomotor statistics have been observed across species, the neural circuit mechanisms that govern locomotor statistics remain unclear. Here, we explore the neural encoding of locomotor statistics in Drosophila melanogaster. Analysis of walking trajectories following loss of an attractive food odor revealed multiple changes in locomotor statistics relative to baseline: a shift towards lower forward and higher angular velocities, and an increase in the autocorrelation of angular velocity. These changes drive localized search that persists for seconds after odor loss. To account for these changes, we constructed a physiologically-inspired computational model of locomotor control, consisting of units whose sums and differences govern forward and angular velocity. Unit activity depends on a connectivity matrix that includes contralateral inhibition between opposing turn-promoting units. This model reproduces the velocity statistics observed in our data, and smoothly shifts from dispersal to local search with increasing contralateral inhibition. Our model thus suggests that contralateral inhibition in pre-motor circuits may play a key role in shaping locomotor statistics. To test this model, we built genetic lines labeling two populations of contralaterally projecting inhibitory (glutamatergic) neurons in the fly pre-motor center, the Lateral Accessory Lobe. Activation of one line decreased forward velocity, increased angular velocity, and widened the angular velocity auto-correlogram, consistent with model predictions. In the second line, activation dramatically decreased forward velocity while silencing increase forward velocity. An updated model with tonic inhibitory drive can reproduce this second role for inhibition. Together, our data and model provide insight into how population activity in a pre-motor center can shape locomotor statistics to produce adaptive behavior.",
        "url": "https://www.world-wide.org/cosyne-23/control-locomotor-statistics-contralateral-6644e097"
    },
    "Dendritic low pass filtering shapes midbrain neural responses to behaviorally relevant stimuli": {
        "title": "Dendritic low pass filtering shapes midbrain neural responses to behaviorally relevant stimuli",
        "authors": "Norma Kühn, Bram Nuttin, Chen Li, Natalia Baimacheva, Katja Reinhard, Vincent Bonin, Karl Farrow",
        "date": "Friday, 10 March 2023",
        "location": "II-044",
        "abstract": "Neurons are equipped with powerful analog processing units – dendrites. However, the role linear and nonlinear dendritic properties play in shaping a neuron’s output to filter behaviorally relevant information and subsequently drive behavior, is poorly understood. Here, we address this question using wide-field neurons of the mouse superior colliculus; a genetically targetable midbrain cell-type that receives direct input from the retina and mediates innate defensive and hunting behaviors. To understand how wide-field neurons combine their inputs, we measured their output: the responses to behaviorally relevant visual stimuli in dendrites and cell-bodies, as well as their inputs: from the retina and collicular inhibitory interneurons, using a combination of viral transsynaptic circuit tracing, electrophysiology and two-photon calcium imaging. We found that wide-field neuron cell-bodies, known to preferably respond to stimuli mimicking approaching and cruising predators, also show strong responses to a “receding prey stimulus” and cluster by contrast preference into three types: On, Off and On-Off. Spatially confined signals measured in wide-field neuron dendrites in response to large stationary stimuli, revealed diverse signals clustering in distinct collicular layers. Corresponding to these diverse signals, we identified ten types of retinal ganglion cells providing ten parallel information streams to wide-field neurons. To determine which combination of inputs and dendritic filtering properties are necessary to reproduce wide-field neuron responses, we tested an array of linear and nonlinear models. This led to three discoveries: First, linear mapping of retinal and local inputs onto wide-field neuron dendrites revealed a layered input organization, but could not accurately reconstruct cell-body responses. Second, contributions of nonlinear dendritic summation were minor. Third, the accurate reconstruction of cell-body responses to approaching, receding and dimming stimuli mandates strong low pass filtering along the extensive dendritic arbor. The precise input-output mapping allowed to model the dendritic properties necessary to reproduce physiological neural responses.",
        "url": "https://www.world-wide.org/cosyne-23/dendritic-pass-filtering-shapes-midbrain-8eff130b"
    },
    "Time uncertainty in threat prediction explains prefrontal norepinephrine release": {
        "title": "Time uncertainty in threat prediction explains prefrontal norepinephrine release",
        "authors": "Aakash Basu, Jen-Hau Yang, Abigail Yu, Samira Glaeser-Khan, Jiesi Feng, Yulong Li, Alfred Kaye",
        "date": "Friday, 10 March 2023",
        "location": "II-045",
        "abstract": "The neuromodulator dopamine has qualities of a prediction error in temporal difference (TD) models of reward learning. However, the neuromodulatory substrates of threat prediction errors have remained elusive. Norepinephrine (NE) is released by surprise and uncertainty, and causal manipulations demonstrate a role for NE in threat learning. Thus, we hypothesized that NE encodes a threat prediction error signal, and compared NE release measurements in mice undergoing threat learning with predictions of TD learning. NE release scales with the strength of fear associations and threat imminence. However, NE temporal dynamics did not match TD learning prediction errors due to sustained release evoked by threat-associated cues. Inclusion of temporal uncertainty into TD models resolved this discrepancy, and NE fit prediction errors in such a model. Subsequent experiments manipulating temporal uncertainty and sensory feedback demonstrated a match between NE and reinforcement learning models incorporating uncertainty.",
        "url": "https://www.world-wide.org/cosyne-23/time-uncertainty-threat-prediction-explains-6e7e6370"
    },
    "A low-dimensional signature of global brain state in the superior colliculus of the macaque": {
        "title": "A low-dimensional signature of global brain state in the superior colliculus of the macaque",
        "authors": "Richard Johnston & Matthew Smith",
        "date": "Friday, 10 March 2023",
        "location": "II-046",
        "abstract": "Recent work has shown that global signals related to arousal are embedded in the population activity of cortical neurons. In mice, slow fluctuations in neural activity are correlated with whisking and locomotion, while in monkeys a similar pattern has been identified (termed “slow drift”) that is: 1) present in visual/prefrontal cortices; 2) correlated with pupil size; and 3) associated with performance on cognitive tasks. These results demonstrate that changes in brain state are represented in the coordinated activity of cortical neurons. However, it is unknown if these fluctuations are also present in subcortical regions that have been implicated in oculomotor control (e.g., the superior colliculus or SC). One might expect an area close to the motor output to be isolated from such fluctuations, as they could lead to unwanted eye movements. Alternatively, they could still be present in the SC but occupy an orthogonal subspace, which is not readout by downstream regions innervating the oculomotor muscles. To investigate if slow drift is present in the SC, we simultaneously recorded from neuronal populations in the superior colliculus (SC) and prefrontal cortex (PFC) of two monkeys while they performed a memory-guided saccade task. Results showed that the activity of individual SC neurons drifted slowly over time, and when principal component analysis (PCA) was applied to the data it revealed a neural activity pattern that was akin to the slow drift previously reported in cortical neurons. Importantly, slow drift in SC was significantly correlated with slow drift in PFC and the timescale of slow drift in the SC was highly similar to that observed in the PFC. These results indicate the brain-wide nature of slow fluctuations in arousal and pose important questions about how perception and movement can be isolated from slow drifts in neural activity (potentially through isolated subspaces).",
        "url": "https://www.world-wide.org/cosyne-23/low-dimensional-signature-global-brain-5f7cbaf7"
    },
    "Dopamine neurons reveal an efficient code for a multidimensional, distributional map of the future": {
        "title": "Dopamine neurons reveal an efficient code for a multidimensional, distributional map of the future",
        "authors": "Margarida Sousa, Pawel Bujalski, Bruno Cruz, Kenway Louie, Daniel McNamee, Joe Paton",
        "date": "Friday, 10 March 2023",
        "location": "II-047",
        "abstract": "Causal inference based on temporal relationships is fundamental for adaptive, intelligent behavior. However, standard value-based reinforcement learning (RL) models learn estimates of temporally discounted average future reward, leading to ambiguity about future reward timing and magnitude. Extending these algorithms to learn a set of values that differ in their sensitivity to reward prediction errors (RPEs) and temporal discounting can support inference. Midbrain dopamine (DA) neurons, known to encode RPEs, display signatures of learning about distributions of reward magnitude. However, it is unclear whether they also display signatures of learning distributions of reward timing, how such encoding might be multiplexed with reward magnitude information, and whether the joint encoding of these two dimensions allows for distributional readout of reward over time at the start of an episode. Here, we generalize distributional RL learning rules to the time domain by proposing a population coding model that optimally represents such information under resource constraints, adapting to the temporal statistics of experienced rewards. If the brain implements such a code, neural RPEs should 1) express variable sensitivity to future reward timing, 2) carry future reward distribution information and, 3) adapt to changes in the temporal statistics of reward. We tested these predictions by recording responses of optogenetically identified midbrain DA neurons to stimuli that predict rewards at variable delays and amounts. Temporal discounts varied among DA neurons, providing future reward timing information. When removing the longest delay, DA RPE responses adapted, increasing encoding accuracy on shorter reward time scales. Finally, we show that a 2D map of future reward amount over time can be decoded from the DA neuron population. Our work suggests that midbrain DA neurons reflect distributional time, in addition to distributional value RL, forming a potential substrate for fundamental computations such as causal inference, context dependent risk attitudes and impulsivity.",
        "url": "https://www.world-wide.org/cosyne-23/dopamine-neurons-reveal-efficient-code-dfc1f2a4"
    },
    "Predictive dynamics improve noise robustness in a deep network model of the human auditory system": {
        "title": "Predictive dynamics improve noise robustness in a deep network model of the human auditory system",
        "authors": "Ching Fang, Erica Shook, Justin Buck, Guillermo Horga",
        "date": "Friday, 10 March 2023",
        "location": "II-048",
        "abstract": "The human auditory system is robust to many types of corrupting noise. However, the neural mechanism that drives this robustness is unclear. Experimental evidence suggests that top-down predictions play an important role in processing stimuli in noisy contexts. Feedback connections are abundant in the auditory cortex, and have been hypothesized to carry predictive signals but are often omitted in large scale models. We evaluate the potential role of predictive dynamics in auditory robustness by introducing these dynamics into a large-scale model of the human auditory system. Specifically, we augment a feedforward deep neural network trained to identify speech in corrupting noise using a recently introduced predictive feedback scheme. We find that predictive dynamics improve network performance on a challenging speech recognition task. These performance gains were associated with denoising of network representations and alterations in layer dimensionality. Finally, we find that the model captures brain data outside of the speech domain. Overall, this work demonstrates that predictive dynamics are a candidate mechanism for denoising representations in the human auditory system. Furthermore, our network model provides a testbed for hypotheses regarding the dynamics of auditory robustness.",
        "url": "https://www.world-wide.org/cosyne-23/predictive-dynamics-improve-noise-robustness-37c6d87d"
    },
    "Hippocampal Neocortical Coupling Varies as a Function of Depth of NREM Sleep": {
        "title": "Hippocampal Neocortical Coupling Varies as a Function of Depth of NREM Sleep",
        "authors": "Rachel Swanson, György Buzsáki, Jayeeta Basu",
        "date": "Friday, 10 March 2023",
        "location": "II-049",
        "abstract": "During NREM sleep, the brain is in a self-organized excitable regime in which alternations between spiking and near cessation of spiking propagate along the forebrain, termed slow oscillations (SOs) or UP and DOWN states in the neocortex, and sharpwave-ripples (SPW-Rs) in the hippocampus (Levenstein 2019). Both gain and loss of function studies have demonstrated the importance of tight temporal coordination between SOs and SPW-Rs for systems consolidation. However, where and how this coordination is spontaneously achieved is unknown, despite being essential for understanding whole-brain mechanisms of systems consolidation. Towards this, we develop a preparation in mice that combines widefield imaging of dorsal neocortex and extracellular silicon probe recordings of hippocampus (HPC) and retrosplenial cortex (RSC), allowing us to monitor multi-scale interaction between regions during sleep, and further develop an existing mean-field model of NREM. We find that interaction between HPC and RSC is well matched by a proposed model whereby both RSC and HPC are in reciprocally perturbable excitable regimes, and the degree to which they can perturb one another depends on both the strength of input received and state of the receiving region. This occurs in three phases, or a neocortical-hippocampal-neocortical loop. First, hippocampal SPW-Rs are preceded by increased fluorescence in mouse visual and association cortices. The number of regions active preceding the SPW-R predicts the magnitude of sharpwave associated with the ripple, thought to reflect the degree of input to the region. The greater the magnitude of input, the larger the amplitude of the evoked ripple, and the larger the DOWN state evoked in CTX. This evoked DOWN is most likely to occur in retrosplenial cortex, and the extent to which it propagates down the cortical hierarchy varies as a function of the depth of NREM.",
        "url": "https://www.world-wide.org/cosyne-23/hippocampal-neocortical-coupling-varies-19be9370"
    },
    "Distinct Fos- and Npas4-mediated synaptic plasticity crucial for memory consolidation": {
        "title": "Distinct Fos- and Npas4-mediated synaptic plasticity crucial for memory consolidation",
        "authors": "Douglas Feitosa Tomé, Meizhen Meng, Xiaochen Sun, Sadra Sadeh, Yingxi Lin, Claudia Clopath",
        "date": "Friday, 10 March 2023",
        "location": "II-050",
        "abstract": "Experiences are encoded in sparse neuronal ensembles that can be defined by the transcription activation of immediate-early genes such as Fos and Npas4. The Fos+ and Npas4+ neuronal ensembles within an engram have been reported to recruit distinct synaptic plasticity mechanisms. However, it remains unknown whether and how Fos- and Npas4-mediated synaptic plasticity support memory consolidation. Here we provide experimental and computational evidence that Fos+ and Npas4+ neuronal ensembles coordinate different excitatory and inhibitory synaptic plasticity mechanisms to promote memory consolidation. Using contextual fear conditioning and electrophysiology recordings, we found that Fos+ and Npas4+ granule cells in the hippocampal dentate gyrus recruit distinct forms of inhibitory synaptic plasticity from parvalbumin (PV+) and cholecystokinin (CCK+) interneurons. Based on these experimental findings, we proposed a computational model in which Fos+ and Npas4+ neurons have specific combinations of excitatory and inhibitory plasticity that led to the emergence of engram selectivity during memory consolidation. In our network model, Fos-mediated plasticity enabled cross-region synaptic coupling — a feature thought to support coupled engram reactivations in systems consolidation of memory. On the other hand, Npas4-mediated plasticity rendered engram ensembles highly robust to reactivation noise during consolidation in our simulations. Our model also predicted that the composition and selectivity of Fos+ and Npas4+ engram ensembles evolve distinctly with time and that blocking the plasticity of PV+ and CCK+ interneurons disrupts memory consolidation. Our work reveals that transcriptionally-defined neuronal ensembles within an engram have both shared and complementary roles in memory consolidation. These results highlight the impact of cell-type-specific synaptic plasticity on a wide range of computational and behavioral functions.",
        "url": "https://www.world-wide.org/cosyne-23/distinct-fos--npas4-mediated-synaptic-b7fdce7f"
    },
    "Hippocampal coding during visual deliberation in freely moving birds": {
        "title": "Hippocampal coding during visual deliberation in freely moving birds",
        "authors": "Hannah Payne & Dmitriy Aronov",
        "date": "Friday, 10 March 2023",
        "location": "II-051",
        "abstract": "The circuit mechanisms that transform sensory input into the observed firing patterns in the hippocampus are unclear. Like primates, birds almost exclusively depend on vision to navigate. However, birds primarily direct gaze using head saccades, rather than eye saccades, and gaze can therefore be readily measured during free movement. We leveraged these features to ask how visual input during navigational decisions is encoded by the hippocampus. We developed a system to estimate gaze in freely moving birds, and designed a task to behaviorally dissociate physical location (“place”) from viewed location (“gaze”). We found neural signals related to vision in the avian hippocampus, including robust modulation of firing during gaze saccades, with putative excitatory and inhibitory neurons active at different phases of the saccade. This temporal pattern suggests a similar role of saccades in visually dependent animals to rodent theta oscillations. We also found that hippocampal activity coordinates the coding of both place and gaze locations. These results yield insight into how visual perception informs hippocampal representations of space and guides behavior.",
        "url": "https://www.world-wide.org/cosyne-23/hippocampal-coding-during-visual-deliberation-f1de6955"
    },
    "The Exponential Family Variational Kalman Filter for Real-time Neural Dynamics": {
        "title": "The Exponential Family Variational Kalman Filter for Real-time Neural Dynamics",
        "authors": "Matthew Dowling, Yuan Zhao, Il Memming Park",
        "date": "Friday, 10 March 2023",
        "location": "II-052",
        "abstract": "Latent variable models have become instrumental in computational neuroscience for reasoning about neural computation. This has fostered the development of powerful offline algorithms for extracting latent neural trajectories from neural recordings. However, despite the potential of real-time algorithms to give immediate feedback to experimentalists, and enhance experimental design, they have received markedly less attention compared to their offline counterparts. We introduce the exponential family variational Kalman filter (eVKF), an online recursive Bayesian method aimed at simultaneously inferring latent trajectories and learning the underlying dynamical system. eVKF works for arbitrary likelihoods and utilizes the constant base measure exponential family to model the latent state stochasticity. Our closed-form variational analogue to the \\emph{predict} step of the Kalman filter leads to a provably tighter evidence lower bound (ELBO) compared to previous methods. With constant computational complexity per step, on the order of milliseconds, eVKF is well suited for fine resolution real-time applications. Our method can decode hand position during a monkey reaching task comparatively well to the offline reference method even though eVKF only processes the data once, in a sequential fashion. We believe eVKF will help to advance the development of online inference algorithms that are capable of learning non-Gaussian, nonlinear dynamics, and open up possibilities of perturbing actual neural systems in real-time to better understand the underlying computation.",
        "url": "https://www.world-wide.org/cosyne-23/exponential-family-variational-kalman-6f2699ed"
    },
    "Ctrl-TNDM: Decoding feedback-driven movement corrections from motor cortex neurons": {
        "title": "Ctrl-TNDM: Decoding feedback-driven movement corrections from motor cortex neurons",
        "authors": "Nina Kudryashova, Matthew Perich, Lee Miller, Matthias Hennig",
        "date": "Friday, 10 March 2023",
        "location": "II-053",
        "abstract": "Recent studies of motor control have shown that the neural population activity in motor cortical areas has a low-dimensional structure: a low number of latent dynamical factors that explain a large fraction of neural variability. It is unclear, however, whether this low-dimensional structure corresponds to task instructions or to behavioral output, since both variables are strongly correlated with one another. To address this question, we analysed neural recordings from premotor and motor cortices of monkeys engaged in a center-out reaching task with a force field perturbation. The perturbation induced transient deviations from the desired trajectory which required correction in real-time. While the instructed behavior (a reach towards the target) is known to be well captured by low-dimensional autonomous dynamical models, the uninstructed component includes online corrections to the hand trajectory that the monkey makes during each trial based on the visual and tactile feedback. Using an RNN decoder, we confirmed that the information about uninstructed behavior can be decoded from neural activity. We next extracted latent dynamical factors using an unsupervised sequential autoencoder model with a controller RNN (LFADS) that can infer unobserved control inputs into the neuronal population. We found that the low-dimensional dynamical factors in LFADS represented instructed reach direction, but could not explain the uninstructed behavioral variability related to online movement corrections. We then modified the LFADS model following the ideas from the recently developed Targeted Neural Dynamical Modeling (TNDM) approach, which aims to align the latent dynamical factors with the observed behavior. Our new Ctrl-TNDM model captured almost all explainable behavioral variability, including uninstructed movement corrections. This result suggests that the low-dimensional latent dynamics in neural activity can explain behavioral variability, but discovering the correct manifold and latent dynamics requires weak supervision with recorded behavior.",
        "url": "https://www.world-wide.org/cosyne-23/ctrl-tndm-decoding-feedback-driven-25339588"
    },
    "Uncertainty differentially shapes premotor and primary motor activity during movement planning": {
        "title": "Uncertainty differentially shapes premotor and primary motor activity during movement planning",
        "authors": "Bence Bagi, Brian M. Dekleva, Lee E. Miller, Juan A. Gallego",
        "date": "Friday, 10 March 2023",
        "location": "II-054",
        "abstract": "Precise movement execution often relies on adequately planning the upcoming action, a process that is largely mediated by the dorsal premotor (PMd) and primary motor (M1) cortices. Due to their anatomical and functional similarities, PMd and M1 are commonly assumed to contain similar planning- related information. Here we show that when planning movements under uncertainty, the activity of PMd and M1 neural populations show distinct features, suggestive of area-specific computations. We analyzed simultaneous recordings from populations of PMd and M1 neurons from monkeys performing both a standard center-out reaching task, and a task requiring them to plan reaches based on uncertain visual information about the target's location (Dekleva et al. eLife 2016). We investigated how uncertainty shaped planning activity by computing “latent dynamics” during the instructed delay epoch for each population. In the uncertainty task, both PMd and M1 latent dynamics contained information about reach direction, as well as the associated uncertainty level. However, the relative importance of these signals varied across areas: M1 activity was mainly organized by reach direction, while in PMd uncertainty was dominant. For both regions, the axes needed to linearly decode uncertainty and reach direction were orthogonal to each other, supporting the view that orthogonal subspaces may enable separate computations. Another intriguing difference between PMd and M1 was that their activity contained qualitatively different information about the intended movement. In agreement with their relative position along the neuraxis, M1 might integrate PMd activity to formulate a final motor plan: decoding performance using PMd activity integrated through time resembled that of instantaneous decoding from M1 latent dynamics, even after subsampling neurons to match firing rate statistics between areas. Thus, despite their apparent similarities, when target information is not clearly specified, PMd and M1 may become primarily involved in different planning-related computations.",
        "url": "https://www.world-wide.org/cosyne-23/uncertainty-differentially-shapes-premotor-de281923"
    },
    "Biased AI systems produce biased humans": {
        "title": "Biased AI systems produce biased humans",
        "authors": "Moshe Glickman & Tali Sharot",
        "date": "Friday, 10 March 2023",
        "location": "II-055",
        "abstract": "Human decision-making biases are pervasive, influencing areas such as finance, law and medicine. Reliance on Artificial Intelligence (AI) systems has been offered as a solution to reduce such systematic errors. However, in judgments ranging from perception to emotion, AI systems can also exhibit biases themselves. For example, a hiring algorithm used by Amazon was inevitably trained to favor men over women and an algorithm used in US hospitals to estimate the need for additional medical care favored white patients over black patients. While the danger of biased algorithms automating and perpetuating existing human biases is known, here we suggest the problem may be even greater. Critical decisions are often made jointly by AI and humans (e.g., AI systems provide support to human physicians in the diagnosis of life-threatening diseases). These human-AI interactions provide a mechanism by which, not only biased humans generate biased AI systems, but biased AI systems can alter human decision-making processes, leaving humans more biased than they were before. Across multiple experiments (N = 1,022), we reveal a feedback loop where human-AI interactions alter the processes underlying human perceptual, emotion and social judgments that subsequently amplify biases in humans. This amplification is significantly greater than observed in human-human feedback loops. Strikingly, the participants underestimate the substantial impact of the biased algorithm on their judgment, which could leave them more susceptible to its influence. Finally, using computational modeling, we show that humans learn from such interactions to become more biased, potentially altering how their decisions are made. These findings demonstrate that biased algorithms not only produce biased evaluations, but crucially increase such biases in humans, creating a feedback loop. The findings highlight the pressing need to increase public awareness of how AI systems influence human decision-making in order to reduce bias contagion and improve AI-human interaction.",
        "url": "https://www.world-wide.org/cosyne-23/biased-systems-produce-biased-humans-bad27b81"
    },
    "Cerebro-cerebellar networks facilitate learning through feedback decoupling": {
        "title": "Cerebro-cerebellar networks facilitate learning through feedback decoupling",
        "authors": "Ellen Boven, Joseph Pemberton, Paul Chadderton, Richard Apps, Rui Ponte Costa",
        "date": "Friday, 10 March 2023",
        "location": "II-056",
        "abstract": "Behavioural feedback is critical for learning in the cerebral cortex. However, such feedback is often not readily available. How the cerebral cortex learns efficiently despite the sparse nature of feedback remains unclear. Inspired by recent deep learning algorithms, we introduce a systems-level computational model of cerebro-cerebellar interactions. In this model a cerebral recurrent network receives feedback predictions from a cerebellar network, thereby decoupling learning in cerebral networks from future feedback. When trained in a simple sensorimotor task the model shows faster learning and reduced dysmetria-like behaviours, in line with the widely observed functional impact of the cerebellum. Next, we demonstrate that these results generalise to more complex motor and cognitive tasks. Finally, the model makes several experimentally testable predictions regarding (1) cerebro-cerebellar task-specific representations over learning, (2) task-specific benefits of cerebellar predictions and (3) the differential impact of cerebellar and inferior olive lesions. Overall, our work offers a theoretical framework of cerebro-cerebellar networks as feedback decoupling machines.",
        "url": "https://www.world-wide.org/cosyne-23/cerebro-cerebellar-networks-facilitate-541c600c"
    },
    "Disentangling input dynamics from intrinsic neural dynamics in modeling of neural-behavioral data": {
        "title": "Disentangling input dynamics from intrinsic neural dynamics in modeling of neural-behavioral data",
        "authors": "Parsa Vahidi, Omid Sani, Maryam Shanechi",
        "date": "Friday, 10 March 2023",
        "location": "II-057",
        "abstract": "Neural dynamics in a given brain region are generated either due to recurrent connections in the region (intrinsic dynamic), or due to temporally structured external inputs (input dynamics). These inputs can be sensory stimuli or excitations from upstream brain regions. While measuring all inputs is infeasible experimentally, measurements of sensory inputs such as task instructions or partial measurements of neural inputs into a brain region are often possible. When learning models of neural population dynamics, current learning methods can either account for measured input but not behavior, or vice versa. Here, we show that accounting for both measured input and behavior during model learning is critical for correct interpretation of neural computations underlying a specific behavior. We thus develop a new analytical learning method that can incorporate measured inputs into a combined neural-behavioral dynamical model. By simultaneously accounting for neural activity, behavior, and measured input during learning, this method dissociates intrinsic behaviorally relevant neural dynamics from both measured input dynamics and other intrinsic neural dynamics and prioritizes their learning so that they are not missed/masked by other intrinsic neural dynamics. First, in simulations, we show that accounting for input but not behavior or vice versa can lead to inaccuracies when learning dynamical models of neural activity. Second, we show that without their prioritized learning enabled by our method, intrinsic behaviorally relevant neural dynamics are learned much less accurately even when inputs are considered. Third, we analyze motor cortical population activity from two public datasets in which monkeys make random reaching movements following task instruction sensory inputs. We find that our method reveals intrinsic behaviorally relevant neural dynamics that are more predictive of neural-behavioral data and remarkably similar across the two datasets/animals; these consistent dynamics are missed by existing methods, which account for either measured input or behavior but not both.",
        "url": "https://www.world-wide.org/cosyne-23/disentangling-input-dynamics-from-intrinsic-b937bec1"
    },
    "Learning from disinformation": {
        "title": "Learning from disinformation",
        "authors": "Juan Vidal-Perez, Raymond J. Dolan, Rani Moran",
        "date": "Friday, 10 March 2023",
        "location": "II-058",
        "abstract": "Reinforcement Learning studies how animals and humans adapt to their environment by learning from experience which actions maximize reward acquisition. Extant research has focused on situations where learners receive veridical reward-feedback. However, as social beings, much of the feedback we receive is provided by others. Critically, such feedback may be misleading because others might manipulate us based on their own –even if well-intended– interests. For example, a colleague might spare your feelings, expressing enthusiasm regarding your imminent Cosyne submission when, they actually find it superficial. A pressing question concerns behavioral adaptations when potentially misleading feedback is provided. We addressed this question using an online modified version of the two-armed bandit task, that informed participants (n=107) about reward-outcomes of their choices through “feedback agents” who occasionally lied (reporting a non- reward when the true outcome was a reward and vice versa). One agent always reported feedback truthfully, whereas three other agents varied in their unreliability, i.e., the proportion of trials in which they lied (15%, 30%, or 50%). Computational modelling of participants’ behavior revealed that credit assignment (i.e., the extent of value-update following reward feedback) increased as a function of feedback-reliability. Strikingly, we also found that while credit assignment for the always-truthful agent was symmetric (i.e., equal for positive and negative outcomes), unreliable feedback elicited a positivity bias such that credit assignment was greater for positive compared to negative feedback. Critically, this feedback-valence learning bias could not be accounted for by optimal Bayesian learning models. Exploratory analyses, aimed at relating learning-biases to mental health, suggest that obsessive-compulsive symptoms and paranoid thoughts are linked to a reduced learning sensitivity to feedback reliability. Our results can help explaining how learning from disinformation might contribute to deficits in mental health and social communication (e.g., political radicalization and belief in conspiracy narratives).",
        "url": "https://www.world-wide.org/cosyne-23/learning-from-disinformation-9d9b487a"
    },
    "Mechanisms of contextual fear memory suppression and extinction by the Nucleus Reuniens-CA1 pathway": {
        "title": "Mechanisms of contextual fear memory suppression and extinction by the Nucleus Reuniens-CA1 pathway",
        "authors": "Heather Ratigan & Mark Sheffield",
        "date": "Friday, 10 March 2023",
        "location": "II-059",
        "abstract": "Remembering and responding to aversive events is a crucial evolutionarily conserved behavior. In mammals, regulation of contextual fear memories depends on both medial prefrontal cortex (mPFC), key for extinguishing non-salient fear responses, and dorsal hippocampal CA1 (dCA1), key for encoding contextual memories. However, there is no direct mPFC to CA1 path, leaving unclear how these regions coordinate. A potential route is through the Nucleus Reuniens (NR), a higher-order thalamic region well-connected to emotional regulation areas. NR is driven by mPFC and sends an excitatory monosynaptic input to the Stratum Lacunosum Moleculare (SLM) of CA1, where CA1 pyramidal cell apical tuft dendrites reside. Both the mPFC-NR pathway and NR itself are necessary for contextual fear memory extinction, but the NR-CA1 pathway’s role is unknown. Our experiments uncover its role in a virtual reality contextual fear memory paradigm at the behavioral and circuit level. We used mild tail shocks to induce context-dependent fear (freezing). Using in-vivo 2-photon calcium imaging of NR-CA1 axons, we discovered the NR-CA1 pathway selectively activates during fear-induced freezing (fear memory recall), but not during non-fearful pausing prior to fear induction. Supporting this, NR axonal activity was well predicted by behavioral information using a gradient boosted decision trees model following fear induction, but poorly predicted before. By selectively inactivating CA1-projecting NR neurons following fear induction, we extended the length of fear-induced freezing epochs, both during inactivation and on the following day when NR was no longer inactivated, revealing a disruption in fear extinction. Population activity recordings of SLM dendrites revealed an increase in the frequency of dendritic transients during fearful freezing, but not during non-fearful pausing epochs. These findings reveal a novel role for Nucleus Reuniens in suppressing contextual fear memories by increasing apical tuft dendritic excitability of CA1 pyramidal cells during contextual fear memory recall, inducing fear extinction.",
        "url": "https://www.world-wide.org/cosyne-23/mechanisms-contextual-fear-memory-suppression-7611c2f5"
    },
    "The prix-fixe menu: a combinatorial code for neuronal function": {
        "title": "The prix-fixe menu: a combinatorial code for neuronal function",
        "authors": "Ari Benjamin, Xiaoyin Chen, Anthony Zador",
        "date": "Friday, 10 March 2023",
        "location": "II-060",
        "abstract": "The striking diversity of cells in the mammalian brain lies in stark contrast with the uniformity of cells in theoretical models and artificial networks. What computational advantage do these myriad cell types provide? Deciphering their roles first requires organizing cells in the appropriate manner. Typically, cells are organized into a hierarchical clustering of cells into cell types. This approach is based on a rich history of cell typing based on morphology and other accessible correlates. However, the very large-scale datasets enabled by advances in DNA sequencing potentially may reveal a finer-grained organization. Here, we propose instead a combinatorial model: we hypothesize that a cell’s transcriptome reflects the conjunction of multiple, potentially interchangeable genetic programs. This combinatorial approach would massively increase cellular diversity compared to a single hierarchy. An analogy is a prix-fixe menu: one dish is available from each meal course, and the potential number of meals grows combinatorially rather than linearly. To quantitatively group and classify cells in this manner, we apply an algorithm that discovers this combinatorial menu from data, known in the information theory literature as Residual Vector Quantization and here as Conjunctional k-Means (CkM). We apply CkM to two whole-brain, single-cell transcription datasets collected by the Allen Institute. We find that the combinatorial menus discovered with CkM explain more variance than standard clustering methods, challenging the standard hierarchical picture of cellular taxonomy. Additionally, we find clear layer- and area-specific patterns of the conjunctional subspace clusters. If the way the genome encodes function is combinatorial, we suggest that a cell's ‘menu selections’ may be more closely related to function than its location in a hierarchical tree. Our results suggest a path forward to exploiting the diversity of neuronal types in models of brain computation.",
        "url": "https://www.world-wide.org/cosyne-23/prix-fixe-menu-combinatorial-code-neuronal-47339e8e"
    },
    "Cortical reactivations predict future sensory responses": {
        "title": "Cortical reactivations predict future sensory responses",
        "authors": "Nghia Nguyen, Mark Andermann, Andrew Lutas, Jesseba Fernando, Josselyn Vergara, Justin McMahon, Jordane Dimidschstein",
        "date": "Friday, 10 March 2023",
        "location": "II-061",
        "abstract": "How do we learn about experiences while being removed from the experience itself? One solution involves offline learning via reactivations. Sensory reactivation involves the recurrence of a pattern of neural activity during sleep or quiet waking that previously occurred during a sensory experience. Prevailing theories of offline memory consolidation posit that the pattern of neurons activated during a sensory experience will be faithfully reactivated, thereby stabilizing the entire pattern. However, sensory-evoked patterns are not stable, but instead drift across repeated experiences. Our study investigates potential roles of reactivations in the stabilization and/or drift of sensory representations. We performed two-photon calcium imaging from ~6,600 neurons simultaneously in lateral visual cortex as mice passively viewed two distinct visual stimuli for hours each day. Each stimulus presentation was followed by a one-minute inter-trial interval to assess for stimulus reactivations. Presentation of a stimulus resulted in transient, stimulus-specific reactivations during the following minute. Stimulus reactivation rates decreased across time, and strongly reflected the content of the most recently presented stimulus. These reactivations depended on local circuit activity, as they were abolished by local silencing during the preceding stimulus. Contrary to prevailing theories, reactivations systemically differed from previous patterns evoked by the stimulus. Instead, they were more similar to future patterns evoked by the stimulus, thereby predicting representational drift. In particular, neurons that participated more or less in early reactivations than in stimulus response patterns subsequently increased or decreased their future stimulus responses, respectively. Using a simple plasticity model, we found that the rate and content of these reactivations was sufficient to accurately predict future changes in stimulus responses and, surprisingly, the decreasing similarity of responses to distinct stimuli. Thus, activity patterns during sensory cortical reactivations may guide the drift in sensory responses to improve sensory discrimination.",
        "url": "https://www.world-wide.org/cosyne-23/cortical-reactivations-predict-future-fb062a35"
    },
    "Reinforcement learning at multiple timescales in biological and artificial neural networks": {
        "title": "Reinforcement learning at multiple timescales in biological and artificial neural networks",
        "authors": "Paul Masset, Pablo Tano, Athar Malik, HyungGoo Kim, Pol Bech, Alexandre Pouget, Naoshige Uchida",
        "date": "Friday, 10 March 2023",
        "location": "II-062",
        "abstract": "In order to thrive in complex environments, animals and artificial agents have to learn to act adaptively to maximize fitness and rewards. Reinforcement learning (RL) algorithms have been successful at training artificial agents to superhuman performance in an array of complex tasks and the activity of dopaminergic neurons has been described by one of their key components, the reward prediction error (RPE). However, classical RL occurs at a single timescale, set by the discount factor, while agents have to make decisions at multiple timescales and behaviorally, humans and animals are known to discount non-exponentially in many situations. Here, we show that agents learning at multiple timescales possesses distinct computational benefits, including (1) a richer representation of the temporal evolution of rewards, (2) an ability to infer reward timing before learning converges and (3) better adaptation to alternative discount mechanisms to produce more accurate estimates and behave more efficiently. Next, by recording optogenetically identified single dopaminergic neurons in mice performing two behavioral tasks, a cued delayed reward task and navigation in a 1-D virtual reality track, we show that they encode RPEs at a diversity of timescales through a diversity of discount factors. This diversity allows us to (1) decode reward timing using a parameter-free approach (2) explain heterogeneous ramping activity across dopaminergic neurons while approaching reward by single neurons with different discount factors experiencing a common value function (or reward expectation) and (3) show that the discount factor of individual neurons is correlated across the two tasks, suggesting that it is a cell-specific property and setting constraints on the biological implementations of multi-timescale RL. Together with other advances such as distributional RL in the reward domain, our work opens new directions for efficient RL algorithms based on distributional coding along several dimensions in both artificial and biological agents.",
        "url": "https://www.world-wide.org/cosyne-23/reinforcement-learning-multiple-timescales-0370ac35"
    },
    "Timing-dependent modulation of working memory by dopaminergic release in the prefrontal cortex": {
        "title": "Timing-dependent modulation of working memory by dopaminergic release in the prefrontal cortex",
        "authors": "Chaofan Ge, Yizhou Zhuo, Zhaoqin Chen, Hongmei Fan, Yulong Li, Chengyu Li",
        "date": "Friday, 10 March 2023",
        "location": "II-063",
        "abstract": "Working memory (WM) is the brain process for actively maintaining information during a short delay period. Dopamine is known to strongly modulate WM, but its temporal specificity in modulating WM and its related neuronal activity remain elusive. Here we report that dopamine modulates olfactory WM behavior in a bi-directional and timing-dependent manner in head-fixed mice performing a delay-paired association task. In vivo imaging of dopamine levels in the medial prefrontal cortex (mPFC) by a newly developed GPCR-activation-based-dopamine sensor (GRABDA) revealed phasic elevation of mPFC dopamine concentration specifically during the early phase of delay period. Optogenetic excitation of dopaminergic projections from ventral tegmental area (VTA) to mPFC during the early and late phase of delay period improved and impaired WM performance, respectively. Applying similar excitation during other time periods or to nucleus accumbens during the delay period had no effect. Single-unit recordings showed that excitation of dopaminergic terminals during the early delay period increased the behavior-related activity gain of mPFC neurons, whereas excitation during the late delay period induced activity noise irrelevant to WM behavior. Thus, precisely timed dopamine modulation of mPFC neuronal activity is critical for WM. This work underscores the importance of temporal control of neuromodulation in the brain.",
        "url": "https://www.world-wide.org/cosyne-23/timing-dependent-modulation-working-9ad4de88"
    },
    "Intracranial electrophysiological evidence for a novel neuro-computational mechanism of cognitive flexibility in humans": {
        "title": "Intracranial electrophysiological evidence for a novel neuro-computational mechanism of cognitive flexibility in humans",
        "authors": "Xinyuan Yan, Seth Koneig, Becket Ebitz, Benjamin Hayden, David Darrow, Alexander Herman",
        "date": "Friday, 10 March 2023",
        "location": "II-064",
        "abstract": "Flexibility in a dynamic and uncertain world is critical for individuals to survive and thrive. An appropriately flexible agent should know when to exploit a known resource or explore for a potentially better one. Previous research indicates that prefrontal brain regions including the orbitofrontal cortex (OFC) and medial prefrontal cortex (mPFC), as well as the anterior insula are critical for value computation and decision-making. However, how these brain regions encode and transfer computed values to resolve the exploration-exploitation dilemma still remains unknown. We studied human cognitive flexibility and its neuro-computational mechanisms with an explore-exploit restless three-armed bandit task while recording intracranial EEG data from mPFC, OFC, dorsal medial prefrontal cortex (dmPFC), and anterior-Insula (AIn). We found that neural oscillations in the alpha, beta and high-gamma band in mPFC and dmPFC reflected feedback processing, while OFC and AIn encoded information in both decision and feedback stages. Interestingly, AIn and OFC were more sensitive to exploit behaviors after positive feedback (i.e., reward), while dmPFC and mPFC only encoded explore behaviors after negative feedback (i.e., non-reward). Alpha-band oscillatory bursting in OFC encoded the explore/exploit latent state before choice. To examine how these prefrontal brain regions compute state-values in exploit/explore decisions, we constructed a foraging based reinforcement learning model. In high-gamma band, AIn encoded the model-computed value of exploitation before choice started, and OFC encoded exploit/explore just before the feedback stage. Finally, we conducted decoding analysis in the three frequency bands across patients by implementing cross-validation and found that feedback (reward and non-reward) in the last trial predicted explore/exploit behaviors in the next trial within OFC and mPFC above chance level. Our findings may shed light on the neuro-computational mechanisms underlying cognitive flexibility and show translational relevance for brain stimulation for treating mental disorders.",
        "url": "https://www.world-wide.org/cosyne-23/intracranial-electrophysiological-02b1410a"
    },
    "Cell assemblies and their underlying connectivity in a detailed, large-scale cortical model": {
        "title": "Cell assemblies and their underlying connectivity in a detailed, large-scale cortical model",
        "authors": "András Ecker, Daniela Egas Santander, Sirio Bolaños-Puchet, James B. Isbister, Michael Reimann",
        "date": "Friday, 10 March 2023",
        "location": "II-065",
        "abstract": "Recent developments in experimental techniques have enabled simultaneous recordings from thousands of neurons, enabling the study of functional cell assemblies. However, determining the patterns of synaptic connectivity giving rise to assemblies remains challenging. To address this, we developed a complementary simulation-based approach, using a detailed, large-scale cortical network model. Using a combination of established methods we detected functional cell assemblies from the stimulus-evoked spiking activity of 185’000 neurons. Then, we studied how the structure of connectivity influences a neuron's membership in one or more assemblies. Specifically, to what degree does common innervation from external sources (e.g., thalamic afferents) shape assembly membership? Additionally, are afferent synapses from assembly neurons scattered across dendritic trees or clustered on branches employing their nonlinear computational capabilities? We found a clear link between a neuron's assembly membership probability and its indegree (number of connections) from neurons in a given assembly, explaining 25% of the variance, and from thalamic fibers (15% of variance). It is also possible to increase the predictive power by generalizing the notion of indegree to higher dimensions. This is done by taking the presence of highly interconnected motifs in the recurrent connectivity of the innervating population into account. Moreover, synapses from cell assemblies tend to spatially cluster on dendritic branches, and considering this information results in a further 15% drop in entropy. In summary, reversing Hebb's postulate, we show how cells that are wired together, fire together, quantifying how connectivity patterns interact to shape the emergence of assemblies. This includes a qualitative aspect of connectivity: not just the amount, but also the local structure matters; from the subcellular level in the form of dendritic clustering to the presence of specific local motifs. This connectivity-based characterization of cell assemblies creates an opportunity to study plasticity at the assembly level, and beyond strictly pairwise interactions.",
        "url": "https://www.world-wide.org/cosyne-23/cell-assemblies-their-underlying-connectivity-9f845e40"
    },
    "Spatial-frequency channels for object recognition by neural networks are twice as wide as those of humans": {
        "title": "Spatial-frequency channels for object recognition by neural networks are twice as wide as those of humans",
        "authors": "Ajay Subramanian, Elena Sizikova, Najib Majaj, Denis G. Pelli",
        "date": "Friday, 10 March 2023",
        "location": "II-066",
        "abstract": "We compare how well human observers and neural networks recognize ImageNet images in filtered noise using the critical-band masking paradigm (Fletcher, 1940). We assess the spatial-frequency tuning of object recognition by measuring its noise tolerance at various frequencies. 16 observers and 4 neural networks performed 16-way categorization of 1050 ImageNet images perturbed by band-limited Gaussian noise of five strengths centered at seven spatial frequencies. We find that the noise sensitivity of object recognition is an inverted, U-shaped function of spatial frequency. Human observer performance is severely impaired over an octave-wide band. Such octave-wide selectivity has frequently appeared in the vision literature where it is called a “channel” (Solomon & Pelli, 1994). Here, this channel is revealed in heatmaps of human and network performance. A demo of this channel presents images perturbed with noise at various frequencies and strengths. Together with previous work (Majaj et al., 2002), this shows that the bandwidth of the human channel is conserved across diverse target kinds: real-world objects, gratings, and letters. We find the classic octave-wide frequency band for humans, and a two-octave-wide band for machines, both centered at ~28 cycles per image. At the peak, humans tolerate four times as much noise variance as networks do. When recognizing objects, networks are known to rely on texture cues whereas humans rely on shape (Geirhos et al., 2018). Data augmentation helps bridge this gap (Hermann et al., 2020, Geirhos et al., 2021, Muttenthaler et al., 2022). Our results show that perhaps the popular notion of texture-vs-shape bias simply reflects the width of the spatial-frequency channel.",
        "url": "https://www.world-wide.org/cosyne-23/spatial-frequency-channels-object-recognition-4e396517"
    },
    "Modeling the orbitofrontal cortex function in navigation through an RL-RNN implementation": {
        "title": "Modeling the orbitofrontal cortex function in navigation through an RL-RNN implementation",
        "authors": "Carlos Wert Carvajal, Raunak Basu, Albert Miguel-Lopez, Hiroshi Ito, Tatjana Tchumatchenko",
        "date": "Friday, 10 March 2023",
        "location": "II-067",
        "abstract": "Since its initial conceptualization by Edward Tolman, cognitive maps – i.e., task-derived internal representations of an environment – have been found in multiple brain regions. In mammalian brains, the orbitofrontal cortex (OFC) can produce a flexible cognitive map underpinning model-based learning. Recent results have shown that this function is compatible with the canonical value-encoding role ascribed to OFC, whereby this region guides decision-making by providing a representation of reward. Hence, recent theories have suggested that the OFC integrates activity from other brain regions and value information to generate a goal-oriented state-space representation that does not remap and can aid generalization. Here, we use recurrent neural networks in a reinforcement learning (RL-RNN) paradigm to reproduce the function of OFC in a goal-directed navigational task. We assumed this region operates as a value-based network separated from action planning, as in actor-critic or REINFORCE-type systems. Our model recreated the switching behavior observed experimentally between two goals, which requires model-based learning to avoid catastrophic forgetting of the attractor states. Moreover, we reproduced the low-dimensional and single-neuron activity recorded in vivo, and show that such a system accounts for model-based learning. We also provide some intuitions into how the OFC supports a stable encoding of goal locations even under changed reward contingencies, or new goals are introduced without plasticity. Notably, our work supports the view of the OFC as both a cognitive map and a value-based system.",
        "url": "https://www.world-wide.org/cosyne-23/modeling-orbitofrontal-cortex-function-37da038b"
    },
    "All-Optical Investigation of Schaller Collateral Synapses in vivo": {
        "title": "All-Optical Investigation of Schaller Collateral Synapses in vivo",
        "authors": "Cynthia Rais & J. Simon Wiegert",
        "date": "Friday, 10 March 2023",
        "location": "II-068",
        "abstract": "Ensembles of neurons in the hippocampus encode the position of an animal navigating in the environment. Although exposed to the same environment over days, the neuronal representation is drifting and new ensembles emerge. Nonetheless the animal’s behavioral performance appears stable over time despite the neuronal drift. While the cellular dynamics of hippocampal coding are well-described, how information is encoded and preserved at the level of individual synapses during spatial navigation is less understood. The drift of the spatial representation in the hippocampus could be a consequence of its high spine turnover, as reported in some studies. Yet, other studies reported high spine stability in the hippocampus. While the relationship to functional synaptic changes remains elusive in vivo, studies in vitro identified a tight link between synaptic plasticity and stability. Here, we aim to understand how synaptic activity and plasticity influence the spine lifetime in vivo, by relating synaptic functional recordings to structural changes in spines at cornu ammonis (CA1) pyramidal cells. We chronically imaged dendritic spines on CA1 cells in the awake mouse, monitoring their synaptic responses to optogenetically stimulated presynaptic CA3 cells. Using this approach, we were able to induce local, synaptic calcium responses at individual spines and to assess the stability of these functionally identified synapses over two weeks. We show that optogenetically identified spines were more stable over days than non-responding, neighboring spines. This suggests that functional connectivity predicts synapse stability. As a consequence, synaptic weights may determine long-term synaptic connectivity and therefore neuronal network connectivity. Finally, this data further highlights the diversity of spine properties and provides basis on integrating further these properties, which determines systems connectivity, for future bio-inspired model of brain function.",
        "url": "https://www.world-wide.org/cosyne-23/all-optical-investigation-schaller-a208b4b6"
    },
    "Next-generation head-mounted microscopes for large-scale neural recordings": {
        "title": "Next-generation head-mounted microscopes for large-scale neural recordings",
        "authors": "Joe Scherrer, Galen Lynch, Jie Zhang, Michale Fee",
        "date": "Friday, 10 March 2023",
        "location": "II-069",
        "abstract": "Miniature head-mounted microscopes have enabled in vivo optical measurements of neural activity in freely moving animals, allowing neuroscientists to study the neural basis of behaviors that are difficult to recapitulate in head-fixed preparations like social interaction and navigation. Existing head-mounted microscopes for small animals are limited to small fields of view (< 1mm2), which limit the number of neurons that can be recorded simultaneously to at most several hundred. However, understanding how behavior is controlled by large neural populations across brain regions requires simultaneous recording in thousands of neurons, which until now has only been possible in small animals using head-fixed preparations. We address these limitations with a novel optical pathway that allows for microscopes with an order of magnitude increase in field-of-view (FOV) over previous designs while also weighing less than any previously published technology, enabling recordings in thousands of neurons while preserving naturalistic behaviors. Most existing epifluorescence microscopes couple excitation light using a dichroic filter placed between the objective lens and tube lens, a design that adds weight and severely limits the types of optics that can be used to focus light onto the image sensor. In contrast, our new optical path uses a light-guide and coupling prism to introduce excitation light, making the optical assembly significantly more compact while allowing the use of cutting-edge lens assemblies designed for smartphone cameras. Using this design, we have recorded calcium activity, for the first time, in thousands of cortical neurons simultaneously in freely moving mice across a 4 mm diameter region of cortex. Using this activity, we can decode the position of the mouse in a circular maze and quantify the relative amount of position information contained in different cortical regions. This order-of-magnitude increase in the size of recordable populations opens the door to testing computational models of cognition across large neural populations and between multiple brain regions.",
        "url": "https://www.world-wide.org/cosyne-23/next-generation-head-mounted-microscopes-737ce754"
    },
    "The neural representation of perceptual uncertainty in mouse visual cortex": {
        "title": "The neural representation of perceptual uncertainty in mouse visual cortex",
        "authors": "Theoklitos Amvrosiadis, Ádám Koblinger, David Liu, Nathalie Rochefort, Máté Lengyel",
        "date": "Friday, 10 March 2023",
        "location": "II-070",
        "abstract": "Perceptual decision making is fraught with uncertainty that comes (at least) in two distinct forms: there can be uncertainty about how a stimulus is perceived, and even for a known stimulus there can be uncertainty about the decision that it licenses. Although putative neural correlates of uncertainty have been described in early sensory areas, these two forms of uncertainty have not been distinguished. Thus, it remains unknown whether and how perceptual uncertainty (presumably computed locally), as opposed to decision uncertainty (presumably computed downstream and conveyed by feedback connections), is represented in sensory cortex. Here, we developed a Bayesian ideal observer model that formalized perceptual and decision uncertainty in a single coherent framework and used it for model-based analyses of behavior and neural responses recorded while mice performed a two-alternative perceptual decision making task. After extensively validating the ideal observer on synthetic data, we fitted it exclusively to animals' behavior during the stimulus period of trials and showed that it accurately predicted their task-related choices in the distinct response period of the same trials. For each trial, the fitted model predicted the level of perceptual and decision certainties that we then used as regressors against simultaneously recorded Ca$^{2+}$ imaging data in the primary visual cortex (V1) during the stimulus period. We characterized both the magnitude and variability of V1 layer 2/3 population responses on single trials. After controlling for a number of directly stimulus- or behavior-related nuisance regressors, using a generalized linear model-approach, we found that perceptual certainty significantly contributed to the variability but not the magnitude of responses, while decision certainty did not significantly contribute to either. These results provide evidence for the representation of perceptual as opposed to decision certainty in V1, and suggest that perceptual uncertainty is encoded by the variability rather than the magnitude of neural responses.",
        "url": "https://www.world-wide.org/cosyne-23/neural-representation-perceptual-uncertainty-e83e6748"
    },
    "Representational Drift Across Short Timescales in the Mouse Visual Cortex": {
        "title": "Representational Drift Across Short Timescales in the Mouse Visual Cortex",
        "authors": "Kathleen Esfahany & Stefan Mihalas",
        "date": "Friday, 10 March 2023",
        "location": "II-071",
        "abstract": "Recent studies on representational drift in the visual cortex have produced an intriguing puzzle, demonstrating that neuronal responses to the same external stimuli change over time while population-level activity remains stable (Deitch et al., 2021; Marks & Gourd, 2021). The purpose of drift, and how the brain either compensates for or takes advantage of this phenomenon to maintain robust perception, remains largely unknown. A recent study found that the geometric properties of drift in the primary visual cortex resemble that of continual learning in the presence of a large amount of dropout regularization in artificial neural networks (Aitken et al., 2021), adding to a growing body of work theorizing that drift may be computationally advantageous (Kappel et al., 2018; Qin et al., 2021). However, these studies focused on representational changes over long timescales (days to weeks). In this study, we focus on short timescales to ask: Are cumulative changes observable over the course of hours, and are they consistent with continual learning? Openly available datasets presented limitations for analyzing short timescales due to the large battery of stimuli used, which limited the number of repeats for any individual stimulus. Therefore, we recorded neural activity with Neuropixels probes in six areas of the mouse visual cortex during 200 repetitions of a natural movie. In the cortical visual areas, we found short timescale drift demonstrated unique geometric properties from drift across longer timescales, with differences in how the magnitude of drift and its alignment with the neural state space varied over time. We conducted a follow-up analysis of features in artificial neural networks to probe these properties. This study sheds light on the potential role of drift in enabling beneficial malleability of the neural code needed for continual learning from external stimuli.",
        "url": "https://www.world-wide.org/cosyne-23/representational-drift-across-short-4e36e5cd"
    },
    "Dopamine release in the nucleus accumbens during backward conditioning": {
        "title": "Dopamine release in the nucleus accumbens during backward conditioning",
        "authors": "Masakazu Taira, Ivy Hoang, Lauren DiFazio, Samuel Millard, Melissa Sharpe",
        "date": "Friday, 10 March 2023",
        "location": "II-072",
        "abstract": "Temporal-difference reinforcement learning proposed that dopamine signals reward prediction errors, which backpropagate scalar values inherent in rewards to reward-predictive cues. This theory is supported by studies of dopamine activity in cue-reward learning, where a reward-paired cue acquires the dopamine response previously evoked by the reward. However, dopamine has recently been implicated in backward reward-cue learning. Specifically, a recent optogenetic study used a backward conditioning paradigm, where sensory cues are presented following the delivery of rewards, and showed that inhibition of dopaminergic neurons at the onset of backward cues during learning disrupted the use of these cues to guide actions. This showed the necessity of dopamine neurons in backward reward-cue learning. However, the dynamics of dopamine release during backward conditioning are unclear. Here, we used fiber photometry recordings to examine dopamine release while rats performed a backward conditioning task. We measured dopamine release in the nucleus accumbens using GRABDA, a dopamine biosensor. In cue-reward learning (i.e., forward-conditioning task), dopamine release progressively decreased at reward delivery and increased at the onset of forward cues, consistent with well-established findings. However, in the backward-conditioning task, the response to reward increased across time. Further, dopamine release at the onset of backward cues was initially high and diminished with additional training. In order to further examine dopamine response to backward cues, we performed a summation test where a forward cue was put in compound with a backward cue predicting the same or different outcome. We found stronger dopamine responses to the compound of forward and backward cues, regardless of whether they predicted the same outcome, revealing a general excitatory response to the backward cues when delivered unexpectedly. These results suggest dopamine release contributes to backward reward-cue associations, demonstrating dopamine acts as a universal teaching signal for learning regardless of motivational significance of the predicted outcome.",
        "url": "https://www.world-wide.org/cosyne-23/dopamine-release-nucleus-accumbens-during-3c4efe2a"
    },
    "Rapid fluctuations in multi-scale correlations of cortical networks encode spontaneous behavior": {
        "title": "Rapid fluctuations in multi-scale correlations of cortical networks encode spontaneous behavior",
        "authors": "Hadas Benisty, Daniel Barson, Andrew Moberly, Sweyta Lohani, Ronald Coifman, Michael Crair, Gal Mishne, Jessica Cardin, Michael Higley",
        "date": "Friday, 10 March 2023",
        "location": "II-073",
        "abstract": "Experimental work across a variety of species has demonstrated that spontaneously generated behaviors are robustly correlated to variation in neural activity within the cerebral cortex. Indeed, functional magnetic resonance imaging (fMRI) data suggest that functional connectivity in cortical networks varies across distinct behavioral states, providing for the dynamic reorganization of patterned activity. However, these studies generally lack the temporal resolution to establish links between cortical signals and the continuously varying fluctuations in spontaneous behavior typically observed in awake animals. Here, we take advantage of recent developments in wide-field mesoscopic calcium imaging to monitor neural activity across the neocortex and simultaneously record cellular resolution activity using 2-photon microscopy in awake mice. Most analyses of state-dependent connectivity in neuronal networks rely on binning data within identified epochs ignoring the potential for rapid, continuous variation in both behavioral state and network configuration. As neurons can be exquisitely sensitive to patterned or synchronized input, it seems reasonable to hypothesize that rapid changes in network correlations are closely linked to the integrative function of single cells. We present here an analytic formulation for modeling dynamics of behavior that goes beyond linear models while preserving interpretability. Firstly, we show that our proposed model for behavior is indeed superior to the commonly used linear models in wide-cortical scales as well as in cellular data. Secondly, we extract a low-dimensional representation for cortical-cellular correlations capturing their latent dynamics and show that behavior is also encoded within multimodal correlations. Lastly, we show that the latent dynamics of the extracted cross-scale correlations reveals subnetworks that are not evident in traditional anatomical atlas-based parcellation of the cortex. These results provide insight into how behavioral information is represented between the mammalian neocortex and cellular networks and demonstrate a new analytical framework for investigating time-varying cross-modality connectivity in neural networks.",
        "url": "https://www.world-wide.org/cosyne-23/rapid-fluctuations-multi-scale-correlations-60c18dc9"
    },
    "The effective number of shared dimensions between neural populations": {
        "title": "The effective number of shared dimensions between neural populations",
        "authors": "Hamza Giaffar, Camille Rullan, Mikio Aoi",
        "date": "Friday, 10 March 2023",
        "location": "II-074",
        "abstract": "A number of recent studies have explored the analysis of multi-area neural recording data and, in particular, the shared communication, computation and representational subspaces between brain areas. These have largely relied upon model-based methods to quantify shared variability between areas, but a standard, model-free measure is lacking. In this work we 1) present a candidate for this measure that we call the effective number of shared dimensions (ENSD), 2) demonstrate the utility and computational efficiency of our measure by visiting results from two recent studies (the \"communication subspace\" described by Semedo et al., 2019, and context dependent decision making described by Mante and Sussillo et al. 2013), and 3) use the measure and its decompositions to discover novel structure in an existing high dimensional olfactory dataset. The ENSD can be applied to data matrices sharing at least one dimension, reduces to the well-known participation ratio when both data sets are equivalent and has other robust and intuitive mathematical properties which we describe. We show that the ENSD allows for simple, model-free analysis of population-level metrics for multi-area by replicating the aforementioned experimental findings and using its constituent statistics to probe alignment in the parallel pathways of the fly olfactory system. This allows us to uncover a novel result, namely that there is an unexpected enrichment in the representation of food related odorants in the lateral horn that is directly related to the small structural bias of the mushroom body. This opens a new perspective on the interaction between innate and learned olfactory representations. Altogether, we show that the ENSD is an interpretable, computationally efficient and model-free dimensionality metric which promises to have applicability to a wide variety of datasets.",
        "url": "https://www.world-wide.org/cosyne-23/effective-number-shared-dimensions-between-7108187f"
    },
    "A complementary systems theory of meta-learning": {
        "title": "A complementary systems theory of meta-learning",
        "authors": "Simon Schug, Nicolas Zucchet, Johannes von Oswald, João Sacramento",
        "date": "Friday, 10 March 2023",
        "location": "II-075",
        "abstract": "Humans have the ability to quickly adapt to new tasks and generalise what they learned to improve the learning process itself. At the core of this capacity for meta-learning lies a difficult credit assignment problem. After a learning episode, the system needs to determine how to change the components of plasticity such that the next time a similar task is encountered, a better learning outcome can be arrived at more quickly. In machine learning, this problem is often approached by storing the entire learning trajectory and revisiting it in reverse-time order, a process that places large demands on memory and is non-local in time. Here, we propose that hippocampal replay enables meta-learning in the neocortex without storing the entire learning trajectory. By contrasting the outcome of learning with the outcome of an auxiliary learning problem prescribed by the hippocampus, neocortical learning can extract long-term credit assignment information with causal synaptic plasticity rules that only require temporarily buffering one intermediate state. Our framework can be understood as a generalisation of contrastive Hebbian learning. It is agnostic to the underlying learning procedure and can accommodate different models of meta-plasticity. We study two distinct models that cast synaptic consolidation as meta-learning either through synaptic changes on multiple timescales or in combination with a model of top-down modulation. Testing our theory on few-shot prediction problems and reward-based learning tasks reveals that our plasticity rules configure the slow components to enable fast adaptation and generalisation. Our theory extends the conventional view on the hippocampus and the neocortex as complementary learning systems, providing a unified perspective of systems-level consolidation and synaptic consolidation.",
        "url": "https://www.world-wide.org/cosyne-23/complementary-systems-theory-meta-learning-5cbc7b79"
    },
    "Sparse Component Analysis: An interpretable dimensionality reduction tool that identifies building blocks of neural computation": {
        "title": "Sparse Component Analysis: An interpretable dimensionality reduction tool that identifies building blocks of neural computation",
        "authors": "Joshua Glaser, Andrew Zimnik, Vladislav Susoy, Liam Paninski, John Cunningham, Mark Churchland",
        "date": "Friday, 10 March 2023",
        "location": "II-076",
        "abstract": "All behaviors, even simple actions, result from the interplay of multiple neural computations, and understanding how a given behavior is generated requires delineating these computations from one another. Traditionally, identifying these critical ‘computational building blocks’ requires a researcher to impose structure on the data: specific task epochs are analyzed separately or specific population-level structure is sought using supervised dimensionality reduction methods. While these approaches can be successful, they have obvious drawbacks – many behaviors cannot be easily parsed into distinct epochs, and it is often not clear, particularly in early, exploratory phases of data analyses, what type of structure one should look for in neural data. Unsupervised methods, like principal component analysis (PCA) identify large neural signals, yet often do not provide the most interpretable low-dimensional view of the data. Here, we present sparse component analysis (SCA), an unsupervised dimensionality reduction method that produces interpretable, low-dimensional representations across a broad range of neural datasets. SCA incorporates three empirically validated assumptions of neural data. First, population-level activity is low dimensional. Second, distinct neural computations tend to occur in orthogonal or nearly-orthogonal subspaces. Finally, and most critical for the present results, distinct computations are dissociable in time from one another. We applied SCA to four diverse neural datasets: motor cortex activity recorded from a reaching monkey, motor cortex activity from monkeys performing a unimanual and bimanual cycling task, and C. elegans interacting in an open field. In all cases, SCA found not only the structure previously reported using more supervised methods, but also found previously unreported structure, such as posture-related signals distinct from movement-related signals and discrete stopping signals related to the end of a cycling movement. SCA provides an unsupervised method for identifying interpretable latent factors and, in conjunction with supervised methods, provides a powerful tool for characterizing neural computations.",
        "url": "https://www.world-wide.org/cosyne-23/sparse-component-analysis-interpretable-5bb733e9"
    },
    "Leveraging computational and animal models of vision to probe atypical emotion recognition in autism": {
        "title": "Leveraging computational and animal models of vision to probe atypical emotion recognition in autism",
        "authors": "Hamid Ramezanpour & Kohitij Kar",
        "date": "Friday, 10 March 2023",
        "location": "II-077",
        "abstract": "Recognizing others’ emotions based on facial expressions is a core component of human social interactions. Previous studies (Wang and Adolphs 2017) have suggested that autistic individuals show differences in their facial emotion recognition compared to neurotypical adults. What are the neural mechanisms that account for these observed differences? Here we lay the groundwork for a new approach combining cutting-edge computational and empirical non-human primate work to test theories of atypical facial emotion recognition in autistic adults. In a recent study, the author(s) observed that artificial neural network (ANN) models of vision developed to achieve a myriad of visual objectives (e.g., object, emotion and face identification) could be fine-tuned to perform facial emotion judgments. Interestingly, the ANNs' image-level behavioral patterns better matched the neurotypical subjects' compared to autistic adults. This behavioral mismatch was most remarkable when the ANN behavior was constructed from units that correspond to the primate inferior temporal (IT) cortex. Here we directly test these two predictions in the rhesus macaques. First, we trained two macaques to perform a binary facial emotion (happy vs. fearful) discrimination task. Consistent with ANN predictions, the macaque image-level behavioral patterns better matched the behavior obtained in human Controls than in autistic individuals. Second, we implanted multi-electrode arrays in the IT cortex of two macaques, and performed large-scale neural recordings while they fixated on images (used in the Wang and Adolphs study). Using the recorded neural multiunit spiking activity, we built regression models (165 IT-based models tested) to predict facial emotion ground truth (“level of happiness”) on held-out images. Consistent with ANN-IT predictions, macaque IT population decodes of facial emotions better matched the neurotypical behavior compared to autistic individuals. Our results, therefore, establish the rhesus macaque as an appropriate species to further probe the neurobehavioral markers with ANN-guided hypotheses and experiment design.",
        "url": "https://www.world-wide.org/cosyne-23/leveraging-computational-animal-models-4e7210ee"
    },
    "Modelling ecological constraints on visual processing with deep reinforcement learning": {
        "title": "Modelling ecological constraints on visual processing with deep reinforcement learning",
        "authors": "Sacha Sokoloski, Jure Majnik, Thomas Euler, Philipp Berens",
        "date": "Friday, 10 March 2023",
        "location": "II-078",
        "abstract": "Normative principles describe how to efficiently encode visual scenes, and supervised learning models show how formal tasks shape visual processing, yet animal vision ultimately adapts to encode survival-relevant features. To study how ecology constrains visual processing, we present a reinforcement learning (RL) framework in which an agent aims to survive in a 3-d environment that it perceives through a vision model. In particular, we consider a visually-guided foraging task: the environment is populated with randomly placed objects, and the agent must learn to identify those that increase or decrease health, so that it may gather or avoid them, respectively. We modulate task difficulty by varying the diversity of the images/textures that we map onto objects, ranging from simple pairs of images, up to the entire CIFAR-10 dataset. We first demonstrate that a linear vision model is sufficient for agent survival when only two visually distinct objects are task-relevant, even in the presence of task-irrelevant distractors, yet increasing the visual diversity of relevant objects eventually necessitates a nonlinear visual system. We next show that the structure of model receptive fields (RFs) is determined by the statistics of task-relevant images, and is unaffected by task-irrelevant images. Lastly, we show that sparsity and efficiency constraints can silence unnecessary channels in the vision model, and allow the agent to survive with orders of magnitude less neural activity. Our framework allows researchers to explore in silico how ecology shapes visual processing, and how behavioral goals and object relevance emerges from an agent's drive for survival. In future work we aim to study the effects of incorporating functionally different objects, such as obstacles, predators, and mates into the environment of the agent.",
        "url": "https://www.world-wide.org/cosyne-23/modelling-ecological-constraints-visual-54826ea9"
    },
    "Discrete communication mediates effective regularization in recurrent neural networks": {
        "title": "Discrete communication mediates effective regularization in recurrent neural networks",
        "authors": "Jan Philipp Bauer, Jonathan Kadmon, Moritz Helias",
        "date": "Friday, 10 March 2023",
        "location": "II-079",
        "abstract": "Neuronal computation is mediated by spikes, yet it is unclear what the benefits of discrete spiking dynamics over continuous firing rates are. Many theoretical and computational studies treat single neurons as continuous units and their output as an effective firing rate. These works view spiking dynamics as a biophysical constraint, e.g., for energy efficiency. Conversely, other theories suggest that the exact timings of single spikes are meaningful. We propose a novel theory that shows the benefits of spiking dynamics on neural computation. In particular, we show that spiking neural dynamics can improve generalization, even when the information is encoded in the averaged firing rates and not in individual spikes. We derive a mean-field theory for large networks of continuous and discrete (binary) neurons in the thermodynamic limit. The readout from the networks is expressed as a Gaussian process shaped by a time-dependent kernel. This function describes how the similarity between a pair of inputs is trans- formed into the similarity of the corresponding network states at later times. We find that the neural codes described by the respective kernels of the discrete and continuous networks have qualitatively different features, even when all other parameters are identical. In particular, discrete networks show strong microscopic chaos at short time scales while maintaining long-range correlations. The local chaos results from the discontinuity in the transfer function of the discrete neurons and is different from that of continuous firing-rate models. We show that this fast divergence allows for regularization, improving readout generalization. Overall, we demonstrate that spiking dynamics can mitigate the overfitting of recurrent networks to noisy data. Our theory contributes a novel explanation of spiking dynamics’ possible benefits in cortical circuits.",
        "url": "https://www.world-wide.org/cosyne-23/discrete-communication-mediates-effective-2dca8eb9"
    },
    "Neural Population Geometry across model scale: A tool for cross-species functional comparison of visual brain regions": {
        "title": "Neural Population Geometry across model scale: A tool for cross-species functional comparison of visual brain regions",
        "authors": "Arna Ghosh, Kumar Krishna Agrawal, Zahraa Chorghay, Arnab Kumar Mondal, Blake A. Richards",
        "date": "Friday, 10 March 2023",
        "location": "II-080",
        "abstract": "Breakthrough in-vivo recording techniques and computational tools allow quantitative characterization of the population geometry from large-scale neural recordings. Activity covariance from such recordings exhibits striking statistical properties, namely a characteristic power law in the eigenspectrum: the decay coefficient of the eigenspectrum α≈1 for mouse and monkey V1 population responses. Concurrently, studies in self-supervised deep neural networks (DNNs) also demonstrate a similar property, i.e., α is close to 1 in their final layers of visual information processing. However, these models are typically overparameterized, and the network size significantly impacts α of emergent representations. This observation begs the question: how does the neural population geometry vary with the \"size\" of a biological neural network? Furthermore, could α be used to compare functional properties of brain areas across species? We show that well-trained DNNs of sufficient width and depth optimized with self-supervised objectives on natural images exhibit α similar to mammalian V1. However, shallower networks do not exhibit the same behavior, raising questions about neural population geometry across the scale of model capacity. Moreover, we present results of how α varies with depth in DNN with canonical architectures, i.e. convolutional neural networks and vision transformers. These observations suggest a vast hypothesis space for observed α given the overall network size and depth of the representation in the information processing hierarchy. Cross-species functional comparison presents several challenges, including normalizing for size, diversity in behavioral repertoire, and information-processing hierarchy. Our work presents a framework for scale-adjusted comparison by providing an extensive characterization of the relationship between α, network size, and information-processing hierarchy. In particular, given neural responses from a brain's visual region, we could compute α and then determine its functional analog in other organisms. Overall, we believe our work contributes to establishing the cross-species homology of visual processing regions in the brain.",
        "url": "https://www.world-wide.org/cosyne-23/neural-population-geometry-across-model-50f39186"
    },
    "Retinal scene statistics for freely moving mice": {
        "title": "Retinal scene statistics for freely moving mice",
        "authors": "Yuchen Hou, Aiwen Xu, Dylan Martins, Amirali Vahid, Elliott Abe, Cristopher Niell, Michael Beyeler",
        "date": "Friday, 10 March 2023",
        "location": "II-081",
        "abstract": "Mice sample the visual scene by moving their head and eyes. However, little is known about how eye and head position are integrated into visual processing during natural movement, because studies of visual processing are generally performed during head fixation. To address this, we analyzed the retinal input encountered during free exploration by measuring the mouse’s visual scene (“worldcam”) and eye/head position using head-mounted cameras and an inertial measurement unit (IMU). Based on these measures, we trained a neural network to estimate the retinal input by gaze-correcting the worldcam video with an affine transformation. We then extracted several spatiotemporal features (e.g., luminance, contrast, optic flow, and Difference of Gaussian (DoG) entropy) of the visual input during free exploration and analyzed how their distributions were affected by gaze-shifting and compensatory eye/head movements. We found that compensatory eye movements decreased optic flow (as expected), but increased overall luminance as well as DoG entropy in the lower half of the visual field. To discover which visual features drove gaze-shifting eye movements, we used VGG-16 to extract convolutional features from video frames immediately preceding a gaze shift and predicted the horizontal angle of the saccadic endpoint. Our model could account for 47% of the variance in saccade targeting. A saliency map analysis of the deep net revealed that the pixels that were most predictive of saccadic endpoints were often localized to nearby objects on the ground consistent with navigation and obstacle avoidance, or to the upper visual field consistent with scanning for predators. These results may provide insight into how mice use their eyes to sample the visual scene, with implications for visual processing beyond head-fixed preparations.",
        "url": "https://www.world-wide.org/cosyne-23/retinal-scene-statistics-freely-moving-6db41a76"
    },
    "Variance-limited scaling laws for plausible learning rules": {
        "title": "Variance-limited scaling laws for plausible learning rules",
        "authors": "Alexander Atanasov, Blake Bordelon, Cengiz Pehlevan",
        "date": "Friday, 10 March 2023",
        "location": "II-082",
        "abstract": "To learn a new task and predict accurately on new stimuli, the brain must extract patterns from limited observations. The learning rule and initial synaptic weights determine how well a network will generalize on new data. Here, we investigate how initial synaptic variability and representation learning affect the learning curves of neural networks (generalization error vs sample size). We show that two scaling regimes hold for many plausible learning rules including feedback alignment (FA), direct feedback alignment (DFA) and Hebb rules, as well as implausible gradient descent (GD). In the small sample limit, the network is well-approximated by an infinite width network, while for large samples, the error plateaus to a final value which scales inversely with network width. We utilize a bias-variance decomposition over random initializations of the weights to show that the variance due to the initial synapse weights is primarily responsible for the deviation from infinite width behavior. We show that this variance vanishes as the network width goes to infinity, and establish connections to kernel methods. Representation learning can reduce both bias and variance for some learning rules (DFA, FA, GD) but not others (Hebb). At a fixed synapse count, the optimal allocation of resources is to use averages over several separately trained networks that have the width proportional to the square root of the number of stimuli.",
        "url": "https://www.world-wide.org/cosyne-23/variance-limited-scaling-laws-plausible-f4ee189a"
    },
    "Forward sweeps predict human planning via model-based roll-outs but not successor-representations": {
        "title": "Forward sweeps predict human planning via model-based roll-outs but not successor-representations",
        "authors": "Oliver Vikbladh, Evan Russek, Neil Burgess",
        "date": "Friday, 10 March 2023",
        "location": "II-083",
        "abstract": "Navigating rodents show “forward sweeps” - sequential reactivation of non-local neural representations of future states starting from their current position. While direct evidence remains scant, it is widely thought that such forward sweeps support model-based (MB) evaluation of actions. However, a key challenge in testing this hypothesis is the absence of experimental paradigms that allow for precise measurement of MB action evaluation. Notably, typical assessments of MB evaluation, i.e. flexibility following changes to rewards (reward revaluation), conflate reliance on full MB evaluation with a simpler approximation strategy, the successor representation (SR). Whereas full MB evaluates actions by sequentially rolling out a one-step model of state transitions, SR relies on cached temporally-flat predictions of states over multiple future time-steps, learned directly from experience. We tested the hypothesis that neural forward sweeps specifically implement forward roll-outs, and thus MB, but not SR evaluation. We designed a novel, highly-powered, behavioural task for MEG, capable of disambiguating behavioural evidence for MB and SR evaluation as well identifying forward sweeps through the task transition model. We found participants’ (N = 30) choices reflected evidence for use of both MB and SR evaluation strategies. We also found that participant’s response times were modulated by MB planning depth, and that this effect was greater in participants whose choices more reflected full MB planning, linking the behavioural measure of MB choice to sequential rollouts. Finally, we found that, across participants, neural evidence for forward sweeps, assessed by decoded sequential reactivations of upcoming task states, was related to behavioural evidence for use of MB, but not SR, choice evaluation. This provides the first direct evidence that forward sweeps support MB evaluation via roll-outs.",
        "url": "https://www.world-wide.org/cosyne-23/forward-sweeps-predict-human-planning-bfa98208"
    },
    "Inferring neural codes from natural behavior in fruit fly social communication": {
        "title": "Inferring neural codes from natural behavior in fruit fly social communication",
        "authors": "Rich Pang, Albert Lin, Christa Baker, William Bialek, Mala Murthy, Jonathan W. Pillow",
        "date": "Friday, 10 March 2023",
        "location": "II-084",
        "abstract": "The cost of experimental neural recordings strongly limits the stimuli or conditions one can present. Ideally, we would therefore like to know how neural responses observed in specific experiments generalize beyond them. E.g., how does the brain’s response to isolated sounds presented in the lab compare to its response to those sounds within natural language in complex social settings? We addressed this problem in fly courtship–a complex, acoustically mediated social behavior. Starting with recorded responses from diverse female neurons to isolated elements of male courtship song, we found these were equally well fit by multiple encoding models. It was unclear, however, if certain models better explained responses to natural song, whose elements unfold in complex sequences. As recording neural responses during courtship or to stimuli adequately spanning natural song space was infeasible, we pursued a novel approach of using the fit encoding models to generate artificial time-varying population responses to songs extracted from a separate, pure-behavior dataset of natural courtship rituals. Reading out the artificial activity to predict future female locomotion extracted from the same rituals let us score each encoding model relative to the behavior data. This revealed one model’s responses–where song inputs were gated by multiplicative adaptation (MA)–predicted locomotion far better than others’, suggesting this model better reflects song coding in natural courtship. Iterating our procedure revealed the MA code relied on slowly integrating, fast-adapting song responses across a multi-timescale neural population, which we found should exhibit a testable signature of accumulator-like natural song responses, and should efficiently transform song into neural activity. This represents a new approach for using behavioral data to gain mechanistic insight into neural coding in natural settings, with which we are presently guiding novel neuroimaging experiments, and sheds new light on how neural population dynamics process temporally complex communication signals.",
        "url": "https://www.world-wide.org/cosyne-23/inferring-neural-codes-from-natural-behavior-add3bca3"
    },
    "Emergent compositional reasoning from recurrent neural dynamics": {
        "title": "Emergent compositional reasoning from recurrent neural dynamics",
        "authors": "William Tong & Cengiz Pehlevan",
        "date": "Friday, 10 March 2023",
        "location": "II-085",
        "abstract": "The ability to reason compositionally is a hallmark of intelligent behavior. This algebraic capacity to assemble new concepts from novel combinations of existing components lies at the heart of many human intellectual endeavors: language, math, science, philosophy, and much more. Further, recent discoveries in animal cognition indicate that compositional reasoning may not be a uniquely human trait --examples include numeracy in non-human primates, spatial navigation using cognitive maps in rodents, and even the use of basic syntax in songbirds (Tervo, Tenenbaum, & Gershman 2016) suggesting a widespread and foundational role in natural intelligence. Despite the importance of this ability, it remains unclear how compositional reasoning manifests in the brain. As a first step towards understanding the relevant neural dynamics, we present an analysis on the emergence of compositional reasoning in recurrent neural networks (RNN) trained on a simple binary addition task. We discover that 1) task-optimized RNNs consistently develop an attractor landscape whose geometry encodes a partially-compositional representation of the task, and 2) RNNs that are expressive enough to learn a fully-compositional solution nonetheless fail to do so through gradient-based methods alone. Rather, models may require a global search strategy like an evolutionary algorithm to identify optimal basins in the loss landscape that converge towards fully-compositional solutions. Together, these findings offer an initial account of how collective neural activity can implement an inference procedure exhibiting basic compositionality.",
        "url": "https://www.world-wide.org/cosyne-23/emergent-compositional-reasoning-from-f101ced1"
    },
    "Optimal control under uncertainty predicts variability in human navigation behavior": {
        "title": "Optimal control under uncertainty predicts variability in human navigation behavior",
        "authors": "Fabian Kessler, Julia Frankenstein, Constantin Rothkopf",
        "date": "Friday, 10 March 2023",
        "location": "II-086",
        "abstract": "Navigation has long been recognized as one of the most fundamental behaviors in animals and humans. While much has been learned by studying navigation behaviorally and its neuronal underpinnings, there is no comprehensive computational account of the uncertainty and variability governing navigation. Current ideal observer models of navigation frame navigation in terms of perceptual cue integration but omit planning and sequential control and, therefore, cannot explain how trajectories and their endpoint variability arise. Because a vast array of natural sensorimotor behaviors in humans, including motor control tasks, locomotion, and ball-catching behavior, has been explained successfully in terms of optimal control under uncertainty, we formulated a dynamic Bayesian actor model of human navigation. Here, we show that spatial uncertainty about task-relevant quantities in the internal model of the navigator, either about self-location, heading direction, or the location of landmarks and objects within the environment, interacts dynamically with different cues during navigation, giving rise to the endpoint variability in homing tasks. The dynamic Bayesian actor model predicts the empirically observed variability in trajectory endpoints across multiple experiments with a single set of biologically plausible parameters. Importantly, we show that optimal sequential actions under uncertainty reconcile several previous reports on seemingly sub-optimal cue integration behavior, which in this model arises as the consequence of dynamic interactions of perceptual, internal, and movement uncertainties. Finally, the dynamic Bayesian actor further offers a computational-level explanation of the role that path integration plays in building up an allocentric cognitive map from sequential egocentric observations of landmarks and objects and how this internal map is used subsequently to plan and execute movements. Thus, this computational model of navigation will allow relating neuronal activity to internal perceptions, subjective utilities, and beliefs instead of external stimuli and making testable predictions for behavior in navigation tasks.",
        "url": "https://www.world-wide.org/cosyne-23/optimal-control-under-uncertainty-predicts-718971b3"
    },
    "Does the fly’s brain center for vector navigation know that the world is 3D?": {
        "title": "Does the fly’s brain center for vector navigation know that the world is 3D?",
        "authors": "Angel Stanoev, Hannah Haberkern, Brad Hulse, Sandro Romani, Vivek Jayaraman",
        "date": "Friday, 10 March 2023",
        "location": "II-087",
        "abstract": "Across species, many navigational spatial representations, including those of head direction and traveling direction, require the integration of changes in sensory information induced by self-motion. In Drosophila, connectomic analysis points to a variety of so-called LNO neurons as key inputs for this information to the central complex (CX), a navigational center of insect brains. Recent studies have reported that the responses of several of these neurons correlate with self-motion and with optic flow resulting from rotations and translations in 2D. However, flying animals, like bats and insects, navigate in 3D. We used the fly’s connectome and genetic tools to identify, target and systematically characterize the optic-flow responses of the near-complete set of LNO neurons using two-photon calcium imaging in tethered and fully-restrained flies. We presented different wide-field optic flow visual stimuli on a cylindrical LED arena, thereby deriving the fly’s encoding of visual motion inputs in isolation. The flies were virtually embedded in a featureless flow field corresponding to rotational or translational motion around a given axis, sampled systematically from the set of 3D vectors on a unit sphere around the fly’s position. We found that all LNO neuron types exhibited consistent tuning profiles centered around a preferred axis and direction to rotational and translational motion. We verified that our results for previously characterized LNO types were in agreement with recent studies. Further, our analysis of the complete set of LNO types showed that appropriately weighted linear combinations of their responses by putative downstream neurons could produce responses tuned to rotations around any 3D vector. These results provide concrete predictions about the possible responses of downstream neurons to 3D optic flow that can be tested with further connectomic analysis and functional measurements and paves the way for the search for 3D navigational representations in the fly CX.",
        "url": "https://www.world-wide.org/cosyne-23/does-flys-brain-center-vector-navigation-05cfb28e"
    },
    "Network dynamics implement optimal inference in a flexible timing task": {
        "title": "Network dynamics implement optimal inference in a flexible timing task",
        "authors": "John Schwarcz, Eran Lottem, Jonathan Kadmon",
        "date": "Friday, 10 March 2023",
        "location": "II-088",
        "abstract": "The brain's ability to produce reliable behaviour in a dynamic world is critical to survival. Humans and animals can quickly adapt their behaviour to subtle environmental changes, suggesting reliance on neuronal activity rather than long term synaptic plasticity. However, it is unclear how a neural network can quickly change its response based on subtle changes in its inputs. We developed a novel GO/NO-GO evidence accumulation task that requires fast responses to hidden-state changes under varying uncertainty levels. The goal is to detect transitions between `safe' and `unsafe' states. In the safe state, a constant GO cue is presented. In the unsafe state, a NO-GO cue is presented with intermittent random misleading GO cues. The probability of a misleading GO cue in the unsafe state is a parameter we control, which defined the noise level in the task. The agent must strike a balance between speed and accuracy: acting prematurely may result in an erroneous trial while waiting to remove uncertainty delays the reward---both reduce the overall reward rate. Importantly, the optimal waiting time depends on the noise level, which we change throughout the experiment. The challenge is that the agent needs to estimate the noise level to evaluate the hidden state and vice versa. We trained mice and artificial recurrent neural networks (ANNs); both quickly adjusted their waiting times to the noise level. We analyzed the trained ANNs' activity and found that networks represent the hidden-state probability and noise level in orthogonal directions. Furthermore, the noise estimation matches that of an ideal Bayesian observer, suggesting that the network learned the structure of the task. Our results show that neural networks can learn flexible task structures and adapt their response online. This study advances our understanding of how neural networks may represent complex and flexible cognitive tasks.",
        "url": "https://www.world-wide.org/cosyne-23/network-dynamics-implement-optimal-inference-bb1c6492"
    },
    "Causal role of the visual cortex in working memory and perceptual bias": {
        "title": "Causal role of the visual cortex in working memory and perceptual bias",
        "authors": "Ivan Voitov & Thomas Mrsic-Flogel",
        "date": "Friday, 10 March 2023",
        "location": "II-089",
        "abstract": "Working memory is a critical component of cognition as it allows for the flexible coupling of sensory input to motor output. However, imprecise maintenance of sensory information in working memory and the influence of intervening sensory inputs may lead to history-dependent biases in behaviour, such as recency or contraction bias. Recent studies have proposed that approximate (Lange et al., 2021) or imbalanced (Deneve & Jardri, 2016) hierarchical Bayesian inference may account for such biases, and have suggested a mapping of latent sensory representations onto the hierarchical organization of neocortex. In line with this, sensory cortical areas have been found to causally contribute to working memory maintenance (Voitov & Mrsic-Flogel, 2022). Here, we investigate the precise role of the primary visual cortex during visual working memory – whether selectively arbitrating perceptual biases or maintaining the latent sensory representations in working memory. We designed a visual working memory task for head-fixed mice which enabled us to both vary the strength of visual working memory representations and the sensory history-dependent perceptual bias on a trial-to-trial basis. We observed distinct psychometric profiles associated with the disruption of working memory by the presentation of repeated distractor stimuli and the perceptual biases induced by the sensory features of these distractor stimuli. To examine the role of early sensory processing in working memory maintenance and perceptual bias, we optogenetically inactivated the primary visual cortex (V1) during the inter-stimulus delay periods. Inactivating V1 did not influence working memory maintenance or perceptual bias in isolation, but instead led to behavioural deficits which were consistent with a disruptive effect on both. Our results therefore indicate that the maintenance of visual working memory and the perceptual biases induced by sensory history are not dissociable early on in the neocortical hierarchy.",
        "url": "https://www.world-wide.org/cosyne-23/causal-role-visual-cortex-working-memory-86d18d10"
    },
    "A simple method to improve regression and correlation coefficient estimates with noisy neural data": {
        "title": "A simple method to improve regression and correlation coefficient estimates with noisy neural data",
        "authors": "Jason E. Pina & Joel Zylberberg",
        "date": "Friday, 10 March 2023",
        "location": "II-090",
        "abstract": "Linear regression and Pearson correlations are bedrock statistical analyses in neuroscience: correlations between neurons are a signature of collective information coding and computation, and linear regression quantifies the linear or nonlinear (e.g., polynomial) relationships among, e.g., neurons or brain regions. However, noise can bias the regression and correlation coefficient estimates towards zero, an effect known as regression dilution. While averaging over trials, time, or neurons--a widespread practice to mitigate noise in neuroscience--reduces the effects of noise, it does not generally eliminate such effects. Here, we present a simple bootstrap-based method to correct for the effects of independent noise on regression and correlation coefficients when the quantities of interest are averages (or other metrics) of the data, regardless of the modality (including electrophysiology, fMRI, calcium imaging, behavioural). We demonstrate the efficacy of the method on simulated data: applied to noisy data, including model neural responses to oriented gratings, our method results in nearly unbiased estimates of the ground truth. In contrast, estimates obtained directly from the averaged data are biased towards zero. Finally, we apply our method to publicly available experimental data. By re-analyzing open-source data that estimate the intersubject correlations (ISCs) of brain regions across multiple subjects, we find that the correlations can be considerably (~1.5-2x) larger than originally reported. Similarly, we find that some regression coefficient estimates reported in a recent calcium-imaging experiment are substantially biased towards zero. This regression dilution obscured whether the neural responses changed across days, as a lack of change--responses on day 2 being the same as on day 1--corresponds to a regression coefficient of 1. Our method avoids such bias, allowing us to find that the neural responses systematically change across days for one stimulus type, but not for another, consistent with other results reported in the experiment.",
        "url": "https://www.world-wide.org/cosyne-23/simple-method-improve-regression-correlation-4e1348fa"
    },
    "Influence of Learning Rules on Representation Dynamics in Wide Neural Networks": {
        "title": "Influence of Learning Rules on Representation Dynamics in Wide Neural Networks",
        "authors": "Blake Bordelon & Cengiz Pehlevan",
        "date": "Friday, 10 March 2023",
        "location": "II-091",
        "abstract": "The learning rules implemented by neural networks in the brain are currently unknown. Understanding how candidate learning rules influence learned representations and prediction dynamics in neural networks could provide a link between experimentally accessible neural response measurements and possible underlying learning rules. To gain insight into how learning rules alter representation dynamics, we provide theoretical analysis of a broad class of learning rules which include exact gradient descent (GD), Feedback-Alignment (FA), Direct-Feedback-Alignment (DFA), Hebbian learning (Hebb) and gated linear networks (GLN). By developing a dynamical mean field theory (DMFT) for wide neural networks, we derive predictions for how neural representations evolve during learning with each of these rules in the large population limit. We show that, for each of these learning rules, the evolution of the output function at infinite width is governed by a time varying effective neural tangent kernel (eNTK). In the lazy training limit, this eNTK is static and does not evolve, while in the rich mean-field regime this kernel’s evolution can be determined self-consistently with DMFT. We show that richness accelerates learning by aligning the true feature gradients to the pseudo-gradient fields and aligning the feature kernels to the structure of the task.",
        "url": "https://www.world-wide.org/cosyne-23/influence-learning-rules-representation-ccc83d08"
    },
    "Computational mechanisms underlying thalamic regulation of prefrontal signal-to-noise ratio in decision making": {
        "title": "Computational mechanisms underlying thalamic regulation of prefrontal signal-to-noise ratio in decision making",
        "authors": "Zhe Chen, Xiaohan Zhang, Michael Halassa",
        "date": "Friday, 10 March 2023",
        "location": "II-092",
        "abstract": "Successful execution of complex decision-making tasks requires identification and processing of multiple sources of uncertainty, such as sensory uncertainty, mapping uncertainty and outcome uncertainty. The mediodorsal (MD) thalamus is a critical partner for the prefrontal cortex (PFC) in cognitive flexibility and resolving uncertainty in decision making [1,2]. Animal experiments have shown that the MD enhances prefrontal signal-to-noise ratio in decision making under uncertainty [3]. However, the computational mechanisms by which the MD enhances prefrontal activity in decision making under uncertainty remain unclear. In addition, how the newly discovered cellular diversity in MD contributes to such computations is unexplored. We developed computational models to dissect these mechanisms, and found that the inclusion of an MD-like feedforward module increased robustness to sensory noise and enhanced working memory maintenance in the recurrent excitatory-inhibitory PFC network performing a context-dependent decision-making task. The task uncertainty was represented by the coherence or congruence of sensory cues. We found that the PFC-MD model outperformed the PFC-alone model in task conditions with high sensory uncertainty. PFC excitatory units showed context-invariant rule tunings, whereas MD units showed modulation with respect to context and cue uncertainty. The MD enhanced working memory maintenance during the task delay. By imposing thalamocortical connectivity constraints, we found cell type-differential modulation in MD-to-PFC connectivity (more specifically, MD1PV and MD2VIP pathways for two target-specific MD subpopulations MD1 and MD2), which independently regulate signal amplification and noise suppression. Furthermore, our models made experimentally testable predictions that connect disrupted thalamocortical connectivity with prefrontal excitation-inhibition (E/I) imbalance and dysfunctional inhibitory cell types. In summary, our biologically realistic PFC-MD models replicate important behavioral and neurophysiological findings, reveal a key computational mechanism of context-invariant, cell-type specific regulation of sensory uncertainty, and provide insight into parsing cognitive deficits for mental disorders such as schizophrenia and autism spectral disorder.",
        "url": "https://www.world-wide.org/cosyne-23/computational-mechanisms-underlying-cfdd3d2e"
    },
    "Discovery of Linked Neural and Behavioral Subspaces with External Dynamic Components Analysis": {
        "title": "Discovery of Linked Neural and Behavioral Subspaces with External Dynamic Components Analysis",
        "authors": "Jacob Yeung, Ji Hyun Bak, Kristofer Bouchard",
        "date": "Friday, 10 March 2023",
        "location": "II-093",
        "abstract": "Neural recordings are often high-dimensional while latent dynamics related to behavior are low-dimensional. Similarly, ethological behaviors are described by large numbers of dynamic features and it is important to know both the dimensionality and composition of the neurally relevant behavioral subspace. However, methods for data-driven identification of behavioral subspaces relevant for neural recordings is nascent. Here, we introduce external Dynamics Components Analysis (eDCA), a linear dimensionality reduction method that finds subspaces of past neural data that have maximal mutual information with subspaces of future behavior data. We validate eDCA on synthetically generated data and show that it identifies ‘causal’ neural subspaces relevant for behavioral subspaces and accurately recovers the relative importance of neural variables relevant for generating behavioral variables. Next, we apply eDCA to data from Macaque arm reaching on a 2D grid with simultaneously recorded neurons from primary motor cortex. We show eDCA neural subspaces decode behavior comparable to state-of-the-art methods (e.g., PSID). When both neural and behavioral data are corrupted by additional variables, we find that eDCA discards the superfluous dimensions. Decoding results additionally indicate that the relevant neural and behavioral subspaces are ~7 and 3 dimensional, respectively. Finally, we apply eDCA to high-dimensional speech data with simultaneously recorded ECoG from speech sensorimotor cortex. From the speech sound spectrograms, eDCA identifies neural subspaces relevant for the less acoustically salient (compared to vowels), but articulatorily important consonant sounds. Together, these results demonstrate that eDCA directly learns subspaces of neural dynamics that are `causally' relevant for subspaces of behavioral dynamics. Thus, by compressing both neural and behavioral data, eDCA removes the burden of manual feature selection in complex, ethological behavior and aids in identifying the dimensionality of the relevant neural and behavioral data.",
        "url": "https://www.world-wide.org/cosyne-23/discovery-linked-neural-behavioral-subspaces-79358ccb"
    },
    "Targeted single-cell ablation uncovers network homeostasis of sound representations in mouse cortex": {
        "title": "Targeted single-cell ablation uncovers network homeostasis of sound representations in mouse cortex",
        "authors": "Takahiro Noda, Jens-Bastian Eppler, Matthias Kaschube, Simon Rumpel, Eike Kienle, Yonatan Loewenstein",
        "date": "Friday, 10 March 2023",
        "location": "II-094",
        "abstract": "Sensory cortices maintain robust sensory representations despite an inevitable loss of neurons during aging and even during the prodromal stages of neurodegenerative diseases. However, the mechanisms that safeguard sensory representations and provide the cortical network with robustness against the loss of neurons are largely unknown. Here, we tested in how far the targeted elimination of functionally identified neurons affects the dynamics of sound-evoked population responses and could trigger homeostatic processes at the network level. We combined longitudinal two-photon calcium imaging of population responses evoked by a set of sound stimuli in the mouse auditory cortex and targeted single-cell laser ablation (microablation). Following several days of baseline imaging, we microablated ~30-40 cells in layer 2/3 per mouse. One day after microablation, we observed reduced sound responses as well as decorrelation toward the tuning of microablated cells in the remaining spared cells which were responsive during baseline. This was most prominent for microablation of sound responsive cells, but modest or no significant effects were observed when non-responsive cells or no cells (control group) were microablated, respectively. A group of newly responsive cells subsequently elevated the response amplitude and compensated signals to the tuning of microablated cells. Furthermore, responses in inhibitory cells were reduced, indicating an E/I imbalance after microablation. We created a representational map from the global population responses using correlation as a measure of pairwise distances. Microablation of sound-responsive neurons caused a massive collapse of the representational map that, however, was only transient and recovered in subsequent days. Together, the targeted elimination of tens of cortical neurons results in specific short-term changes in the local network dynamics, impairing its ability to form a distinct representation of the auditory world, however, in the following days the network homeostatically reinstates the representation, suggesting an underlying network-specific mechanism beyond the classical firing rate homeostasis.",
        "url": "https://www.world-wide.org/cosyne-23/targeted-single-cell-ablation-uncovers-32fd6c91"
    },
    "Temporal pattern recognition in retinal ganglion cells is mediated by dynamical inhibitory synapses": {
        "title": "Temporal pattern recognition in retinal ganglion cells is mediated by dynamical inhibitory synapses",
        "authors": "Simone Ebert, Thomas Buffet, Semihchan Sermat, Olivier Marre, Bruno Cessac",
        "date": "Friday, 10 March 2023",
        "location": "II-095",
        "abstract": "The efficient coding theory postulates that sensory neurons compress relevant information before sending it to the rest of the brain. To this end, these neurons are thought not to signal all input features, but only surprising events, e.g. mismatches between expected and perceived inputs. In the retina, it has been shown that ganglion cells, the retinal output, strongly respond when a periodic sequence of flashes suddenly ends. Strikingly, the latency of this response shifts by the same amount as the period of the flash sequence, as if ganglion cells responded to the omitted flash with constant latency. This suggests that the retina has a temporal expectation of when the omitted stimulus should have occurred, and is able to signal the violation of this expectation. The mechanism behind this predictive latency shift remains unclear. Several models have been proposed, but have not been corroborated by data. Here we combined modeling and experiments to show that this Omitted Stimulus Response is due to inhibitory neurons with depressing synapses. When blocking glycinergic inhibitory transmission in the retina, we found that the response remained, but the predictive latency shift was lost. Based on this result, we developed a model of the retinal circuit where the response to the omitted stimulus arises from an interplay between excitatory and delayed inhibitory inputs. Inhibition delays the response at the end of the sequence, while the depressing synapse is necessary to shift this delay as a function of the frequency of the flash sequence. Our circuit model reproduced our experimental findings and generated new predictions that we confirmed by further experiments. Since depressing inhibitory synapses are ubiquitous in sensory circuits, our results suggest they could be a key component to generate predictive responses that have been observed in several brain areas.",
        "url": "https://www.world-wide.org/cosyne-23/temporal-pattern-recognition-retinal-ed1f4045"
    },
    "Learning a divisive normalization model with a denoising objective": {
        "title": "Learning a divisive normalization model with a denoising objective",
        "authors": "Xinyuan Zhao & Eero Simoncelli",
        "date": "Friday, 10 March 2023",
        "location": "II-096",
        "abstract": "Sensory neurons in many organisms and brain areas exhibit a form of local gain control that has been described as \"divisive normalization'' (Carandini & Heeger, 2011) in which the stimulus-driven activity of each neuron is divided by a factor involving the summed activity of a group of neurons. Redundancy reduction has been proposed as normative explanation of divisive normalization, and previous work has used this principle for learning normalization models (Schwartz & Simoncelli, 2000). Specifically, redundancy in filtered representations of images can be reduced by dividing by an estimate of the local standard deviation (the square root of a weighted average of squared responses). Incidentally, a local standard deviation estimation is also used for removing noise from image signals with spatially-varying variance (\"heteroskedastic'') corrupted with noise. Based on this, we introduce a joint normalization/denoising model, and optimize both the input filters and the normalization weights to minimize estimation error (the squared distance between the input and the denoised images). We find that learned input filters are oriented, and well-matched to the distribution of receptive field shapes found in macaque V1 (not shown). In addition, the learned normalization weights allow the model to reproduce the variations in surround suppression strength across different spatial locations found in V1. Finally, the normalized representation in our model provides a high-quality prediction of human perception of image quality. These results show that a denoising objective is capable of driving the learning of the divisive normalization model (including both input filters and normalization weights). Given the ubiquity of noise in the brain, we expect these principles to be applicable to other stages of visual hierarchy, and to other sensory systems.",
        "url": "https://www.world-wide.org/cosyne-23/learning-divisive-normalization-model-188f73ac"
    },
    "Effects of Neural Heterogeneity on the Low-Dimensional Dynamics of Spiking Neural Networks": {
        "title": "Effects of Neural Heterogeneity on the Low-Dimensional Dynamics of Spiking Neural Networks",
        "authors": "Richard Gast, Sara A. Solla, Ann Kennedy",
        "date": "Friday, 10 March 2023",
        "location": "II-097",
        "abstract": "The physiological properties of neurons influence their population dynamics to shape neural computation and behavior. These physiological properties are diverse: the brain is composed of many genetically distinct neuronal cell types with pronounced physiological and functional differences. But neurons of the same cell type are also not identical, and exhibit heterogeneity in their physiological properties. We call this \"within-type\" heterogeneity, in contrast to the former, \"between-type\" heterogeneity. Whereas the contributions of distinct neuron types to neural network dynamics has been studied intensely, within-type heterogeneity has received less attention. Recent results suggest, however, that the loss of within-type heterogeneity might underlie pathological brain dynamics seen in epilepsy \\cite{rich_loss_2022}. We provide insight into the computational consequences of within-type heterogeneity by studying the effect of distributed physiological properties of neurons on emergent dynamics in networks of one or more cell type. Specifically, we derive a novel mean-field model that incorporates heterogeneity in the spiking thresholds of neurons, a measurable property that has been associated with the sigmoidal input-output relationship that many neural populations exhibit \\cite{robinson_propagation_1997}. Our model allows us to determine a direct relationship between the variance of the spike thresholds across neurons and the resulting low-dimensional mean-field network dynamics. Building on this model, we use bifurcation analysis to show that the heterogeneity of inhibitory interneurons plays a crucial role in shaping the dynamic regimes of neural circuits: heterogeneous inhibitory interneuron populations promote asynchronous, multistable regimes, whereas homogeneous interneurons facilitate synchronized dynamics. We also show that spike threshold heterogeneity interacts with synaptic input heterogeneity in sparse networks to alter the community structure of the network and the effective dimensionality of the network dynamics. We thus show that continuously distributed, within-type heterogeneity can dramatically impact neural population dynamics, and introduce a new mean-field model for future studies of heterogeneous neural networks.",
        "url": "https://www.world-wide.org/cosyne-23/effects-neural-heterogeneity-low-dimensional-75370073"
    },
    "Language emergence in reinforcement learning agents performing navigational tasks": {
        "title": "Language emergence in reinforcement learning agents performing navigational tasks",
        "authors": "Tobias Wieczorek, Maximilian Eggl, Tatjana Tchumatchenko, Carlos Wert Carvajal",
        "date": "Friday, 10 March 2023",
        "location": "II-098",
        "abstract": "Biological neural networks have evolved to produce complex social behavior such as communication and cooperation. Social communication only works if cues provided by one individual influence the neural activity and neural representations of the environment in another - particularly internal abstractions in planning and learning new tasks. How this translation works at the level of neural networks is still unclear. We hypothesize that synthesizing and learning to use a state representation that is common across several neural networks is critical to understanding the brain’s function underlying animals' generalization capabilities. In this work, we use artificial neural networks (ANNs) - used in computational neuroscience as model systems to reveal the mechanisms at work in neural networks in vivo - to understand how communicated information about a navigational task learned by one network can enhance the learning process of another. Work establishing communication protocols between two artificial intelligence (AI) agents grounded in natural language has already been performed, albeit with finite pre-provided vocabularies. We lift this restriction by allowing language to develop freely, gaining a deeper understanding of how biological neural networks synthesize shared and individual state-space representations. Using a gridworld model, we establish a communication protocol for navigation between ANN teacher and student agents. A message is passed by the teacher (trained on task) to an untrained student to improve goal-finding. However, as language is a lower-dimensional representation of a high-dimensional object, the maze solution is compressed to a message in a sparsity-promoting manner before it is passed. We find that decoding the message and using it helps the student achieve a significantly higher goal-finding rate and the developed “language” generalizes the goal’s location across different task worlds. Intriguingly, a two-dimensional state space representation develops in the message space, similar to how place cells represent two-dimensional spaces in animal brains.",
        "url": "https://www.world-wide.org/cosyne-23/language-emergence-reinforcement-learning-59cbc066"
    },
    "Automatic spike sorting correction and burst detection for high-density electrophysiological recordings": {
        "title": "Automatic spike sorting correction and burst detection for high-density electrophysiological recordings",
        "authors": "Sai Susheel Koukuntla, Timothy Harris, Adam Charles",
        "date": "Friday, 10 March 2023",
        "location": "II-099",
        "abstract": "High-density electrophysiological probes have substantially increased the spatial resolution and scale of neural recordings. Popular spike sorting algorithms, e.g. Kilosort (Pachitariu et al. 2016), SpyKING CIRCUS, etc., use waveform template matching to isolate single units from the large-scale recordings, but these algorithms make numerous errors which often require hours of manual curation to correct. Bursting neurons pose an additional challenge in spike-sorting: the shape and amplitude of a neuron’s waveform can change significantly over the course of a burst. Thus, waveform shape- based template matching may fail to group together spikes from the same burst. Analyzing bursting patterns can shed light on important aspects of brain function such as memory formation, synaptic plasticity, and inter-region communication that would be difficult to study otherwise. Regardless, no reliable method exists to automatically detect bursts from large-scale electrophysiological recordings. We develop here a two-stage algorithm that corrects spike sorting errors and identifies single-unit bursts. To automatically determine which spike clusters to merge, we devised novel metrics that quantify waveform similarity and cross-correlation significance. To extract hierarchical bursting structure from single-unit spike trains, we adapted a Hidden Markov model used to detect bursts in text data. On a real dataset from mouse hippocampus, our spike sorting correction method performs comparably to a human curator. Furthermore, we validated our burst detection model on both real and simulated data. The two stages of our algorithm can be used independently and the algorithm is post hoc, i.e., it can be integrated into existing spike sorting pipelines.",
        "url": "https://www.world-wide.org/cosyne-23/automatic-spike-sorting-correction-burst-4abc9e26"
    },
    "Slow, low-dimensional dynamics in balanced networks with partially symmetric connectivity": {
        "title": "Slow, low-dimensional dynamics in balanced networks with partially symmetric connectivity",
        "authors": "Xiaoyu Yang, Giancarlo La Camera, Gianluigi Mongillo",
        "date": "Friday, 10 March 2023",
        "location": "II-100",
        "abstract": "Cortical dynamics are slow and low dimensional. Relaxation, as measured for instance by the auto-correlation of the spike counts, can be slow (~seconds) compared to single neurons and synapses’ time constants (~hundreds of milliseconds). Moreover, spiking activity is coordinated across neural circuits despite weak, zero-lag cross-correlations between pairs of neurons. Thus, neural circuit dynamics can be described by a small number of collective variables compared to the number of neurons. By which mechanism(s) do slow and low-dimensional dynamics arise in cortical networks, and how are they related? Existing theories explain them as a result of precise adjustments of the synaptic connectivity. Slow relaxation is obtained, for instance, when the network operates close to the edge of stability, which depends on the variance of the synaptic efficacies. Low-dimensional dynamics is obtained, for instance, if the connectivity matrix is rank-deficient, which seems to require some form of synaptic plasticity. We note that the rank of a matrix and the variance of its elements can be independently adjusted. Here, we show that slow and low-dimensional dynamics naturally arise in balanced networks in the presence of partially symmetric synaptic connectivity that is consistent with experimental observations. The partial symmetry leads to an effective retarded self-interaction that slows down the dynamics and it tends to induce strong cross-correlations between pairs of neurons. These, however, are actively suppressed in the balanced regime, leading to strongly correlated network states with weak pair-wise correlations. We illustrate the computational relevance of this regime by showing that the network can dynamically (and robustly) retain the memory of a random stimulation over long time intervals. Taken together, our results suggest that slow and low-dimensional dynamics are a generic feature of balanced cortical networks, and can lead to robust, long-lived memory traces even in the absence of learning-related synaptic plasticity.",
        "url": "https://www.world-wide.org/cosyne-23/slow-low-dimensional-dynamics-balanced-fe12715d"
    },
    "Conductance Based Integrate and Fire Model with Correlated Inputs Captures Neural Variability": {
        "title": "Conductance Based Integrate and Fire Model with Correlated Inputs Captures Neural Variability",
        "authors": "Logan Becker, Thibaud Taillefumier, Nicholas Priebe, Eyal Seidemannn, Baowang Li",
        "date": "Friday, 10 March 2023",
        "location": "II-101",
        "abstract": "The spiking activity of neurons is highly variable and is often described as a Poisson process. This variability comes from random fluctuations within the membrane potential (V) that leads to random spike times. Prior analysis has shown that the variability of V, in response to stimuli, became quenched, where the variance (σ2) decreased as the mean (μ) increased. However, recent in-vivo primate data has shown that σ2 also can increase with μ. Here we propose a new analytical and computational framework to show that conductance-based integrate-and-fire (C-IF) neurons can accurately capture μ and σ2 as well as the skewness (γ) of V. Specifically, we show that when subjected to uncorrelated Poissonian inputs, μ and σ2 simultaneously increase whereas γ decreases in response to stimulus drive. However, for biophysical parameters, we find that σ2 and γ are an order-of-magnitude smaller than in-vivo estimates. We then show that accounting for realistic values of σ2 and γ requires the inclusion of weak but nonzero spiking input correlations. To do so, we model the impact of spiking input correlations via Levy-process-based synaptic drives, leveraging the theory of statistical exchangeability. We then perform an exact moment analysis of the stationary neural response using techniques from queueing theory. Practically, our approach produces closed-form expressions for μ, σ2 and γ, which can be used to estimate network-level features such as input synaptic numbers and spiking correlations. Theoretically, our approach suggests that mean-field description of neural activity shall be revised to include nonzero spiking correlation.",
        "url": "https://www.world-wide.org/cosyne-23/conductance-based-integrate-fire-model-ecff4652"
    },
    "VIP interneuron contributions to state-dependent sensory processing": {
        "title": "VIP interneuron contributions to state-dependent sensory processing",
        "authors": "Katie Ferguson, Jenna Salameh, Jessica Cardin",
        "date": "Friday, 10 March 2023",
        "location": "II-102",
        "abstract": "Several populations of GABAergic interneurons (INs) are strongly regulated by neuromodulatory input during distinct behavioral states, and thus may be key contributors to flexible cortical function. One prominent model suggests vasoactive intestinal peptide-expressing INs (VIP-INs) activate upon arousal, suppress the activity of downstream INs (SST-INs), and consequently disinhibit pyramidal neurons (PNs). This VIP-SST-PN disinhibitory circuit is hypothesized to be a general cortical circuit motif allowing behavioral state signals to modulate sensory processing. Cortical VIP-INs, however, have complex patterns of connectivity, including synaptic connections to excitatory PNs, and reciprocal inhibitory (I) connections with other INs. Current models largely fail to account for these complex context-dependent I-I interactions, leaving the role of distinct IN populations within the active cortical network largely unexplored. Furthermore, in inhibitory stabilized networks, hyperpolarization of INs may lead to a paradoxical increase in inhibitory activity, suggesting that I-I interactions are unlikely to be as straightforward as initially hypothesized. We used both chronic and acute manipulations to examine the state- and context-dependent role of I-I interactions. We expressed the calcium indicator GCaMP6 in VIP-INs and, using intersectional genetic tools, in SST-INs or PNs. We used two-photon imaging and high-throughput analyses to assess how VIP-INs influence SST-IN or PN activity in the primary visual cortex of awake mice across arousal states. To determine the behavioral impact of VIP-INs, we assessed mouse perceptual performance on a contrast detection task while optogenetically inhibiting VIP-INs. Our data reveals that VIP-INs contribute significantly to the encoding of low contrast stimuli and have an unanticipated non-linear contribution to the stimulus size tuning properties of SST-INs and PNs. In a contrast detection task, perceptual thresholds for stimulus detection were significantly higher when VIP-IN were inhibited, an effect that was amplified for small stimuli, indicating that VIP-INs cells play a powerful functional non-linear role in visual perception.",
        "url": "https://www.world-wide.org/cosyne-23/interneuron-contributions-state-dependent-188583ed"
    },
    "Turning neurons RIV, SMB, and SAAD gates mechanosensory response in C. elegans upstream of AVA": {
        "title": "Turning neurons RIV, SMB, and SAAD gates mechanosensory response in C. elegans upstream of AVA",
        "authors": "Sandeep Kumar, Anuj Sharma, Andrew Leifer",
        "date": "Friday, 10 March 2023",
        "location": "II-103",
        "abstract": "An important goal of the nervous system is to integrate sensory cues with an animal’s current behavior state to generate a suitable motor response. However, the underlying neuronal mechanism behind how neural circuits integrate sensory and behavior signals remains unknown. To answer this question, we performed a systematic high-throughput optogenetic interrogation of the neural circuits underlying mechanosensorimotor processing in the nematode C. elegans. When C. elegans detects gentle touch from the environment, it usually responds by moving backward, also known as reversals. The likelihood of reversing depends on the current behavior state of the worm. A worm is less likely to reverse in response to a touch stimulus delivered during turning than one delivered when moving forward. To understand the underlying circuit mechanism, we optogenetically activated downstream interneurons in the mechanosensory processing pathway when the animal was either moving forward or turning. Activation of interneurons AIZ, RIM, AIB, or AVE, during forward locomotion, were much more likely to evoke reversals than did activation during turning. In contrast, activation of neuron AVA evoked reversals with similar likelihood regardless of whether the worm was moving forward or turning, suggesting that AVA lies functionally downstream of the integration of turning and mechanosensory related signals. We propose that turning neurons RIV, SMB, and SAAD send turning-related signals that inhibit or disrupt mechanosensory signals. When we inhibited these turning-related neurons, it restored the animal’s evoked reversal response to mechanosensory stimuli, even during turns. Taken together, these results suggest a potential circuit mechanism in which signals from turning neurons RIV, SMB, and SAAD act as a gate to inhibit or impede the propagation of mechanosensory-related signals, and that these turning related signals act somewhere upstream of neuron AVA.",
        "url": "https://www.world-wide.org/cosyne-23/turning-neurons-saad-gates-mechanosensory-b221ca12"
    },
    "Statistical learning yields generalization and naturalistic behaviors in transitive inference": {
        "title": "Statistical learning yields generalization and naturalistic behaviors in transitive inference",
        "authors": "Samuel Lippl, Larry Abbott, Kenneth Kay, Greg Jensen, Vincent Ferrera",
        "date": "Friday, 10 March 2023",
        "location": "II-104",
        "abstract": "A hallmark of intelligence is the ability to infer how stimuli in the world are interrelated. Transitive inference (TI) tasks test if subjects can generalize transitively (A\">\"B and B\">\"C implies A\">\"C), an important case of such relational inference. Despite longstanding study, it remains an open question how the brain, or even statistical learning systems more generally, implements TI. Here we show that a wide range of statistical and biological learning models generalizes transitively and replicates key behavioral patterns observed in humans and animals performing TI. Further, we characterize analytically how specific model components give rise to these behaviors. From both formal analyses and simulations, we find that (i) models with factorized input representations necessarily perform TI as these models are constrained to express an orderly internal representation of the items in the task (a \"rank\" representation), (ii) models implementing standard statistical inductive biases (namely margin maximization, gradient descent on standard loss functions, and kernel ridge regression) not only perform TI, but also emergently express a rank representation, and (iii) over the course of learning, these models systematically combine memorization and the rank representation. Our account can parsimoniously explain three empirically observed behavioral patterns. Further, we (iv) find analytically that it explains transitive generalization and TI behaviors in neural networks (NNs) in the infinite-width limit and, through simulations, confirm this for slim NNs as well. Our findings show systematically how minimal statistical learning principles can explain the rich behaviors empirically observed in TI, a classic paradigm for investigating relational cognition.",
        "url": "https://www.world-wide.org/cosyne-23/statistical-learning-yields-generalization-752c334f"
    },
    "Entorhinal grid-like signals reflect temporal context for human timing behavior": {
        "title": "Entorhinal grid-like signals reflect temporal context for human timing behavior",
        "authors": "Ignacio Polti, Matthias Nau, Raphael Kaplan, Virginie van Wassenhove, Christian F Doeller",
        "date": "Friday, 10 March 2023",
        "location": "II-105",
        "abstract": "An important ability for successful interaction with the environment is the estimation of magnitudes such as the duration of an event. To improve duration estimates, the brain must compensate for sensory uncertainty, which it does by encoding the statistical regularities that link co-occurring stimuli and tasks (i.e., temporal context). The entorhinal cortex (EC) supports the encoding of such task regularities, which has been suggested to rely on grid cells that the EC is known to harbor. On population level, grid cells exhibit a six-fold rotational symmetry as a function of gaze direction, which is thought to be measurable with functional magnetic resonance imaging (fMRI). Here, we therefore tested whether temporal context modulates grid-like fMRI activity in the human EC, and characterized in detail its relationship to behavioral performance in a time-to-contact (TTC) estimation task. We indeed found that EC activity signaled the accuracy as well as biases in timing behavior, and that grid-like activity reflected timing errors consistent with temporal-context encoding. Importantly, our findings are well explained by Bayesian models of time perception, suggesting that the human EC contributes to adapting internal timing mechanisms to the temporal statistics of the environment.",
        "url": "https://www.world-wide.org/cosyne-23/entorhinal-grid-like-signals-reflect-c6314368"
    },
    "Understanding network dynamics of compact assemblies of neurons in zebrafish larvae optic tectum during spontaneous activation": {
        "title": "Understanding network dynamics of compact assemblies of neurons in zebrafish larvae optic tectum during spontaneous activation",
        "authors": "Nicole Sanderson, Carina Curto, Enrique Hansen, Germán Sumbre",
        "date": "Friday, 10 March 2023",
        "location": "II-106",
        "abstract": "How does intrinsic network structure shape spontaneous coordinated neural dynamics? Previous work has shown that overlapping tectal neuronal assemblies can be circuit mechanisms for robust visual detection [1]. To better understand how these assemblies give rise to emergent dynamics, we use single-photon calcium imaging of triple transgenic zebrafish larvae optic tectum (OT), letting us simultaneously record spontaneous activity of 1000s of neurons in the absence of stimulation. What is the composition of cell types within the assemblies? What role do the inhibitory and excitatory neurons play in modulating assembly dynamics? We look at the E-I ratio of neurons within the assemblies, as well as the ratio of E-I activity during and outside of spontaneous assembly activation. We observe that assemblies maintain a consistent ratio of E-I activity during and outside of activation, even though total neural activity goes up during acti- vation. How are neurons interacting within the assemblies? Next we investigate the structure of the neural correlations using topological approaches invariant under nonlinear monotonic translations of the data, such as those introduced when measuring neural activity via calcium signal strength. We observe that topological signatures of neural correlation differ during versus outside of activation, in particular suggesting low dimensional dynamics during activation. Modeling assembly dynamics with threshold-linear networks lets us further relate these observed topological signatures to features of the network’s structure influential on its dynamics.",
        "url": "https://www.world-wide.org/cosyne-23/understanding-network-dynamics-compact-a3656048"
    },
    "Towards understanding the microcircuit in monkey primary visual cortex in-vivo": {
        "title": "Towards understanding the microcircuit in monkey primary visual cortex in-vivo",
        "authors": "Nicole Carr, Shude Zhu, Kenji Lee, Xiaomo Chen, Ruobing Xia, Alec Perliss, Tirin Moore, Chandramouli Chandrasekaran",
        "date": "Friday, 10 March 2023",
        "location": "II-107",
        "abstract": "The primary visual cortex (V1) is fundamental for visual processing. Transcriptomics suggests that the microcircuit in V1 consists of many inhibitory and excitatory cell types1. However, exactly how those diverse cell populations participate in visual cognition in vivo is unknown. To address this question, we recorded from V1 of two anesthetized monkeys using high-density Neuropixel probes across all layers of cortex2. We identified single neuron waveforms using Kilosort2, followed by rigorous manual curation. Our final dataset was composed of 801 negative spiking neurons (from 2529 units, 5 sessions). We used histology and current source density to assign neurons to layers and then applied a recently developed nonlinear dimensionality reduction technique (WaveMAP3) to delineate candidate cell types. WaveMAP revealed 9 candidate cell types ranging from narrow and triphasic, to broad biphasic waveforms. These candidate cell types were localized to distinct laminae, demonstrated heterogeneous firing rate responses, functional properties, and spatial profiles. Four of the narrow spiking cell classes were largely localized to Layer 4 of V1 and were likely stellate cells. Of these narrow spiking classes, one cell class demonstrated backpropagating action potentials (recently shown in mouse V14), whereas another had the highest and most sustained firing rates. Narrow, triphasic waveforms were in all layers except layer 2/3 and had the slowest and lowest visual response suggesting these are perhaps outputs from V1. In contrast, broad spiking waveforms were found in all layers. Of note, there was a cell class localized to Layer 5/6, with the broadest waveforms, robust firing rates, and the shortest response latency, which resembles Layer 6 pyramidal neurons that receive direct geniculocortical input. Together, our results show that high density electrophysiology and machine learning analysis help delineate cell types within a cortical column, furthering our understanding of microcircuits in the visual cortex.",
        "url": "https://www.world-wide.org/cosyne-23/towards-understanding-microcircuit-38f1874a"
    },
    "Spatiotemporally Localized Norepinephrine Modulates the Prefrontal Neural Manifold": {
        "title": "Spatiotemporally Localized Norepinephrine Modulates the Prefrontal Neural Manifold",
        "authors": "Samira Glaeser-Khan, Alfred Kaye, Neil Savalia",
        "date": "Friday, 10 March 2023",
        "location": "II-108",
        "abstract": "Norepinephrine (NE) is a neuromodulator that is released from projections of the locus coeruleus via extra-synaptic vesicle exocytosis (Fuxe, Borroto-Escuela, front. Physiol 2012). Previously, NE in the prefrontal cortex (PFC) was thought to be a homogenous field created by bulk release, but it remains unknown whether phasic (fast, short-term) fluctuations in NE can produce a spatially heterogeneous field, which could then structure cell firing at a fine spatial scale. To understand how spatiotemporal dynamics of NE release in the PFC affect neuronal firing, we performed a novel in-vivo two-photon imaging experiment in layer ⅔ of the prefrontal cortex using a green fluorescent NE sensor and a red fluorescent Ca2+ sensor, which allowed us to simultaneously observe fine-scale neuronal and NE dynamics. We found that the local NE field differs from the global NE field in transient periods of decorrelation, which are influenced by proximal NE release events. Release and reuptake events can occur at the same location but at different times, and differential recruitment of release and reuptake sites over time is a potential mechanism for creating a heterogeneous NE field. Using generalized linear models predicting cell firing dynamics, we showed that cellular Ca2+ fluctuations are overall influenced by both the heterogeneous local NE field and by the global NE field. During periods of local/global NE field decoupling, the heterogeneous local field and not the global field drives cell firing dynamics. To further clarify the relationship between NE and cell firing, we can use the population coding approach to understand how local and global neuromodulation functions to induce off- and on-manifold perturbations. Our results point to the importance of local, small-scale, phasic NE fluctuations for structuring cell firing, which may provide a mechanism for cognitive flexibility.",
        "url": "https://www.world-wide.org/cosyne-23/spatiotemporally-localized-norepinephrine-0752293d"
    },
    "Pose estimation made better, easier, and faster with video semi-supervised learning on the cloud": {
        "title": "Pose estimation made better, easier, and faster with video semi-supervised learning on the cloud",
        "authors": "Dan Biderman, Matt Whiteway, Cole Hurwitz, Nicholas Greenspan, Robert Lee, Ankit Vishnubhotla, Michael Schartner, Julia Huntenberg, Richard Warren, Dillon Noone, Federico Pedraja, The International Brain Lab The International Brain Lab, Nathaniel Sawtell, Liam Paninski",
        "date": "Friday, 10 March 2023",
        "location": "II-109",
        "abstract": "Computer vision algorithms now allow neuroscientists to quantify animal movement in unprecedented detail, shedding new light on problems in motor control, social behavior, navigation, and beyond. Existing models are only trained with labeled frames (supervised learning). Although effective in many cases, the supervised approach requires extensive image annotation, struggles to generalize to new videos, and produces noisy outputs that hinder downstream analyses. We address each of these limitations by introducing unlabeled video clips to model training and inference, and exploiting their spatiotemporal statistics in two different ways. First, we develop a suite of unsupervised training objectives that penalize the network whenever its predictions violate multiple-view geometry, smoothness of physical motion, or depart from a low-dimensional subspace of plausible body configurations. Second, we develop a new network architecture that predicts pose for a given frame using temporal context from surrounding (unlabeled) frames. Context frames resolve most brief occlusions and detection ambiguities (such as confusion between nearby and similar-looking body parts). We present results on two datasets: freely swimming mormyrid fish and head-fixed running mice, both densely tracked from multiple views. Our algorithms achieve better performance with fewer labels (sample-efficient), generalize better to unseen videos even when labels are abundant (out-of-distribution robustness), and provide smoother and more reliable trajectories for downstream analysis. Finally, we release a PyTorch Lightning package that supports easy model development and accelerated training, and a cloud-hosted application that allows users to annotate data, quickly train models, and predict new videos, directly from the browser and without any local installation.",
        "url": "https://www.world-wide.org/cosyne-23/pose-estimation-made-better-easier-faster-d1c7fb90"
    },
    "Self-generated vestibular prosthetic input updates forward internal model of self-motion": {
        "title": "Self-generated vestibular prosthetic input updates forward internal model of self-motion",
        "authors": "Kantapon Wiboonsaksakul, Charles Della Santina, Kathleen Cullen",
        "date": "Friday, 10 March 2023",
        "location": "II-110",
        "abstract": "The brain must differentiate between externally-generated and self-generated sensory inputs to build stable perception and generate appropriate behavior. Despite recent advances in neuroprostheses, little is known about how the brain interprets prosthetic sensory input, especially when self-generated. Here, we asked: How does the brain learn to distinguish self-generated prosthetic stimulation? To do this, we leveraged the well-understood neural pathways and behavior readouts of the vestibular system. A monkey was implanted with a vestibular prosthesis that restores sensory information via nerve stimulation and trained to make coordinated eye-head gaze-shifts between horizontal targets. Each session comprised a three-block learning paradigm: baseline gaze-shifts, gaze-shifts with prosthetic stimulation, and washout without stimulation. We hypothesized that 1) prosthetic stimulation would first engage vestibular reflex pathways, resulting in truncated gaze-shifts but also that 2) the brain would then update its internal model to account for this new sensory input. Consistent with our predictions, gaze position error initially increased after stimulation onset. Furthermore, this error then exponentially decayed within ~60 trials, with early washout trials showing oppositely-directed gaze position error, indicating a central adaptation rather than simply reflex suppression. We next asked whether the observed adaptation was due to updating a forward internal model (i.e., the brain’s prediction of self-generated prosthetic sensory input) or instead was simply the result of updating the gaze controller’s inverse model (i.e., the required motor command). To do this, we tested learning in a gaze adaptation paradigm where the target was jumped forward 5. This learning, which requires mainly the updating of inverse model, demonstrated substantially slower adaptation (~300 trials). Together, our results show that the brain can quickly learn to use self-generated prosthetic input by updating its forward internal model of self-motion. Importantly, these findings provide new insights on how the brain interprets prosthetic sensory inputs to generate accurate behavior.",
        "url": "https://www.world-wide.org/cosyne-23/self-generated-vestibular-prosthetic-02769331"
    },
    "Metric space learning in the hippocampus": {
        "title": "Metric space learning in the hippocampus",
        "authors": "Zhenrui Liao & Attila Losonczy",
        "date": "Friday, 10 March 2023",
        "location": "II-111",
        "abstract": "The hippocampus is the episodic memory and spatial navigation center of the brain. The cognitive map metaphor identifies episodic memory with ``navigation'' through a space of arbitrary learned relationships. However, what structures are admissible as ``cognitive maps'' remains unclear, particularly whether these maps are constrained to obey the same rules as physical space. We hypothesize that the hippocampus learns metric spaces as its cognitive maps. We test this hypothesis by training mice to learn and solve relational queries in a finite metric space which cannot be embedded in 2D Euclidean space, consisting of virtual reality (VR) hallways connected by licking choice ``doors''. By performing two-photon calcium imaging of hippocampal area CA1 during this task, we find behavioral and neural evidence that mice can learn these nonspatial metric spaces. Finally, we construct a modular, ``end-to-end'' model of how the hippocampus (i) segments a stream of high-dimensional, entangled sensory input into discrete concepts via one-shot learning, (ii) learns sequences of these concepts via Hebbian plasticity, and (iii) embeds the structure of the world into the weight matrix of a recurrent network capable of emitting samples (replay) from that structure, which a model-based agent can use to solve reward-seeking tasks. This work experimentally tests a formalization of the widely-used ``cognitive map'' conceptual model decoupled from Euclidean space, with implications for how such maps are used to solve abstract reasoning tasks.",
        "url": "https://www.world-wide.org/cosyne-23/metric-space-learning-hippocampus-8264f9ab"
    },
    "Spiking and bursting activity in stochastic recurrent networks": {
        "title": "Spiking and bursting activity in stochastic recurrent networks",
        "authors": "Audrey Teasley & Gabriel Ocker",
        "date": "Friday, 10 March 2023",
        "location": "II-112",
        "abstract": "Pyramidal neurons in mammalian cortical layer 5 (L5) send long-range projections to other cortical areas and subcortical structures. Understanding the outputs of the cortex thus requires understanding the activity of these neurons. Thick-tufted L5 pyramidal neurons generate two types of action potentials: 1) the classic sodium-potassium action potentials (Na-K APs) generated at the axon hillock, which propagate down the axon to trigger neurotransmitter release and backpropagate across the soma and dendritic tree, and 2) slow calcium spikes in the apical dendrite, triggered by the coincidence of a back-propagating Na-K AP and dendritic depolarization [Larkum et al., 1999]. These calcium spikes can then trigger a burst of Na-K APs. Somatostatin-positive Martinotti interneurons, which specifically target the apical dendrite, can gate dendrite-dependent bursts. Dendrite-dependent bursting has been proposed as a mechanism for coincidence detection [Larkum, 2013], multiplexed spike-burst sensory coding [Naud and Sprekeler, 2018], and provide a substrate for powerful and biologically plausible learning algorithms, e.g., [Greedy et al., 2022, Payeur et al., 2021]. Understanding these theoretically requires a theory for the joint spiking and bursting activity in cortical networks. Here, we study a simple stochastic model of dendrite-dependent bursting. Using tools from statistical field theory, we develop the joint probability density functional of spikes and bursts in recurrent networks. This allows the prediction of mean spike and burst rates, as well as pairwise and higher-order correlations between spikes and bursts. We show how somatic vs dendritic-targeting connectivity shapes population activity. Our approach opens new avenues to investigating how bursting nonlinearities interact with network structure to shape population activity",
        "url": "https://www.world-wide.org/cosyne-23/spiking-bursting-activity-stochastic-d01e4005"
    },
    "Coherence influences the dimensionality of communication subspaces": {
        "title": "Coherence influences the dimensionality of communication subspaces",
        "authors": "Shivang Rawat, David Heeger, Stefano Martiniani",
        "date": "Friday, 10 March 2023",
        "location": "II-113",
        "abstract": "The brain relies on communication between specialized cortical areas to accomplish complex cognitive tasks. To understand this ability of the brain, we need a deeper understanding of information transfer across cortical areas. There are two leading hypotheses for communication between cortical areas: 1) The communication through coherence (CTC) hypothesis posits that coherent oscillations between source and target populations of neurons are required for information propagation. 2) The information transmission via communication subspace (CS) hypothesis, recently introduced by Semedo et al., advances the idea that low-dimensional subspaces of population activity are responsible for communication across cortical areas. There is a clear divide between these two mechanisms and the CTC hypothesis, in particular, has been surrounded by considerable skepticism, with many authors reducing oscillations in the cortex to an epiphenomenon (viz., a by-product with no functional role). Here, we reconcile these two mechanisms of communication through a spectral decomposition of communication subspaces. In our main result, we predict that coherence influences the dimensionality of the CS: Dimensionality is lowest, and the prediction performance is highest, at frequencies that exhibit a peak in coherence between a source and target population (e.g., V1 to V2). We arrive at these results by developing an analytical theory of communication for circuits described by stochastic dynamical systems exhibiting fixed-point solutions. We compute directly (i.e., by a simulation-free method) the predictive performance for the mean-subtracted activity of a target population from that of a source population, and show that our predictions are in agreement with the experimental results by Semedo et al. Then via a band-pass filtered version of the covariance matrix, we arrive at our main result. Hence, our theory makes experimentally-testable predictions of how oscillations influence interareal communication while advancing a new hypothesis for the functional role of oscillatory activity in the brain.",
        "url": "https://www.world-wide.org/cosyne-23/coherence-influences-dimensionality-95bf0e8c"
    },
    "Context-dependent sensory adaptation in cortical area MT as a substrate of flexible decision-making": {
        "title": "Context-dependent sensory adaptation in cortical area MT as a substrate of flexible decision-making",
        "authors": "Kara McGaughey, Joshua Gold, Nathan Tardiff, Kyra Schapiro, Hannah Lefumat",
        "date": "Friday, 10 March 2023",
        "location": "II-114",
        "abstract": "Visual decisions typically require accumulation of uncertain sensory information to make inferences about the state of the world. This inference process is complicated by the fact that the state of the world can change, which often requires adjustments in how sensory information is accumulated. Previous work has modeled optimal inference in these changing environments [1-2]. One key feature of these models is a leakage of accumulated evidence, where the leak rate depends on environmental stability. For example, in more unstable environments, an increased leak rate helps remove pre-change evidence and thus attenuate beliefs that would hinder choice accuracy. This kind of context-dependent leak can describe human decision-making behavior, but its neural implementation remains unknown. We propose that this leak involves, at least in part, context-dependent changes in cortical sensory adaptation during evidence encoding. Specifically, we hypothesize that the adaptation dynamics of evidence encoding are modulated by the rate of change of recent sensory inputs, enabling the decision process to adjust to stimulus statistics. We trained two macaques on a random-dot motion task where we manipulated context stability via “change-points,” or abrupt switches in motion direction. We recorded activity of neurons in middle temporal area (MT), which contribute causally to decisions about motion direction [3]. Preliminary results suggest that monkeys were less sensitive to evidence as a function of viewing time in more unstable contexts (i.e., more change-points), which is consistent with a leak that depends on stimulus context. Moreover, neural responses in MT were more strongly adapted in an unstable versus stable context. This context-dependent adaptation both diminished the ability of single neurons to discriminate between motion directions and related to the monkey’s behavioral sensitivity to evidence during the task. Collectively, these results suggest that recent stimulus dynamics can induce changes in evidence encoding that contribute to flexible perceptual decisions.",
        "url": "https://www.world-wide.org/cosyne-23/context-dependent-sensory-adaptation-4aeed686"
    },
    "Path integration in insects as an optimized circuit": {
        "title": "Path integration in insects as an optimized circuit",
        "authors": "Pau Vilimelis Aceituno, Dominic Dall'Osto, Ioannis Pisokas",
        "date": "Friday, 10 March 2023",
        "location": "II-115",
        "abstract": "Insects demonstrate a remarkable ability to navigate the world -- foraging for food and returning to their nests over large distances. Simple neural circuits have been shown to underlie insect navigation behaviours, encoding the animal's head direction and velocity vector as a sinusoidal activity pattern\\cite{heinze2007maplike,lyuBuildingAllocentricTravelling2022}. We offer novel mathematical insights into the benefits of this sinusoidal encoding, suggesting that it might offer an evolutionary advantage in terms of noise resilience. Previous work has recognised that encoding vectors as sinusoidal population activity patterns enables vector addition by simple piecewise activity addition~\\cite{lyuBuildingAllocentricTravelling2022,pisokasHeadDirectionCircuit2020}. However, we show that other activity patterns also fulfil this property (Fig.~\\ref{fig:noise_resilience}), calling into question whether this is the only advantage of a sinusoidal activity pattern. In this work we use signal processing formalism to demonstrate that the sinusoid is the most noise-resilient activity shape that allows for stable path integration, given that it is coupled with a sinusoidal connectivity. We additionally show that the required sinusoidal connectivity will arise automatically in a network of neurons which have their weights updated with a Hebbian learning rule. This analytical result demonstrates that the weight matrix and the activity could naturally converge to sinusoidal shapes during development. By considering Oja's rule, a variant of Hebbian learning, we find that a sinusoidal connectivity pattern is stable -- indicating that a perturbation of the neural connectivity will be corrected by this learning rule. Our work shows how simple neural circuits can follow clear mathematical principles, and how tools from signal processing can offer novel interpretations of biological findings. Beyond neuroscience, robust path integration remains a key area of research in robotics. This work could therefore inspire novel biologically-inspired path integration approaches by roboticists or neuromorphic chip designers.",
        "url": "https://www.world-wide.org/cosyne-23/path-integration-insects-optimized-circuit-2e405788"
    },
    "Responses to inconsistent stimuli in pyramidal neurons: An open science dataset": {
        "title": "Responses to inconsistent stimuli in pyramidal neurons: An open science dataset",
        "authors": "Colleen J. Gillon, Jérôme A. Lecoq, Jason E. Pina, Timothy M. Henley, Yazan N. Billeh, Shiella Caldejon, Jed Perkins, Matthew T. Valley, Ali Williford, Yoshua Bengio, Timothy Lillicrap, Joel Zylberberg, Blake A. Richards",
        "date": "Friday, 10 March 2023",
        "location": "II-116",
        "abstract": "Pyramidal neurons have apical dendrites that are both physically and electrically segregated from their cell bodies. In sensory cortex, these apical dendrites receive primarily top-down signals from associative and motor regions, while the cell bodies and nearby dendrites of these same pyramidal neurons are mostly targeted by bottom-up or locally recurrent inputs from the sensory periphery. Due to these differences, a number of theories in computational neuroscience postulate a unique role for apical dendrites in shaping sensory processing and plasticity in the face of new or surprising stimuli. Despite this strong interest, technical challenges in data collection mean that there is very little data available on which these ideas can be tested. Here we present an openly available dataset that fills this gap and was collected through an expertly designed and operated data collection pipeline. This dataset contains high-quality two-photon calcium imaging from both the apical dendrites and the cell bodies of visual cortical pyramidal neurons in awake, behaving mice over multiple days as they are presented with consistent and inconsistent visual stimuli. Many cell bodies and dendrite segments could be tracked over days, enabling analyses of how their responses change over time. This dataset allows neuroscientists to explore the differences between apical and somatic processing and plasticity, and sets an example for supporting reproducibility and reusability in neuroscience.",
        "url": "https://www.world-wide.org/cosyne-23/responses-inconsistent-stimuli-pyramidal-fc9a1ebc"
    },
    "The thermal adjustment used in neuronal biophysical models is wrong: Here is how to fix it": {
        "title": "The thermal adjustment used in neuronal biophysical models is wrong: Here is how to fix it",
        "authors": "Bahram Pahlavan, Nicolas Buitrago, Fidel Santamaria",
        "date": "Friday, 10 March 2023",
        "location": "II-117",
        "abstract": "There is a substantial effort, and cost, invested towards biophysical modeling of brain networks. Practically all biophysical models of voltage-activated conductances use Hodgkin-Huxley (HH) mechanisms obtained at an experimental temperature and adjusted to a modeling temperature. To do so, all models use the temperature correction factor Q10, which is assumed fixed. By performing an analysis of published data of the reaction rates of sodium, potassium, and calcium membrane conductances, we demonstrate: 1) Q10 is indeed temperature dependent; 2) this relationship is quantitatively and qualitatively similar across conductances; and 3) there is a strong effect at low temperatures (< 15 °C). We show that Macro-Molecular Rate Theory (MMRT), originally developed to study enzyme-related reactions outside neuroscience, explains this temperature dependency. MMRT predicts the existence of optimal temperatures at which reaction rates start decreasing as temperature increases, a phenomenon that we also found in the published data sets and was previously ignored. We tested the consequences of using MMRT adjusted reaction rates in the HH model of the squid’s giant axon. The MMRT adjusted model reproduces the temperature dependence of the rising and falling times of the action potential. The model also reproduces these properties for squid species that live in different climates. In a second example, we compared spiking patterns of biophysical models based on human cortical neurons from the Allen Cell Types Database. The original models, calibrated at 34 °C, failed to generate realistic spikes at room temperature in more than half of the tested models, while the MMRT produces realistic spiking in all conditions. We propose that the optimal temperature could be a thermodynamical barrier to avoid over excitation in neurons. While this study is centered in membrane conductances, our results have important consequences for all biochemical reactions involved in neuronal signaling.",
        "url": "https://www.world-wide.org/cosyne-23/thermal-adjustment-used-neuronal-biophysical-1ae68d78"
    },
    "Sequential learning in recurrent neural networks create memory traces of learned tasks": {
        "title": "Sequential learning in recurrent neural networks create memory traces of learned tasks",
        "authors": "Joanna Chang, Claudia Clopath, Juan A. Gallego",
        "date": "Friday, 10 March 2023",
        "location": "II-118",
        "abstract": "Animals can learn and perform many behaviors without interference. However, it is unclear how changes in neural activity during learning avoid interference with activity underlying similar behaviors. Recently, Losey et al. (bioRxiv, 2022) identified a possible explanation by examining monkey motor cortical population activity under a brain-computer interface (BCI) paradigm where linear mappings controlled a computer cursor. The activity produced for a known mapping was altered after learning a new mapping in a way that made the activity more beneficial for this new mapping. That is, the activity retained a “memory trace” of the new mapping without compromising the performance for the already known mapping. Since these memory traces suggest a potential substrate for continual learning, we sought to understand how and when they arise. To probe the effects of different learning processes on the memory trace, we modeled motor cortical neural activity during the same BCI paradigm using a recurrent neural network. We replicated several experimental results by sequentially training the network on two mappings that required activity in the same low-dimensional subspace, or manifold, representing “within-manifold” perturbations. Intriguingly, we observed memory traces even when network activity was not specifically constrained to maintain both maps. Thus, memory traces may inherently arise from sequential learning. While the presence of these traces was consistent across different BCI maps, their magnitudes differed greatly. Initial changes in behavior imposed by a given mapping were a good predictor of the memory trace’s magnitude, but initial changes in network activity were not. This allowed us to characterize, for the first time, differences in learning between different BCI mappings that represent easily-learnable within-manifold perturbations. Overall, we provide a taxonomy of the neural and behavioral factors shaping continual learning, allowing us to examine potential underlying mechanisms and behavioral constraints in future work.",
        "url": "https://www.world-wide.org/cosyne-23/sequential-learning-recurrent-neural-3b5e9a37"
    },
    "Robust Sequence Recall in Asymmetric Modern Hopfield Networks": {
        "title": "Robust Sequence Recall in Asymmetric Modern Hopfield Networks",
        "authors": "Hamza Chaudhry, Dmitry Krotov, Cengiz Pehlevan",
        "date": "Friday, 10 March 2023",
        "location": "II-119",
        "abstract": "Sequential memory is an essential attribute of natural and artificial intelligence that enables agents to encode, store, and retrieve complex sequences of stimuli and actions. Biologically plausible models of sequential memory have been proposed where recurrent neural networks are trained with temporal asymmetric Hebbian (TAH) rules. However, these networks have limited capacity, defined by the maximum length of sequence they can reliably recall, due to overlaps between stored memories reducing the signal to noise ratio. Inspired by recent work in Modern Hopfield Networks (MHN), we expand the capacity of this model by introducing a polynomial nonlinearity to the interaction term. This enhances the separation of patterns. We derive theoretically the improved scaling law for the maximal length of the stored sequence of patterns and verify this result with numerical simulation. Furthermore, we show that our extended model can be implemented as a biologically plausible network with similarities to the cortico-basal ganglia-thalamo-cortical loop, responsible for selecting and generating complex motor sequences.",
        "url": "https://www.world-wide.org/cosyne-23/robust-sequence-recall-asymmetric-modern-1ccfb2f2"
    },
    "On the Context-Dependent Efficient Coding of Olfactory Spaces": {
        "title": "On the Context-Dependent Efficient Coding of Olfactory Spaces",
        "authors": "Gaia Tavoni",
        "date": "Friday, 10 March 2023",
        "location": "II-120",
        "abstract": "Sensory neural representations are modulated by a variety of contextual factors, such as multi-modal cues, stimulus history, novelty, behavioral utility, and internal states. Despite decades of attention in systems neuroscience, many questions persist regarding how sensory codes adapt to these different variables. Here, we study this problem in the olfactory system. We focus on a neural circuit (the bulb) where incoming odor inputs are integrated with extensive contextual feedback from areas of the brain involved in multi-sensory association, attention, memory, and decision- making. While most research in olfaction has examined the structure and function of this system through bottom-up modeling and experimental approaches, here we start from normative principles to derive a theory for context-enhanced efficient coding of olfactory spaces. Our theory is based on the information-theoretic premise that optimal codes strive to maximize the overall entropy (decodability) of neural representations while minimizing neural costs. A novel feature of our approach consists in incorporating feedback into this framework, which allows us to make a number of predictions on how optimal odor representations change with the statistics of olfactory and associated contextual spaces. These predictions will be tested in electrophysiology and behavioral experiments. We also show in a biophysical model that our normative solution can be implemented at the level of the neural circuit through synaptic plasticity. This is a striking result that reconnects our theoretical findings to biologically plausible processes, thus bridging normative and mechanistic levels of analysis. Our theory is generalizable to other sensory systems and establishes a conceptual foundation for studying sensory coding associated with behavior.",
        "url": "https://www.world-wide.org/cosyne-23/context-dependent-efficient-coding-6cdad1c2"
    },
    "Parallel synapses with transmission nonlinearities increase the neuronal classification capacity": {
        "title": "Parallel synapses with transmission nonlinearities increase the neuronal classification capacity",
        "authors": "Yuru Song & Marcus Benna",
        "date": "Friday, 10 March 2023",
        "location": "II-121",
        "abstract": "Recent experimental results have found that a cortical neuron typically has multiple synaptic contacts with a given postsynaptic neuron. Here, we refer to such synaptic connections with the same presynaptic axon and the same postsynaptic neuron as parallel synapses. Whether they provide a functional benefit is currently under investigation. To avoid functional redundancy, these parallel synapses must have different computational properties. To model this, we assume that the amount of neurotransmitter released by each synapse can be described by a sigmoidal transmission function of its presynaptic input. These transmission functions' size, slope, and threshold can be learned via gradient descent. We determine the classification capacity of a neuron with such nonlinear parallel synapses, defined as the maximum number of random patterns it can learn in a typical binary classification task. Given a small number of parallel synapses on each axon, this quantity exceeds the perceptron capacity of a neuron with only linear synaptic connections, which is twice the number of presynaptic axons. Furthermore, if the number of parallel synapses is unconstrained during training, the model neuron can effectively implement almost arbitrary aggregate transmission functions for each axon, as long as they are monotonically increasing. In this case, we show that the capacity achievable by our learning algorithm is even larger than with a number of parallel synapses that’s limited during the learning process. We also found that this capacity appears to grow somewhat faster than linearly with the number of presynaptic axons. Interestingly, however, the number of parallel synapses needed to implement the solutions resulting from successful learning in this model is typically still relatively small. Altogether, our study shows that multiple parallel and nonlinear synapses connecting each input axon to a postsynaptic neuron can enhance its capacity for learning and memory.",
        "url": "https://www.world-wide.org/cosyne-23/parallel-synapses-with-transmission-565167a2"
    },
    "A mechanistic model for the formation of globally consistent maps of space in complex environments": {
        "title": "A mechanistic model for the formation of globally consistent maps of space in complex environments",
        "authors": "Sugandha Sharma, Sarthak Chandra, Ila Fiete",
        "date": "Friday, 10 March 2023",
        "location": "II-122",
        "abstract": "When animals are placed in multi-compartment or complex environments, entorhinal grid cells exhibit fragmentation of their highly regular spatial tuning curves, with a disjoint grid map for each compartment. However, as the animal explores and increases familiarity with the environment’s geometric and topological structure, the grid maps gradually approach a single globally consistent periodic map [1,2]. Here we show that Hippocampal-MESH — a novel neocortical-hippocampal-entorhinal recurrent circuit model that we introduce in parallel submitted abstracts — can, with the addition of slow plasticity in the hippocampal-entorhinal synapses, reproduce experimental findings of fragmented grid maps evolving to locally and then globally consistent maps at different timescales. We consider environments with two chambers separated by a barrier, with distinct grid maps, then remove the barrier and model the dynamics of grid cell tuning in response to the merger of the two chambers into one. If there are landmarks signaling the removed boundary location, the learned discontinuity between the two maps initially leads to abrupt remapping when traversing across the removed boundary, with the original chambers' maps near the far walls of the space. Plasticity between the representations on both sides of the former boundary gradually leads, at intermediate times, to a smooth interpolation of the two maps. At longer timescales, the tendency to generate local consistency of grid maps cascades through the generated representations, driving shifts in the map which eventually evolve to a globally consistent grid map, with phases in between the original maps of the two environments before barrier removal. These results encapsulate key findings of entorhinal map plasticity, thereby providing the first neocortical-hippocampal-entorhinal model that captures grid map fragmentation at short timescales (as described in a parallel submitted abstract), interpolation at intermediate timescales and map merger at long timescales all enshrined within the same architecture.",
        "url": "https://www.world-wide.org/cosyne-23/mechanistic-model-formation-globally-1aa450be"
    },
    "A more realistic predictive coding model of the cortical hierarchy": {
        "title": "A more realistic predictive coding model of the cortical hierarchy",
        "authors": "Siavash Golkar, Tiberiu Tesileanu, Yanis Bahroun, Anirvan Sengupta, Dmitri Chklovskii",
        "date": "Friday, 10 March 2023",
        "location": "II-123",
        "abstract": "Predictive coding (PC) has emerged as an influential normative model of neural computation, with numerous extensions and applications. As such, much effort has been put into mapping PC faithfully onto the cortex, but there are issues that remain unresolved or controversial. In particular, current implementations often involve biologically unrealistic features such as separate value and error neurons and symmetric forward and backward weights across different brain regions. In this work, we show that the PC framework in the linear regime can be modified to map faithfully onto the cortical hierarchy in a manner compatible with empirical observations. By employing a disentangling-inspired constraint on hidden-layer neural activities, we derive an upper bound for the PC objective. Optimization of this upper bound leads to an algorithm that shows the same performance as the original objective and maps onto a biologically plausible network. The units of this network can be interpreted as multi-compartmental neurons with non-Hebbian learning rules, with a remarkable resemblance to recent experimental findings. In particular, one of the plasticity mechanisms derived from our objective is akin to recently observed plasticity mediated by the calcium plateau potential in pyramidal neurons. Our circuit does not explicitly compare the output with the desired target, but we demonstrate that in our model, the calcium plateau signal implicitly encodes the relevant error information. We verify our algorithm empirically on a number of datasets and show that it performs comparably to the unconstrained PC framework.",
        "url": "https://www.world-wide.org/cosyne-23/more-realistic-predictive-coding-model-64dd081f"
    },
    "A manifold of heterogeneous vigilance states across cortical areas": {
        "title": "A manifold of heterogeneous vigilance states across cortical areas",
        "authors": "Julia Wang, Sylvain Chauvette, Robert Kwapich, Igor Timofeev, Tatiana Engel",
        "date": "Friday, 10 March 2023",
        "location": "II-124",
        "abstract": "Vigilance states are conventionally divided into wake, slow-wave sleep (SWS) and rapid eye-movement (REM) sleep based on distinct patterns of neural activity and muscle tone. These states are traditionally thought to be global. However, there is growing evidence for a departure from a simple model of three basic states. Sleep and wake may be more continuous rather than discrete states. Short periods of wake-like activity in sleep and vice versa can occur regularly. This diversity of state expression is further complicated by evidence of local sleep across the brain. To account for the complexity and heterogeneity of vigilance states across the cortex, we turned to an unsupervised deep learning technique, a variational autoencoder (VAE), to discover a low-dimensional manifold on which the brain states evolve. We recorded local field potentials simultaneously on 14 channels across the cortex of mice during normal sleep-wake cycle. The manifold discovered by our unsupervised model from these data captured the three basic states of vigilance, but also revealed micro-states and transition dynamics. When applied to data from multiple electrodes across the cortex, our model uncovered heterogeneity of vigilance state expression across cortical areas, such as absence of REM in certain areas. We also discovered that micro-states can occur locally and characterized the spatiotemporal dynamics of global transitions between states, such as patterns of SWS to REM propagation from the visual cortex or persistence of slow rhythm in the frontal cortex in transition to wake. These results provide strong evidence of the non-global nature of brain states, refuting the accepted notion of global uniform states and adding to the growing literature of heterogeneous brain states.",
        "url": "https://www.world-wide.org/cosyne-23/manifold-heterogeneous-vigilance-states-0d0963d9"
    },
    "Assemblies and the k-Cap Process: The Effects of Locality on Neural Firing Dynamics": {
        "title": "Assemblies and the k-Cap Process: The Effects of Locality on Neural Firing Dynamics",
        "authors": "Mirabel Reid & Santosh S. Vempala",
        "date": "Friday, 10 March 2023",
        "location": "II-125",
        "abstract": "The $k$-cap (or $k$-winners-take-all) process is a simple model of firing activity and inhibition in the brain. The process models the formation of neural assemblies, a longstanding proposal for the representation of abstract concepts in the brain. It is applied to a directed graph as follows: in each iteration, a subset of $k$ vertices of the graph are identified as winners; the next round winners are the vertices that have the highest total degree from the current winners, with ties broken randomly. Previous theoretical analyses of neural assemblies model the connectome as a directed Erd\\\"{o}s-R\\'{e}nyi random graph, where each synaptic connection is equally likely. While a reasonable starting point, the model does not take into account {\\em locality} of synapses. Here we study directed geometric random graphs in any constant dimension, which allow the synapse probability to be a function of spatial locations of the endpoints or other neuronal features. In this setting, we study the the dynamics of firing neurons under inhibition, as modeled by the $k$-cap process. Our work represents the first rigorous analysis of assembly formation in such a more accurate representation of the connectome. The structure which emerges, both theoretically and in simulation, reflects properties of assemblies which have been noted experimentally but have not yet justified theoretically: our analysis reveals that within a small number of time steps ($\\polylog(k)$) (1) firing neurons lie in a small ball, and (2) within this ball, the subset of $k$ firing neurons are essentially random.",
        "url": "https://www.world-wide.org/cosyne-23/assemblies-k-cap-process-effects-locality-4a0a57bb"
    },
    "Decoding momentary gain variability from neuronal populations": {
        "title": "Decoding momentary gain variability from neuronal populations",
        "authors": "Corey M Ziemba, Zoe Boundy-Singer, Robbe Goris",
        "date": "Friday, 10 March 2023",
        "location": "II-126",
        "abstract": "Neural activity in visual cortex is well described by models composed of a deterministic tuning function, a stochastic gain, and a point process. Recent work has shown that in the responses of neurons in the visual cortex of nonhuman primates, variability in the gain is tuned to the statistics of the sensory input. This suggests that gain variability may reflect signal rather than noise. Some theories of neural coding suggest that perceptual uncertainty may be encoded in neural response variability, and that, specifically, gain variability appears well suited to inform downstream uncertainty estimates. However, this notion critically requires that gain variability can be instantaneously read-out in a neurally plausible manner, and previous proposals have required a decoder to have substantial knowledge of the functional organization of the decoded populations. Here, we simulated neural population activity and studied the performance of a heuristic decoder of gain variability, derived from the expected variance of mixture distributions. This decoder exclusively relies on operations of summation, squaring, and division, and requires no knowledge of the selectivity of the input population. With increasing population size, estimates of gain variability increasingly approximate ground truth, and for input populations larger than 100, the decoder’s performance was excellent. We found the decoder to perform robustly at short timescales, across different stimulus strengths, and with realistic levels of correlated spiking variability. Together, our findings show that cross-neuron gain variability can in principle be read-out instantaneously using neurally plausible operations. We conclude that the visual cortex may employ a coding strategy whereby stimulus identity and stimulus uncertainty are encoded independently from each other.",
        "url": "https://www.world-wide.org/cosyne-23/decoding-momentary-gain-variability-fedd5afb"
    },
    "If mitral cells are the answer, what is the question?": {
        "title": "If mitral cells are the answer, what is the question?",
        "authors": "Sina Tootoonian & Andreas Schaefer",
        "date": "Friday, 10 March 2023",
        "location": "II-127",
        "abstract": "Why does the olfactory bulb contain two projection neuron populations? Called mitral and tufted cells (MCs and TCs), both sample receptor input at glomeruli but lie in different bulb layers, project to different regions of piriform cortex and form parallel circuits wherein TCs interact mainly with the anterior olfactory nucleus (AON), and MCs with piriform cortex (PC) proper. Experiments have revealed that (1) MCs are primarily driven by TCs, perhaps why (2) MC responses come later in the sniff cycle than TCs; (3) MCs receive excitatory cortical feedback from the AON; and (4) MC responses are harder to decode for odour properties than TCs. We connect these observations and propose that parallel TC-AON and MC-PC circuits provide parallel explanations of glomerular input as caused by high dimensional latent odour features and implemented in AON/PC pyramidal activity. However, the more peripheral TC-AON circuit uses a simple prior to quickly sketch the olfactory environment, while the deeper MC-PC circuit uses a more complex prior to construct a more accurate explanation of the odour input. Steady-state MC/TC activity reflects the error between glomerular input and its explanations, so the better explanation by the MC-PC circuit yields lower activity, potentially explaining observation (4) above. The similarity of the two computations makes it natural to express MC drive in terms of TC activity, and doing so in circuitry readily reproduces observations (1-3). Thus we suggest MCs are the answer to how the olfactory system can explain glomerular inputs using a more complex prior than that of the TC-driven circuitry, while still using that drive to avoid unnecessary computation.",
        "url": "https://www.world-wide.org/cosyne-23/mitral-cells-answer-what-question-efc1ee0e"
    },
    "Uncertainty-robust goal embedding in the prefrontal cortex for flexibly stable learning": {
        "title": "Uncertainty-robust goal embedding in the prefrontal cortex for flexibly stable learning",
        "authors": "Yoondo Sung & Sang Wan Lee",
        "date": "Friday, 10 March 2023",
        "location": "II-128",
        "abstract": "Mounting evidence suggests that the prefrontal cortex encodes environmental uncertainty for value-based decision-making. However, how uncertainty influences goal-seeking at the neural level remains elusive. We used human fMRI data collected with a two-stage Markov decision task to investigate the neural embeddings of goal and uncertainty during reinforcement learning (RL). We found that the neural activity patterns of the lateral prefrontal cortex (LPFC) and orbitofrontal cortex (OFC) encode the immediate goals and the environmental uncertainty levels, compared with other brain areas involved in decision-making, including the hippocampus, primary visual cortex, and ventral striatum. We also found that the LPFC and OFC selectively represent uncertainty in specific goal-seeking conditions, suggesting that these brain regions use uncertainty information to guide goal-directed behavior. These results motivated us to examine whether and how the goal and uncertainty embedding in the PFC guides goal-directed learning. Our key findings are as follows: 1) LPFC shows mixed representations of specific goal x uncertainty (shattering dimensionality analysis), which explains behavioral flexibility. 2) Those neural representations of goal information are robust against uncertainty change (cross-condition generalization performance analysis), which explains behavioral stability. 3) Notably, both separability and robustness of goal representation predict optimal goal-seeking behavior. In summary, our study provides a detailed account of how goal and uncertainty embeddings in the LPFC guide flexible and stable RL.",
        "url": "https://www.world-wide.org/cosyne-23/uncertainty-robust-goal-embedding-prefrontal-2d8b7f73"
    },
    "Distinct roles of excitatory and inhibitory neurons in the macaque IT cortex in object recognition": {
        "title": "Distinct roles of excitatory and inhibitory neurons in the macaque IT cortex in object recognition",
        "authors": "Sachi Sanghavi & Kohitij Kar",
        "date": "Friday, 10 March 2023",
        "location": "II-129",
        "abstract": "Distributed neural population activity in the macaque inferior temporal (IT) cortex, which lies at the apex of the visual ventral stream hierarchy, is critical in supporting an array of object recognition behavior. Previous research, however, has been agnostic to the relevance of specific cell types, inhibitory vs. excitatory, in the formation of “behaviorally sufficient” IT population codes that can accurately predict primate object confusion patterns. Therefore, here, we first compared the strength of behavioral predictions of neural decoding (“readout”) models constructed from specific (putative) cell types in the IT cortex. We performed large-scale neural recordings while monkeys (n=3) fixated images (640) presented (100ms) in their central (8 deg) field of view. Monkeys (n=3) also performed binary object discrimination tasks (8 objects; 640 images; 28 binary tasks). We performed PCA (and spike shape) based spike sorting analysis to categorize the recorded neural signals into two groups: broad-spiking (125; putative excitatory) and narrow-spiking (37; putative inhibitory) neurons. We observed that decoding strategies (205 linking hypotheses tested) derived from excitatory neurons significantly outperform those produced by inhibitory neurons in overall accuracy and image-by-image match to monkey behavioral patterns. Given that current artificial neural network (ANN) models of the ventral stream (as documented in Brain-Score) explain ~50% of macaque IT neural variance and produce human-like accuracies in object recognition tasks, we compared their predictions of putative excitatory (Exc) vs. inhibitory (Inh) IT neurons. Interestingly, we observed that ANNs predict Exc neurons significantly better than Inh neurons (Exc-Inh = 10%; p<0.0001). Taken together, the correlative evidence for cell-type specificity in the linkage between IT population activity and object recognition behavior, along with the novel cell-type specific benchmarks (that disrupt the current Brain-Score ranking of the encoding models for macaque IT), provides valuable guidance for the next generation of more refined brain models.",
        "url": "https://www.world-wide.org/cosyne-23/distinct-roles-excitatory-inhibitory-fe6f3c15"
    },
    "Mice alternate between inference- and stimulus-bound strategies during probabilistic foraging": {
        "title": "Mice alternate between inference- and stimulus-bound strategies during probabilistic foraging",
        "authors": "Daniel Burnham, Zachary Mainen, Fanny Cazettes, Luca Mazzucato",
        "date": "Friday, 10 March 2023",
        "location": "II-130",
        "abstract": "Essential features of the world are often hidden and must be inferred by constructing internal models based on indirect evidence. During naturalistic foraging, animals must continually choose between trying to exploit a depleting food source at their current location and leaving to explore a new source at the expense of costly travel epochs. When is it best to leave the current site for another one? In a deterministic environment, the optimal strategy is to leave the current site when the immediate rate of reward drops below the average rate - a stimulus-bound strategy, assigning each action a value that is updated based on its immediate outcome. This strategy, however, is not optimal in a realistic foraging scenario, where rewards are encountered probabilistically and the optimal strategy is inference-bound, requiring the animal to infer the hidden structure of the world. Motivated by recent studies showing that mice alternate between discrete strategies during perceptual decision-making [1], here we tested the hypothesis that mice behavior during a probabilistic foraging task switches between inference- and stimulus-bound strategies within the same session. We developed a novel hidden Markov model with linear emissions (LM-HMM) to capture this switching dynamic and validated this model on ground truth data generated from a synthetic agent performing the task. When applied to mice engaged in the task, the LM-HMM revealed that mice switch between three strategies: a persistent inference-bound, an impulsive inference-bound, and a stimulus-bound strategy. Our results establish a new approach to modeling complex decision-making behavior involving accumulation of evidence and inference.",
        "url": "https://www.world-wide.org/cosyne-23/mice-alternate-between-inference--stimulus-bound-89936db2"
    },
    "Data-driven discovery of long timescale behavioral strategies during sensory evoked locomotion": {
        "title": "Data-driven discovery of long timescale behavioral strategies during sensory evoked locomotion",
        "authors": "Gautam Sridhar, Antonio Costa, Massimo Vergassola, Claire Wyart",
        "date": "Friday, 10 March 2023",
        "location": "II-131",
        "abstract": "Survival requires the brain to generate flexible and adaptive behavioral mechanisms across multiple timescales. To understand how short timescale behaviors are chained to generate long sequences, we leverage high throughput behavioral recordings of the larval zebrafish subjected to diverse sensory stimuli. Fish swim in short and discrete burst-like motions bouts. We construct a maximally predictive state space by stacking consecutive bouts, and then investigate the time evolution of state-space densities through transfer operators. Their spectral decomposition reveals two stereotyped long timescale behaviors that last tens to hundreds of seconds - a “Cruising” strategy dominated by forward locomotion and a “Roaming” strategy, where the animal repeats fast changes in orientation. These strategies are reliably found across arenas of different geometries. Surprisingly, visual or chemical stimuli do not yield novel strategies but drive the animal into either strategy. While appetitive stimuli during prey capture shift the behavior to cruising, aversive stimuli promote roaming. Our analysis reveals a simple dichotomy in the structure of motor strategies adopted by larval zebrafish to adjust navigation to external stimuli.",
        "url": "https://www.world-wide.org/cosyne-23/data-driven-discovery-long-timescale-1482464e"
    },
    "Decomposed linear dynamical systems for C. elegans functional connectivity": {
        "title": "Decomposed linear dynamical systems for C. elegans functional connectivity",
        "authors": "Eva Yezerets, Noga Mudrik, Yenho Chen, Christopher Rozell, Adam Charles",
        "date": "Friday, 10 March 2023",
        "location": "II-132",
        "abstract": "Recent work has indicated that functional connections between C. elegans neurons can be clustered by their role in behavior, i.e. forward vs. reverse crawling vs. turning (Linderman et al. 2019). Furthermore they show how data-driven dynamical systems, e.g., the recurrent switching linear dynamical systems (rSLDS), can be learned in an unsupervised way from whole-brain recordings (Kato et al. 2015). However, these approaches ascribe a discrete overall state to the system at each time point, potentially missing different dimensions of variability in the data. For example, such models cannot flexibly describe the continuous transitions that occur during behaviors and cannot capture persistent underlying states or gradual changes. Using decomposed linear dynamical systems (dLDS) models, it is possible to gain this additional insight into C. elegans circuit dynamics, with the benefit of linear dynamical systems’ intepretability based in sparse dynamics representations and the flexibility of continuously varying dynamics coefficients. We thus develop a dLDS model based on dictionary learning to investigate how motifs in dynamics coefficients reflect changes in behavior, e.g. from post-reversal turns to forward crawling. We show that not only does rSLDS output unrealistic periods of high oscillation between discrete behavioral state labels in all tested C. elegans examples, but that dLDS smoothly describes these time snippets in terms of the dynamics coefficients c, which can vary continuously instead of discretely switching on and off. As in Brennan et al. (2019), we see substantial inter-individual differences in the dynamics and the loading matrices between the latent states and the calcium imaging traces. Model validation on toy examples has also shown that dLDS models can flexibly model changes in speed and direction of the same subdynamic using the dynamics coefficients. Therefore, we conclude that dLDS can more robustly describe how circuits encode behavior.",
        "url": "https://www.world-wide.org/cosyne-23/decomposed-linear-dynamical-systems-d73c5bf0"
    },
    "An accessible hippocampal dataset for benchmarking models of cognitive mapping": {
        "title": "An accessible hippocampal dataset for benchmarking models of cognitive mapping",
        "authors": "Alexandra Keinath, Justin Quinn Lee, Mark Brandon",
        "date": "Friday, 10 March 2023",
        "location": "II-133",
        "abstract": "Recent empirical studies have revealed spatial tuning in traditionally non-spatial brain regions, as well as coding differences across species in traditionally spatial regions. These findings have in part motivated new models of cognitive mapping that make quantitative predictions at multiple levels of explanation. Taken together, these advances highlight a growing need to quantitatively compare spatial codes across brain regions, species, levels of explanation, and against computational models. To address this need, here we leverage a Representational Similarity Analysis framework to quantitatively compare the geometric determinants of the rodent hippocampal code to model predictions. We recorded large hippocampal populations via head-mounted miniscope imaging as mice repeatedly explored ten uniquely-shaped environments generated by opening and closing parts of a 3 x 3 grid. Traditional analyses replicated and extended several classic findings while also revealing previously unreported dynamics, such as stabilization of representational drift with experience and more heterogenous single-cell responses in more complex shapes. Critically, the grid-based design of this shapespace afforded the construction of a rich and reliable (noise ceiling: Kendall’s Tau ~0.7) representational matrix summarizing the similarity of the hippocampal code within and across environments – ideal for quantitative comparison with other assays via the RSA toolbox. We then compared this empirical matrix to those generated from several popular models of spatial coding, including a stable model, a dynamic boundary-tethered model, boundary vector cell (BVC) models, and boundary-based successor representation models. Of the models tested, only some parameterizations of BVC and boundary-based successor models approached the theoretical maximum fit. These results thus demonstrate that this dataset can serve as an empirical benchmark for tuning, evaluating, and comparing models of cognitive mapping. Moreover, these results motivate future work characterizing and comparing the geometric determinants of spatial representations across brain regions, species, and levels of explanation with this paradigm.",
        "url": "https://www.world-wide.org/cosyne-23/accessible-hippocampal-dataset-benchmarking-f6f7502e"
    },
    "Locomotion is associated with straighter neural trajectories for natural movies in mouse visual cortex": {
        "title": "Locomotion is associated with straighter neural trajectories for natural movies in mouse visual cortex",
        "authors": "Xingyu Zheng, Maxwell Ruckstuhl, Mohammad Yaghoubi",
        "date": "Friday, 10 March 2023",
        "location": "II-134",
        "abstract": "Sensory systems transform inputs from the environment into internal representations that capture aspects of the information useful in downstream computation and behavior. These representations are not rigid, static reflections of the external world but are dynamically modulated by fluctuating cortical and behavioral states. Locomotion, for example, is associated with facilitative changes in stimulus representation in the mouse visual cortex (Vinck et al 2015). How does sensory processing in the visual system support downstream behavior? \"Straightening\" hypotheses posit that an important role of the visual system is to straighten representations across time and state space, enabling prediction through simple linear extrapolation (Hénaff et al 2019) and discrimination between objects. Whether this phenomenon depends on behavioral states has not been tested. In this work, we leverage publicly available data and infer the neural trajectories of a natural movie stimulus in the 2D embedding of the stable representation similarity space in locomoting and stationary mice. We show that locomotion influences not only encoding quality but also the structure of the encoding of natural videos, resulting in straighter neural trajectories in multiple visual areas. This observed effect is not merely the result of increased response reliability; it also holds true for single-trial analysis. Moreover, we find that this effect is greater in the ventral visual area VISl than in the dorsal area VISal, supporting the two-stream hypothesis that attributes object manifold untangling to ventral processing (DiCarlo and Cox 2007). We demonstrate a powerful instance where an etiologically important behavior modulates the transformation of complex, naturalistic stimuli to yield a more accurate and predictive encoding.",
        "url": "https://www.world-wide.org/cosyne-23/locomotion-associated-with-straighter-a60a7d48"
    },
    "Deep Neural Imputation: A Framework for Recovering Incomplete Brain Recordings": {
        "title": "Deep Neural Imputation: A Framework for Recovering Incomplete Brain Recordings",
        "authors": "Sabera Talukder, Jennifer Sun, Matthew Leonard, Bing Brunton, Yisong Yue",
        "date": "Friday, 10 March 2023",
        "location": "II-135",
        "abstract": "We study the problem of time series imputation in multivariate neural recordings. Compared to standard time series imputation settings, new challenges for imputing neural recordings include the lack of adjacent timestamps for electrodes missing over days, and generalization across days and participants with different electrode configurations. Due to these challenges, the standard practice in neuroscience is to discard electrodes with missing data, even if only a part of the recording is corrupted, significantly reducing already difficult to obtain data. We propose Deep Neural Imputation (DNI), a framework to recover missing electrode recordings by learning across sessions, spatial locations, and participants. We first instantiate DNI with natural linear baselines, then develop encoder-decoder approaches based on masked electrode modeling. We evaluate DNI on 12 distinct multielectrode, naturalistic-behavior human neural datasets, even though canonically in neuroscience, only a few hours of a single participant's recordings would be treated as a distinct dataset to be analyzed separately. Finally, we demonstrate DNI's data imputation ability across many metrics and integrate DNI into an existing neural decoding, data analysis pipeline.",
        "url": "https://www.world-wide.org/cosyne-23/deep-neural-imputation-framework-recovering-c45e98ed"
    },
    "Zero-shot learning of decodable natural features from the retina using a U-net": {
        "title": "Zero-shot learning of decodable natural features from the retina using a U-net",
        "authors": "Siwei Wang, Benjamin Hoshal, Elizabeth de Laittre, Olivier Marre, Michael Berry, Stephanie Palmer",
        "date": "Friday, 10 March 2023",
        "location": "II-136",
        "abstract": "Much of sensory neuroscience focuses on presenting stimuli that are chosen by the experimenter because they are parametric and easy to sample and are thought to be behaviorally relevant to the organism. However, it is not generally known what the relevant features are in complex, natural scenes. This work focuses on using the retinal encoding of natural movies to determine the presumably behaviorally-relevant features that the brain represents. It is prohibitive to parameterize a natural movie and its respective retinal encoding fully. We use time within a natural movie as a proxy for the whole suite of features evolving across the scene. We then use a task-agnostic deep architecture, to model the retinal encoding process and characterize its representation of ‘time in the natural scene’ in a compressed latent space. In our end-to-end training, an encoder learns a compressed latent representation from a large population of salamander retinal ganglion cells responding to natural movies, while a decoder samples from this compressed latent space to generate the appropriate future movie frame. We show that the retina is responding to texture and motion features that change over time. To our surprise, we find that the retina has a generalizable encoding for time in the natural scene: The latent space learned from one movie can be used to do zero-shot decoding (without retraining) of time in an unseen, novel movie. This finding suggests that the retina leverages feature representations that are common across natural movies.",
        "url": "https://www.world-wide.org/cosyne-23/zero-shot-learning-decodable-natural-7a15af4b"
    },
    "A role for hippocampal CA1 in structural learning in mice": {
        "title": "A role for hippocampal CA1 in structural learning in mice",
        "authors": "Svenja Nierwetberg, Andrew Macaskill, David Orme",
        "date": "Friday, 10 March 2023",
        "location": "II-137",
        "abstract": "Learning relationships between cues in our environment enables us to recognise common underlying structures of events and is thought to form the basis of episodic memory. This type of learning - often called relational or structural learning - requires retaining the identity of a stimulus as well as its relation to other cues, for example its position in time or location in space. One area implicated in structural learning is the hippocampus. Specifically, neurons in the CA1 area of the hippocampus have been shown to represent variables essential for constructing a relational structure of the environment, such as cue configurations and their order in space and time. To investigate the neural mechanisms of structural learning, we designed an odour-based task that requires mice to learn not only about sets of odour cues, but about their relative order in time. Importantly, the task design allows for manipulation of the temporal structure and identity of cues separately, allowing dissociation of their neural mechanisms. Using this task, we found that mice can generalise learnt structures across large changes in both timing and identity of cues, suggesting flexible use of previously learnt relational structures. In line with a role for hippocampal circuitry, optogenetic inactivation of ventral CA1 (vCA1) markedly impaired task performance, but only when cues were separated across a delay longer than 10s. Together we show that mice can rapidly learn and flexibly perform an olfactory structural learning task, and that vCA1 plays an important role in connecting the individual cues of the structure across a delay. Using single-cell calcium imaging, our ongoing work is investigating how neurons in vCA1 represent unique features in this task, in particular the means by which odour information is maintained across the delay period. Together, the project aims to understand how vCA1 contributes to structural learning and its generalisation.",
        "url": "https://www.world-wide.org/cosyne-23/role-hippocampal-structural-learning-9e7a9c52"
    },
    "A thalamocortical circuit gates memory consolidation": {
        "title": "A thalamocortical circuit gates memory consolidation",
        "authors": "Andrew Toader, Josue Regalado, Yan Ran Li, Andrea Terceros, Nakul Yadav, Sloane Satow, Alessandra Bonito Oliva, Priya Rajasethupathy",
        "date": "Friday, 10 March 2023",
        "location": "II-138",
        "abstract": "The hippocampus is necessary for the initial encoding and recent storage of memories; under the standard model of systems consolidation, it is thought that the memory trace eventually reorganizes from the hippocampus to a distributed cortical network, with the anterior cingulate cortex playing a central role in remote memory retrieval. However, little is known about the mechanisms responsible for coordinating this process. Additionally, the intermediate memory representations in the brain and the circuits that might gate and select memories for permanent storage remain unknown. To facilitate the longitudinal tracking of memory circuits in the brain, we first developed a novel virtual reality-based behavioral task for mice that allowed us to probe memory recall over weeks-to-months. We used fiber photometry to record neural activity from multiple regions across the brain throughout consolidation and identified a unique and significant neural correlate of memory in anterior thalamus that emerged in training and persisted for weeks. Inhibition of the anteromedial thalamus (AM) to anterior cingulate cortex projections during training resulted in substantial memory consolidation deficits, whereas excitation of the same projection drove the consolidation of otherwise unconsolidated memories. To gain mechanistic understanding of the role of AM during consolidation, we developed a technique for simultaneously imaging three different, deep, brain regions with single-cell resolution in the behaving mouse for the first time. Briefly, this technique utilizes a microendoscopic fiber bundle to image through brain-implanted gradient-index lenses, projecting multiple imaging planes back onto a single objective. Using this technology, we uncovered that the anteromedial thalamus rapidly forms preferential tuning to consolidated memories, and establishes inter-regional correlations that are causally required for synchronizing and stabilizing cortical representations to achieve successful memory consolidation.",
        "url": "https://www.world-wide.org/cosyne-23/thalamocortical-circuit-gates-memory-456efab5"
    },
    "Automated neuron tracking inside moving and deforming animals using deep learning and targeted augmentation": {
        "title": "Automated neuron tracking inside moving and deforming animals using deep learning and targeted augmentation",
        "authors": "Mahsa Barzegar Keshteli, Vladislav Susoy, Core Francisco Park, Kseniia Korchagina, Ariane Delrocq, Aravinthan D. T. Samuel, Sahand Jamal Rahi",
        "date": "Friday, 10 March 2023",
        "location": "II-139",
        "abstract": "Advances in functional brain imaging now allow sustained rapid 3D visualization of large numbers of neurons inside behaving animals. To decode circuit activity, imaged neurons must be individually segmented and tracked. This is particularly challenging when the brain itself moves and deforms inside a flexible body. The field has lacked general methods for solving this problem effectively. To address this need, we developed a method based on a convolutional neural network (CNN) with specific enhancements which we apply to freely moving C. elegans. For a traditional CNN to track neurons across images of a brain with different postures, the CNN must be trained with ground truth (GT) annotations of similar postures. When these postures are diverse, an adequate number of GT annotations can be prohibitively large to generate manually. We introduce ‘targeted augmentation’, a method to automatically synthesize reliable annotations from a few manual annotations. Our method effectively learns the internal deformations of the brain. The learned deformations are used to synthesize annotations for new postures by deforming the manual annotations of similar postures in GT images. The technique is germane to 3D images, which are generally more difficult to analyze than 2D images. The synthetic annotations, which are added to diversify training datasets, drastically reduce manual annotation and proofreading. Our method is effective both when neurons are represented as individual points or as 3D volumes. We provide a GUI that incorporates targeted augmentation in an end-to-end pipeline, from manual GT annotation of a few images to final proofreading of all images. We apply the method to simultaneously measure activity in the second-layer interneurons in C. elegans: RIA, RIB, and RIM, including the RIA neurite. We find that these neurons show rich behaviors, including switching entrainment on and off dynamically when the animal is exposed to periodic odor pulses.",
        "url": "https://www.world-wide.org/cosyne-23/automated-neuron-tracking-inside-moving-6f75b072"
    },
    "Cerebellar involvement in supra-second time prediction": {
        "title": "Cerebellar involvement in supra-second time prediction",
        "authors": "Ellen Boven, Jasmine Pickford, Joseph Pemberton, Nadia Cerminara, Rui Ponte Costa, Richard Apps",
        "date": "Friday, 10 March 2023",
        "location": "II-140",
        "abstract": "Neural circuits process temporal intervals during adaptive behaviour. However, it is unclear how temporal information enables the brain to create causal maps and predict future events. While the cerebellum is well-known to support sub-second intervals for motor control, the ability to track environmental changes in the range of seconds to minutes is thought to be supported mostly by cerebral areas. We hypothesized that the cerebellum also contributes to behavioural control on a supra-second timescale by interacting with the neocortex through cerebro-cerebellar loops. Using a supra-second time estimation task and inhibitory chemogenetics we show that rats with cerebellar impairment underestimate time, suggesting that cerebellar contributions to time processing are not restricted to short sub-second intervals. Next, we trained a cerebro-cerebellar computational model on the same task. The model captures our behavioural findings while making predictions for how the cerebellum drives cerebral dynamics for successful time estimation. Taken together, our results suggest that the cerebellum supports adaptive behaviour over a wide range of temporal intervals.",
        "url": "https://www.world-wide.org/cosyne-23/cerebellar-involvement-supra-second-80e5df3f"
    },
    "Multi-object memory and prediction in the primate brain": {
        "title": "Multi-object memory and prediction in the primate brain",
        "authors": "Nicholas Watters, John Gabel, Joshua Tenenbaum, Mehrdad Jazayeri",
        "date": "Saturday, 11 March 2023",
        "location": "III-001",
        "abstract": "Primates excel at reasoning about physical scenes comprised of objects, flexibly generalizing to novel compositions of objects. Many cognitive theories attribute this capacity to structured representations in working memory called “object files” that encode object features in independent subspaces that can be readily retrieved and processed. However, these theories remain largely un-tested in the primate brain. We developed a task for non-human primates (NHPs) that requires remembering the positions and identities of multiple objects on a visual display. In some conditions the objects move under deterministic physics, requiring the subject to additionally track their kinematics. NHPs were able to perform this task and generalized to a variety of held-out conditions including (i) novel object identities, (ii) novel spatial configurations, and (iii) novel kinematics. Several brain regions in the frontal cortex have been implicated in the representation and processing of visual information in working memory, including the frontal eye fields (FEF) and dorsomedial frontal cortex (DMFC). Accordingly, we recorded simultaneously from large populations of single neurons in FEF and DMFC in two NHPs while they performed the task. To test different possible neural instantiations of the object-file theory, we formulated specific neural hypotheses, developed metrics to distinguish between them, validated those metrics in artificial networks, and applied those metrics to our neural data. We found that neural activity in both FEF and DMFC during working memory is consistent with an object file representation where the assignment of objects to files is determined by the spatial configuration of the objects in the visual field. Moreover, we found that neural activity is not consistent with a variety of alternative models. Our results reject some but not all models of multi-object representation in the brain.",
        "url": "https://www.world-wide.org/cosyne-23/multi-object-memory-prediction-primate-053197aa"
    },
    "Mouse visual cortex as a limited-resource system that self-learns a task-general representation": {
        "title": "Mouse visual cortex as a limited-resource system that self-learns a task-general representation",
        "authors": "Aran Nayebi, Nathan Kong, Chengxu Zhuang, Justin Gardner, Anthony Norcia, Daniel Yamins",
        "date": "Saturday, 11 March 2023",
        "location": "III-002",
        "abstract": "Studies of the mouse visual system have revealed a variety of visual brain areas in a roughly hierarchical arrangement, together with a multitude of behavioral capacities, ranging from stimulus-reward associations, to goal-directed navigation, and object-centric discriminations. However, an overall understanding of the mouse's visual cortex organization, and how this organization supports visual behaviors, remains unknown. Here, we take a computational approach to help address these questions, providing a high-fidelity quantitative model of mouse visual cortex. By analyzing factors contributing to model fidelity, we identified key principles underlying the organization of mouse visual cortex. Structurally, we find that comparatively low-resolution and shallow structure were both important for model correctness. Functionally, we find that models trained with task-agnostic, unsupervised objective functions, based on the concept of contrastive embeddings were substantially better than models trained with supervised objectives. Finally, we show that the unsupervised objective builds a general-purpose visual representation that enables the system to achieve better transfer on out-of-distribution visual, scene understanding and reward-based navigation tasks. Our results suggest that mouse visual cortex is a low-resolution, shallow network that makes best use of its limited resources to create a light-weight, general-purpose visual system -- in contrast to the deep, high-resolution, and more task-specific visual system of primates.",
        "url": "https://www.world-wide.org/cosyne-23/mouse-visual-cortex-limited-resource-713217db"
    },
    "Behavioral strategies and neural signatures underlying stay/switch decision-making in Drosophila": {
        "title": "Behavioral strategies and neural signatures underlying stay/switch decision-making in Drosophila",
        "authors": "Max Aragon & Mala Murthy",
        "date": "Saturday, 11 March 2023",
        "location": "III-003",
        "abstract": "In natural environments, animals must decide when to commit to one option, such as searching for food, or switching to another option, such as escaping a predator. How the nervous system mediates this “stay/switch” decision-making process during naturalistic behavior remains largely unknown. Here, we study stay/switch decisions in fruit flies by presenting optogenetically-driven heat pulses during courtship of a female. We developed a closed-loop stimulation paradigm in which the male receives optogenetic stimulation conditioned on his real-time song production. In response to the stimulus, flies made one of two decisions: a “switch” decision characterized by a U-turn response away from the female, or a “stay” decision characterized by little to no change in the male’s rotational speed or male-female distance and a continuation of courtship. Using SLEAP-based automated pose tracking, we quantified multiple dimensions of courtship, and constructed a generalized linear model to predict the male’s upcoming decision. We found that among multiple social features, female forward velocity (fFV) has the highest predictive ability (mean cross-validated accuracy = 62%, n=51 flies). The associated fFV filter shape suggests that the male fly integrates fFV information over hundreds of milliseconds, and that high forward velocity leads to “switch” decisions. We next considered how the brain implements stay/switch decisions by recording brain-wide neural activity with 2-photon microscopy in a male fly while he received optogenetic heat pulses during courtship with a virtual female. Our imaging data revealed that multiple brain regions contain decision-predictive activity, which is consistent with a distributed computation. Furthermore, we found that the alignment between neural populations that encode the optogenetic stimulus and the fly’s rotational speed strongly captures the animal’s turning behavior on a trial-to-trial basis. Together, these behavioral and neural results demonstrate both the strategies and neural computations underlying decision-making during naturalistic behaviors.",
        "url": "https://www.world-wide.org/cosyne-23/behavioral-strategies-neural-signatures-ce2a2407"
    },
    "A normative theory of aggression": {
        "title": "A normative theory of aggression",
        "authors": "Sergey Shuvaev, Evgeny Amelchenko, Grigori Enikolopov, Alexei Koulakov",
        "date": "Saturday, 11 March 2023",
        "location": "III-004",
        "abstract": "Aggression, leading to the formation of social hierarchy, has an evolutionary role in reducing conflict and facilitating the allocation of limited resources. Previous studies in mice have identified the regions involved in the neural circuitry of aggression, yet the mechanisms leading to the emergence of aggressive behavior remain to be poorly understood. To analyze such mechanisms, we used a mouse chronic social conflict paradigm where multiple aggressive phenotypes were formed, for which we obtained behavioral readouts (134 mice) and whole-brain snapshots of neuronal activity (c-Fos; 54 mice). We modeled the paradigm as a normal-form game to define the optimal actions for mice based on their strengths and used the Bayesian inference approach to model the animals’ beliefs about their strengths. Using our model and behavioral data, we formed and validated several hypotheses about the reward schedule, information availability, and evidence accumulation corresponding to aggressive behavior. Using our whole-brain c-Fos data, we found that the beliefs in our model are significantly correlated with neuronal activity in multiple distinct locations throughout the brain. Overall, our resulting model proposes a normative basis for the emergence of aggressive behavior and identifies the brain regions possibly involved in corresponding computations.",
        "url": "https://www.world-wide.org/cosyne-23/normative-theory-aggression-5698b9e3"
    },
    "A dynamic sequence of visual processing initiated by gaze shifts": {
        "title": "A dynamic sequence of visual processing initiated by gaze shifts",
        "authors": "Philip Parker, Dylan Martins, Emmalyn Leonard, Nathan Casey, Shelby Sharp, Elliott Abe, Matthew Smear, Jacob Yates, Jude Mitchell, Cristopher Niell",
        "date": "Saturday, 11 March 2023",
        "location": "III-005",
        "abstract": "Animals move their head and eyes as they explore and sample the visual environment. Previous studies have demonstrated neural correlates of head and eye movements in rodent primary visual cortex (V1), but the sources and computational roles of these signals are unclear. We addressed this by combining measurement of head and eye movements with high density neural recordings in freely moving mice. V1 neurons responded primarily to gaze shifts, where head movements are accompanied by saccadic eye movements, rather than to head movements where compensatory eye movements stabilize gaze. A variety of activity patterns immediately followed gaze shifts, including units with positive, biphasic, or negative responses, and together these responses formed a temporal sequence following the gaze shift. Gaze shift transients appeared to represent the temporal response to the rapid onset of new visual input as they were greatly diminished in the dark for the vast majority of units and were similar to those evoked by sequentially flashed stimuli in head-fixed conditions. Notably, neurons responded in a sequence that matches their spatial frequency (SF) preference, from low to high SF tuning, consistent with coarse-to-fine processing of the visual scene following each gaze shift. Recordings in foveal V1 of freely gazing head-fixed marmosets revealed a similar sequence of temporal response following a saccade, as well as the progression of SF tuning. Together, our results demonstrate that active vision in both mice and marmosets consists of a dynamic temporal sequence of neural activity associated with visual sampling.",
        "url": "https://www.world-wide.org/cosyne-23/dynamic-sequence-visual-processing-initiated-66f265f0"
    },
    "Abstract structure and generalization in sensorimotor networks configured with semantic-based instruction embeddings": {
        "title": "Abstract structure and generalization in sensorimotor networks configured with semantic-based instruction embeddings",
        "authors": "Reidar Riveland & Alex Pouget",
        "date": "Saturday, 11 March 2023",
        "location": "III-006",
        "abstract": "One of the most essential language skills that humans possess is the ability to correctly execute actions based on linguistic instructions. Here we use the latest advances in Natural Language Processing (NLP) to create a neural model of this cognitive ability. Models are trained on a set of 50 psychophysical tasks which require cognitive competencies well studied in the literature. Information about tasks demands is embedded using a transformer architecture pre-trained on an NLP task. Our best performing model, clipNet, uses 33M parameters pre-trained on embedding images and their corresponding text captions. The resultant instruction embeddings allowed the network to perform a previously unseen tasks at 85% correct on average based exclusively on information in the instruction (i.e. zero-shot learning). Surprisingly, gptNetXL, which is pre-trained on predicting the next word in a sentence and uses 1.5 billions parameter to embed instructions, exhibits a generalization performance of just 68%. In clipNet we found that language scaffolds sensorimotor representations such that activity for interrelated tasks share a common geometry with the semantic representations of instructions, allowing language to cue the proper composition of practiced skills in unseen settings. This structure was largely absent in gptNetXL. We show that this geometry is present throughout the language processing hierarchy for clipNet but not gptNetXL. Finally, we also demonstrate how clipNet can generate a linguistic description of a novel task it has identified using motor feedback, which can subsequently guide a partner model to perform the task. Our models offer experimentally testable predictions outlining how linguistic information must be represented in order to enable flexible cognition.",
        "url": "https://www.world-wide.org/cosyne-23/abstract-structure-generalization-sensorimotor-ff43e744"
    },
    "Experience drives the development of novel and reliable cortical representations from endogenously structured networks": {
        "title": "Experience drives the development of novel and reliable cortical representations from endogenously structured networks",
        "authors": "Sigrid Trägenap, David E. Whitney, David Fitzpatrick, Matthias Kaschube",
        "date": "Saturday, 11 March 2023",
        "location": "III-007",
        "abstract": "Cortical circuits embody remarkably reliable neural representations of sensory stimuli that are critical for perception and action. The fundamental structure of these network representations is thought to arise early in development prior to the onset of sensory experience. However, how these endogenously generated networks respond to the onset of sensory experience, and the extent to which they reorganize with experience remains unclear. Here we examine this ‘nature-nurture transform’ using chronic in vivo calcium imaging to probe the developmental emergence of the representation of orientation in visual cortex of the ferret, a species with a well-defined modular network of orientation-selective responses. At eye opening, visual stimulation of endogenous networks evokes robust modular patterns of cortical activity. However, these initial evoked activity patterns are strikingly different from those in experienced animals, exhibiting a high degree of variability both within and across trials that severely limits stimulus discriminability. In addition, visual experience is accompanied by a number of changes in the structure of the early evoked modular patterns including a reduction in dimensionality and a shift in the leading pattern dimensions indicating significant network reorganization. Moreover, these early evoked patterns and their changes are only loosely constrained by the endogenous network structure of spontaneous activity, and spontaneous activity itself reorganizes considerably to align with the novel evoked patterns. Based on a computational network model whose predictions closely match the biology, we propose that the initial evoked activity patterns reflect novel visual input that is only poorly aligned with the endogenous networks and that highly reliable visual representations emerge from a realignment of feedforward and recurrent networks that is optimal for these novel patterns of visually driven activity.",
        "url": "https://www.world-wide.org/cosyne-23/experience-drives-development-novel-18f7b589"
    },
    "Sensory predictions are embedded in cortical motor activity": {
        "title": "Sensory predictions are embedded in cortical motor activity",
        "authors": "Jonathan A Michaels, Mehrdad Kashefi, Jack Zheng, Olivier Codol, Jeff Weiler, Andrew Pruszynski",
        "date": "Saturday, 11 March 2023",
        "location": "III-008",
        "abstract": "While moving through the world, such as biking down a bumpy trail, our bodies encounter external forces that cannot be predicted by our own motor output. Delayed sensory feedback is generally too slow to allow accurate state estimation during responses to external forces, so the nervous system may solve this problem by using prior information to make rapid sensory predictions during feedback control. However, it is unknown how flexibly these priors can be set nor how neural activity underlies these fundamental abilities. To answer this, we designed a reaching task in which subjects (human or macaque) were visually cued about the probability distribution from which the direction of upcoming elbow perturbations would be drawn. On single trials and without extensive training humans integrate these probability cues into sensory priors that bias their muscle activity within 70 ms of perturbation onset, faster than the time it takes to initiate a ‘voluntary’ movement. In a similar experiment, a monkey showed the same ability to use sensory predictions during rapid feedback responses. High-density recordings revealed a clear signature of sensory priors in dorsal premotor (PMd) and motor cortex (M1), but not in somatosensory cortex (S1). To understand the computational basis of this signal, we trained artificial neural networks to control a realistic biomechanical model of the arm and perform similar tasks. The model readily learned to take advantage of sensory priors, showing remarkably similar behavior, muscle and neural activity to humans and monkeys. These combined results uncover a link between sensory predictions and movement – neural dimensions responsible for detecting the direction of a perturbation are biased by sensory priors during motor planning, allowing the brain to rapidly act when the perturbation is detected but before the perturbation direction is fully resolved.",
        "url": "https://www.world-wide.org/cosyne-23/sensory-predictions-embedded-cortical-3f7686ac"
    },
    "Explainable and consistent embeddings of high-dimensional recordings using auxiliary variables": {
        "title": "Explainable and consistent embeddings of high-dimensional recordings using auxiliary variables",
        "authors": "Steffen Schneider, Jin Hwa Lee, Rodrigo González Laiz, Célia Benquet, Mackenzie Mathis",
        "date": "Saturday, 11 March 2023",
        "location": "III-009",
        "abstract": "Mapping behavioral actions to neural activity is a fundamental goal of neuroscience. As our ability to record large neural and behavioral data increases, there is growing interest in modeling neural dynamics during adaptive behaviors to probe neural representations (Urai et al., 2022; Krakauer et al., 2017). In particular, neural latent embeddings can reveal underlying correlates of behavior, yet, we lack non-linear techniques that can explicitly and flexibly leverage joint behavior and neural data. Here, we fill this gap with a novel contrastive learning method that jointly uses time-series data and auxiliary labels in either a (supervised) hypothesis- or (self-supervised) discovery-driven manner to produce consistent, high-performance latent spaces. This method is particularly useful for joint modeling of neural and behavioral data. To benchmark our method, we first consider variants of a synthetic neural dataset that have different noise and firing characteristics. We find that our contrastive learning method outperforms generative models (pi-VAE; Zhou & Wei, 2020) and common tools for dimensionality reduction (tSNE and UMAP), in both the recovery of the ground truth latents and in the variance across runs (R² linear regression between true & recovered embeddings, mean/SEM: 92.0/0.02: ours, 84.1/0.62: pi-VAE, 80.9/0.04: UMAP, 78.8/0.30: tSNE). Critically, such non-linear methods should be identifiable, and explainable. Therefore, we sought to explore the explainablity of our method. Since most ``explainable AI'' methods lack theoretical guarantees, it is difficult to judge whether they have produced the correct result. Therefore, we design another synthetic dataset with a tractable ground-truth attribution map between neurons and auxiliary variables. Then, we leverage theoretical guarantees of our learning objective to estimate this attribution map from the Jacobian matrix of the learned feature encoder. Empirically, our model estimates the connections between neurons and auxiliary variables with high accuracy and outperforms a supervised learning baseline.",
        "url": "https://www.world-wide.org/cosyne-23/explainable-consistent-embeddings-high-dimensional-f33ac834"
    },
    "Representational Drift as a Result of Implicit Regularization": {
        "title": "Representational Drift as a Result of Implicit Regularization",
        "authors": "Aviv Ratzon, Dorgham Khatib, Mariell Sellevoll, Genela Morris, Dori Derdikman, Omri Barak",
        "date": "Saturday, 11 March 2023",
        "location": "III-010",
        "abstract": "Recent studies show that, even in constant environments, the tuning of single neurons to outside world variables gradually changes over time in a variety of brain regions [1, 2, 3, 4, 5]. This phenomenon, termed representational drift, has changed the way we think about the stability of memory and perception, but its driving forces and properties are still mostly unknown. We combine data analysis and modeling to show that implicit regularization can partially explain drift. We train an artificial neural network on a predictive coding task. We continue training in the presence of noise after good performance is obtained. We find that neurons become tuned to position early in training, but that the tuning slowly changes as training continues. Specifically, the network is spontaneously and slowly converging to a sparse solution, while maintaining a good representation of the environment. Recent results from the machine learning community offer an analytical explanation to this process [7]. Intuitively, when a learning system is perturbed by noise during learning it will aspire to be robust to that type of noise by slowly minimizing an implicit regularizer. We then analyze data from an experimental paradigm in which drift was demonstrated, and observe similar trends. Drift is relative to time spent in a specific context, it results in a slow sparsification process, and the overall decoding error remains constant. We conclude that learning of a given stimulus or environment is divided into three phases: a short transient of familiarity with the environment in which representations form, a long transient of implicit regularization in which representations change in a specific direction, and a steady state of null drift in which representations change randomly.",
        "url": "https://www.world-wide.org/cosyne-23/representational-drift-result-implicit-c0ea1717"
    },
    "Towards encoding models for auditory cortical implants": {
        "title": "Towards encoding models for auditory cortical implants",
        "authors": "Antonin Verdier & Brice Bathellier",
        "date": "Saturday, 11 March 2023",
        "location": "III-011",
        "abstract": "Exploring novel approaches to auditory rehabilitation, we aim to demonstrate, in mice, the efficiency of an optogenetic cortical implant. Several studies have shown that mice can use patterned optogenetic stimulations of the sensory cortex to drive their behaviour. It was however never tested if it is possible to provide a detailed representation of sensory inputs through such stimulation patterns. To explore this key question for cortical implant devices, we developed a novel sensory encoding model based on a convolutional autoencoder, which is able to temporally compress and denoise 500ms sounds into a 10x10 array of stimulation sites while preserving latent space continuity and detailed sound information. To minimize spatial crosstalk between stimulation sites, we actually limit the latent representations to the 10 largest activations and impose spatial sparseness constraints during model training. We could then demonstrate that mice can discriminate these activity patterns when applied onto their auditory cortex using a video-projector setup for mesoscopic patterned optogenetic stimulation. After mastery of the discrimination task, we presented in catch trials various new patterns from the model and observed that several mice elicit similar behavioural categorization responses across patterns. This demonstrates that the artificial patterns imposed to auditory cortex produce a robust representation structure that can be used to solve a task. These results indicate that constrained autoencoder model can be used for generating artificial auditory perception via an array of cortical stimulators. We aim to further benchmark these artificial perceptions against already acquired auditory discrimination performances of normally-hearing mice.",
        "url": "https://www.world-wide.org/cosyne-23/towards-encoding-models-auditory-cortical-ab8cae42"
    },
    "Dissection of inter-area interactions of motor circuits": {
        "title": "Dissection of inter-area interactions of motor circuits",
        "authors": "Enida Gjoni, Ram Dyuthi Sristi, Haixin Liu, Shahar Dror, Xinlei Lin, Keelin O'Neil, Oscar Arroyo, Sun Woo Hong, Sonja Blumenstock, Byung-kook Lim, Gal Mishne, Takaki Komiyama",
        "date": "Saturday, 11 March 2023",
        "location": "III-012",
        "abstract": "Motor behaviors arise from dynamic interactions of interconnected neural populations across distributed brain areas. The underlying principles of information flow remain largely unknown. Here, we investigate the functional roles of motor cortex and intralaminar thalamus in driving specific subpopulations of the striatum - the input nucleus of the basal ganglia - during movements. We recorded the activity of direct and indirect pathway medium spiny neurons (dMSNs and iMSNs) in the striatum as mice performed a skilled motor task, by in vivo two-photon calcium imaging through gradient refractive index (GRIN) lens. Furthermore, using monosynaptic pseudo-typed rabies virus we identified and imaged the activity of corticostriatal and thalamostriatal neurons that specifically project to dMSNs and iMSNs, through a glass window or a GRIN lens, respectively. MSNs showed a sustained population activity throughout movement duration that peaked at movement offset. In contrast, their cortical and thalamic inputs showed opposing activity dynamics, with corticostriatal activity concentrated around movement onset and offset and thalamostriatal activity engaged during movements. To examine activity differences among dMSNs and iMSNs and their inputs, we developed Trial Ensemble Attention network (TEA-net) – a recurrent neural network (RNN) with attention that leverages trial-to-trial variability –to predict the neuronal type based on their activity. This approach followed by clustering analysis identified quintessential activity patterns that were distinct between dMSNs and iMSNs and between cortical and thalamic neurons that specifically project onto them. The results provide insights into the mechanisms of integration of distinct long-range inputs carrying diverse information by MSN subpopulations.",
        "url": "https://www.world-wide.org/cosyne-23/dissection-inter-area-interactions-f18c327d"
    },
    "Inhibitory control of plasticity promotes stability and competitive learning in recurrent networks": {
        "title": "Inhibitory control of plasticity promotes stability and competitive learning in recurrent networks",
        "authors": "Patricia Rubisch & Matthias Hennig",
        "date": "Saturday, 11 March 2023",
        "location": "III-013",
        "abstract": "Current voltage-dependent plasticity models assume that any plastic event needs a postsynaptic action potential and use induction mechanisms that are insensitive to postsynaptic voltage fluctuations. However, experiments have demonstrated that inhibitory inputs can affect plasticity updates, likely through voltage-dependent effects. To address such findings, here we introduce the novel Voltage-Dependent Pathway model (VDP) where the induction variables track the membrane potential, increasing its sensitivity to fast fluctuations. We first confirm that this model produces spike-timing dependent plasticity (STDP) kernels. In addition, inhibitory inputs temporally close to plasticity-inducing events change the potentiation/depression ratio as reported experimentally, an effect that cannot be reproduced with previous models. This allows inhibition to control the direction of plasticity events. We next show that this has a stabilising effect in recurrent networks, and induced circuit-level competitive effects. In spontaneously active recurrent networks where both excitatory and inhibitory synapses are plastic, stronger inhibition due to increasing activity in the excitatory population slows weight growth, thus stabilising the population activity. Furthermore, a network receiving inputs from two or more afferent pathways that are correlated within each pathway, but not between them, will develop neurons selective to only one of the pathways. This effect, which simulates developmental processes such as eye-specific segregation, depends on competition through recurrent inhibition: a selective neuron will activate inhibitory feedback, which in turn causes depression of afferent synapses from the same pathway to other neurons. This work predicts that plasticity is sensitive to fast membrane potential fluctuations, and that this leads to competitive effects that do not rely on weight normalisation, but are instead driven by recurrent inhibition.",
        "url": "https://www.world-wide.org/cosyne-23/inhibitory-control-plasticity-promotes-fbff51aa"
    },
    "Cortically motivated recurrence enables visual task extrapolation": {
        "title": "Cortically motivated recurrence enables visual task extrapolation",
        "authors": "Vijay Veerabadran, Yuan Tang, Ritik Raina, Virginia de Sa",
        "date": "Saturday, 11 March 2023",
        "location": "III-014",
        "abstract": "Biological neural networks use an abundance of “recurrent” connections, yet state-of-the-art deep neural network based computer vision models are predominantly feedforward. Why does biological vision evolve to employ recurrence pervasively? In this paper, we aim to address this question from a machine learning and modeling framework highlighting a critical functional advantage of employing recurrent computations: we show that a recurrent network is naturally able to adapt its computational budget flexibly during inference and generalizes in a zero-shot manner within-task across difficulties. We contribute LocRNN, a recurrent neural network module that is designed based on a prior computational model of biological recurrent intracortical connections (Li, 1998). LocRNN learns highly accurate solutions to Mazes and PathFinder -- two challenging vision benchmarks inspired by prior psychophysics tasks to test DNNs' ability to integrate long-range spatial dependencies. LocRNN is able to flexibly use more recurrent iterations during inference to zero-shot generalize to more difficult instantiations of each task (compared to training difficulty level) without requiring extra training data, a potential functional advantage of recurrence that biological visual systems capitalize on. Our ablation study of LocRNN highlights the fundamental importance of interneurons, piecewise linear activation, and recurrent gating. Our work encourages further study of the role of recurrence as an important biological mechanism underlying domain generalization, task extrapolation, and the incorporation of biological insights to design DNNs.",
        "url": "https://www.world-wide.org/cosyne-23/cortically-motivated-recurrence-enables-fc767b25"
    },
    "A pre-cerebellar brainstem integrator implements self-location memory and enables positional homeostasis": {
        "title": "A pre-cerebellar brainstem integrator implements self-location memory and enables positional homeostasis",
        "authors": "En Yang, Maarten Zwart, Benjamin James, Mikail Rubinov, Ziqiang Wei, Sujatha Narayan, Nikita Vladimirov, Brett Mensh, James Fitzgerald, Misha Ahrens",
        "date": "Saturday, 11 March 2023",
        "location": "III-015",
        "abstract": "To track and control self-location, animals integrate their movements through space. Representations of self-location are observed in the mammalian hippocampal formation (1,2), but it is unknown if positional representations exist in more ancient brain regions, how they arise from integrated self-motion, and by what pathways they control locomotion. Here, in a head-fixed, fictive-swimming, virtual-reality preparation (3), we exposed larval zebrafish to a variety of involuntary displacements. They tracked these displacements and, many seconds later, moved toward their earlier location through corrective swimming (‘positional homeostasis’). This behavior is captured by a control system that integrates visual motion into a displacement estimate and combines this with instantaneous velocity to drive corrective swimming. Based on this control theoretic description, we screened the entire brain at cellular resolution for neural activity representing self-location. Whole-brain functional imaging revealed a network in the medulla (SLO-MO for Self Location encoding Medulla Oblongata neurons) that stores a memory of location and induces an error signal in the inferior olive to drive future corrective swimming. Activity of SLO-MO neurons integrates visual motion into a persistent signal, with individual neurons persisting for a variety of timescales. Ablating one functional class of SLO-MO cells, such as those encoding forward displacements, abolishes the memory capacity of the other functional class (such as neurons encoding backward displacements), suggesting recurrent connectivity implementing attractor dynamics. Ablating SLO-MO also abolishes displacement-memory behavior. Optogenetically manipulating SLO-MO cells evokes displacement-memory behavior as if memories are optically ‘implanted’. SLO-MO connects to the inferior olive, where it induces a long-lasting displacement error signal that is communicated to the cerebellum. Consistent with this multiregional circuit diagram, ablating inferior olive cells abolishes displacement corrections. These results reveal a multiregional hindbrain circuit in vertebrates that integrates self-motion and stores self-location to control locomotor behavior.",
        "url": "https://www.world-wide.org/cosyne-23/pre-cerebellar-brainstem-integrator-6975f550"
    },
    "A novel deep neural network models two streams of visual processing from retina to cortex": {
        "title": "A novel deep neural network models two streams of visual processing from retina to cortex",
        "authors": "Minkyu Choi, Kuan Han, Xiaokai Wang, Zhongming Liu",
        "date": "Saturday, 11 March 2023",
        "location": "III-016",
        "abstract": "Human vision uses two neural pathways, namely the ventral and dorsal streams. The two streams are structurally segregated from the eyes to the primary visual cortex and continue onto the ventral temporal cortex and the dorsal parietal cortex. The ventral stream supports visual recognition and the dorsal stream guides visual attention and eye movement. Although this two-stream organization is well supported by empirical evidence, there are currently no image-computable models substantiating neural computation along two segregated pathways similar to the ventral and dorsal streams in the human brain. To fill this gap, we have implemented a two-stream neural-network model with novel features inspired by the human brain and eyes. The model learns where to look through one stream (i.e., the “where” stream) and learns what is seen through the other (i.e., the “what” stream). The two streams sample visual input with different acuity, density, and coverage similar to visual sampling by magnocellular and parvocellular retinal ganglion cells. We demonstrate that this two-stream model can attend to salient objects, perform object recognition, and explain cortical responses in humans freely watching a 115-min movie. The “what” and “where” streams in the model can selectively predict the cortical responses in the ventral and dorsal streams, respectively. The model generates human-like visual attention and recognition and its internal computational process explains the structural and functional segregation of the ventral and dorsal streams in the human brain. Whereas existing neural-network models focus on visual recognition and encoding along the ventral stream, our model accounts for both the ventral and dorsal streams and connects retinal sampling to cortical processing as integral parts of the same system. This model takes computer vision one step closer to human vision and offers novel computational insights to visual processing in humans.",
        "url": "https://www.world-wide.org/cosyne-23/novel-deep-neural-network-models-streams-4e4fffd8"
    },
    "Initial conditions combine with sensory evidence to induce decision-related dynamics in PMd": {
        "title": "Initial conditions combine with sensory evidence to induce decision-related dynamics in PMd",
        "authors": "Pierre Boucher, Tian Wang, Laura Carceroni, Gary Kane, Krishna Shenoy, Chandramouli Chandrasekaran",
        "date": "Saturday, 11 March 2023",
        "location": "III-017",
        "abstract": "We employed a dynamical systems perspective to bridge decision-related neural activity and decision-making behavior, a fundamentally unresolved problem. The dynamical systems approach posits that neural dynamics (X) are parameterized by a state equation (dX/dt=F(X)+U) with varying initial conditions (x0) and that evolves in time by combining at each time step, recurrent activity (F) and inputs (U). We considered different dynamical systems that make predictions about whether 1) initial conditions substantially predict subsequent dynamics and reaction time (RT) and/or choice, and 2) whether inputs are combined with initial conditions to lead to differences in choice-related dynamics. We evaluated which of the various dynamical mechanisms best described neural population activity by investigating neural population dynamics in the dorsal premotor cortex (PMd) of monkeys performing a red-green RT checkerboard discrimination task. Prestimulus neural state, a proxy for the initial condition, predicted poststimulus neural trajectories and showed organized covariation with RT. Furthermore, faster RTs were associated with faster pre- and poststimulus dynamics as compared to slower RTs, with these effects observed within a stimulus difficulty. Poststimulus dynamics depended on both the sensory evidence and initial condition, with easier stimuli and “fast’’ initial conditions leading to the fastest choice-related dynamics whereas harder stimuli and “slow” initial conditions led to the slowest dynamics. Finally, changes in initial condition were related to the outcome of the previous trial, with slower pre- and poststimulus population dynamics and RTs on trials following an error as compared to trials following a correct response. Models with initial conditions that are random or biased towards one choice, or with sensory encoding delays are inconsistent with these findings. Instead, these results suggest that decision-related activity in PMd are most consistent with a dynamical system where inputs combine with outcome-sensitive initial conditions that covary with eventual RT to induce decision-related dynamics.",
        "url": "https://www.world-wide.org/cosyne-23/initial-conditions-combine-with-sensory-21170ed6"
    },
    "From recency to central tendency biases in working memory: a unifying network model": {
        "title": "From recency to central tendency biases in working memory: a unifying network model",
        "authors": "Vezha Boboeva, Alberto Pezzotta, Athena Akrami, Claudia Clopath",
        "date": "Saturday, 11 March 2023",
        "location": "III-018",
        "abstract": "The central tendency bias, or contraction bias, is a phenomenon where the judgment of the magnitude of items held in working memory (WM) is biased towards the average of past observations. It is assumed to be an optimal strategy by the brain, and commonly thought of an expression of the brain’s ability to learn the statistical structure of sensory inputs. On the other hand, recency biases such as serial dependence are also commonly observed, and are thought to reflect the content of WM. Recent results from an auditory delayed comparison task in rats, suggest that both biases may be more related than previously thought: when the posterior parietal cortex (PPC) was silenced, both short-term and contraction biases were reduced. Here, we show how a volatile WM content susceptible to shifting to the past sensory experience – producing short-term sensory history biases – naturally leads to contraction bias. Errors at individual trials are sampled from the full distribution of the stimuli, and are not due to a gradual shift of the memory towards the sensory distribution’s mean. Our results are consistent with a broad set of behavioural findings in humans and rodents. We make specific predictions on neuronal dynamics in the PPC and downstream working memory areas, as well as how contraction bias may be altered, upon manipulations of the sensory stimulus distribution, inter-trial and inter-stimulus delay intervals. We also contrast our model predictions for a variety of sensory stimulus distributions against the Bayesian optimal model.",
        "url": "https://www.world-wide.org/cosyne-23/from-recency-central-tendency-biases-ce03bd2c"
    },
    "Thalamic head-direction cells are organized irrespective of their inputs": {
        "title": "Thalamic head-direction cells are organized irrespective of their inputs",
        "authors": "Guillaume Viejo, Sofia Skromne Carrasco, Adrien Peyrache",
        "date": "Saturday, 11 March 2023",
        "location": "III-019",
        "abstract": "Continuous attractor networks support various cognitive functions yet the neuronal dynamics and circuits supporting these dynamics in vivo remain unclear. The HD circuit is a canonical example of such network and HD cells each fire for a specific direction of the animal’s head. In the anterodorsal nucleus of the thalamus (ADn), HD cells maintain their mutual coordination during sleep, when sensory inputs are virtually absent, supporting the view of an attractor-driven system. The rigid organization of HD cell activity in the ADN begs the question of the origin of these structured patterns. The upstream structure, the lateral mammillary nucleus (LMN), is a central component of the HD signal generator circuit, though of supporting the attractor properties of the network. We thus investigated the organization of LMN activity across brain states, and its relationship to ADn. To this end, we recorded ADN-LMN neuronal ensembles during exploration and sleep. Here we show that during non Rapid-Eye-Movement sleep (nREM), LMN-HD cells coordination was reduced while simultaneously recorded ADN neurons maintained the same level of mutual coherence. The decreased level of correlation in LMN resulted, at least in part, by a switch to hypersynchronous spiking activity in which neurons co-fired irrespective of their mutual preferred direction. Inter-spikes intervals (ISIs) during the transition to a preferred direction revealed a discrete activation of ADN neurons as opposed to a continuous activation of LMN neurons. Simulating a population of ADN neurons with a non-linear integration of LMN inputs was enough to replicate the enhanced coordinated activity in the ADN during nREM sleep. Our results suggest that the response property of ADN neurons is sufficient to generate attractor dynamics.",
        "url": "https://www.world-wide.org/cosyne-23/thalamic-head-direction-cells-organized-edc612fc"
    },
    "Harnessing the flexibility of neural networks to predict meaningful theoretical parameters in a multi-armed bandit task": {
        "title": "Harnessing the flexibility of neural networks to predict meaningful theoretical parameters in a multi-armed bandit task",
        "authors": "Yoav Ger, Eliya Nachmani, Lior Wolf, Nitzan Shahar",
        "date": "Saturday, 11 March 2023",
        "location": "III-020",
        "abstract": "Classical studies in reinforcement learning (RL) heavily rely on normative models of behavior, models that often stress interpretability over predictive capabilities. More recently, neural network models emerged as a descriptive modeling paradigm capable of high predictive power, however, with limited interpretation. To address these issues, we sought to augment the expressiveness of theoretically interpretable RL models with the high flexibility and predictive power of neural networks. Specifically, we introduce a novel framework whereby a neural network is trained to predict theoretically meaningful RL parameters from behavioral observations. We first simulated behavior from a large number of artificial RL agents performing a two-armed bandit task. We then trained a recurrent neural network, using the trial-by-trial artificial data to predict the agent’s hidden theoretical RL parameters from observed action-reward history. At test time, and without further optimization, we illustrate the network's successful recovery of unseen agents' RL parameters, even when their true RL parameters dynamically changed across task performance. We then applied our network to estimate non-stationary theoretical RL parameters of empirical data, where healthy and psychiatric individuals completed a similar two-armed bandit task. We found better performance in the action prediction of our network compared to two alternative methods of RL parameters estimation (non-stationary Bayesian particle filtering and stationary maximum-likelihood). We demonstrate the advantage of our modeling approach by describing high volatility in the parameters’ estimation of psychiatric individuals, a group known for unstable internal mental states. Finally, we discuss how our framework may facilitate future research where temporal changes in latent parameters can be correlated with meaningful high-temporal neural measures.",
        "url": "https://www.world-wide.org/cosyne-23/harnessing-flexibility-neural-networks-499c34b9"
    },
    "Traveling UP states in the post-subiculum reveal an anatomical gradient of intrinsic properties": {
        "title": "Traveling UP states in the post-subiculum reveal an anatomical gradient of intrinsic properties",
        "authors": "Dhruv Mehrotra, Daniel Levenstein, Adrian Duszkiewicz, Sam Booker, Angelika Kwiatkowska, Adrien Peyrache",
        "date": "Saturday, 11 March 2023",
        "location": "III-021",
        "abstract": "Cortical activity is characterized by state-specific dynamics arising from the interplay between connectivity, cellular diversity, and intrinsic properties. During non-Rapid Eye Movement (NREM) sleep, cortical population activity alternates between periods of neuronal firing (“UP” states) and neuronal silence (“DOWN” states). Patterns of neuronal activity at DOWN-to-UP (DU) transitions have functional relevance beyond sleep: they are related to sensory coding during wakefulness and support homeostatic processes and memory consolidation. Despite this functional importance, the factors that organize these spiking patterns remain unknown but mechanisms that rely on network connectivity or intrinsic excitability have been proposed. In order to elucidate the mechanisms that organize spontaneous activity, we recorded populations of neurons in the head-direction cortex (HDC, i.e., post-subiculum), where the behavioral correlates of most neurons are well accounted for. Neuronal tuning to HD was independent of anatomical position. However, while UP-DOWN (UD) transitions were synchronous along the dorsoventral (DV) axis, we observed sequential activation of neurons at DU transitions. To understand the mechanisms underlying these traveling waves at UP state onset, we built a computational model with a linear array of recurrently connected adapting units and compared the effects of different biophysical gradients. We found that, unlike gradients in local connectivity, excitability/input, and adaptive current, a gradient in rectifying current (Ih) was able to uniquely reproduce the experimental observations, and predict a yet-unobserved relationship between UP onset and post-DOWN rebound activity. Subsequent ex vivo intracellular recordings confirmed the predicted DV gradient of Ih in HDC. In conclusion, precisely organized spontaneous population activity patterns may be independent of circuit features and sensory coding but instead may only reflect intrinsic neuronal properties. Yet, the resulting traveling waves have the potential to anatomically segment computation in output structures like the medial entorhinal cortex (MEC) and indirectly, the hippocampus.",
        "url": "https://www.world-wide.org/cosyne-23/traveling-states-post-subiculum-reveal-de6e052f"
    },
    "Inter-animal transforms as a guide to model-brain comparison": {
        "title": "Inter-animal transforms as a guide to model-brain comparison",
        "authors": "Javier Sagastuy Brena, Aran Nayebi, Daniel Yamins, Imran Thobani, Rosa Cao",
        "date": "Saturday, 11 March 2023",
        "location": "III-022",
        "abstract": "To address the question of how to compare DNN model activations to brain data, we investigate what transforms best describe similarity in neural activity in the same brain area between conspecifics. We expect neural responses to be functionally highly similar within a species (since we expect findings to generalize across animals). What kind of transform will make such similarity most evident? That is, under what kind of transform are conspecifics’ neural responses highly similar to each other? Researchers often default to linear regression as a reasonable transform class for measuring neural response similarity. We propose an improved transform class that uses a generalized linear model (GLM) whose noise matches the approximately Poisson noise in the neural data, and whose non-linear link function is akin to the activation function of a biological neuron. Incorporating these biologically motivated constraints into the inter-animal transform class substantially improves similarity scores compared to linear regression. We then build a DNN model of mouse visual cortex that swaps out ReLU activations for a more biologically plausible softplus activation function, combined with Poisson noise, to produce activations that are more similar to neural responses. We find that a Poisson GLM whose link function exactly matches the model activation function again yields the highest similarity scores between different randomly seeded instances of our softplus models. This result gives mechanistic insight into why the best performing animal transform class has a non-linear link as well as Poisson noise structure. Moreover, we show that our Poisson GLM not only achieves higher similarity scores for the same layer between model instances, but also scores activations in model layers that are physically far apart as highly dissimilar to each other. Finally, we estimate the number of neurons and number of stimuli that would need to be recorded to accurately estimate inter-animal similarity.",
        "url": "https://www.world-wide.org/cosyne-23/inter-animal-transforms-guide-model-brain-2c73f23a"
    },
    "A spatiotemporal orchestration of balanced cholinergic effects regulates cortical activation": {
        "title": "A spatiotemporal orchestration of balanced cholinergic effects regulates cortical activation",
        "authors": "William Munoz, Daniel Levenstein, Kirk Manson, Richard Hardstone, Robin Tremblay, Chiung-Yin Chung, Robert Machold, György Buzsáki, Bernardo Rudy",
        "date": "Saturday, 11 March 2023",
        "location": "III-023",
        "abstract": "During arousal, attention, and memory formation, functionally relevant areas of the neocortex enter an “activated” state marked by desynchronized activity. Previous pharmacological experiments have shown that acetylcholine plays a fundamental role in cortical activation via muscarinic receptors. However, muscarinic receptors have diverse and sometimes contradictory effects in different cell types and cortical layers, and as a result the mechanism(s) of this activating influence remain unclear. Computational models have predicted that increasing excitatory neuron excitability (an M1-type muscarinic receptor-mediated effect) drives activation, while synaptic adaption (an M2-type mediated effect) sustains the activated state, but this is yet to be tested in an experimental preparation. To investigate how these diverse cellular actions mediate the effects on cortical activation, we generated cell-type- and receptor-type-specific conditional knockout mice for M1- and M2-type muscarinic receptors and used high-density silicon probes to record all layers of the somatosensory cortex while monitoring whisker movement and pupil size. We observed that cortical activation can vary in both the degree of activation, and its spatiotemporal spread through the cortical column. While large pupil dilations were coupled to whisking, acetylcholine release, and column-wide cortical activation, small dilations were associated only with localized activation in the infragranular layers. Remarkably, we found that ablating M2-type signaling on excitatory synapses facilitated the propagation of the activated state throughout the cortical column, instead of the activated state collapse predicted in silico. Ablating M1-type signaling on excitatory or dendritic-targeting inhibitory neurons attenuated or enhanced the magnitude of activation, respectively. These opposing effects of M1-type signaling shifted the baseline cortical state from an infragranular delta rhythm (which suppressed activation) to a supragranular one (which facilitated activation), suggesting that acetylcholine plays a push-pull, balancing role on cortical activation. In summary, we reveal an orchestration of cholinergic-mediated processes that promote and control the spatiotemporal dynamics of cortical activation.",
        "url": "https://www.world-wide.org/cosyne-23/spatiotemporal-orchestration-balanced-a859adf6"
    },
    "A neural model for hierarchical and counterfactual information processing inspired by human behavior": {
        "title": "A neural model for hierarchical and counterfactual information processing inspired by human behavior",
        "authors": "Cheng Tang, Mahdi Ramadan, Mehrdad Jazayeri",
        "date": "Saturday, 11 March 2023",
        "location": "III-024",
        "abstract": "The human brain finds solutions to complex multi-stage decision problems that are far more flexible than those learned by artificial systems. Cognitive theories attribute this flexibility to specific algorithms such as hierarchical information processing and counterfactual reasoning. We first developed a moderately challenging multi-stage decision-making task as a baseline paradigm for evaluating the computational basis of cognitive strategies in humans. Comparing behavior to inference models implementing various cognitive algorithms, we found that humans use a hierarchical strategy to solve the task sequentially, and when uncertain, revise their decisions by considering counterfactuals. Next, we used a set of experiments to reverse engineer the constraints from which these algorithms derive. Experiment 1 indicated that the hierarchical strategy results from a processing bottleneck associated with processing parallel streams of evidence. Experiment 2 indicated that compensatory counterfactuals are imperfect due to working memory (WM) limits. Experiment 3 indicated that humans are computationally rational in that the degree to which they rely on counterfactuals depends on how good their working memory is. To test the causal role of these computational constraints, we next asked whether imposing such constraints on self-supervised artificial recurrent neural network (RNN) models would lead to human-like solutions in RNNs. Confronted with the original maze task, RNNs established solutions identical to humans: sequential decisions followed by suboptimal counterfactuals. To test for causality, we developed a battery of RNNs in which we relaxed one or more of these constraints. Analysis of these lesioned models indicated that processing bottlenecks, working memory noise, and self-supervision were crucial constraints for the emergence of human-like strategies in RNNs. Finally, we found that distinct cognitive algorithms (e.g., hierarchical and counterfactual) are mere subdivisions in a strategy continuum including optimal, counterfactual, postdictive, and hierarchical, that the RNN may adopt depending on the level of noise in working memory.",
        "url": "https://www.world-wide.org/cosyne-23/neural-model-hierarchical-counterfactual-5d82b818"
    },
    "Machine learning of functional network and molecular mechanisms in autism spectrum disorder subtypes": {
        "title": "Machine learning of functional network and molecular mechanisms in autism spectrum disorder subtypes",
        "authors": "Amanda Buch, Petra Vertes, Jakob Seidlitz, So Hyun Kim, Logan Grosenick, Conor Liston",
        "date": "Saturday, 11 March 2023",
        "location": "III-025",
        "abstract": "Autism Spectrum Disorder (ASD) describes a diverse group of neurodevelopmental disorders encompassing a wide range of clinical impairments. The two core symptoms that define ASD are social communication impairments and restricted and repetitive behaviors, and there is a wide range of cognitive and language abilities. How distinct neurobiological substrates give rise to differing clinical symptoms in subsets of ASD patients is unknown. Using a large, publicly available neuroimaging dataset comprising resting state functional magnetic resonance imaging (rsfMRI) scans from N=299 subjects with ASD and N=907 neurotypical controls, we identified three latent dimensions of functional brain network connectivity that predict individual differences in ASD symptoms and behaviors. We show that patients with ASD can be grouped into distinct neurophysiological subgroups based on patterns of dysfunctional connectivity and clinical behaviors. In this cohort, functional connectivity features were extracted from rsfMRI data, regularized canonical correlation analysis was used to identify associations between connectivity features and behavioral data, and ASD subjects were clustered along these dimensions. Cross-validation analyses showed high stability in the brain-behavior dimensions, with replicable clusters in held-out data and a second out-of-sample dataset (National Database for Autism Research; NDAR). Next, we integrated neuroimaging data with gene expression data from the Allen Human Brain Atlas, and found that within each subgroup, ASD-related functional connectivity was explained by regional differences in the expression of distinct gene sets. We replicated these findings using the BrainSpan developmental atlas. These were enriched for transcriptionally-regulated and ASD-associated genes along with immune and synaptic signaling pathways. In sum, our results identify discrete ASD subgroups associated with specific ASD behaviors and neurophysiological signatures, and these different forms of ASD implicate distinct genetic mechanisms. The results of this study suggest a promising new approach for understanding the neurobiological substrates of ASD.",
        "url": "https://www.world-wide.org/cosyne-23/machine-learning-functional-network-a6b5fd25"
    },
    "Prioritizing experience replay when future goals are unknown": {
        "title": "Prioritizing experience replay when future goals are unknown",
        "authors": "Yotam Sagiv, Thomas Akam, Ilana Witten, Nathaniel Daw",
        "date": "Saturday, 11 March 2023",
        "location": "III-026",
        "abstract": "Although hippocampal place cells prominently \"replay\" nonlocal trajectories, the computational function of these events remains elusive. One hypothesis holds that replay plans routes to current goals by propagating information about rewards over space. An alternative view contends that replay learns and maintains routes more generally, separate from current goals or plans, to update a \"cognitive map\". The former view has been formalized in a reinforcement learning framework (Mattar and Daw, 2018), which predicts which trajectories should be replayed preferentially (\"prioritized\") to support planning. However, recent data appear to contradict this perspective, showing a disconnect between replayed destinations and current goals (Gillespie et al., 2021), and no similar theory exists to formalize the alternative perspective. Here, we generalize the Mattar account to address replay for a map of routes to many locations (a variant of the successor representation), when which of these contain reward is unknown or expected to change in the future. This leads to a prioritization strategy that evaluates candidate trajectories for replay according to a learned distribution over possible future goal locations, rather than with respect to the current reward function. We show that replay in an agent with this objective explains experimental results in which replay is systematically focused on different goals than the animal's current behavior.",
        "url": "https://www.world-wide.org/cosyne-23/prioritizing-experience-replay-when-a6a4f15e"
    },
    "Distinct brain states modulate visual cortical processing in mouse": {
        "title": "Distinct brain states modulate visual cortical processing in mouse",
        "authors": "Shailaja Akella, Peter Ledochowitsch, Joshua H. Siegle, Hannah Belski, Michael A. Buice, Severine Durand, Christof Koch, Shawn R. Olsen, Xiaoxuan Jia",
        "date": "Saturday, 11 March 2023",
        "location": "III-027",
        "abstract": "Variations in brain states and behavioral profiles clearly influence neuronal activity in the visual cortex[1,2]. However, the mechanisms behind these influences and their consequent effect on sensory encoding remain to be determined. Here, we address this issue by analyzing simultaneous recordings of spiking activity and local field potentials (LFPs) from visual and subcortical regions of (N = 25) awake mice viewing a naturalistic movie. Applying a hidden Markov model (HMM) to cortical LFPs, we consistently identified three stable states in each mouse: a high-frequency state (dominated by gamma oscillations), a low-frequency state (dominated by beta and theta oscillations), and an intermediate state. These brain states strongly reflected behavioral states and mouse arousal levels, where the high-frequency state was associated with the most pronounced movements and largest pupil sizes. To quantify the contribution of state modulations to neuronal activity, we designed an HMM-regression model where the inclusion of LFPs and state dependency improved the explained variance of population activity by ~14%. In individual neurons, we observed the highest shared variance during low arousal states, whereas higher arousal states induced more irregular firing. Consequently, population spiking demonstrated the highest mutual information (MI) with visual stimuli during high-arousal states, with MI gradually decreasing along the visual hierarchy. To investigate whether all areas are modulated equally by brain states, we evaluated state transition-triggered population responses in the visual cortical areas, lateral geniculate nucleus (LGN), and hippocampal regions. Across all areas, transitions towards a higher arousal state increased population activity and vice versa. Interestingly, the earliest changes in these neuronal responses preceded the state transitions and reflected a direction of state-dependent influences from the hippocampus, propagating down the visual hierarchy and towards LGN. Overall, we observed a top-down wave of state modulations of the visual cortices, which differentially affected visual processing based on arousal levels.",
        "url": "https://www.world-wide.org/cosyne-23/distinct-brain-states-modulate-visual-7cdd9c21"
    },
    "Reliable neural manifold decoding using low-distortion alignment of tangent spaces": {
        "title": "Reliable neural manifold decoding using low-distortion alignment of tangent spaces",
        "authors": "Johannes Nieuwenhuis, Dhruv Kohli, Alexander Cloninger, Gal Mishne, Devika Narain",
        "date": "Saturday, 11 March 2023",
        "location": "III-028",
        "abstract": "Since the advent of large-scale extracellular recordings in neuroscience and the widespread adoption of neural population frameworks, there is an increased need to achieve efficient decoding of task-relevant behavioral information from neural dynamics. The most prevalent methods to uncover task-related topologies in population dynamics, often approximated as neural manifolds, are linear dimensionality reduction methods such as principal component analysis (PCA). These techniques, however, find large-variance subspaces within which to embed neural manifolds and such embeddings do not necessarily provide the most informative means to decode behavioral metrics. On the other hand, nonlinear manifold learning techniques enable direct access to manifold geodesics, which may improve behavioral metric decoding or provide new analysis perspectives. Many manifold learning techniques, unfortunately, produce highly-distorted embeddings, which severely curtails their effectiveness for neuroscience applications. Optimization of these techniques for neural data presents its own challenges since neural data are often noisy, sparse, and nonhomogenous. To address this, we leverage recurrent neural network models (RNN), which can reliably replicate neural dynamics underlying several behaviors. We use RNNs to construct and control task-based manifolds with known dynamics, intrinsic dimensions, noise, sparsity, and density. Using these as a testbed, we present a manifold learning technique, Riemannian Alignment of Tangent Spaces (RATS), which efficiently constructs and aligns local views to obtain a global embedding. We demonstrate that RATS yields the lowest distortion embeddings when compared to several manifold learning techniques. This leads to improved decoding of behavioral metrics from noisy and sparse task-relevant manifolds underlying two sensorimotor tasks. Methods like RATS could help better decipher the elusive links between neural population dynamics and behavior, an issue that remains central to systems neuroscience.",
        "url": "https://www.world-wide.org/cosyne-23/reliable-neural-manifold-decoding-using-4829f207"
    },
    "Clustering Inductive Biases with Unrolled Networks": {
        "title": "Clustering Inductive Biases with Unrolled Networks",
        "authors": "Jonathan Huml, Abiy Tasissa, Demba Ba",
        "date": "Saturday, 11 March 2023",
        "location": "III-029",
        "abstract": "The classical sparse coding (SC) model represents visual stimuli as a convex combination of a handful of learned basis functions that are Gabor-like when trained on natural image data. However, the Gabor-like filters learned by classical sparse coding far overpredict well-tuned simple cell receptive field profiles observed empirically. While neurons fire sparsely, neuronal populations are also organized in physical space by their sensitivity to certain features. In V1, this organization is a smooth progression of orientations along the cortical sheet. A number of subsequent models have either discarded the sparse dictionary learning framework entirely or whose updates have yet to take advantage of the surge in unrolled, neural dictionary learning architectures. A key missing theme of these updates is a stronger notion of \\emph{structured sparsity}. We propose an autoencoder architecture (WLSC) whose latent representations are implicitly, locally organized for spectral clustering through a Laplacian quadratic form of a bipartite graph, which generates a diverse set of artificial receptive fields that match primate data in V1 as faithfully as recent contrastive frameworks like Local Low Dimensionality, or LLD \\citep{lld} that discard sparse dictionary learning. By unifying sparse and smooth coding in models of the early visual cortex through our autoencoder, we also show that our regularization can be interpreted as early-stage specialization of receptive fields to certain classes of stimuli; that is, we induce a weak clustering bias for later stages of cortex where functional and spatial segregation (i.e. topography) are known to occur. The results show an imperative for \\emph{spatial regularization} of both the receptive fields and firing rates to begin to describe feature disentanglement in V1 and beyond.",
        "url": "https://www.world-wide.org/cosyne-23/clustering-inductive-biases-with-unrolled-9dc555fa"
    },
    "Visuomotor Association Orthogonalizes Visual Cortical Population Codes": {
        "title": "Visuomotor Association Orthogonalizes Visual Cortical Population Codes",
        "authors": "Samuel Failor, Matteo Carandini, Kenneth Harris",
        "date": "Saturday, 11 March 2023",
        "location": "III-030",
        "abstract": "Stimuli trigger a pattern of activity across neurons in cortex, whose firing rates define a stimulus's representation in a high-dimensional vector space. Learning a visuomotor task can affect the responses of visual cortical neurons, but how and why training modifies population-level representations is unclear. One hypothesis is that representational plasticity in visual cortex facilitates visuomotor associations by downstream motor systems. Learning systems exhibit \"inductive biases\", meaning they form some stimulus-motor associations more easily than others. An animal's inductive biases presumably reflect its neuronal representations; its ability to form distinct motor associations for different stimuli depends on the representational similarity of the stimuli. Thus, the plasticity of sensory cortical representations may change inductive bias: for an animal to make different associations to two stimuli, the cortical representations of the stimuli must differentiate, such as if the evoked firing vectors were orthogonalized. A second hypothesis is that task training increases the fidelity of stimulus coding in sensory cortex, which improves decoding accuracy by downstream regions. However, this hypothesis presupposes that the population code in naive cortex suffers from low fidelity, which recent recordings of large cortical populations have questioned. We used two-photon calcium imaging to study how the tuning of V1 populations changes after mice learn to associate opposing actions with differently oriented gratings. Training did not improve the fidelity of stimulus coding, as it was already perfect in naive animals thanks to a subpopulation of highly reliable neurons. Instead, training caused the population's responses to motor-associated stimuli to become more orthogonal. The basis of this training-evoked orthogonalization was the sparsening of stimulus representations, an effect which could be summarized by a simple nonlinear transformation of naive neuronal firing rates and whose convexity was largest for motor-associated stimuli.",
        "url": "https://www.world-wide.org/cosyne-23/visuomotor-association-orthogonalizes-b29e68ce"
    },
    "Individualized representation learning of resting-state fMRI": {
        "title": "Individualized representation learning of resting-state fMRI",
        "authors": "Kuan Han, Minkyu Choi, Xiaokai Wang, Zhongming Liu",
        "date": "Saturday, 11 March 2023",
        "location": "III-031",
        "abstract": "Modest success has been made in using resting state fMRI (rs-fMRI) to predict individualized behaviors. Here, we describe a scalable and modular system for individualized representation learning of rs-fMRI. The system includes a “deep” base with “shallow” adds-on. The “deep” base is trained through multiple stages of self-supervised learning with unlabeled rs-fMRI. After the base is trained and fixed, the “shallow” adds-on are trained with supervised learning for behavior prediction. The base includes a variational auto-encoder (VAE) for unsupervised learning of spatial representations, a Bi-directional Encoder Representations from Transformer (BERT) for self-supervised learning of temporal dynamics, and a subspace learning of individualized representations. In each module, an encoder is paired with a decoder to ensure reversible transformation from the brain to the feature space and vice versa. The add-on uses a multilayer perceptron (MLP) to predict behavioral scores with individualized representation extracted from the base model. We demonstrate that this system can predict individualized scores on cognition, significantly outperforming the state-of-the-art connectome-based predictive modeling method. The system also uncovers the brain networks underlying individual variations of cognitive phenotypes.",
        "url": "https://www.world-wide.org/cosyne-23/individualized-representation-learning-ca2574bc"
    },
    "A population code for spatial representation in the larval zebrafish telencephalon": {
        "title": "A population code for spatial representation in the larval zebrafish telencephalon",
        "authors": "Chuyu Yang, Lorenz Mammen, Byoungsoo Kim, Drew Robson, Jennifer Li",
        "date": "Saturday, 11 March 2023",
        "location": "III-032",
        "abstract": "The vertebrate telencephalon is the site of complex cognitive processes such as spatial cognition. The larval zebrafish telencephalon is a compact circuit of ~10,000 neurons that nevertheless contains homologous structures to the mammalian basal ganglia and limbic system (e.g. hippocampus and amygdala). However, despite long-standing evidence that spatial navigation and learning in adult fish requires an intact telencephalon, cells believed to underlie spatial cognition in mammals (e.g. place and grid cells) have yet to be established in any fish species. Using a tracking microscope to image brain-wide activity at cellular resolution in freely swimming larval zebrafish, we can compute the spatial specificity of every cell in the zebrafish brain. Strikingly, in every animal, cells with the highest spatial specificity are enriched in the zebrafish telencephalon. These cells form a population code of space, from which we can decode the animal’s spatial location across time. In a novel environment, the activity of these place-encoding cells undergoes remapping. In a constant environment, the activity manifold of place-encoding cells gradually untangles across time. Given the compact nature of the zebrafish telencephalon, this reduced model system is uniquely positioned for building a complete mechanistic model of spatial cognition.",
        "url": "https://www.world-wide.org/cosyne-23/population-code-spatial-representation-7ccc1139"
    },
    "A Hopf-like bifurcation produces depolarization block that expands the peripheral encoding of odors": {
        "title": "A Hopf-like bifurcation produces depolarization block that expands the peripheral encoding of odors",
        "authors": "Philip Wong, David Tadres, Thuc To, Jeff Moehlis, Matthieu Louis",
        "date": "Saturday, 11 March 2023",
        "location": "III-033",
        "abstract": "Animals identify odors based on the combinatorial activation of olfactory sensory neurons having distinct chemical receptive fields. However, as the dose response of any olfactory sensory neuron is believed to follow a sigmoidal function that grows monotonically until it reaches a plateau, the subset of olfactory sensory neurons activated by an odor is expected to scale up with the odor concentration, undercutting the efficiency of combinatorial coding. Here we show that olfactory sensory neurons can in fact undergo a silent state upon strong and prolonged excitation called depolarization block, as part of their normal physiological function at ethologically-relevant odor concentrations. This silencing typically occurs at odor concentrations three orders of magnitude above the detection threshold of the olfactory sensory neuron. Using a data-driven model of the olfactory transduction cascade paired with a conductance-based spike generation model, we present a plausible biophysical mechanism that explains the emergence of depolarization block as a dynamical Hopf-like bifurcation. Quantitative predictions related to the history dependence and timescale of depolarization block are validated experimentally, allowing us to predict and simulate the activity of olfactory sensory neurons during larval navigation in odor gradients. We find that the same odor can induce depolarization block in distinct types of olfactory sensory neurons according to a concentration sequence matching their relative sensitivities to the odor, which fractionates the odor concentration space into domains corresponding to different subsets of active olfactory sensory neurons. We argue that depolarization block might facilitate perceptual recognition and discrimination over a large odor concentration range by maintaining sparsity in neural representations. While the role of depolarization block has been largely overlooked in chemosensory systems, our results suggest that this phenomenon creates a new dimension that expands the coding capacity of the peripheral encoding of odors.",
        "url": "https://www.world-wide.org/cosyne-23/hopf-like-bifurcation-produces-depolarization-b16753cd"
    },
    "A cortical microcircuit for reinforcement prediction error": {
        "title": "A cortical microcircuit for reinforcement prediction error",
        "authors": "Quentin Chevy, Rui Ponte Costa, Zoltan Szadai, Rozsa Balazs, Adam Kepecs",
        "date": "Saturday, 11 March 2023",
        "location": "III-034",
        "abstract": "Although distinct cortical regions specialize in different functions, they also benefit from receiving global reinforcement feedback to tune local processing. When and how those reinforcement signals shape cortical computations remains however largely unknown. Here, we present experimental evidence showing that acetylcholine inputs throughout the cortex form the backbone for a global signal, that presents the main characteristic of an unsigned reinforcement prediction error computation : modulation of the reinforcement response by expectation and coding of predictive cues. We show that this global signal is then integrated with local information by VIP interneurons, a specific GABAergic cell type that promotes plasticity through disinhibition, and that is known to respond to primary reinforcers across cortex. Thanks to a neural circuit involving local somatostatin (SST) interneurons, local sensory inputs indeed appear to null out the predictive cue coding transmitted by the cholinergic system to the VIP interneurons. To test the computational functions of this cortical circuit motif involving local VIP and SST inhibitory neurons and global acetylcholine, we designed a simple cortex-inspired reinforcement learning model. When we add disinhibitory VIP interneurons as a local relay for global reinforcement, our model performance improves due to an adaptable learning rate as well as protection against forgetting. Overall, our results provide new experimental and theoretical evidence for a microcircuit implementation of adaptive reinforcement learning in the cortex.",
        "url": "https://www.world-wide.org/cosyne-23/cortical-microcircuit-reinforcement-01778f0d"
    },
    "Phase remembers: trained RNNs develop phase-locked limit cycles in a working memory task": {
        "title": "Phase remembers: trained RNNs develop phase-locked limit cycles in a working memory task",
        "authors": "Matthijs Pals, Jakob Macke, Omri Barak",
        "date": "Saturday, 11 March 2023",
        "location": "III-035",
        "abstract": "Neural oscillations are ubiquitously observed in many brain areas. One proposed functional role of these oscillations is that they serve as an internal clock, or ‘frame of reference’ relative to which information can be encoded. In line with this hypothesis, there have been many empirical observations of this phase code in the brain. What are the latent dynamics and circuits that support phase coding with neural oscillations? Here, we propose a new computational hypothesis which is derived from analyzing trained recurrent neural networks (RNNs). We train RNNs on a working memory task, while also giving them access to a reference oscillation (either a pure sine wave or rat CA1 local field potentials). The task is to produce an oscillation such that its phase maintains the identity of transient stimuli. Although this task could be solved with static attractors, we find networks converging to oscillatory dynamics that persist in the absence of oscillatory input. Reverse engineering these trained network reveals bistability: in particular, each phase-coded memory corresponds to a separate limit cycle attractor in a toroidal manifold. We characterise the nonlinear dependence of the stability of the attractor dynamics on reference oscillation amplitude and frequency, properties that can be experimentally observed. To understand the computations underlying stable phase-coding, we show that trained networks converge to dynamics that can be described as two phase coupled oscillators. Using this insight, we condense our trained networks to a reduced model consisting of two functional modules: one that generates an oscillation and one that implements a coupling function between the internal oscillation and external reference. We show how incoming stimuli transiently modify this coupling function. In summary, by reverse engineering the dynamics and connectivity of trained RNNs, we propose a novel mechanism by which neural networks can harness reference oscillations for working memory.",
        "url": "https://www.world-wide.org/cosyne-23/phase-remembers-trained-rnns-develop-4211e85e"
    },
    "Only two types of attractors support representation of continuous variables, and learning over long time-spans": {
        "title": "Only two types of attractors support representation of continuous variables, and learning over long time-spans",
        "authors": "Piotr Sokol & Memming Park",
        "date": "Saturday, 11 March 2023",
        "location": "III-036",
        "abstract": "Attractor dynamics are essential components of neural computation— they have given rise to elegant, interpretable models of population coding and working memory. Frequently, attractors are classified based on whether their invariant manifolds can represent discrete/continuous variables, with point attractors being an example of the former and ‘continuous attractors’ of the latter. Here we highlight that ‘learnability’ is another quality that may serve to differentiate neural dynamics while offering novel insight. Counterintuitively, good working memory does not necessarily imply that a well-defined, directional learning signal (i.e., gradient) exists. We develop a differential geometric theory that shows that only two kinds of neural dynamics–continuous attractors and quasi-periodic attractors–are fundamentally capable of learning arbitrarily distant temporal relationships. Surprisingly, we find that requiring that an invariant manifold carries persistent learning signals is equivalent to requiring that it faithfully represent continuous variables. The intuitive explanation for this equivalence is that the learning signal (gradient) is an infinitesimal perturbation of the neural state. For such perturbations to be faithfully representable in a biological neural network, the neural states: (1) need to be bounded and, (2) must not asymptotically approach a point attractor. Our analysis further distinguishes continuous and quasi-periodic attractors. Continuous attractors infamously suffer from the fine-tuning problem but also have trivial gradients; both problems hinder their ability to learn and produce temporally structured behavior. By comparison, quasi-periodic attractors do not require fine-tuning and generate richly structured gradients, which facilitates learning and generation of temporally-complex behavior with long-range dependencies. Our theory proposes that oscillatory activity is an observable signature of biological neural dynamics that can support temporal dependence learning Dually, these results have broad implications for the design of artificial learning systems. We propose a novel initialization scheme for RNNs that outperforms specialized architectures in tasks with long-range temporal dependencies. Lastly, the framework we introduce significantly expands upon the dynamical systems tools in use, making it of independent interest.",
        "url": "https://www.world-wide.org/cosyne-23/only-types-attractors-support-representation-538d5e2e"
    },
    "Spectral learning of Bernoulli latent dynamical system models for decision-making": {
        "title": "Spectral learning of Bernoulli latent dynamical system models for decision-making",
        "authors": "Iris Stone, Yotam Sagiv, Memming Park, Jonathan W. Pillow",
        "date": "Saturday, 11 March 2023",
        "location": "III-037",
        "abstract": "A central problem in systems neuroscience is to understand the relationship between sensory stimuli, neural activity, and decision-making behavior. Latent linear dynamical systems (LDS) models are one powerful framework for characterizing these relationships. For example, LDS models can be used to describe the hidden dynamics that govern how an animal's decision-making strategy evolves continuously over time. However, fitting LDS models to data using standard methods such as the expectation-maximization (EM) algorithm is computationally expensive and prone to local optima. We address these shortcomings by developing a spectral learning method for fast, efficient fitting of input-driven LDS models with Bernoulli observations. Our method addresses gaps in the field by providing an efficient estimator (BErnoulli SpecTral Linear Dynamical System or bestLDS) for the setting of binary time series data driven by external inputs. Our approach extends traditional subspace identification (SSID) methods (van Overschee & Moore, Automatica 1994; Ho & Kalman, Regelungstechnik 1966) to the Bernoulli setting via a transformation of the first and second sample moments. The result is a fixed-cost estimator that avoids the hazards of local optima and the long computation time of fitting procedures like EM. In regimes where data is limited or assumptions about the statistical structure of the data are not met, bestLDS provides good initializations for standard approximate EM fitting. Finally, we show that our estimator provides substantial benefits in application to binary choice data from mice performing a sensory decision-making task.",
        "url": "https://www.world-wide.org/cosyne-23/spectral-learning-bernoulli-latent-dynamical-3e13ad93"
    },
    "Automated identification of data-consistent spiking neural network models": {
        "title": "Automated identification of data-consistent spiking neural network models",
        "authors": "Richard Gao, Michael Deistler, Jakob Macke",
        "date": "Saturday, 11 March 2023",
        "location": "III-038",
        "abstract": "Variations in cellular and network parameters shape neural dynamics and computation. Mechanistic models, such as spiking neural networks (SNNs), are instrumental for linking recordings of neural population dynamics to their underlying circuit parameters. However, SNNs lack analytical expressions and accessible gradients for parameter inference (i.e., model identification), making it difficult to systematically identify a single configuration that can reproduce experimental data, let alone the full space of data-consistent models and their uncertainty. As a result, SNNs are often reduced a priori to have few free parameters, limiting their potential as mechanistic models of neural circuits and dynamics. Here, we leverage recent advances in simulation-based inference (SBI) to perform automated model identification for SNNs with high-dimensional parameter spaces using arbitrary features of neural recordings. Simulating 500,000 random configurations of an adaptive exponential integrate-and-fire (AdEx) network with clustered connectivity, we observe complex dynamics with non-trivial dependencies to 28 model parameters representing neuronal, synaptic, and connectivity mechanisms. To enable Bayesian parameter inference, we train a deep neural density estimator on this simulated dataset to approximate the posterior distribution over parameters given observed data. We first validate our approach by performing inference on simulated network activity with known parameter values. SBI identifies many models (including the ground-truth) that can reproduce both observed and unobserved features of network dynamics, revealing covariance structure and degeneracy between parameters. We then perform inference on real experimental data: applied to a dataset of brain organoid recordings, we identify models consistent with observed network burst features, while elucidating the co-evolution of cellular and network parameters over 40 weeks of development. Together, these results demonstrate how SBI can advance our understanding of the dynamical regimes of flexibly parameterized SNNs, while providing mechanistic explanations and generating hypotheses about hidden circuit properties that underlie changes in brain network dynamics.",
        "url": "https://www.world-wide.org/cosyne-23/automated-identification-data-consistent-30f05ccc"
    },
    "Neural population dynamics of computing with synaptic modulations": {
        "title": "Neural population dynamics of computing with synaptic modulations",
        "authors": "Stefan Mihalas & Kyle Aitken",
        "date": "Saturday, 11 March 2023",
        "location": "III-039",
        "abstract": "In addition to long-time scale rewiring, synapses in the brain are subject to significant modulation that occurs at much shorter time scales and allows them to process short-term information. Despite this, models of the brain like recurrent neural networks (RNNs) often have their weights frozen after training, relying on an internal state stored in neuron activity to process temporal information. Although networks with dynamical synapses have been explored previously, often said dynamics are added to networks that also have recurrent connections and thus the short-time scale computational capabilities of synapse modulation alone remain unclear. In this work, we analyze the dynamics of a network that relies solely on synaptic modulations to process short-time scale information, the multi-plasticity network (MPN). We thoroughly examine the neural population dynamics of the MPN trained on integration-based tasks and compare it to known RNN dynamics, findings the two to have fundamentally different behavior and attractor structure. We find said differences in dynamics allow the MPN to outperform its RNN counterparts on several neuroscience-relevant tasks. Of note, analyzing the synaptic modulation population dynamics reveals the MPN has a significantly simpler attractor structure that allows it to be more flexible in training and sequential-learning settings. Our findings demonstrate the computational power of synapse modulations and the potential advantages of computing through them.",
        "url": "https://www.world-wide.org/cosyne-23/neural-population-dynamics-computing-09acf1b3"
    },
    "Neural Manifolds Underlying Naturalistic Human Movements in Electrocorticography": {
        "title": "Neural Manifolds Underlying Naturalistic Human Movements in Electrocorticography",
        "authors": "Zoe Steine-Hanson, Rajesh P. N. Rao, Bing Brunton",
        "date": "Saturday, 11 March 2023",
        "location": "III-040",
        "abstract": "An open question in neuroscience is how the brain controls naturally generated movements. An increasing number of studies have shown that high-dimensional neural population dynamics lie within low-dimensional manifolds, which may be integral to neural control of behavior. However, many of these studies have focused on neural activity recorded during experimentally driven movements with little variability, leaving open the question of whether low-dimensional neural manifolds persist during naturalistic movements. In this paper, we investigate neural population dynamics in naturalistic reaching movements across 12 individuals’ electrocorticography (ECoG) data recorded during their 5 day hospital stay. We found that for all 12 individuals the neural dynamics during four types of arm movements did lie within the same neural manifolds. These manifold spaces also did not drift significantly across the multiple days of their hospital stay. We then compared neural dynamics between individuals for the same types of movements, and found that the manifolds were also aligned between individuals. The alignment of these neural manifold spaces during naturalistic movement indicates that neural manifolds may represent a general principle of movement control.",
        "url": "https://www.world-wide.org/cosyne-23/neural-manifolds-underlying-naturalistic-f760d5be"
    },
    "Identifying state-dependent interactions between brain regions during decision making": {
        "title": "Identifying state-dependent interactions between brain regions during decision making",
        "authors": "Orren Karniol-Tambour, E. Mika Diamanti, David Zoltowski, Lucas Pinto, Carlos Brody, David W. Tank, Jonathan W. Pillow*",
        "date": "Saturday, 11 March 2023",
        "location": "III-041",
        "abstract": "Understanding how multiple brain regions interact to produce behavior is a major challenge in systems neuroscience, with many regions causally implicated in common tasks such as sensory processing and decision making. Evidence-based decision-making involves multiple brain regions across cortex, suggesting a distributed neural mechanism, but a precise description of interactions between regions remains an open problem. Addressing this problem requires developing new analysis methods that account for communication between areas, and pairing these with novel experimental approaches to capture neural activity across disparate brain regions during decision making. Here we developed MR-SDS, a multiregion, nonlinear switching state space model that decomposes global dynamics into local and cross-communication components in the latent space. Critically, the model allows us to estimate and quantify the directional “messages” communicated between regions at each timepoint. We first applied the model to a multiregion evidence accumulation simulation, finding the model accurately recovered latent states and dynamics. We then applied the model to multi-region, cellular-resolution two-photon mesoscope recordings. We simultaneously imaged excitatory neurons in 3 cortical areas, visual AM, premotor M2 and retrosplenial cortex, using a random-access two-photon microscope, while mice performed a sensory-accumulation decision making task. In preliminary analysis, our method revealed distinct local dynamics and communication profiles across regions, such as bi-directional communication between AM and M2, and feed-forward communication from AM to retrosplenial. Additionally, our analysis suggests sensory effects are weaker drivers of cortical dynamics than local recurrence and cross-region interactions, despite the sensory nature of the task. Thus, we introduce an important method for analyzing multiregion neural activity and communication, and showcase preliminary analysis of a novel multiregion dataset to help elucidate the role of different cortical regions in decision making.",
        "url": "https://www.world-wide.org/cosyne-23/identifying-state-dependent-interactions-6bdfc996"
    },
    "Model metamers complement existing benchmarks of biological and artificial neural network alignment": {
        "title": "Model metamers complement existing benchmarks of biological and artificial neural network alignment",
        "authors": "Jenelle Feather & Josh McDermott",
        "date": "Saturday, 11 March 2023",
        "location": "III-042",
        "abstract": "The proliferation of deep artificial neural network models has given rise to widespread interest in comparing such models to biological sensory systems. Model metamers – stimuli that produce the same responses in a model as a natural stimulus – have been proposed as a powerful test of the extent to which a model replicates the invariances of a biological sensory system. However, it has remained unclear whether discrepancies evident from metamers are the same as those identified by other model comparison benchmarks, and whether modifications that have been introduced to address other well-known model discrepancies also serve to mitigate metamer-related discrepancies. We considered three recently introduced benchmarks for model comparison and asked whether performance on these benchmarks predicts the extent to which a model’s metamers are recognizable to humans. First, we examined performance on two sets of image distortions that show benefits of training models on larger and more diverse image sets. Second, we assessed whether a model’s over-reliance on texture cues (a commonly cited difference between humans and neural networks) relates to model metamer recognition. Third, we evaluated model predictions of neural responses in V1, V2, V4, and IT. In each case, performance on the benchmarks was at best weakly related to the human-recognizability of a model’s metamers. The results show that metamers are complementary to other popular model comparison benchmarks, and identify distinct failure modes of current neural network models. More generally, our work highlights the uses of model-driven stimulus synthesis to better understand and refine models of the brain.",
        "url": "https://www.world-wide.org/cosyne-23/model-metamers-complement-existing-benchmarks-3c6aa86d"
    },
    "Population activity in sensory cortex informs confidence in a perceptual decision": {
        "title": "Population activity in sensory cortex informs confidence in a perceptual decision",
        "authors": "Zoe Boundy-Singer, Corey M Ziemba, Robbe Goris",
        "date": "Saturday, 11 March 2023",
        "location": "III-043",
        "abstract": "Observers are aware of the fallibility of perception. When we experience a high degree of confidence in a perceptual interpretation, that interpretation is more likely to be correct than when we feel less confident. Here we ask how neural population activity in sensory cortex informs confidence in perceptual decisions. We used multilaminar electrode arrays to record population activity in the primary visual cortex of a macaque monkey performing a perceptual confidence task. Specifically, the animal judged the orientation of ambiguous stimuli (“clockwise” vs “counter-clockwise”) and simultaneously reported their confidence in this decision (“high” vs “low”). Analysis of the choice behavior revealed that high confidence choices were more accurate than low confidence choices, and that both stimulus strength (rotation magnitude) and stimulus reliability (high vs low contrast) impacted the confidence report. We then asked how this choice behavior related to V1 population activity. Consistent with recent studies of perceptual decision-making, V1 activity was not predictive of variability in the animal’s perceptual choice within single stimulus conditions. However, these same neural responses did predict variability in the animal’s confidence reports. Trials with more overall spiking activity were associated with more confident perceptual decisions. We studied the temporal evolution of this association and found it to reach significance immediately after response onset. Together, these results suggest that V1 responsiveness directly informs downstream estimates of perceptual orientation certainty, which in turn impact confidence in orientation categorization decisions.",
        "url": "https://www.world-wide.org/cosyne-23/population-activity-sensory-cortex-informs-5477c57b"
    },
    "Distinct organization of visual and non-visual signals in visual cortex": {
        "title": "Distinct organization of visual and non-visual signals in visual cortex",
        "authors": "Ali Haydaroglu, Michael Krumin, Jingkun Guo, Alipasha Vaziri, Kenneth Harris, Matteo Carandini",
        "date": "Saturday, 11 March 2023",
        "location": "III-044",
        "abstract": "Information from rich visual signals and ongoing behavioral variables simultaneously drive the same neurons in the cortex without corrupting each other (Niell et al. 2010, Stringer et al. 2019, Shimaoka et al. 2019). How does the anatomical organization of the cortex support the joint coding of these streams of information? We hypothesized that stimulus-driven and non-stimulus activity follow different anatomical organizations in the visual cortex. To investigate the physical distribution of these signals, we used the Light Beads Microscope (LBM, Demas et al. 2021) to volumetrically image the activity of large populations of neurons in awake mice. We developed a novel 3D cell extraction pipeline to accurately determine the 3D position and morphology of cells in large volumes, which was not possible with existing 2D analysis pipelines. First, we investigated the organization of visual signals by asking whether cells that occupy the same cortical minicolumn have similar orientation preferences. As previously reported (Kondo et al. 2016, Ringach et al. 2016), we found a columnar organization with a sharp dropoff: cells that were within 10 um of each other in the x-y plane had similar stimulus responses across depths, but there was no similarity at larger laminar distances. Next, we investigated the non-stimulus activity of the same cells by looking at the structure of noise correlations. We found that non-stimulus activity also maintained a similar 10 um columnar structure extending up to 100 um in depth. Additionally, we found strong, long-range laminar structure in the pairwise correlation of non-stimulus activity extending across 1 mm. This organization was not present in stimulus responses. The distinct anatomical organization of these two streams of information is analogous to their orthogonal coding in high-dimensional neural space, suggesting that distinct local circuit patterns may act as a mechanism for this separation.",
        "url": "https://www.world-wide.org/cosyne-23/distinct-organization-visual-non-visual-2ef46a08"
    },
    "Hierarchical Modular Structure of the Drosophila Connectome": {
        "title": "Hierarchical Modular Structure of the Drosophila Connectome",
        "authors": "Alexander Kunin, Xaq Pitkow, Krešimir Josić, Jiahao Guo, Kevin Bassler",
        "date": "Saturday, 11 March 2023",
        "location": "III-045",
        "abstract": "The structure of neural circuitry plays a crucial role in brain function. Previous studies of brain organization generally had to trade off between coarse descriptions at a large scale and fine descriptions on a small scale. Researchers have now reconstructed tens to hundreds of thousands of neurons at synaptic resolution, enabling investigations into the interplay between global, modular organization, and cell type-specific wiring. Analyzing data of this scale, however, presents unique challenges. To address this problem we applied novel community detection methods to analyze the synapse-level reconstruction of an adult fruit fly brain containing over 20 thousand neurons and 10 million synapses. Using a machine-learning algorithm, we find the most densely connected communities of neurons by maximizing a generalized modularity density measure. We resolve the community structure at a range of scales, from large (on the other of thousands of neurons) to small (on the order of tens of neurons). We find that the network is organized hierarchically and larger-scale communities are composed of smaller-scale structures. Our methods identify well-known features of the fly brain, including its sensory pathways. Moreover, focusing on specific brain regions, we are able to identify subnetworks with distinct connectivity types. For example, manual efforts have identified layered structures in the fan-shaped body. Our methods not only automatically recover this layered structure, but also resolve finer connectivity patterns to downstream and upstream areas. Combining our network analysis with cell type data, we are able to identify repeated cell type-specific wiring patterns composed of as few as three neurons. These methods show that the fine-scale, local network reconstruction made possible by modern experimental methods are sufficiently detailed to identify the organization of the brain across scales, and enable novel predictions about the structure and function of its parts.",
        "url": "https://www.world-wide.org/cosyne-23/hierarchical-modular-structure-drosophila-02bc6e93"
    },
    "Optimizing population codes for distributional representation": {
        "title": "Optimizing population codes for distributional representation",
        "authors": "Mehrdad Salmasi & Maneesh Sahani",
        "date": "Saturday, 11 March 2023",
        "location": "III-046",
        "abstract": "Animals learn to reason and act successfully based on internal estimates of the state of their environment and their relationship to it. Such perceptual estimation is complicated by noise and ambiguity in sensory signals, but many experiments demonstrate behaviour (in humans and other animals) that accounts near optimally for the resulting uncertainty. Theories of how distributional uncertainty may be represented in neuronal activity have largely focused on competing views of the parametric or stochastic form of the belief representation, and less on how individual codes might be adapted to the nature and shape of uncertainty that an animal encounters. Here, we present a framework within which the optimal encoding functions associated with a distributed distributional code (DDC) can be derived, based on the family of distributions experienced. In particular, we consider encoding functions that constrain as tightly as possible a set of encoded belief distribution functions that are sparse within a fixed basis. This hypothesis leads to a simple optimisation principle for neural codes of uncertainty, leading to an efficient representation of distributional beliefs. The principle determines the shapes of the encoding functions, and provided a normative account for a range of tuning curve shapes. In the context of hippocampal place representations, the framework predicts the adaptive distribution of place fields in different environments, and particularly the accumulation of place fields around frequently occupied locations. Finally, the optimal code alters with statistics and experienced sequence of beliefs, offering a potential account for dynamical changes in tuning curves associated with representational drift.",
        "url": "https://www.world-wide.org/cosyne-23/optimizing-population-codes-distributional-925f6e51"
    },
    "Learning beyond the synapse: activity-dependent myelination, neural correlations, and information transfer": {
        "title": "Learning beyond the synapse: activity-dependent myelination, neural correlations, and information transfer",
        "authors": "Jeremie Lefebvre & Afroditi Talidou",
        "date": "Saturday, 11 March 2023",
        "location": "III-047",
        "abstract": "Learning relies as much on synaptic weight modifications as it does on the timing of neural signaling. For instance, variability in axonal length and diameter may compromise spike-timing-dependent plasticity (STDP) by dispersing action potential timing, preventing synaptic potentiation and depression. Activity-dependent myelination (ADM), a form of brain plasticity relying on neuron-glia feedback, has been shown to normalize conduction times across different axons through adaptive, neuron-activity-dependent changes in axonal conduction velocity (CV). While historically seen as a mere compensation mechanism for the variable distances separating neurons, myelination is now recognized as a highly dynamic process supporting and imparting flexibility to various forms of neural computations ranging from learning, and memory consolidation to stimulus discrimination. We here employed a recurrent neural network of spiking Poisson neurons endowed with neuron-glia feedback and examined the functional consequences of ADM plasticity on population coding. We found that ADM plasticity implements a gain control mechanism up-regulating neuronal responses to dynamic stimuli, as well as tuning network correlations. Glia-mediated changes in CV along distinct axons were found to be titrated autonomously to promote AP coincidence, reinforcing the probability of post-synaptic response and hence to enhance information transfer. Such features were found to be preserved across spatial scales and to be axon specific, scaling with axon length, with longer axons supporting faster conduction compared with shorter ones. Neural integration relying on tight temporal precision, we exposed the network to dynamic inputs with different spatial and temporal statistics. ADM was found to enhance information transmission of such stimuli through axon-specific tuning of CV and the subsequent recruitment of stochastic resonance. Taken together, our results suggest that ADM represents an essential component of brain plasticity, coordinating neural responses to support the implementation of various forms of neural computations.",
        "url": "https://www.world-wide.org/cosyne-23/learning-beyond-synapse-activity-dependent-db68c082"
    },
    "Controlling human cortical and striatal reinforcement learning with meta prediction error": {
        "title": "Controlling human cortical and striatal reinforcement learning with meta prediction error",
        "authors": "Jae Hoon Shin, Jee Hang Lee, Sang Wan Lee",
        "date": "Saturday, 11 March 2023",
        "location": "III-048",
        "abstract": "Value-based decision-making in a context-changing environment is known to be guided by the two distinctive reinforcement learning (RL) strategies: goal-directed and habitual learning. Despite decades-long efforts to reveal that different environmental variables influence these RL processes, it remains unknown exactly how we create a situation by manipulating a set of environmental variables to guide these processes separately. This is mostly because of the complex interactions between environmental variables and RL, often beyond the experimenter’s comprehension. Here we show that an RL algorithm can be trained to control the task variables to guide human RL in a goal-directed manner. We individually fitted a computational model1 of goal-directed and habitual learning (called cognitive models) to the 82 subjects’ behavior data collected with a two-stage Markov decision-making task. Then we trained another RL algorithm (called a task controller) on another task to separately manipulate the key variables of the cognitive models: reward and state prediction error. Specifically, the task controller’s state and action are respectively defined as the cognitive model’s prediction errors and the task parameters: transition probability and reward profiles. The task controller was set to maximize or minimize the cognitive model’s prediction errors, while the cognitive model acts as a conventional human reward-maximizing agent: obtaining the reward from the task as much as possible. This asymmetric game setting enables the task controller to predict the prediction error of human RL (called meta prediction error). First, we showed in a subject-wise permutation test that the task controller learned a subject-independent policy. Second, we ran two fMRI experiments (n=50 in total, 25 for each controller condition) with the task whose parameters are determined by this task controller. We found the effect of task control on the behavior (choice optimality), latent process (prediction errors), and neural levels (cortex and striatum).",
        "url": "https://www.world-wide.org/cosyne-23/controlling-human-cortical-striatal-df28fba5"
    },
    "Input-dominated Hebbian learning enables image-computable E-I networks": {
        "title": "Input-dominated Hebbian learning enables image-computable E-I networks",
        "authors": "Samuel Eckmann, Yashar Ahmadian, Máté Lengyel",
        "date": "Saturday, 11 March 2023",
        "location": "III-049",
        "abstract": "Recurrent network models of excitatory (E) and inhibitory (I) neurons with supralinear activation functions have successfully explained several cortical computations, including response normalization and surround suppression. Unlike more abstract approaches, such networks allow direct comparisons with experimentally measured neural activities and synaptic strengths. However, the scope of these networks remained limited as their connectivity needed to be designed by hand or fitted by complex machine learning algorithms to yield stable activity and computations. Here we present a method to efficiently construct stable recurrent E-I networks with connectivity that reflect the statistical regularities of high-dimensional natural images using a diverse set of feedforward receptive fields. We build on recent work that demonstrated the emergence of functional E-I networks via online Hebbian learning from an input population with homogeneous tuning curves, and employ a simple covariance plasticity rule at all recurrent synapses without constraints on input tuning. When the network's activity is dominated by feedforward inputs, we can solve for the steady-state weight matrix analytically. This allows us to construct stable networks with recurrent weights adapted to complex input statistics without hand-tuning or numerical optimization. We demonstrate our approach by constructing two fully connected networks of 6,500 neurons and >40 million synapses each, encoding natural image datasets resembling the upper and lower visual field of mice, respectively. We found that correlations between cross-oriented receptive fields in the upper visual field were weaker than those in the lower visual field, while iso-oriented receptive fields were more strongly correlated in the upper visual field. These statistics became reflected in the networks' synaptic connectivity and predicted weaker cross-orientation, but stronger iso-orientation surround suppression in the lower compared to the upper visual field. In summary, our method enables image-computable models of stable, supralinear E-I networks that allow for detailed comparison with heterogeneous cortical circuits.",
        "url": "https://www.world-wide.org/cosyne-23/input-dominated-hebbian-learning-enables-1e3107f3"
    },
    "Functional consequences of highly shared feedforward inhibition in the striatum": {
        "title": "Functional consequences of highly shared feedforward inhibition in the striatum",
        "authors": "Lihao Guo, Pascal Helson, Arvind Kumar",
        "date": "Saturday, 11 March 2023",
        "location": "III-050",
        "abstract": "The striatum is crucial for motor control and reinforcement learning. The striatum has only 1% fast-spiking interneurons (FSI) which constitute feedforward inhibition (FFI). Therefore, striatal neurons receive a high degree of shared FFI, which makes the striatum a unique network in the brain. Here we ask, what role such high shared FFI may play in striatal function besides inducing synchrony. We found that with highly shared connectivity FSIs increase the trial-by-trial variability of striatal responses. Moreover, when the striatum is driven by correlated inputs, FSIs decorrelate the responses but when input is uncorrelated, FSIs correlate the responses. Thus, with their high connectivity to striatal neurons, FSIs create a correlation fixed point in the striatum. This effect disappears when we reduced the FSIs’ shared connectivity by increasing the number of FSIs in our model. This non-monotonic effect of FSIs in controlling striatal correlation underlies a temporal winner-take-all dynamics, especially in the early stages of learning e.g. in pattern separation. FSI connectivity is modulated by acetylcholine which can, in a context-dependent manner, dynamically control the effect of FSIs on trial-by-trial variability and pattern separation ability. Our results generalize to other small populations of neuron types with high connection probabilities.",
        "url": "https://www.world-wide.org/cosyne-23/functional-consequences-highly-shared-cf66e835"
    },
    "Sensorimotor prediction errors in the mouse olfactory cortex": {
        "title": "Sensorimotor prediction errors in the mouse olfactory cortex",
        "authors": "Priyanka Gupta, Marie Dussauze, Uri Livneh, Dinu Albeanu",
        "date": "Saturday, 11 March 2023",
        "location": "III-051",
        "abstract": "During behavior, sensation and action operate in closed-loop. Movements shape sensory input, and sensory inputs guide motor commands: where one looks determines what one sees. Through experience, the brain learns the reciprocal relationship between sensory inputs and movements to build internal models that accurately predict the sensory consequences of upcoming actions (sensorimotor predictions). This exchange of sensory inputs and egocentric expectations is at the core of active perception. Experimental investigation of this idea has been sparse and split between behavioral interrogation of sensory-guided, precise motor control in primates (visuomotor adaption tasks) and the search for neuronal substrates of sensory predictions in rodents via simpler running-based closed-loop behaviors. To study internal models both at behavioral and circuit-level, we developed a novel behavioral task where head-fixed mice are trained to steer the left-right location of an odor source by controlling a light-weight lever with their forepaws. In this manner, 1) we link a precise motor action to well-defined sensory expectations (odor location) and 2) subsequently violate the learnt expectations via online sensory feedback perturbations in trained animals. Strikingly, mice readily counter these sensorimotor errors, making precise corrective movements that provide us a read-out of their individually learnt sensorimotor expectations. In other modalities (vision, audition), sensorimotor error-signals have been observed in primary cortical areas. Using chronic recordings during behavior, we tested whether the olfactory cortex performs similar sensorimotor computations. We find that odor-driven responses in cortical neurons are strongly re-shaped by olfacto-motor expectations. Transient perturbations often triggered responses that were stronger than those evoked by any other task variable. Our results suggest that olfactory cortex computes sensorimotor prediction errors by integrating sensory information with movement-related predictions, presumably relayed via top-down feedback. Using cell-type analysis and activity manipulations, we are currently identifying the circuit elements that facilitate the comparison of olfactory inputs with predictions.",
        "url": "https://www.world-wide.org/cosyne-23/sensorimotor-prediction-errors-mouse-4fdbb96c"
    },
    "Network dimensions alter reversal learning strategies": {
        "title": "Network dimensions alter reversal learning strategies",
        "authors": "Michelangelo Naim, Dan Gibson, Georgios Papageorgiou, Yudi Xie, Mitchell Ostrow, Ann M. Graybiel, Guangyu Robert Yang",
        "date": "Saturday, 11 March 2023",
        "location": "III-052",
        "abstract": "How do animals adapt in a dynamic world? Sometimes, our expectations about the world are drastically violated, such as when we accidentally bite into spoiled food. In these circumstances, we must adjust or face further harm. A classical experimental paradigm to study this behavior is reversal learning, where the values of stimuli are suddenly reversed, for example from positive to negative. Here we investigate how computational models of neural circuits can express the many behavioral strategies empirically observed in reversal learning. We report that simply introducing more neurons in a neural network can dramatically alter an agent's reversal learning strategy. We first demonstrate this phenomenon in simple few-parameter actor-critic models trained on a reversal learning task. Introducing one additional parameter into a two-parameter model can induce a switch in its learning strategy, even though the original strategy remains available to the model. Next, we show that this phenomenon occurs more generally in neural networks trained on the same task. Increasing the width of a neural network (number of neurons per layer) can once again induce a switch in its learning strategy. Moreover, we show that a shallow network and a deep network of equal size can employ different strategies. Together, these results suggest that network dimensions (width, depth) provide an inductive bias towards different learning strategies. Our findings suggest a new perspective to consider in the neural basis of reversal learning.",
        "url": "https://www.world-wide.org/cosyne-23/network-dimensions-alter-reversal-learning-14473fd8"
    },
    "Brain-wide, specialized and state-dependent cortical encoding of reward, value and action switching during reversal learning": {
        "title": "Brain-wide, specialized and state-dependent cortical encoding of reward, value and action switching during reversal learning",
        "authors": "Murat Yildirim, Nhat Le, Yuma Osako, Yizhi Wang, Abigail Dulski, Alexandria Barlowe, Hiroki Sugihara, Peter So, Mriganka Sur",
        "date": "Saturday, 11 March 2023",
        "location": "III-053",
        "abstract": "In reversal learning tasks, large-scale circuits in multiple brain areas are involved in encoding multiple decision variables, such as trial outcomes, action values and action switching. It is unknown how spatiotemporal patterns of cortical encoding differentially encode these variables and whether the encoding depends on the level of engagement in the task. Here, we used a combination of large-scale imaging techniques and computational methods to investigate the representation of reward-related decision variables at the widefield and single-neuron levels. Widefield imaging and unsupervised analysis of cortical activity segment cortical activation into cortex-wide neural modes, each associated with a different spatial footprint, temporal dynamics and encoding of reward and error. Three-photon imaging of single-neurons across superficial and deep layers in the ACC, RSC, motor and visual cortex revealed brain-wide but specialized processing of reward-related variables. We discovered widespread representation of outcome, value, and switching in all four regions, with layer-specific enrichment of outcome encoding in the retrosplenial cortex (RSC) and of action values encoding in the anterior cingulate cortex (ACC). Outcome representation was enhanced in high-performance behavioral states but only weakly represented in low-performance states. Together, these results revealed specialized and state-dependent distributions of outcome, value, and switch representations across large-scale cortical circuits.",
        "url": "https://www.world-wide.org/cosyne-23/brain-wide-specialized-state-dependent-60626a34"
    },
    "Unifying mechanistic and functional models of cortical circuits with low-rank, E/I-balanced spiking networks": {
        "title": "Unifying mechanistic and functional models of cortical circuits with low-rank, E/I-balanced spiking networks",
        "authors": "William Podlaski & Christian Machens",
        "date": "Saturday, 11 March 2023",
        "location": "III-054",
        "abstract": "Network models are often designed to capture selective aspects of cortical circuits. On one end, mechanistic models such as balanced spiking networks resemble activity regimes observed in data, but are often limited to simple computations. On the other end, functional models like trained deep networks can show comparable performance and dynamical motifs, but are far removed from experimental physiology. Here, we put forth a new framework for excitatory-inhibitory spiking networks which retains key properties of both mechanistic and functional models. Based on previous studies of the geometry of spike-coding networks, we consider a population of spiking neurons with low-rank connectivity, allowing each neuron’s threshold to be cast as a boundary in a space of population modes, or latent variables. Each neuron’s boundary divides this latent space into subthreshold and suprathreshold areas, which determines its contribution to the input-output function of the network. Then, incorporating Dale’s law as a connectivity constraint, we demonstrate how a network of inhibitory (I) neurons forms a convex, stable boundary in the latent coding space, and a network of excitatory (E) neurons forms a concave, unstable boundary. Finally, we show how the combination of the two yields stable dynamics at the crossing of the E and I boundaries. The resultant E/I networks are balanced, inhibition-stabilized, and exhibit asynchronous irregular activity, thereby closely resembling cortical dynamics. Moreover, the latent variables can be mapped onto a constrained optimization problem, and are capable of universal function approximation. The combination of these dynamical and functional properties leads to unique insights, including specified computational roles for E/I balance and Dale’s law. Finally, the intuitive geometry of the representations, plus the link to constrained optimization, makes our framework a promising candidate for scalable and interpretable computation in biologically-plausible spiking networks.",
        "url": "https://www.world-wide.org/cosyne-23/unifying-mechanistic-functional-models-c7857810"
    },
    "Propofol anesthesia destabilizes neural dynamics across cortex": {
        "title": "Propofol anesthesia destabilizes neural dynamics across cortex",
        "authors": "Adam Eisen, Leo Kozachkov, Andre Bastos, Jacob Donoghue, Meredith Mahnke, Scott Brincat, Sarthak Chandra, Emery Brown, Ila Fiete, Earl Miller",
        "date": "Saturday, 11 March 2023",
        "location": "III-055",
        "abstract": "Anesthesia is ubiquitous in hospitals, yet a mechanistic understanding of how anesthetic drugs induce unconsciousness is lacking. A prominent hypothesis suggests that dynamic stability is critical to cortical function: awake brains are poised at a state that is sufficiently excitable for activity generation and propagation, yet controllable and stable. Measuring dynamic stability during the transition from consciousness to anesthetic unconsciousness could identify the neural mechanisms disrupted by anesthesia, and thus provide insight into the neural basis of consciousness. Related work suggests that anesthesia could either destabilize or excessively stabilize neural dynamics—the question remains unresolved. This is likely due to the lack of rigorous approaches to estimating stability in neural data and the paucity of studies performing this analysis using electrophysiology. Harnessing results from dynamical systems theory, we develop a novel and principled approach, Delayed Linear Analysis for Stability Estimation (DeLASE), to quantifying population-level dynamic stability that is scalable to large volumes of neural data. DeLASE constructs linear delay dynamical systems models of activity and discounts the impact of further back states to estimate stability. We validate DeLASE by verifying it can accurately infer changes in stability in simulated networks from partial observation of activity. We then apply DeLASE to local field potentials from four areas across the macaque cortex during transitions between awake and anesthetized states and find that neural dynamics are destabilized in anesthetic unconsciousness relative to wakefulness. This suggests some degree of stability is necessary for conscious processing. Accordingly, we find that stimulus-evoked trajectories diverge in anesthesia - whereas in wakefulness they quickly stabilize - presenting a neural mechanism for a lack of stimulus information integration in unconsciousness. Given the hypothesized changes of stability in neuropsychiatric conditions like depression, anxiety, and schizophrenia, the impact of our rigorous stability estimation approach could provide a quantitative link across multiple fields of study.",
        "url": "https://www.world-wide.org/cosyne-23/propofol-anesthesia-destabilizes-neural-31ddf309"
    },
    "Arousal dynamics: diverse measurements of a universal manifold": {
        "title": "Arousal dynamics: diverse measurements of a universal manifold",
        "authors": "Ryan Raut, Zachary Rosenthal, Xiaodan Wang, Adam Bauer, Steven Brunton, Bing Brunton, J. Nathan Kutz",
        "date": "Saturday, 11 March 2023",
        "location": "III-056",
        "abstract": "Recent findings from awake, behaving animals lead us to hypothesize the existence of an underlying dynamical process whose manifestations are observed across diverse neural, physiological and behavioral measurements. Our ability to construct nonlinear mappings between such measurements (here, pupillometry and widefield calcium imaging) from a latent, low-rank representation of their dynamics provides strong support for this hypothesis. Specifically, we introduce an integrative theoretical framework that casts arousal as a dynamical process unfolding along a low-dimensional manifold that segregates different physiological regimes (i.e., brain and body states), each of which has a high-dimensional expression in the space of measurements. This motivates a data-driven approach to parsimoniously link observables that evolve according to a common but unknown dynamical mechanism. Our approach exploits Takens’ embedding theorem from dynamical systems theory, which permits the (topology-preserving) reconstruction of a full-state attractor manifold from a single observable and its time history. Takens’ theorem enables a strong prediction – and thus, a challenging test – of our framework: in theory, a single arousal-related observable (e.g., pupil size) should suffice to reconstruct high-dimensional observables, to the extent that a dynamical mechanism is shared. We test this prediction by performing simultaneous pupillometry and widefield calcium imaging in awake mice. The latter reports the large-scale spatial structure of cortical activity, which we hypothesize to be tightly regulated in accordance with arousal dynamics. We train neural networks to approximate the hypothesized mapping from delay-embedded pupil time series to widefield measurements. This procedure enables us to reconstruct a surprising extent of cortex-wide spatiotemporal dynamics in awake mice (i.e., 74 ± 8% of variance < 0.2 Hz in held-out data, vs. 13 ± 10% without delay embedding (mean ± std, n=7 mice)). Our framework and findings thus elucidate an arousal-related dynamical mechanism that is both richer and substantially further-reaching than presently recognized.",
        "url": "https://www.world-wide.org/cosyne-23/arousal-dynamics-diverse-measurements-70a9a951"
    },
    "Inhibitory gating of non-linear dendrites enables stable learning of assemblies without forgetting": {
        "title": "Inhibitory gating of non-linear dendrites enables stable learning of assemblies without forgetting",
        "authors": "Mikołaj Maurycy Miękus, Christoph Miehl, Sebastian Onasch, Julijana Gjorgjieva",
        "date": "Saturday, 11 March 2023",
        "location": "III-057",
        "abstract": "Neuronal assemblies — groups of neurons with strong recurrent connectivity — are thought to be the basic building blocks of perception and memory in the brain: representations of specific concepts. Activation of an assembly signals the presence of its associated concept to downstream targets. An efficient implementation should allow similar concepts to be represented by similar assemblies, sharing a subset of neurons. However, learning overlapping assemblies in computational models is difficult. Similar assemblies tend to either merge or diverge during the learning process. The same mechanism also leads to a problem known as `catastrophic forgetting', where the learning of a new assembly can disrupt the existing structure and thus lead to `forgetting' of previously learned assemblies. We propose a combination of biologically motivated mechanisms as a solution to these challenges: A neuron model with non-linear dendritic dynamics, inhibition enabling context-dependent dendritic gating, and spike-timing-dependent plasticity. These components allow for learning stable, overlapping neuronal assemblies for a variety of distinct tasks without catastrophic forgetting. Furthermore, by learning stable associations, our assembly framework can carry out diverse computations.",
        "url": "https://www.world-wide.org/cosyne-23/inhibitory-gating-non-linear-dendrites-6d52b265"
    },
    "Alignment of ANN Language Models with Humans After a Developmentally Realistic Amount of Training": {
        "title": "Alignment of ANN Language Models with Humans After a Developmentally Realistic Amount of Training",
        "authors": "Eghbal Hosseini, Martin Schrimpf, Yian Zhang, Samuel Bowman, Noga Zaslavsky, Evelina Fedorenko",
        "date": "Saturday, 11 March 2023",
        "location": "III-058",
        "abstract": "Artificial neural networks (ANN) have emerged as computationally plausible models of human language processing. A major criticism of these models is that the amount of training data they receive far exceeds that of humans. Here, we use two complementary approaches to ask how the models’ ability to capture human neural and behavioral responses to language is affected by the amount of training data. First, we evaluate GPT-2 models trained on 1 million, 10 million, 100 million, or 1 billion tokens against a neural (fMRI) and a behavioral (reading times) benchmark. Because children are exposed to approximately 100 million words during the first 10 years of life, we consider the 100-million-token model developmentally plausible. Second, we test the performance of a GPT-2 model that is trained on a 9-billion dataset to reach state-of-the-art next-word prediction performance against the same human benchmarks at different stages during training. Across both approaches, we find that (i) the models trained on a developmentally plausible amount of data already achieve near-maximal performance in capturing neural and behavioral responses to language. Further, (ii) lower perplexity - a measure of next-word prediction performance - is associated with stronger alignment with the human benchmarks, suggesting that models that achieve sufficiently high next-word prediction performance also acquire human-like representations of the linguistic input. In tandem, these findings establish that although some training is necessary for the models’ ability to predict human responses to language, a developmentally realistic amount of training (~100 million tokens) may suffice.",
        "url": "https://www.world-wide.org/cosyne-23/alignment-language-models-with-humans-af915ceb"
    },
    "Variable syllable context depth in Bengalese finch songs: A Bayesian sequence model": {
        "title": "Variable syllable context depth in Bengalese finch songs: A Bayesian sequence model",
        "authors": "Noémi Éltető, Lena Veit, Avani Koparkar, Peter Dayan",
        "date": "Saturday, 11 March 2023",
        "location": "III-059",
        "abstract": "Birdsong is an important model for vocal learning and sequential motor behavior. Similarly to human language, songs, notably those of Bengalese finches and canaries, exhibit higher-order sequence structure, meaning that the statistics of one syllable may depend on a number of previous syllables. However, this number (the context depth) varies in a manner that has challenged previous formal approaches. Here we used a hierarchical non-parametric Bayesian sequence model (based on Teh, 2006; Elteto et al., 2022) that seamlessly combines predictive information from shorter and longer contexts of previous syllables, weighing them proportionally to their predictive power. We fit our model to songs of 8 different Bengalese finches, each with > 300 song bouts (Veit et al., 2021). The model inferred the context depth, showing that it varied substantially, with some syllables depending just on one deterministic predecessor, but others depending on $>10$ previous syllables. Underlying this variability was syllables forming alternating and repeating chunks, i.e. strings of fixed subsequences. When fitted at the chunk-level, our model revealed different chunk-motifs that characterize how bouts typically start, unfold, and end. The model was also able to predict the flexibility with which birds can learn to switch between syllable transitions based on external cues.",
        "url": "https://www.world-wide.org/cosyne-23/variable-syllable-context-depth-bengalese-78612c76"
    },
    "Augmented Gaussian process variational autoencoders for multi-modal experimental data": {
        "title": "Augmented Gaussian process variational autoencoders for multi-modal experimental data",
        "authors": "Rabia Gondur, Evan Schaffer, Mikio Aoi, Stephen Keeley",
        "date": "Saturday, 11 March 2023",
        "location": "III-060",
        "abstract": "Characterizing the relationship between neural population activity and behavioral data is a central goal of neuroscience. While latent variable models (LVMs) are successful in describing high dimensional data, they are typically only designed for a single type of data, making it difficult to identify structure shared across different experimental data modalities. Here, we address this shortcoming by proposing an LVM which extracts shared and independent latents for distinct, simultaneously recorded experimental modalities. We do this by combining Gaussian Process Factor Analysis (GPFA), an interpretable LVM for neural spiking data with temporally smooth latent space, with Gaussian Process Variational Autoencoders (GPVAEs), which similarly use a GP prior to characterize correlations in a latent space, but admit rich expressivity due to a deep neural network mapping to observations. We achieve interpretability in our model by constraining the latent space to partition variability into components either shared between or independent to each modality. To make inference in our model scalable, we parameterize the latents in the Fourier domain. Using this approach, we show improved performance compared to standard inference. We validate our model on simulated multi-modal data consisting of neural spikes and smoothly rotating MNIST images. We show that the multi-modal GPVAE is able to not only identify the shared and independent latent structure across modalities accurately, but provides good reconstructions of both images and neural rates on held-out trials. Lastly, we demonstrate our framework on fly whole-brain calcium imaging alongside tracked limb positions, analyzing shared and independent subspaces between brain and behavior. We find that the subspace shared across modalities best isolates distinct fly behaviors.",
        "url": "https://www.world-wide.org/cosyne-23/augmented-gaussian-process-variational-ed13e865"
    },
    "Dorsolateral prefrontal cortex is a key cortical locus for perceptual decisions": {
        "title": "Dorsolateral prefrontal cortex is a key cortical locus for perceptual decisions",
        "authors": "Kenji Lee, Nicole Carr, Tian Wang, Maria Medalla, Jennifer Luebke, Chandramouli Chandrasekaran",
        "date": "Saturday, 11 March 2023",
        "location": "III-061",
        "abstract": "Perceptual decision-making involves combining sensory evidence with available choices to arrive at an appropriate action to report the choice. When sensory evidence and potential actions to report choice are simultaneously available, neural activity in dorsal premotor (PMd) and lateral intraparietal (LIP) cortices covary with sensory evidence and choice. However, when sensory evidence and possible actions are separated in time, PMd and LIP show action selection related responses and only when the stimulus-response relationship is apparent. Thus, these areas are largely involved in action selection. However, in many settings, evidence must be held in working memory before possible actions are known. How does decision-making occur if sensory evidence and potential actions to report choice are not simultaneously represented? Is there a brain area that supports these decision-related computations in such settings? Here, we trained a monkey in a perceptual decision-making task that separated the deliberation on sensory evidence from the action selection process by a working memory delay. The monkey initially viewed a central red-green checkerboard for 900 ms. After a variable working memory delay , two targets, red and green, appeared and the goal was to touch the target that matched the dominant color in the checkerboard. While the monkey performed this task, we recorded in the dorsolateral prefrontal cortex (DLPFC) at a wide variety of cortical depths and found the following: DLPFC neurons—especially deep DLPFC—encode sensory evidence with information persisting into a working memory period. When targets are presented, DLPFC neurons encoded the target configuration at a short latency (∼100 ms). Finally, DLPFC neurons signaled action choice related signals with low latency (200 ms) once the stimulus-response association is revealed. This low latency response to sensory evidence, potential actions, and action choice all suggest that DLFPC is a key cortical locus involved in perceptual decision-making.",
        "url": "https://www.world-wide.org/cosyne-23/dorsolateral-prefrontal-cortex-cortical-cfbdbdb3"
    },
    "A vast space of compact strategies for effective decisions": {
        "title": "A vast space of compact strategies for effective decisions",
        "authors": "Tzuhsuan Ma & Ann Hermundstad",
        "date": "Saturday, 11 March 2023",
        "location": "III-062",
        "abstract": "When foraging in dynamic and uncertain environments, animals can benefit from basing their decisions on smart inferences about hidden properties of the world. Typical theoretical approaches for understanding the strategies that animals use in such settings combine Bayesian inference and value iteration to derive optimal behavioral policies that maximize total reward given changing beliefs about the environment. However, specifying these beliefs requires infinite numerical precision; with limited resources, this problem can no longer be decomposed into the separate steps of optimizing inference and optimizing action selection. To understand the space of behavioral policies in this constrained setting, we enumerate and evaluate all possible behavioral programs that can be constructed from just a handful of states. We show that only a small fraction of the top-performing programs can be constructed by approximating Bayesian inference; the remaining programs are structurally or even functionally distinct from Bayesian. To assess structural and functional relationships among all programs, we developed novel tree-embedding algorithms; these embeddings, which are capable of extracting different relational structures within the program space, reveal that nearly all good programs are closely connected through single algorithmic “mutations”. We demonstrate how one can use such relational structures to efficiently search for good solutions via an evolutionary algorithm. Moreover, these embeddings reveal that the diversity of non-Bayesian behaviors originates from a handful of key mutations that broaden the functional repertoire within the space of good programs. The fact that this diversity of non-optimal behavior does not significantly compromise performance suggests that these same strategies might generalize across tasks.",
        "url": "https://www.world-wide.org/cosyne-23/vast-space-compact-strategies-effective-85a02cc1"
    },
    "Spontaneous neural fluctuations and traveling waves are coordinated topographically across cortical and subcortical areas": {
        "title": "Spontaneous neural fluctuations and traveling waves are coordinated topographically across cortical and subcortical areas",
        "authors": "Zhiwen Ye & Nicholas Steinmetz",
        "date": "Saturday, 11 March 2023",
        "location": "III-063",
        "abstract": "Spontaneous neural fluctuations and traveling waves are often observed in large scale population activity in diverse brain areas and in various brain states (Lubenov et al. 2009; Muller et al. 2016; Hamid et al. 2021). Spatiotemporal dynamics of neural activity, including traveling waves, likely implement diverse computations, including motor planning, decision making, and memory consolidation (Ermentrout & Kleinfeld 2001; Muller et al 2018). However, the detailed spatiotemporal patterns of wave propagation have not been well characterized in awake mammals. Critically, it is still largely unknown whether spatiotemporal patterns are shared and coordinated across different brain areas. Using GCaMP7f widefield imaging in the mouse dorsal cortex, we identified that 3-6 Hz oscillations during awake immobility (Einstein et al. 2017; Jacobs et al. 2022; Nestvogel & McCormick 2022) are globally distributed. Traveling waves, including spirals, emerged during 3-6 Hz oscillations. Spiral waves are highly concentrated in the center of the somatosensory cortex (SSp), and coordinated between left and right hemispheres, as well as between anterior and posterior cortex. As a result of observing this spatial phase symmetry, we found that neural fluctuations and spiral waves in the posterior cortex can be fully predicted by anterior cortical fluctuations with linear regression, and the spatial distribution of the activity regression kernels closely matches the axonal projection maps. To determine whether these waves are coordinated beyond the cortex, we used simultaneous cortical widefield imaging and 4-shank Neuropixels 2.0 recording in the subcortical areas. We quantified moment-to-moment cortical wave with optical flow methods and found that the timing, location and propagation direction of the cortical wave could be predicted using rich subcortical spiking data from striatum and thalamus. Together these results demonstrate that the propagating waves of neural activity are shared across multiple cortical maps and subcortical regions, raising new possibilities for their functional consequences.",
        "url": "https://www.world-wide.org/cosyne-23/spontaneous-neural-fluctuations-traveling-e7c11e1f"
    },
    "The vanishing dopamine in Parkinson's disease": {
        "title": "The vanishing dopamine in Parkinson's disease",
        "authors": "Chaitanya Chintaluri & Tim P Vogels",
        "date": "Saturday, 11 March 2023",
        "location": "III-064",
        "abstract": "Parkinson's disease (PD), characterized by the absence of dopamine in the striatum[1], is caused by the death of the substantia nigra pars compacta dopamine (SNcDA) neurons in the mid-brain. The cause of this cell loss is attributed to irreparable damage due to a dysregulation cascade originating from excess cytosolic dopamine[2]. However, it is unresolved if dopamine dysregulation in SNcDA neurons themselves is the cause of PD or if it is a mere symptom. Here, we introduce a theory of specialized non-causal action potentials that serve metabolic homeostasis called `metabolic spikes' which can account for spontaneous activity observed in many neuron types including SNcDA. We propose that loss of these metabolic spikes in SNcDA can account for both, the cause of PD and the subsequent dopamine dysregulation. Neurons, presumably in anticipation of synaptic inputs, keep their ATP levels at a maximum such that they are ATP-surplus/ADP-scarce during synaptic quiescence. With ADP availability as the rate-limiting step, ATP production stalls in their mitochondria when energy consumption is low, leading to the formation of toxic Reactive Oxygen Species(ROS). Under these circumstances, `metabolic spikes’ serve to restore ATP production and relieve ROS toxicity. In a metabolism-coupled model of SNcDA that senses ROS and initiates spikes, we identified three categories of deficits that could decrease metabolic spikes and consequently deplete the dopamine tone seen in PD. Importantly in PD, such lowered extracellular dopamine level is misread by D2-autoreceptors and dopamine synthesis is increased. With dopamine vesicles being already full, excess dopamine produces disruptive aldehyde (DOPAL) leading to dysregulation and ultimately cell death. Metabolic spikes, though relevant for cellular health, may thus be an integrated neuronal mechanism that operates in synergy with synaptic integration and forms a basic principle of network dynamics and behaviour, as exemplified in PD.",
        "url": "https://www.world-wide.org/cosyne-23/vanishing-dopamine-parkinsons-disease-6e15b63d"
    },
    "Blazed oblique plane microscopy reveals scale-invariant predictions of brain-wide activity": {
        "title": "Blazed oblique plane microscopy reveals scale-invariant predictions of brain-wide activity",
        "authors": "Maximilian Hoffmann, Jörg Henninger, Johannes Veith, Lars Richter, Benjamin Judkewitz",
        "date": "Saturday, 11 March 2023",
        "location": "III-065",
        "abstract": "Due to the size and opacity of vertebrate brains, it has until now been impossible to simultaneously image neuronal circuits at cellular resolution across the entire adult brain. Thus, any recording is an implicit subsampling of the total activity, be it by local averaging (e.g. mesoscopic calcium imaging, fMRI), local sampling (e.g.multi-photon microscopy), or spatially distributed sparse sampling (e.g. electrode arrays). Understanding the precise relationship between these different sampling strategies has been a major challenge in neuroscience. Importantly, it is unknown how to trade off these levels of description in terms of their predictive power for global brain activity. To gain insights into this question we use our recently developed blazed oblique plane microscopy (OPM) to perform the first brain-wide recording of neuronal activity at single-cell resolution in an adult vertebrate, Danionella, at a volume rate of 1 Hz. We find scale-free decay of cellular correlations and, remarkably, spatial self-similarity of predictive power. In other words, a set of randomly sampled neurons and the same number of coarse-grained macrovoxels predict cellular activity throughout the brain-wide population equally well.",
        "url": "https://www.world-wide.org/cosyne-23/blazed-oblique-plane-microscopy-reveals-bffd959c"
    },
    "Hippocampal CA2 modulates its geometry to solve the memory-generalization tradeoff for social memory": {
        "title": "Hippocampal CA2 modulates its geometry to solve the memory-generalization tradeoff for social memory",
        "authors": "Lorenzo Posani, Lara Boyle, Steven A. Siegelbaum, Stefano Fusi",
        "date": "Saturday, 11 March 2023",
        "location": "III-066",
        "abstract": "Social memory, one's ability to recognize and remember experiences with other conspecifics, consists of several discrete psychological processes. These include the ability to rapidly detect whether an individual is novel or familiar (“I know that person, but from where?”) and the recollection of an individual’s specific identity and the associated set of past experiences (“ah, we met at COSYNE last year”). These processes have conflicting demands and requirements. Familiarity is an abstract concept that can readily generalize to any individual in any context. In contrast, social episodes consist of complex multi-dimensional experiences with a particular individual at specific places and times. How does the brain manage these conflicted memory requirements? Are there brain mechanisms that provide for the abstraction of familiarity and simultaneously enable detailed storage and recall of social experience? Here, we use calcium imaging from large populations of hippocampal CA2 pyramidal neurons to show that their activity is able to accommodate these competing demands by representing novel and familiar individuals in distinct representational geometries. We found that through the encoding of novel animals in low-dimensional representations, CA2 activity enables the identity of novel animals to be readily disentangled from their position. Such low-dimensional representations suffer from having a limited memory storage capacity. We found that CA2 solves this problem by transforming the representations of familiar individuals into a higher dimensional geometry, favoring memory storage at the cost of generalization. Crucially, the degree of this familiarity-induced increase of dimensionality correlated with behavioral performance in a social recognition test. Our results provide the first evidence that experience-dependent transformations in the geometry of neural representations can enable the hippocampal activity to meet the distinct demands of generalization and high-capacity storage needed to support social memory.",
        "url": "https://www.world-wide.org/cosyne-23/hippocampal-modulates-geometry-solve-bfddb7a3"
    },
    "Orbitofrontal cortex forms representations of latent states during learning": {
        "title": "Orbitofrontal cortex forms representations of latent states during learning",
        "authors": "David Barack & C Daniel Salzman",
        "date": "Saturday, 11 March 2023",
        "location": "III-067",
        "abstract": "Both humans and monkeys are skillful at learning to form representations of latent states of their environments, those that must be inferred from observations. The neural circuits that govern this sophisticated skill include the orbitofrontal cortex, hippocampus, amygdala and other regions. Whether these regions merely store representations of latent states or actively construct them remains to be described. Further, if they are constructed, the mechanism for forming them is unknown. Here, we report on monkeys playing a simplified version of the game battleship, designed to investigate learning these latent states, while neural recordings were performed in orbitofrontal cortex. Monkeys visually uncovered one shape per trial over multiple choices. Monkeys were adept learners, as assessed against the optimal choice that maximizes expected reward. Analysis of orbitofrontal neurons suggest a role in learning environmental states. One third of neurons signal the entropy over the distribution of possible states, which dropped during learning as monkeys gathered evidence to rule in or rule out shapes. In addition, the fraction of neurons that represented locations of parts of shapes doubled during learning. Finally, the dimensionality of the population decreased during learning. Our results suggest that the orbitofrontal cortex forms representations of latent states during learning by recruiting neurons into coalitions that increases their covariation and consequently decreases the population dimensionality. Uncovering this role for orbitofrontal cortex extends previous studies by describing how latent state representations are refined over time as evidence is gathered from the environment. Finding evidence for the formation of neural coalitions underlying these representations suggests one mechanism by which representations of latent states are formed.",
        "url": "https://www.world-wide.org/cosyne-23/orbitofrontal-cortex-forms-representations-c72217fe"
    },
    "Distinct transformations of perceptual sensitivity by inhibitory neuron subtypes in V1": {
        "title": "Distinct transformations of perceptual sensitivity by inhibitory neuron subtypes in V1",
        "authors": "Joseph Del Rosario, Soon Ho Kim, Zachary Mobille, Kayla Peelman, Stefano Coletta, Brice Williams, Alejandra Del Castillo Valerio, Hannah Choi, Bilal Haider",
        "date": "Saturday, 11 March 2023",
        "location": "III-068",
        "abstract": "There remains significant debate about the role of cortical inhibition for visual selectivity and perception [1,2]. A long-standing view states feedforward excitation dictates neural selectivity for visual features, while cortical inhibition reacts with unselective feedback simply to regulate activity levels. Yet much work shows that cortical inhibition drives distinct computational transformations of visual selectivity in excitatory neurons [3-7]. It has yet to be shown if these effects of inhibition on neural selectivity also drive equivalent transformations of visual perceptual sensitivity. Here, we provide crucial evidence that activation of different cortical inhibitory neuron types drives distinct computational transformations of neural selectivity, and these changes simultaneously drive equivalent transformations of psychometric sensitivity. Our findings provide a critical missing link between the activity of cortical inhibitory neurons, their effects on neural selectivity, and causal effects on trial-by-trial sensitivity of visual perception. To address this topic, we trained mice to detect visual stimuli of varying contrasts while measuring neural population activity in primary visual cortex (V1). On a fraction of trials, we optogenetically activated parvalbumin (PV) or somatostatin (SST) inhibitory neurons distant from the recording site. This allowed us to probe how inhibition across cortical space impacts neural selectivity and perceptual sensitivity independent from stimulus drive. PV stimulation diminished perceptual responses uniformly across all contrasts, causing a subtractive change in psychometric sensitivity. Surprisingly, SST stimulation caused a divisive change in perceptual sensitivity. A generalized linear model predicted the subtractive or divisive effects on perceptual sensitivity from simultaneously measured changes in neural population activity on single trials, and a leaky-integrate-and-fire (LIF) circuit model identifies that distinct spatial footprints of PV and SST inhibition underlie these effects. These results establish that cortical inhibitory circuits provide multiple distinct routes for flexible transformation of neural selectivity and perceptual sensitivity to visual contrast, a key aspect of visual coding.",
        "url": "https://www.world-wide.org/cosyne-23/distinct-transformations-perceptual-083920bf"
    },
    "“Attentional fingerprints” in conceptual space: Reliable, individuating patterns of visual attention revealed using natural language modeling": {
        "title": "“Attentional fingerprints” in conceptual space: Reliable, individuating patterns of visual attention revealed using natural language modeling",
        "authors": "Caroline Robertson, Katherine Packard, Amanda Haskins",
        "date": "Saturday, 11 March 2023",
        "location": "III-069",
        "abstract": "The eyes are a window into the mind. Eye-tracking studies in the psychology literature report large individual differences in how people deploy attention when scanning photographs of real-world environments. Yet, a key question remains unanswered. Are the eyes a window into a specific mind? In other words, are individual differences in gaze allocation unique to a person and stable within that person? If so, what representational space structures these individual “attentional fingerprints”? Here, we developed a novel approach for describing abstract semantic information present in real-world scenes using a computational language model. We then measured participants’ (N = 42) naturalistic attention while they actively explored real world environments in head-mounted virtual reality. For each participant, we modeled the relationship between their attentional patterns and an abstract semantic feature space (using a natural language processing model, BERT) in N-1 scenes, and iteratively predicted attention in a left-out scene. In brief, we find evidence for reliable, individuating patterns of attention (i.e., “attentional fingerprints”) in abstract semantic space.",
        "url": "https://www.world-wide.org/cosyne-23/attentional-fingerprints-conceptual-96756ef6"
    },
    "Accounting for visual cortex variability with distributed neural activity states": {
        "title": "Accounting for visual cortex variability with distributed neural activity states",
        "authors": "Anna Li, Ziyu Lu, J. Nathan Kutz, Eric Shea-Brown, Nicholas Steinmetz",
        "date": "Saturday, 11 March 2023",
        "location": "III-070",
        "abstract": "Sensory neuron responses vary across repeated presentations of the same stimuli, but whether this trial-to-trial variability represents noise versus unidentified signals remains unresolved (1–3). Some of the variability can be attributed to correlations of neural activity with locomotion, arousal, and other overt movements (4–7). We hypothesized that distributed brain states, i.e., patterns of neural activity observable in other brain regions, may account for more of the unexplained trial-to-trial variability in responses of sensory cortical neurons. To test this, we used Neuropixels 2.0 probes to record neural activity in the mouse primary visual cortex (VISp) while subjects passively viewed images. We recorded videos of behavior alongside neural activity from other brain regions: in some experiments, we recorded spiking activity of anterior cingulate area (ACAd) and in others we recorded widefield calcium signals from the dorsal cortex. We then used reduced rank regression to determine what fraction of the variability in visual responses was attributable to observed behavior and to distant neural activity. Our results indicate that distant neural activity explained 57.6±5% (mean ± SEM) of the maximum explainable VISp variability, significantly (p < 0.001) more than the 24.7±4% explained by the previously demonstrated behavioral factors. The ability to account for so much variability prompted us to consider whether the remaining unexplained variability was consistent with the common assumption that sensory cortical neurons emit spikes according to a Poisson process with time-varying rate (8). We found that the residual unexplained variance of VISp neurons was below that expected from a Poisson process, with a Fano factor of 0.42±0.02, substantially less than 1. Our results argue that the Poisson-like variability arises not from noise but rather is explained by activity patterns shared with other connected brain regions.",
        "url": "https://www.world-wide.org/cosyne-23/accounting-visual-cortex-variability-98d05ffc"
    },
    "Computation with sequences of neural assemblies": {
        "title": "Computation with sequences of neural assemblies",
        "authors": "Max Dabagia, Christos Papadimitriou, Santosh S. Vempala",
        "date": "Saturday, 11 March 2023",
        "location": "III-071",
        "abstract": "Assemblies are subsets of neurons whose coordinated excitation could represent the subject's thinking of an object, idea, episode, or word, and so they provide a promising basis for a theory of how neurons and synapses give rise to higher-level cognitive phenomena. This key role of assemblies was hypothesized by the pioneering work of Hebb, while progress in neural recording technology in recent years has allowed their existence to be experimentally verified. Recent studies have documented the creation and activation of assemblies of neurons in sequence, especially after being trained on tasks involving sequential decisions. Here we study the brain's mechanisms for creating and using assembly sequences in the recently developed Assembly Calculus (AC), a simple and well-defined model of computation in the brain. We show that (1) the repeated presentation of a sequence of stimuli leads to the creation of a sequence of corresponding assemblies; upon future presentation of any small contiguous sub-sequence of stimuli, the corresponding assemblies are activated and continue until the end of the sequence, (2) when the stimulus sequence is projected to two brain areas in a ``scaffold'', both memorization and recall are more efficient, giving rigorous backing to the cognitive phenomenon that memorization and recall are easier with scaffolded memories, (3) more generally, we demonstrate that assemblies can be linked to simulate an arbitrary finite state machine (FSM), thereby capturing the brain's ability to memorize algorithms. This also makes the AC capable of arbitrary computation simply by the presentation of a suitable stimulus sequence, without explicit control commands. These findings provide a theoretical explanation at the neuronal level of complex phenomena such as rat learning behavior and human sequence memorization, as well as a concrete hypothesis as to how the brain's remarkable computational abilities could be realized.",
        "url": "https://www.world-wide.org/cosyne-23/computation-with-sequences-neural-assemblies-1b2e6490"
    },
    "Mechanisms of prediction in linear networks": {
        "title": "Mechanisms of prediction in linear networks",
        "authors": "Jared Salisbury & Stephanie Palmer",
        "date": "Saturday, 11 March 2023",
        "location": "III-072",
        "abstract": "Predicting the future state of the environment is a crucial task for neural systems, which must compensate for significant delays in both sensation and action. Despite this fundamental importance, we lack a rigorous theoretical understanding of the underlying mechanisms of prediction. While several phenomenological and biophysical mechanisms have been proposed to model experimental data, they are typically nonlinear and difficult to analyze. On the other hand, prediction has been exhaustively studied in classical linear filtering theory, but this engineering approach does not explicitly address the question of mechanism. Here, we start with the simplest possible operational definition of prediction and derive necessary and sufficient conditions for a linear network to be predictive. We identify feedback and feedforward inhibition as the primary mechanisms of prediction, and calculate analytically how the temporal horizon for prediction depends on connection weights and time constants for small networks. We then show how to generalize from this first order description to higher order, and prove that the minimum size of the network increases with the complexity of the desired prediction. While the theory is developed in the absence of noise, we demonstrate analytically that sensitivity to noise grows rapidly with the prediction horizon and order, limiting the practical utility of overly ambitious predictors. Finally, we discuss how interacting populations can be made predictive, which is key since strong lateral interactions are associated with a slowing of dynamics. The linear approach developed here provides a basis for understanding nonlinear systems through linearization and conjugacy arguments, and thus unifies some of the disparate nonlinear models in the field. We hope it will aid in the dissection and interpretation of neural circuit motifs involved in prediction, and conjecture that explicitly incorporating mechanisms of prediction in artificial neural networks may facilitate their training and performance on prediction tasks.",
        "url": "https://www.world-wide.org/cosyne-23/mechanisms-prediction-linear-networks-9fcb4a65"
    },
    "Multi-modal composition of physiological signals to delineate candidate cell types in-vivo": {
        "title": "Multi-modal composition of physiological signals to delineate candidate cell types in-vivo",
        "authors": "Chandramouli Chandrasekaran, Anna Lakunina, Santiago Jaramillo, Kenji Lee",
        "date": "Saturday, 11 March 2023",
        "location": "III-073",
        "abstract": "Precise identification of in-vivo cell types using electrophysiological signals would allow for the simultaneous monitoring of different cell populations during behavior. Current approaches typically classify waveforms into broad- and narrow-spiking. However, these methods rarely augment analysis of waveforms with other physiological properties (e.g., inter-spike intervals) or validate against “ground truth” obtained through optotagging. We need a principled and validated approach to combine multiple physiological properties to delineate cell types in-vivo in an unsupervised manner. Our approach, “PhysMAP”, inspired by advances in multi-omics, uses a weighted k-nearest neighbors (WNN) approach to combine physiological properties (e.g., waveform shape, inter-spike interval [ISI], and peri-stimulus time histogram [PSTH]) in order to generate shared latent structure as a high-dimensional graph. We validated PhysMAP using optotagged electrophysiological datasets from mice. In a mouse juxtacellular S1 dataset, cell types were clearly separated by waveform and more modestly separated in ISI and PSTH. We next tested if a multi-modal representation better separated types from one another using two approaches: First, we measured classification accuracy of cell types with a multi-modal representation. We found that—across the board—balanced accuracy was higher for the multi-modal compared to the features of the waveform in isolation. Results were similar for a second in-vivo mouse extracellular dataset from auditory cortex. Second, we performed Louvain clustering on UMAP graphs for either individual modalities or the multi-modal representation and assessed the similarity between the clusters and optotagged cell classes (using the modified adjusted rand index [MARI]). Across Louvain resolutions, MARI was higher for the combined vs. individual modalities. Thus, PhysMAP provides a principled way for unsupervised identification of cell types from electrophysiology. Long term, multi-modal composition is a path towards a physiological database to “lookup” cell types in-vivo.",
        "url": "https://www.world-wide.org/cosyne-23/multi-modal-composition-physiological-d1c63a42"
    },
    "Wake-like Skin Patterning and Neural Activity During Octopus Sleep": {
        "title": "Wake-like Skin Patterning and Neural Activity During Octopus Sleep",
        "authors": "Tomoyuki Mano, Aditi Pophale, Kazumichi Shimizu, Teresa Iglesias, Kerry Martin, Makoto Hiroi, Keishu Asada, Paulette García Andaluz, Thi Thu Van Dinh, Leenoy Meshulam, Sam Reiter",
        "date": "Saturday, 11 March 2023",
        "location": "III-074",
        "abstract": "While sleeping, many vertebrate groups alternate between at least two sleep stages: rapid eye movement (REM) and slow wave sleep (SWS), in part characterized by wake-like and synchronous brain activity respectively. Sleep stage alternation has been implicated in learning and memory function experimentally1, and has motivated several techniques in training artificial neural networks2. If the functions ascribed to 2-stage sleep are truly general, one might expect to find similar phenomena outside the vertebrate lineage. Here we delineate neural and behavioral correlates of 2-stage sleep in octopuses, marine invertebrates which evolutionarily diverged from vertebrates ~550 MYA and have independently evolved large brains and behavioral sophistication. Octopus sleep is rhythmically interrupted by ~60 second bouts of pronounced body movements and rapid changes in their neurally controlled skin patterns. We show that this constitutes a distinct ‘active’ sleep stage, being homeostatically regulated, rapidly reversible, and coming with increased arousal threshold. Neuropixels recordings from the octopus central brain reveal that local field potential (LFP) activity during active sleep resembles that of waking. LFP activity differs across brain regions, with the strongest activity during active sleep seen in the Superior Frontal and Vertical lobes, anatomically connected regions associated with learning and memory function. During ‘quiet’ sleep, these regions are relatively silent but generate LFP oscillations resembling mammalian sleep spindles in frequency and duration. Computational analysis reveals the rich skin pattern dynamics of active sleep, which move through states strongly resembling waking skin patterns. The range of similarities with vertebrates implies that aspects of 2-stage sleep in octopuses may represent convergent features of complex cognition.",
        "url": "https://www.world-wide.org/cosyne-23/wake-like-skin-patterning-neural-activity-4c22ec82"
    },
    "Self-timed self-supervised learning": {
        "title": "Self-timed self-supervised learning",
        "authors": "Rosa Zimmermann & Robert Gütig",
        "date": "Saturday, 11 March 2023",
        "location": "III-075",
        "abstract": "Life can be easier if one knows the structure of the world, for instance, that a distant roar, a whiff of a heavy musky smell, and black stripes on orange background are caused by a single physical entity. Indeed, the question how such structures can be discovered by the neural networks of the brain has challenged neuroscientists for many decades. A key constraint is that central nervous systems must learn about the structure of the world from observing correlations within continuous streams of spikes that arrive from their sensory peripheries. Recently, a novel family of unsupervised spiking neural network models, self-supervised neural networks, have been shown highly potent in discovering ensembles of recurring spike patterns even when their individual occurrences within background noise were rare and temporally asynchronous. In these models an internal supervisory circuit drives learning within a layer of processing neurons by providing teaching signals computed from the processing layer's past activity. A central limitation of these models is their reliance on the presence of an externally given trial structure: The given end of a sensory episode prompts the supervisory circuit to compute its teaching signals and initiate a learning step within the processing layer. Here we develop a self-timed version of self-supervised networks whose teaching circuit requires neither external clock nor trial-end signals, but rather uses the processing layer's activity to also decide the timing of learning steps. We demonstrate that self-timed self-supervised networks match the performance (convergence times) of the original trial-based learning model, substantially broadening the range of settings to which this approach is applicable. We explore the stability of the learning dynamics arising from the interactions between synaptic plasticity and homeostatic mechanisms. Our work provides a biologically plausible unsupervised neural network model for multi-modal learning of recurring spike patterns within parallel continuous sensory streams.",
        "url": "https://www.world-wide.org/cosyne-23/self-timed-self-supervised-learning-2ce14881"
    },
    "Coordinated geometric representations of learned knowledge in hippocampus and frontal cortex": {
        "title": "Coordinated geometric representations of learned knowledge in hippocampus and frontal cortex",
        "authors": "Manuel Schottdorf, Joshua B. Julian, Jesse C. Kaminsky, Carlos Brody, David W. Tank*",
        "date": "Saturday, 11 March 2023",
        "location": "III-076",
        "abstract": "Interactions between frontal cortex and hippocampus (HPC) play a key role in decision-making behaviors. Here, we test how these brain areas coordinate their representations of behavioral and cognitive variables in a task that requires both. We use a virtual reality task in which mice navigate in a T-maze and accumulate transiently visible and stochastic left/right cues to infer the correct reward location. Neural data is recorded acutely with up to 10 Neuropixel shanks simultaneously in bilateral HPC and medial prefrontal cortex (mPFC). To compare neural activity patterns, we analyze this data with state space models, in which each neuron is represented by an activity axis, and population activity constitutes a trajectory in this high-dimensional space. We demonstrate that mPFC neural activity across trials does not fill this space, but lies on a structured, low-dimensional, and non-linear subspace. Population activity can therefore be parameterized by a relatively small number of latent variables that span this neural activity manifold. Similar to previous observations in the HPC, we find that behavioral and cognitive variables, like position in the maze and accumulated visual evidence, are represented as smooth gradients on the mPFC manifold. HPC and mPFC also encoded position and evidence with similar precision and geometry. We demonstrate this similarity between regions by training a decoder on the HPC manifold and decoding behavioral variables from mPFC and vice versa. Despite similar encoding of position and evidence between regions, a communication subspace analysis suggests a differential representation of position and evidence in both areas. The results reported here, together with a growing literature of related findings across brain regions and tasks, contributes to a better understanding of how task-relevant variables might be integrated through mPFC-HPC interactions in decision making.",
        "url": "https://www.world-wide.org/cosyne-23/coordinated-geometric-representations-ee990348"
    },
    "Clustered representation of vocalizations in the auditory midbrain of the echolocating bat": {
        "title": "Clustered representation of vocalizations in the auditory midbrain of the echolocating bat",
        "authors": "Jennifer Lawlor, Melville Wohlgemuth, Cynthia F. Moss, Kishore Kuchibhotla",
        "date": "Saturday, 11 March 2023",
        "location": "III-077",
        "abstract": "Categorical perception of sensory inputs, including human speech, enables adaptive behavior and is thought to emerge in the sensory cortex. There would be significant computational advantages, however, to functional specialization before cortical processing. To what extent do categorical representations emerge earlier in the auditory hierarchy? To address this, we reasoned that the ideal species would exhibit expert auditory sensing and a rich repertoire of vocalizations, akin to human listening and speech. The big brown bat, Eptesicus fuscus, stands out in the animal kingdom for its acoustic communication for self-navigation (through echolocation) and for social interactions (with conspecifics). Eptesicus fuscus move in three dimensions through their environment and must rapidly distinguish between vocalizations intended for navigation and those intended for social interaction. Here, we used two-photon calcium imaging in the awake big brown bat, to enable large-scale (7,868 neurons in three bats), spatially resolved recordings in the inferior colliculus (IC) during auditory playback. We discovered a novel, superficial tonotopy in the IC that was orthogonal to spatially clustered representations of social and navigation vocalizations. Population decoding revealed sharp boundaries across, but not within, these categories. Auditory models for perceptual categorization rely on the idea that the periphery and midbrain possess mostly a feedforward and filter-bank role. Our data support a revised view of categorical perception in which ethologically relevant sensory streams are spatially segregated early in the auditory hierarchy and provide parallel channels of organized information to downstream regions.",
        "url": "https://www.world-wide.org/cosyne-23/clustered-representation-vocalizations-fc297b5a"
    },
    "State-dependent navigation strategies in C. elegans vary with olfactory learning": {
        "title": "State-dependent navigation strategies in C. elegans vary with olfactory learning",
        "authors": "Kevin S. Chen, Jonathan W. Pillow, Andrew Leifer",
        "date": "Saturday, 11 March 2023",
        "location": "III-078",
        "abstract": "Animals flexibly adjust behavior depending on the environmental context and learned experience. The nematode C. elegans modulates its preference towards an odor source depending on its pairing with food or starvation. However, precisely how the worm alters its navigation strategy in response to olfactory learning has not been characterized, in part due to challenges with measuring the exact odor cues in the environment. Here, we used a novel apparatus and optogenetics to measure and then model learned odor-navigation strategies in worms. Specifically, we modelled navigation using a Mixture of Generalized Linear Models (MoGLMs), where each GLM corresponds to a particular strategy known to exist in worms: (1) biased random walk, in which the probability of a turn is modulated by odor concentration and (2) weathervaning, in which the head angle depends on the local odor gradient. We fit this model to detailed locomotion data under a precisely measured butanone odor concentration, after the worm had olfactory learning experiences. The inferred parameters show that learning bidirectionally modulates the sensing kernels for both strategies. We corroborated this finding using optogenetics, confirming that the behavioral response to optogenetic activation of an olfactory neuron is bidirectionally modulated by learning. We then extended our model to a hidden-Markov model (HMM), with each state corresponding to a distinct MoGLM. This model provided a substantially better fit to data, in contrast to prior work assuming worms employ a fixed navigation strategy. Finally, we showed that the inferred HMM outperforms a fixed strategy, indicating that a worm with multi-state switching achieves a normatively better solution to the olfactory navigation problem. By combining a new modeling approach with new measurements of odor-guided behavior, we provide a new paradigm for understanding state-dependent olfactory navigation and learning in C. elegans.",
        "url": "https://www.world-wide.org/cosyne-23/state-dependent-navigation-strategies-876bbd93"
    },
    "Motor cortex fine-tunes preparatory activity to cope with uncertainty": {
        "title": "Motor cortex fine-tunes preparatory activity to cope with uncertainty",
        "authors": "Soyoung Chae & Sung-Phil Kim",
        "date": "Saturday, 11 March 2023",
        "location": "III-079",
        "abstract": "Voluntary movement is often prepared by motor cortex before its execution. Motor cortical neurons exhibit preparatory-activity, a neural correlate of upcoming movement [1]. Animals adopt different behavioral strategies in response to uncertainties existing in nature such as environmental cue informing ‘go’ [2]. However, how motor cortical circuits cope with such uncertainty while benefiting from explicit information is less understood. Here, we analyzed firing activity of anterolateral motor cortex (ALM) while mice performed one of the two different auditory delayed-response tasks: random or fixed delay task. In random delay task, delay length was randomly determined thus mice could not predict when go cue would be given. In fixed delay task, delay length was fixed across trials. We sought out preparation subspace (P) to infer putative preparatory-activity. In both tasks, we found that preparatory-activity on P increased during delay and mechanistic of upcoming movement (e.g., RT) was predicted by neuronal state on P (data not shown here). In random delay task, preparatory-activity on P quickly reached a state to make movement right after delay started and persisted until go cue. Unexpectedly, progression of preparatory-activity on P made RT longer in fixed delay task while resulting in more accurate decisions. In fact, there were positive correlations between behavioral accuracy and RT only in the fixed delay task. Both neuronal and behavioral data supported that preparation process was altered to increase decision accuracy by sacrificing RT to receive more rewards. We further tested why increasing decision accuracy resulted in longer RT. We found that as preparatory-activity was altered in direction of increasing accuracy, it required a larger cost in state transition which result in longer RT. In conclusion, preparatory-activity in motor cortex is altered depending on the presence of time uncertainty by fine-tuning preparatory-activity in a way to respond to temporal predictability.",
        "url": "https://www.world-wide.org/cosyne-23/motor-cortex-fine-tunes-preparatory-3b6c130e"
    },
    "An attractor model explains space-specific distractor biases in visual working memory": {
        "title": "An attractor model explains space-specific distractor biases in visual working memory",
        "authors": "Sanchit Gupta & Sridharan Devarajan",
        "date": "Saturday, 11 March 2023",
        "location": "III-080",
        "abstract": "Working memory (WM) enables retaining and manipulating information for brief periods. Attractor models have been developed for explaining diverse phenomena linked to WM, including error-correcting dynamics [1], cardinal repulsion [2], serial biases [3], and the like [4-5]. Yet, in the real-world, a relevant stimulus must be remembered despite interference from distractors that can occur unpredictably in time and anywhere in space. We provide novel experimental evidence, and suggest a computational mechanism, for biases induced by spatially and temporally unpredictable, task-irrelevant distractors in visual WM. We tested n=24 human participants on a continuous response, visual WM task while recording brain activity with scalp electroencephalography. Briefly, participants memorized the orientation of bilaterally presented gratings following which they were retrospectively cued to the location more likely to be probed for response (70% cue validity). During the WM delay a distractor grating appeared at an unpredictable time and, randomly, with equal probability, at one of the two erstwhile stimulus locations. We discovered that the decoded neural representation of the cued stimulus was systematically biased towards the distractor’s orientation when the latter appeared in the same hemifield as the former (Fig. 1C, p=0.01). Yet, surprisingly, the cued representation was biased away from the distractor’s orientation when they appeared on opposite hemifields (Fig. 1C, p=0.026). A similar pattern of distractor-induced biases occurred for the uncued stimulus also (Fig. 1C; same-hemifield p=0.005, opposite-hemifield p=0.162). Behavioral reports confirmed these antagonistic bias trends (p<0.05, Fig. 1D). We developed a WM model with distinct ring attractors [5] representing stimuli in each hemifield, while also incorporating topographic, cross-hemifield inhibition (Fig. 2A). The model faithfully replicated each of the experimentally observed biases, neural and behavioral (Fig. 2B-C). In sum, task-irrelevant distractors induce space-specific, antagonistic biases in visual WM. Our results suggest that cross-hemifield inhibition suffices to fully explain these biases.",
        "url": "https://www.world-wide.org/cosyne-23/attractor-model-explains-space-specific-cc238aca"
    },
    "Superior colliculus supports touch-guided corrections during licking in mice": {
        "title": "Superior colliculus supports touch-guided corrections during licking in mice",
        "authors": "Brendan Ito, Brian Kardon, Jesse Goldberg",
        "date": "Saturday, 11 March 2023",
        "location": "III-081",
        "abstract": "Successful actions require correcting for movement errors in real-time. When grasping an object, unexpected touches at the hand evoke rapid adjustments in grip. Touch-guided corrections require proprioceptive and mechanosensory feedback to be integrated with ongoing motor commands and transformed into an updated plan. To determine how touch events guide ongoing movements, we combined kilohertz frame-rate imaging and a deep neural network to track lingual kinematics in 3D as head-fixed mice retrieved water from a moving spout. We detected the offset of tongue-spout contact on the first lick (L1) of a lick bout and randomly displaced the spout to the left or right such that the next lick (L2) would nick the spout with the side of the tongue. Mice produced rapid nick-guided corrections: left nicks guided the third lick (L3) left, and right nicks guided L3 right. We used electrophysiology and closed-loop photoinhibition to screen cortical, midbrain, and cerebellar regions previously implicated in directional licking. Neural activity in anterolateral motor cortex (ALM) exhibited contact-related information, but surprisingly, bilateral inactivation of ALM, tongue-jaw primary motor or somatosensory cortex (TJM1, TJS1), and the fastigial nucleus of the cerebellum did not impair touch-guided corrections. Interestingly, bilateral photoinhibition of lateral superior colliculus (lSC) impaired lick kinematics to a larger degree than cortical regions, and unilateral photoinhibition of lSC, but not cortical areas, abolished contact-guided corrections to the contralateral side. Consistent with a role for touch-guided re-aiming, lSC neurons were rapidly activated by contact events on the contralateral surface of tongue. For visuomotor control, SC has been shown to have a sensorimotor map in which a novel stimulus in the contralateral visual field directs saccades to unexpected targets. Our findings suggest that the SC may have an analogous somato-sensorimotor map of tongue space for rapid adjustment of tongue kinematics during licking.",
        "url": "https://www.world-wide.org/cosyne-23/superior-colliculus-supports-touch-guided-8cfc4552"
    },
    "Distributing task-related neural activity across a cortical network through task-independent connections": {
        "title": "Distributing task-related neural activity across a cortical network through task-independent connections",
        "authors": "Christopher Kim, Arseny Finkelstein, Carson Chow, Karel Svoboda, Ran Darshan",
        "date": "Saturday, 11 March 2023",
        "location": "III-082",
        "abstract": "Task-related neural activity is widespread across populations of neurons during goal-directed behaviors. However, little is known about the synaptic reorganization and circuit mechanisms that lead to broad activity changes. Here we trained a limited subset of neurons in a spiking network with strong synaptic interactions to reproduce the activity of neurons in the motor cortex during a decision-making task. We found that task-related activity, resembling the neural data, emerged across the network, even in the untrained neurons. Analysis of trained networks showed that strong untrained synapses, which were independent of the task and determined the dynamical state of the network, mediated the spread of task-related activity. Optogenetic perturbations suggest that the motor cortex is strongly coupled, supporting the applicability of the mechanism to cortical networks. Our results reveal a cortical mechanism that facilitates distributed representations of task-variables by spreading the activity from a subset of plastic neurons to the entire network through task-independent strong synapses.",
        "url": "https://www.world-wide.org/cosyne-23/distributing-task-related-neural-activity-6ef60464"
    },
    "On-line SEUDO for real-time cell recognition in Calcium Imaging": {
        "title": "On-line SEUDO for real-time cell recognition in Calcium Imaging",
        "authors": "Iuliia Dmitrieva, Sergey Babkin, Adam Charles",
        "date": "Saturday, 11 March 2023",
        "location": "III-083",
        "abstract": "Closed-loop neuroscience experimentation, where recorded neural activity is used to modify the experiment on-the-fly, is critical for deducing causal connections and optimizing experimental time. A critical step in creating a closed-loop experiment is real-time inference of neural activity from streaming recordings. One challenging modality for real-time processing is calcium imaging (CI) via multi-photon microscopy. CI enables the recording of activity in large populations of neurons however, often requires batch processing of the video data to extract single-neuron activity from the fluorescence videos. Extremely few methods attempt real-time CI processing, and are often susceptible to spurious noise in the image statistics and difficulties in separating overlapping components. In this work we use the recently proposed robust estimator---Sparse Emulation of Unused Dictionary Objects (SEUDO) algorithm---as a basis for a new on-line frame-by-frame processing algorithm that simultaneously identifies neurons in the fluorescence video and infers their time traces in a way that is robust to as-yet unidentified neurons. Real-time SEUDO (real-SEUDO) initializes the set of known fluorescing components in the video as empty, and iteratively identifies new components (i.e., Regions Of Interest, ROIs) from the streaming CI videos by running the SEUDO and analyzing the residual activity. SEUDO returns the robust estimate of each neuron's activity, providing on-line updates as to the individual component trim-traces. To ensure that real-SEUDO is capable of real-time updates, the processing time of each frame must be less than the sampling period. To achieve this goal, we developed fast C-based implementations of all the algorithms that can run SUEDO and the cell detection stage at >30Hz. We find that the overall quality of real-SEUDO matches offline algorithms (e.g., CNMF), and outperformes the current on-line approach (OnACID).",
        "url": "https://www.world-wide.org/cosyne-23/on-line-seudo-real-time-cell-recognition-424c4241"
    },
    "Direct cortical inputs to hippocampal area CA1 transmit complementary signals for goal-directed navigation": {
        "title": "Direct cortical inputs to hippocampal area CA1 transmit complementary signals for goal-directed navigation",
        "authors": "John Bowler & Attila Losonczy",
        "date": "Saturday, 11 March 2023",
        "location": "III-084",
        "abstract": "The entorhinal cortex (EC) is central to the brain’s navigation system. Its subregions are conventionally thought to compute dichotomous representations for spatial processing: medial entorhinal cortex (MEC) provides a global spatial map, while lateral entorhinal cortex (LEC) encodes specific sensory details of experience. While local recordings of EC circuits have amassed a vast catalogue of specialized cell types that could support navigation computations in the brain, we have little direct evidence for how these signals are actually transmitted outside of the EC to its primary downstream reader, the hippocampus, which itself is critical for the formation of spatial and episodic memories. Here we exploit in vivo sub-cellular imaging to directly record from EC axon terminals as they locally innervate hippocampal area CA1, while mice performed navigational and spatial learning tasks in virtual reality. We find distinct and overlapping representations of task, location, and context in both MEC and LEC axons. While MEC transmitted a highly location- and context-specific code, LEC inputs were strongly biased by ongoing navigational goals and reward. Surprisingly, the position of the animal could be accurately decoded from either entorhinal subregion. Our results challenge prevailing dogma on the routing of spatial and non-spatial information from the cortex to the hippocampus, indicating that cortical interactions upstream of the hippocampus are critical for combining these processing streams to support navigation and memory.",
        "url": "https://www.world-wide.org/cosyne-23/direct-cortical-inputs-hippocampal-area-4ba6c31f"
    },
    "Behavioral and brainwide correlates of dynamic reward prediction": {
        "title": "Behavioral and brainwide correlates of dynamic reward prediction",
        "authors": "Anna Bowen, David Ottenheimer, Garret Stuber, Nicholas Steinmetz",
        "date": "Saturday, 11 March 2023",
        "location": "III-085",
        "abstract": "Adaptive behavior is guided by dynamic evaluations of the reward environment, which can be influenced by factors like reward frequency and internal motivational state. We implemented a behavioral task in water deprived headfixed mice that included fluctuating probabilities of reward following auditory stimuli. Mice adjusted their anticipatory licking, a proxy for reward expectation, according to both the recent reward rate and their diminishing motivation for reward. We developed a reinforcement learning model that revealed the synergistic impacts of recent reward history, overall reward rate, and satiety on individual subjects’ behavior. This model captured session and subject variability and allowed us to calculate a trial-by-trial estimate of expected value. To interrogate the neural implementation of expected value, we recorded the spiking activity of ~10,000 individual neurons across multiple brain systems, including prefrontal cortex, striatum, amygdala, hypothalamus, thalamus, midbrain, and pons. We then performed a kernel regression to predict the activity of individual neurons. By incorporating the model-generated value estimates into our kernel model, we were able to identify neurons across all regions with activity that fluctuated along with value. Interestingly, these value correlates were present in both the tonic activity and phasic cue-evoked responses of individual neurons, with regional differences in the prominence of each. For instance, substantia innominata value neurons had strong value modulation of cue-evoked activity, while prefrontal cortex value neurons modulated their tonic firing according to trial value. Overall, our findings demonstrate a role for proximal and global reward rate, as well as satiety, in subjects’ reward predictions, and indicate the presence of diverse value coding schemes spread across many brain systems with potential to dynamically contribute to adaptive behavior.",
        "url": "https://www.world-wide.org/cosyne-23/behavioral-brainwide-correlates-dynamic-9e14cf1b"
    },
    "The cortical dictionary: high-capacity memory in sparsely connected networks with columnar organization": {
        "title": "The cortical dictionary: high-capacity memory in sparsely connected networks with columnar organization",
        "authors": "Haozhe Shan, Ludovica Bachschmid Romano, Haim Sompolinsky",
        "date": "Saturday, 11 March 2023",
        "location": "III-086",
        "abstract": "Neurons with recurrent connectivity can store memory patterns as attractor states in their dynamics, forming a plausible basis for associative memory in the brain. Classical theoretical results concerning fully connected recurrent neural networks (RNNs) with binary neurons and Hebbian learning rules find that they can store at most O(N) memories, where N is the number of neurons. However, under the physiological constraint that neurons are sparsely connected, this capacity is dramatically reduced to O(K), where K is the average number of presynaptic neurons (estimated to be O(10^3 ∼ 10^4) in mammalian neocortex; note that each connection may consist of multiple synaptic contacts). This reduced capacity is inconsistent with the high capacity of human memory, particularly in language vocabularies and vision. In this work, we propose and analyze a biologically plausible mechanism that restores high-capacity memory storage under sparse connectivity. We assume that neurons in the network are organized into “columns”: in each memory, neurons from the same column encode the same feature(s), similar to columns in primary sensory areas. We propose special column-synchronizing dynamics that can utilize the columnar-coding redundancy to overcome sparse connectivity. We analytically computed the memory capacity of the model using the path-integral formulation from statistical physics. The results show that for a fixed column size M, memory capacity grows linearly with network size N until it saturates at O(MK). For optimal choice of M for each N , the memory capacity column size is O(sqrt(NK)). To our best knowledge, our results provide the first computational basis for storing a large number of memories under sparse connectivity. They also demonstrate a potential benefit of having a redundant neural code in long-term memory where many neurons encode the same memorized feature(s).",
        "url": "https://www.world-wide.org/cosyne-23/cortical-dictionary-high-capacity-memory-fe52cd15"
    },
    "Dissecting modular recurrent neural networks trained to perform un-cued task switching": {
        "title": "Dissecting modular recurrent neural networks trained to perform un-cued task switching",
        "authors": "Yue Liu & Xiao-Jing Wang",
        "date": "Saturday, 11 March 2023",
        "location": "III-087",
        "abstract": "Animals can switch rapidly between multiple well-learned tasks without being explicitly instructed on which task to perform, a cognitive function termed un-cued task switching. This function relies on higher-order cortical areas to maintain and update the task rule representation, and use this representation to gate the sensorimotor pathway. How different brain regions and neuronal types interact to achieve this function is not well understood. We investigated a collection of modular recurrent neural networks (RNNs) trained to perform an analog of the Wisconsin Card Sorting Test (WCST), a classic task involving un-cued task switching. Each network consists of two interacting modules: a “prefrontal cortex (PFC)” module which encodes the task rule and a “sensorimotor” module which performs the sensorimotor mapping conditioned on the rule. Each module contains a canonical circuit with excitatory neurons and three types of inhibitory neurons. We extensively analyzed dozens of networks trained with different hyperparameters and discovered common underlying circuit motifs. Specifically, two types of neuronal responses emerge among the excitatory neurons in the PFC module - one that persistently encodes the rule and the other that transiently encodes the conjunction of negative feedback and rule. The PFC recurrent connectivity matrix can be equivalently described by a low-dimensional connectivity between six neuronal groups. In the sensorimotor module, a geometric relationship between input weight vectors from different stimulus features ensures appropriate action selection. The PFC module gates the sensorimotor module by sending long-range projections that connect excitatory neurons with similar rule preferences. In addition, excitatory neurons in the sensorimotor module are disinhibited by somatostatin (SST) neurons with the opposite rule preference. Lastly, the extent to which different dendritic branches encode different task rules is largely determined by the sparsity of the connections from the SST neurons to the excitatory neurons. Collectively, our study revealed distinct intra-areal and inter-areal neural circuit mechanisms underlying un-cued task switching.",
        "url": "https://www.world-wide.org/cosyne-23/dissecting-modular-recurrent-neural-cc94f973"
    },
    "Cross-trial alignment reveals a low-dimensional cortical manifold of naturalistic speech production": {
        "title": "Cross-trial alignment reveals a low-dimensional cortical manifold of naturalistic speech production",
        "authors": "Cheol Jun Cho, Edward Chang, Gopala Anumanchipalli",
        "date": "Saturday, 11 March 2023",
        "location": "III-088",
        "abstract": "Finding a low-dimensional manifold of neural signals is crucial for understanding neural computation and developing a robust brain-computer interface (BCI). Latent variable models have been proposed to find such manifolds, and proved to be successful in various cognitive and behavioral tasks. However, natural speaking is a complex coordination of multiple motor tasks, and due to such complex nature, it has been challenging to find a low-dimensional and behaviorally relevant manifold of the speech cortex. We hypothesize that contents represented on the manifold should be consistent across repeated trials, and propose to disentangle the contents from the noisy signals by cross-trial alignment. To this end, a sequential autoencoder is trained to yield two temporal factors: signal factor to represent all the information including noise, and content factor to represent cross-trial consistent information. This disentanglement is achieved by contrastive alignment loss which is designed to maximize mutual information (MI) between the content factors and the signal factors, where the signal factors are sampled from other trials and temporally aligned by a jointly trained Aligner. We applied the method to high-density intracranial electrocorticography (ECoG) collected while speaking a set of sentences multiple times. Compared to previous models (e.g., LFADS), the content factor has a much lower effective dimensionality, and articulatory behavior can be best decoded from the factors learned by our approach. Furthermore, pre-/post-speech clusters and rotational dynamics during speaking are clearly identifiable on a single-trial manifold of the content factor, which is not as clear in other factors. Our method reveals a low-dimensional cortical manifold without requiring behavioral readouts, and enables us to characterize dynamic structures of complex naturalistic speaking behavior. These would contribute to understanding neural mechanisms of speech production and improving speech BCIs.",
        "url": "https://www.world-wide.org/cosyne-23/cross-trial-alignment-reveals-low-dimensional-d732d98c"
    },
    "A Method for Testing Bayesian Models Using Neural Data": {
        "title": "A Method for Testing Bayesian Models Using Neural Data",
        "authors": "Gabor Lengyel, Sabyasachi Shivkumar, Ralf Haefner",
        "date": "Saturday, 11 March 2023",
        "location": "III-089",
        "abstract": "Bayesian models have been successful at accounting for human and animal behavior, yet to what degree they can also explain neural activity is still an open question. While decoding approaches that link neural variability to behavioral uncertainty provide some evidence, stronger tests have tried to link posterior beliefs about specific latent variables in a generative model to neural responses. On one hand, the specificity of the resulting predictions is desirable since it allows us to decide which of the infinitely many parameterizations of the task model (ideal observer) is more closely aligned with the brain's internal model. On the other hand, it is unclear under what conditions we can even expect a match of predictions and data given that current models are drastic simplifications of the rich internal model the brain uses. Furthermore, this approach so far has required strong assumptions about how probabilities are represented in neural responses. Here, we formalize and address both of these problems and derive predictions for when they can be overcome. In particular, we show how to meaningfully differentiate between Bayesian models using neural data with a weak assumption about the neural representation of probabilities, i.e. a kind of linearity that holds for a wide class of probabilistic representations including distributed distributional codes (DDCs) and neural sampling schemes. We demonstrate our method by using simulated V1 neural data to differentiate between two Bayesian models for an orientation discrimination task that are practically indistinguishable based on behavior. The first model contains orientation as an explicit variable to be inferred, while the second model assumes inference over a set of oriented gratings. Our results pave the way for strong and rigorous neural tests of Bayesian models of behavior using neural data, and give us deeper insights into how to correctly interpret neural data.",
        "url": "https://www.world-wide.org/cosyne-23/method-testing-bayesian-models-using-0733a2b9"
    },
    "Layer-specific control of cortical inhibition by NDNF interneurons": {
        "title": "Layer-specific control of cortical inhibition by NDNF interneurons",
        "authors": "Laura Naumann, Loreen Hertäg, Henning Sprekeler",
        "date": "Saturday, 11 March 2023",
        "location": "III-090",
        "abstract": "Accurate perception requires the integration of external (bottom-up) and internally generated (top-down) information. The main recipient of top-down projections in cortex is layer 1, which houses the dendrites of pyramidal cells (PC; Schuman et al., 2021). While layer 1 is devoid of excitatory cell bodies, it contains a variety of interneurons, including neurogliaform cells expressing neuron-derived neurotrophic factor (NDNF; Abs et al., 2018). NDNF interneurons are unique in that they provide slow inhibition, partially via non-synaptic volume release of GABA (Pardi et al. 2020). Yet, their contribution to cortical computations is still unclear. Here, we propose that NDNF interneurons control cortical inhibition in a layer-specific manner. Specifically, we suggest that NDNF-mediated volume release targets presynaptic GABA receptors at the outputs of somatostatin-expressing (SOM) interneurons in layer 1, leaving SOM outputs in lower levels unaffected. We demonstrate in a computational model how this mechanism gradually replaces SOM-mediated inhibition to PC dendrites with NDNF-mediated inhibition, which carries top-down rather than bottom-up information and is slower in time. The competition for dendritic inhibition stems from a mutual inhibition motif between NDNF interneurons and SOM outputs. Notably, it relies on presynaptic inhibition and does not require synaptic connections from NDNF to SOM interneurons. We show that the motif can become bistable such that top-down inputs to NDNF interneurons function as a switch for different circuit dynamics. Finally, we find that the connections of NDNF interneurons within the circuit introduce additional (dis-) inhibitory pathways, changing how the circuit responds to cell type-specific perturbations. Our model elucidates how NDNF interneurons restructure inhibitory circuitry in cortical layer 1. Because NDNF interneurons receive a broad range of top-down inputs, the model suggests a neural mechanism by which top-down information can modulate cortical processing on behaviourally relevant timescales.",
        "url": "https://www.world-wide.org/cosyne-23/layer-specific-control-cortical-inhibition-c85238e1"
    },
    "Reduced correlations in spontaneous activity amongst CA1 engram cells": {
        "title": "Reduced correlations in spontaneous activity amongst CA1 engram cells",
        "authors": "Amy Monasterio, Gabriel Ocker, Steve Ramirez, Benjamin Scott",
        "date": "Saturday, 11 March 2023",
        "location": "III-091",
        "abstract": "Memories are believed to be stored in the strengthened synaptic connectivity between distributed networks of neurons after learning. This biophysical memory trace is often referred to as an engram, provisionally defined as the cells activated during learning, reactivated during memory retrieval, and causally linked to the expression of memory. Recent work exploring the activity of these ensembles in vivo demonstrates that after learning, c-Fos tagged populations consist of highly active, correlated ensembles of hippocampal neurons. The current model for engram formation predicts that during learning, c-Fos tagged cells undergo synaptic potentiation, resulting in their increased propensity to be reactivated together during memory retrieval, which has yet to be demonstrated with in vivo recording from engram cells. Given previous modeling work on assembly formation in recurrent networks, we reasoned that if memory formation resulted in strengthened synaptic connectivity between CA3 and CA1 engram cells, we would be able to detect this via increased correlations of their spontaneous activity. Here, we tested this prediction with a spiking network model, in which an ‘engram’ was directly simulated in a population of CA1 neurons by strengthening their common inputs from CA3. We observed a relative increase in pairwise correlations of the spontaneous activity of tagged CA1 engram neurons with one another. We then tested this model in vivo by combining two-photon calcium imaging with the c-Fos driven TetTag system to identify IEG tagged putative engram neurons and simultaneously record their population activity. Surprisingly, we observed that after contextual fear conditioning, c-Fos tagged cells in CA1 displayed relatively lower spontaneous correlations compared to neighboring non-tagged cells, which disagrees with our proposed model. These results are inconsistent with a model of engram formation based on simple Hebbian learning rules in excitatory synapses, and may indicate that engram activation is gated by context-dependent or retrieval-dependent sensory inputs.",
        "url": "https://www.world-wide.org/cosyne-23/reduced-correlations-spontaneous-activity-081315a3"
    },
    "Distinct neural dynamics in prefrontal and premotor cortex during decision-making": {
        "title": "Distinct neural dynamics in prefrontal and premotor cortex during decision-making",
        "authors": "Tian Wang, Nicole Carr, Kenji Lee, Yuke Li, Chandramouli Chandrasekaran",
        "date": "Saturday, 11 March 2023",
        "location": "III-092",
        "abstract": "Dorsolateral prefrontal cortex (DLPFC) and dorsal premotor cortex (PMd) are two association brain areas implicated in decision making. However, whether these brain areas have similar or distinct decision-related dynamics remains an open question. In addition, anatomical studies suggest considerable connectivity heterogeneity between DLPFC areas and parietal lobe, temporal lobe, and ventrolateral prefrontal cortex. Whether different areas within the DLPFC also demonstrate distinct decision-related dynamics is also an open question. We addressed these open questions by comparing the neural dynamics between these two brain areas of monkeys performing a decision-making task. In this task, monkeys discriminated the dominant color of a red-green checkerboard and reported their decision with an arm movement. Randomized target configurations allowed us to decouple color choice from action choice and allowed us to examine representation of task variables, including target configuration, color choice, and action choice (defined as arm reaching direction). Examination of single-unit responses, principal and demixed principal components analysis, and decoding analysis all strongly suggested that neural activity in DLPFC is modulated by target configuration, color choice, and action choice. In contrast, neural activity in PMd was predominantly action choice related, with minimal target configuration and color choice signals across the whole trial. Decoding analysis suggested that all these decision-related variables were more strongly represented in deeper cortical areas of DLPFC compared to the more superficial cortical areas. Our results suggest that during perceptual decisions, choice is computed in deep DLPFC and then emerges in superficial areas of prefrontal cortex and PMd, a result consistent with predictions of multi-area recurrent neural network models [2]. Simultaneous electrophysiological recordings are needed to test this hypothesis. In summary, DLPFC and PMd demonstrated distinct dynamics as DLPFC encodes target configuration, color, and direction signals, while PMd is largely responsive only to action choice.",
        "url": "https://www.world-wide.org/cosyne-23/distinct-neural-dynamics-prefrontal-9f68ad5e"
    },
    "Retuning of Hippocampal Place Representations During Sleep": {
        "title": "Retuning of Hippocampal Place Representations During Sleep",
        "authors": "Kamran Diba, Kourosh Maboudi, Caleb Kemere, Bapun Giri, Hiroyuki Miyawaki",
        "date": "Saturday, 11 March 2023",
        "location": "III-093",
        "abstract": "Hippocampal representations that underlie spatial memory undergo continuous refinement following formation during exploration. Understanding the role of sleep in this process has been challenging because of the inaccessibility of place fields when animals are not actively exploring a maze. Here, we devised a novel Bayesian learning approach based on the spike-triggered average decoded position in ensemble recordings to track dynamically the spatial tuning of individual neurons during offline states in freely moving rats. Measuring these dynamic tunings, we found spatial representations within hippocampal sharp-wave ripples that were stable for hours during sleep and were strongly aligned with place fields initially observed during maze exploration. In multiple regression analysis, these representations were explained by a combination of factors that included the pre-configured structure of firing rates in sleep before exposure to the environment, and representations that emerged during theta oscillations and awake sharp-wave ripples on the maze, revealing the contribution of these events in forming ensembles during sleep. Strikingly, the ripple representations during sleep predicted the future place fields of neurons during re-exposure to the maze, even when those fields deviated from previous place preferences. These observations demonstrate that ripples during sleep drives representational drift observed across maze exposures. In contrast, we observed tunings with poor alignment to maze place fields during other time periods, including in sleep and rest before maze exposure, during rapid eye movement sleep, and following the initial several hours in slow-wave sleep. In sum, the novel decoding approach described here allowed us to infer and characterize the retuning of place fields during offline periods, revealing the rapid emergence of representations following novel exploration and the active role of sleep in the representational dynamics of the hippocampus.",
        "url": "https://www.world-wide.org/cosyne-23/retuning-hippocampal-place-representations-b48fb284"
    },
    "Compact neural representations in co-adaptive Brain-Computer Interfaces": {
        "title": "Compact neural representations in co-adaptive Brain-Computer Interfaces",
        "authors": "Pavithra Rajeswaran, Alexandre Payeur, Guillaume Lajoie, Amy L. Orsborn",
        "date": "Saturday, 11 March 2023",
        "location": "III-094",
        "abstract": "Brain-computer interfaces (BCIs) offer a unique method to study learning dynamics by defining a causal mapping between neural activity and movement. Examples include studying the acquisition of an arbitrary sensorimotor mapping or perturbing a learned mapping to study adaptation. Alternatively, the sensorimotor mapping (“decoder”) can be purposefully adapted in closed loop, as the subject controls the BCI, to improve performance. Beyond improving performance for applications, closed-loop decoder adaptation (CLDA) also allows the study of learning mechanisms under changing motor demands. Here, we studied neural plasticity in an adaptive BCI. Monkeys controlled a cursor towards targets using multi-unit activity from motor cortex. CLDA was used to both improve performance of initial decoders and to replace non-stationary units to maintain performance across days. We first analyzed the evolution of target encoding in both readout units and non-readout units (units recorded but not used for BCI control) using multiclass logistic regressions. During training, the readouts became significantly more predictive than the non-readouts, showing that credit was preferentially assigned to the readouts. Also, only a subset of units became necessary for efficient target encoding, which we define as a compact representation. This has not been reported with fixed decoders. To explore whether CLDA contributed to forming compact representations, we developed a novel neural network model with biologically plausible learning to simulate BCI tasks with and without decoder adaptation. Without CLDA, the representation was on average less compact, as determined by the impact of each readout neuron on task performance. Our findings reveal a potentially fragile neural representation dominated by only a few units that directly results from adapting sensorimotor mappings during learning. As a testbed that captures properties of experimental data, our model can be used to design new CLDA strategies to maintain performance while also creating redundant neural encodings needed for robust performance.",
        "url": "https://www.world-wide.org/cosyne-23/compact-neural-representations-co-adaptive-0898463c"
    },
    "Myelin loss disrupts neural synchrony directing skilled motor behavior in mouse primary motor cortex": {
        "title": "Myelin loss disrupts neural synchrony directing skilled motor behavior in mouse primary motor cortex",
        "authors": "Kimberly Gagnon, Gustavo Della Flora Nunes, Dailey Nettles, Ryan Williamson, Daniel Denman, Ethan Hughes, Cristin Welle",
        "date": "Saturday, 11 March 2023",
        "location": "III-095",
        "abstract": "Synchronization of neural activity is a fundamental component of information processing in the nervous system. Precise axonal conduction is required for correlated spiking activity between pairs of neurons at the millisecond timescale. Previous studies report that myelin loss results in deficient action potential propagation and a loss of population synchronization in the gamma band. Loss of myelination in demyelinating diseases like multiple sclerosis (MS) results in impaired motor function in patients with MS. However, a deeper understanding of how demyelination alters the timing, synchrony, and connectivity of motor microcircuits underlying behavioral impairments is needed. To determine the effect of demyelination on microcircuits required for skilled motor performance, high density Neuropixel recordings were performed in mice trained in a dexterous reaching task. Demyelination was induced via oral delivery of cuprizone, and concurrent in vivo two-photon imaging tracked myelin loss and repair in MOBP-EGFP transgenic mice. We found that varying degrees of demyelination concomitantly altered pairwise coordination of cortical neurons and behavioral performance. Furthermore, we found that demyelination caused layer-specific and cell-type specific hyperexcitability. Unexpectedly, we found that hyperexcitability was closely correlated with higher levels of remyelination and behavioral performance. Understanding how demyelination alters cortical microcircuits and neural synchrony to influence behavior will provide insights into the role of myelin in neural computation and strategies for recovery from myelin loss.",
        "url": "https://www.world-wide.org/cosyne-23/myelin-loss-disrupts-neural-synchrony-948d0543"
    },
    "Recurrent circuits improve neural response prediction and provide insight into cortical circuits": {
        "title": "Recurrent circuits improve neural response prediction and provide insight into cortical circuits",
        "authors": "Harold Rockwell, Sicheng Dai, Yimeng Zhang, Stephen Tsou, Ge Huang, Yuanyuan Wei, Tai Sing Lee",
        "date": "Saturday, 11 March 2023",
        "location": "III-096",
        "abstract": "Feedforward convolutional neural networks are currently the state-of-the-art approach for characterizing the transfer function of early visual cortical neurons. It is well known that the visual cortex has massive recurrent connections. Would models using recurrent circuits provide better neural response prediction than feedforward models? Here, we show that recurrent models consistently outperform feedforward ones when their parameters and hyperparameters are carefully matched. These benefits are robust against variation in the type of activation functions, loss function, number of channels, and many other hyperparameters. They are generally higher when lower amounts of data are used, suggesting that recurrence improves data-efficiency. We test our models on three datasets with different stimulus presentation paradigms, and find that the improvement of recurrent models is greater when stimuli are presented through a wide-field aperture as opposed to a receptive field-sized aperture, and for a long duration as opposed to a short one. Since both of those conditions likely increase the amount of recurrent processing involved in generating the recorded cortical data, we view this as supporting the claim that the recurrent models’ learned circuits are performing a similar function to the real cortical circuits. Additionally, we propose a new formulation of our recurrent models as ensembles of multiple, weight-tied feedforward processing paths of different lengths. This reformulation allows us to test the effect of removing paths from the models, and comparing the results between datasets, we find that longer paths, resulting from more recurrent processing, are more important for wide-aperture, long-duration recordings. This adds credence to our analysis based on the recurrent models’ performance improvement, and supports its suggestion that in order to characterize the properties of cortical responses generated by recurrence, stimulation paradigms that evoke that recurrence, as well as models suited to match it, are required.",
        "url": "https://www.world-wide.org/cosyne-23/recurrent-circuits-improve-neural-response-55595de6"
    },
    "Exactly-solvable statistical physics model of large neuronal populations": {
        "title": "Exactly-solvable statistical physics model of large neuronal populations",
        "authors": "Christopher Lynn, Caroline Holmes, Qiwei Yu, Stephanie Palmer, William Bialek",
        "date": "Saturday, 11 March 2023",
        "location": "III-097",
        "abstract": "In networks of neurons, fine-scale interactions build upon one another to produce large-scale patterns of activity. But inferring these interactions from state-of-the-art experiments poses a fundamental challenge: As the number of cells increases, the number of possible interactions quickly outpaces the number of available statistics. Thus, rather than inferring all interactions, one must focus on a sparse network. Here, we seek to identify the most informative network of effective interactions in large neuronal populations. We show that the optimal network -- in a precise information-theoretic sense -- is the one that provides the most information about the population while remaining maximally ignorant about all other interactions. For general networks, solving this \"minimax entropy\" problem is computationally prohibitive. However, for networks with tree topologies, we present an exact solution; that is, we propose a method for efficiently inferring the maximally informative tree of interactions in large populations. We apply our method to over one thousand neurons in the mouse hippocampus. Despite containing only 0.1% of all possible interactions, the optimal tree reduces the entropy of independent neurons by 14% (over 50 times more than a random tree). In fact, the optimal tree accurately predicts the distribution of population-wide activity and even increases in accuracy as the population grows. Moreover, while random interactions are nearly evenly split between positive and negative, the optimal tree is almost entirely positive, with activity in one neuron inducing activity in the others. Together, these results suggest that a sparse network of strong excitatory interactions may guide the collective activity. Broadly, our framework allows principled models from statistical physics to keep pace with the explosion of large-scale neural recordings.",
        "url": "https://www.world-wide.org/cosyne-23/exactly-solvable-statistical-physics-308e9d0c"
    },
    "A role for cortical pattern separation in enhancing visual memory": {
        "title": "A role for cortical pattern separation in enhancing visual memory",
        "authors": "Catrina Hacker, Barnes Jannuzi, Travis Meyer, Madison Hay, Nicole Rust",
        "date": "Saturday, 11 March 2023",
        "location": "III-098",
        "abstract": "Humans have a remarkable ability to remember whether they've seen an image before, with considerable visual detail. Unlike the visual perceptual confusions of images, visual memory confusions are not approximately predicted by the distances between population representations in inferotemporal cortex (ITC), or its analogs in artificial neural networks. The leading hypothesis to account for this discrepancy proposes that the hippocampus (HC) applies a nonlinear transformation of its cortical inputs to better separate them before memory storage, a mechanism called hippocampal pattern separation (HPS). Less appreciated is evidence that cortical adaptation can also separate population responses under real-world and often-encountered conditions, when visual inputs are enriched for one type (for example, seeing a dog among many other dogs at a dog park). We call this mechanism adaptation-induced cortical pattern separation (aCPS), and we propose that it enhances visual memory. To determine relative contributions of HPS and aCPS to visual memory, we recorded from monkey ITC and HC during a single-exposure visual familiarity task. Images appeared in one of two types of short blocks: random blocks with images from many categories, or categorical blocks enriched for a single object category. We found evidence for both aCPS and HPS in our data, however, aCPS was 4.5-fold more effective at separating the population responses to images than HPS. Additionally, we estimated the behavioral consequence of aCPS to be considerable: a 35% enhancement in memory performance relative to a hypothetical world without it. Finally, to evaluate the plausibility that aCPS operates via adaptation, we extended the IT-layer of an artificial neural network to simulate this mechanism and found that the resulting model recapitulated notable signatures of our data. Together, these results establish a role for cortical pattern separation in enhancing visual memory under conditions that are often encountered during real world viewing.",
        "url": "https://www.world-wide.org/cosyne-23/role-cortical-pattern-separation-enhancing-c16ea3aa"
    },
    "State-dependent modulation of dependencies in a laminar cortical circuit": {
        "title": "State-dependent modulation of dependencies in a laminar cortical circuit",
        "authors": "Alec Sheffield, Anirban Das, Anirvan Nandy, Monika Jadi",
        "date": "Saturday, 11 March 2023",
        "location": "III-099",
        "abstract": "Adaptive information processing is crucial for flexible brain function and spatial attention is a quintessential example of this process. It is crucial for recognizing and interacting with behaviorally relevant objects in a cluttered environment. How the deployment of spatial attention aids hierarchical computations of object recognition is unclear. Two key mechanisms have been proposed: First is an improvement in the efficacy of information transfer, supported by an attentional increase in inter-areal correlations along the hierarchy. A second proposal is an improvement in information capacity through a reduction of shared fluctuations, supported by attentional decrease in correlations within a visual area. Since pairwise correlations capture both directed and shared components of fluctuations, it is unclear if they support the proposed mechanisms. To test these proposals, it is crucial to estimate the attentional modulation of directed information across and shared information within the stages of visual hierarchy. Using network-based statistical modeling of laminar activity in visual area V4, we estimated the strength of laminar directed dependencies. We quantified their modulation across attention conditions (attend-in vs. attend-away) in a change detection task and found that they are indeed strengthened between the input and superficial layers. Using partial information decomposition framework, we estimated modulation of shared dependencies and found that they are reduced within laminar populations. Surprisingly, we found a strengthening of directed dependencies within the laminar populations, a finding not previously predicted. Crucially, this modulation pattern was also observed across behavioral outcomes (hit vs. miss) that are mediated by endogenous state fluctuation. By “decomposing” the modulation of dependency components and in combination with prior theoretical work, our results suggest a computational model - enhanced information flow between and improved information capacity within encoding stages - of optimal sensory states that are attained by either task demands or endogenous fluctuations in brain state.",
        "url": "https://www.world-wide.org/cosyne-23/state-dependent-modulation-dependencies-986bc7c3"
    },
    "Dopamine projections to the basolateral amygdala drive the encoding of identity-specific reward memories": {
        "title": "Dopamine projections to the basolateral amygdala drive the encoding of identity-specific reward memories",
        "authors": "Ana Sias, Yousif Jafar, Caitlin Goodpaster, Kathia Ramírez-Armenta, Tyler Wrenn, Nicholas Griffin, Melissa Sharpe, Kate Wassum",
        "date": "Saturday, 11 March 2023",
        "location": "III-100",
        "abstract": "Summary: Dopamine has long been known to critically contribute to learning. The canonical view is that midbrain dopamine neurons broadcast errors in reward prediction. These learning signals are thought to cache the general value of an outcome to its predictor and to reinforce response policies that rely on past success, rather than forethought of specific outcomes. But, to ensure flexible behavior, we do not just learn the general value of predictive events. We also encode the relationships between these cues and the identifying features of their associated outcomes. Such stimulus-outcome memories are fundamental components of the internal model of environmental relationships we use to generate the predictions and inferences needed for flexible, advantageous decision making. New data have challenged the value-centric dogma of dopamine function, indicating it plays a much broader role in learning than originally thought, including potentially supporting stimulus-outcome learning. Here we reveal a role for dopamine in forming detailed identity-specific stimulus-outcome memories and evaluate the pathway through which this occurs. Using fiber photometry, cell-type and pathway-specific bidirectional optogenetic manipulations, Pavlovian cue-reward conditioning, and a decision-making test in male and female rats, we show that ventral tegmental area dopamine (VTADA) neurons drive the encoding of stimulus-outcome memories through projections to the basolateral amygdala (BLA). Dopamine is released in the BLA during stimulus-outcome pairing and VTADA-->BLA activity is both necessary and sufficient to link the identifying features of a reward to a predictive cue, but does not mediate general value assignment or reinforcement. These data reveal a critical pathway through which dopamine mediates the encoding of identity-specific reward memories and, more broadly, suggest dopamine may support different forms of learning through its projections to diverse targets.",
        "url": "https://www.world-wide.org/cosyne-23/dopamine-projections-basolateral-amygdala-4626a8fc"
    },
    "V4 neurons are tuned for local and non-local features of natural planar shape": {
        "title": "V4 neurons are tuned for local and non-local features of natural planar shape",
        "authors": "Tim Oleskiw, James Elder, Gerick Lee, Andrew Sutter, Anitha Pasupathy, Eero Simoncelli, J. Anthony Movshon, Lynne Kiorpes, Najib Majaj",
        "date": "Saturday, 11 March 2023",
        "location": "III-101",
        "abstract": "Planar shape, i.e., the silhouette contour of a solid body, carries rich information important for object recognition, including both local (curvature) and global shape cues. While curvature-selective neurons have been identified in area V4 of primate, it remains unclear whether a) curvature is the best way to characterize the shape selectivity of these neurons and b) whether selectivity is limited to local shape. Here we employ a unique array of shape stimuli to dissociate tuning for local and global shape properties. These stimuli have been used previously to identify an intriguing congruence between the curvature statistics of natural shape and the population response of shape-selective V4 neurons. However, this evidence is indirect, as neural curvature selectivity was not analyzed at the single-neuron level. To address these limitations, we first assess how model neurons, trained on single-unit V4 responses, encode the curvatures of various shape stimuli. A mutual information analysis reveals that these neurons are tuned to extract information more efficiently from shapes with natural curvature distributions, indicating a tuning to the ecological statistics of curvature. Second, to more directly measure neuronal tuning for natural shape we recorded activity from area V4 of a juvenile Macaca nemestrina observing natural and synthetic shapes. Consistent with our model neuron analysis, we found that synthetic shapes with natural curvature distributions elicited stronger responses than synthetic shapes with more random distributions, despite having much lower entropy. Remarkably, we also found that natural shapes elicited stronger V4 responses than synthetic shapes with matching curvature statistics, indicating selectivity for non-local shape features. Together, our findings demonstrate for the first time that V4 neurons are tuned to the ecological statistics of both local and non-local object shape not explained by existing models of V4 shape selectivity.",
        "url": "https://www.world-wide.org/cosyne-23/neurons-tuned-local-non-local-features-8df476df"
    },
    "Credit-based self-organization yields cortex-like topography in deep convolutional networks": {
        "title": "Credit-based self-organization yields cortex-like topography in deep convolutional networks",
        "authors": "Amirozhan Dehghani & Pouya Bashivan",
        "date": "Saturday, 11 March 2023",
        "location": "III-102",
        "abstract": "Across the primate neocortex, neurons dedicated to similar functions are likely to be found physically nearby. In the high-level visual cortex, this principle gives rise to cortical patches with distinct category selectivity that were previously observed across many species including macaque monkeys and humans. Models of visual cortex based on artificial neural networks (ANN) have been shown to contain internal representations that are remarkably similar to those observed in the visual cortex. However, unit selectivity in these models emerges without any particular spatial order (i.e. no topography). Recent work has made progress in building models with inherent topography, however, the efficacy of these approaches has only been demonstrated in shallow ANNs or partly-topographic ANNs [1,2]. Inspired by Kohonen’s self-organizing feature maps (SOM), we propose a new algorithm for learning topographically organized representations in neural networks which we call credit-based SOM (CB-SOM). Unlike Kohonen’s SOM which relies on unit activation for competitive selection of units during learning, CB-SOM guides the selection process by considering each unit’s assigned credit in lowering a behaviorally relevant objective. We trained several variations of the ResNet18 architecture on Imagenet dataset while enforcing topographical organization between units in all layers of this network according to: a) Kohonen’s SOM; b) Kohonen’s SOM with random unit selection; c) Kohonen’s SOM with credit-based unit selection. We show that 1) convolutional networks with topographic representations across all layers can be trained with moderate reduction in their behavioral performance (~17-27% top-1 accuracy on Imagenet-Fig.3); 2) topographically organized categoryselective patches emerge in neural networks trained with different variations of SOM algorithm (Fig. 1,2,4); 3) the emerging category-selective patches in CB-SOM are substantially more brain-like compared to alternative models (Fig.3). Together, these results highlight the potential of credit-based competitive algorithms such as that presented here in replicating the cortical topography in modern ANNs.",
        "url": "https://www.world-wide.org/cosyne-23/credit-based-self-organization-yields-688b73af"
    },
    "Eigenvalue spectral properties of sparse random matrices for neural networks": {
        "title": "Eigenvalue spectral properties of sparse random matrices for neural networks",
        "authors": "Isabelle Harris, Hamish Meffin, Anthony Burkitt, Andre Peterson",
        "date": "Saturday, 11 March 2023",
        "location": "III-103",
        "abstract": "We study randomly connected neural networks to understand the effects of network architectures on network dynamics. Specifically, we examine the impact of sparse connectivity combined with Dale’s law on network stability by analysing the eigenspectrum of the networked Jacobian. Previous work has examined the effects of Dale’s law for fully connected random matrices that are balanced (zero mean) [3] or unbalanced [1] and sparse matrices with constant weights for each population [2]. Our work significantly extends these results by integrating both Dale’s law and sparsity into both balanced and unbalanced matrices with random weights. We find that the stability and density of the eigenspectrum becomes nonlinearly dependent on the sparsity, population means and variances of the weights and give explicit formulae describing this. Contrary to the balanced, single population case where the sparsity linearly scales the eigenspectrum [5], we find for unbalanced, single populations and (un)balanced two population cases, the sparsity scales the eigenspectrum nonlinearly. This happens for all cases except when both population means are zero, i.e., the balanced single population case. Further, we show the eigenspectral density becomes non-uniform for the above cases which extends previous results. We give an explicit formula for the spectral density when sparsity is introduced with Dale’s law: the spectral radius and density has a nonlinear dependence on the population means, variances and sparsity parameter for both the balanced and unbalanced cases. We deduce new analytical formulas for the eigenspectral radius and outlier, which explicitly describes how these properties nonlinearly change as functions of the sparsity parameter, the individual population means and variances. Sparsity and Dale’s law are fundamental anatomical properties of biological neural networks, and by quantifying the effects of these properties, we gain insight into how network structure influences system stability and neural network behaviour.",
        "url": "https://www.world-wide.org/cosyne-23/eigenvalue-spectral-properties-sparse-0dfac3f4"
    },
    "Exploring a neural circuit for estimating ambient wind direction in flight": {
        "title": "Exploring a neural circuit for estimating ambient wind direction in flight",
        "authors": "Christina May, John Crimaldi, Floris van Breugel, Katherine Nagel",
        "date": "Saturday, 11 March 2023",
        "location": "III-104",
        "abstract": "To navigate in a natural environment, a flying fly must estimate and contend with external forces such as wind. Estimating wind direction is difficult because the fly cannot directly sense ambient wind in flight. Instead, the fly experiences a vector sum of self-generated motion and the motion imposed by wind, which produces both mechanosensory (airflow) and visual (optic flow) experience. How the fly brain integrates these sensory inputs to estimate ambient wind direction is not known. Here we explore how a circuit in the Drosophila Central Complex (CX) might integrate airflow and optic flow experience to estimate wind direction during flight. We first developed a physical model to estimate the airflow and optic flow a flying fly experiences during wind gusts. This model demonstrates that wind causes airflow and optic flow directions to diverge, with transient changes in airflow direction followed by sustained changes in optic flow direction. We next imaged calcium activity from a set of CX inputs, called PFNs, that had previously been shown to encode airflow and optic flow. We found that one population (PFNd) encodes both airflow and optic flow direction with dynamics that mimic those seen in our physical model (transient airflow and sustained optic flow responses). In response to coherent airflow and optic flow, PFNd neurons exhibit nonlinear amplification, suggesting they encode confidence about the fly’s direction of travel. Finally, we examined calcium activity in a set of downstream local neurons called h∆J. While PFNd neurons respond reliably to the same stimulus across trials, h∆J neurons show divergent responses to the same stimulus. h∆J neurons instead accumulated stable patterns of activity over minutes, suggesting a role in estimating wind direction from noisy sensory input. Together, these models and experiments illuminate circuit principles for estimating the direction of an external force from complex multi-sensory experience.",
        "url": "https://www.world-wide.org/cosyne-23/exploring-neural-circuit-estimating-2afb75f4"
    },
    "Differential Stability of Task Variable Representations in Retrosplenial Cortex": {
        "title": "Differential Stability of Task Variable Representations in Retrosplenial Cortex",
        "authors": "Luis Franco & Michael Goard",
        "date": "Saturday, 11 March 2023",
        "location": "III-105",
        "abstract": "Cortical neurons store information across different timescales, from seconds to years. Although the stability of cortical representations is variable across regions, it can vary within a region as well. Association areas are known to multiplex behaviorally relevant variables, but it is not known whether all task variables are stored with similar representational stability. Here, we longitudinally measured the activity of neuronal populations in the retrosplenial cortex (RSC) using two-photon calcium imaging during the performance of a context-choice association task. We find that the activity of neurons tuned to three relevant task variables exhibits distinct levels of stability across days. Moreover, using linear classifiers trained on a reference day, we quantified the coding stability of these task variables. We find that RSC representations of environmental context and trial outcome display higher stability than motor choice, both at the single cell and population levels. Together, our findings show an important characteristic of association areas, where diverse information is stored with varying levels of stability, maintaining an adequate balance between stability and flexibility to subserve behavioral demands.",
        "url": "https://www.world-wide.org/cosyne-23/differential-stability-task-variable-3b44d96b"
    },
    "The modulation of social decision-making function by dominance status in male mice": {
        "title": "The modulation of social decision-making function by dominance status in male mice",
        "authors": "Neven Borak & Johannes Kohl",
        "date": "Saturday, 11 March 2023",
        "location": "III-106",
        "abstract": "An animal’s dominance status strongly affects its behavioural decision making in social contexts. While the thalamocortical circuitry involved in the establishment of male mouse social status has received much attention in the literature, it remains unclear how these representations of rank modulate downstream areas to yield distinct behavioural phenotypes. Here we report in vivo miniscope recordings from the medial preoptic area (MPOA) and the ventromedial hypothalamus (VMH) - two areas involved in social decision-making that show differential c-Fos expression depending on social rank. Recordings were made during the tube test, an established assay of social dominance – and during chemoinvestigation of male and female conspecifics. A linear model could predict tube test behaviours such as pushing, resisting, and retreating with high accuracy from the activity of both areas, suggesting their involvement in competitive behaviour. We also found differences between dominant and subordinate mice in the tuning properties and behaviour evoked neural responses in these areas and correlated these differences with the behavioural traits of the animal. Additionally, the low-dimensional population dynamics compared across mice using canonical correlation analysis (CCA) were found to be more strongly correlated between mice of the same rank compared to mice of opposite ranks, which indicates neuromodulation of these areas by dominance status. Preliminary optogenetic stimulation of projections from the medial prefrontal cortex – an area previously shown to encode dominance – to the MPOA indicates enhanced competitive performance in the tube test. Together, these results characterise the modulation of social perception in the hypothalamus by dominance rank and how that can result in distinct behavioural phenotypes. They also propose a unifying circuit model that integrates these nodes into the existing thalamocortical circuit that encodes rank.",
        "url": "https://www.world-wide.org/cosyne-23/modulation-social-decision-making-function-5ac2aca9"
    },
    "Critical Learning Periods for Multisensory Integration in Deep Networks": {
        "title": "Critical Learning Periods for Multisensory Integration in Deep Networks",
        "authors": "Michael Kleinman, Alessandro Achille, Stefano Soatto",
        "date": "Saturday, 11 March 2023",
        "location": "III-107",
        "abstract": "We show that the ability of a neural network to integrate information from diverse sources hinges critically on being exposed to properly correlated signals during the early stages of learning. Interfering with the learning process during this initial stage can permanently impair the development of a skill, both in artificial (Achille et al., 2019) and biological systems where the phenomenon is known as a critical learning period (Wiesel, 1982). Critical periods have since been described in many different species and sensory organs: for example, barn owls originally exposed to misaligned auditory and visual information cannot properly localize prey (Knudsen & Knudsen, 1990). We show that critical periods arise from the complex and unstable early transient dynamics, which are decisive of final performance of the trained system and their learned representations. In fact, using a simple linear model, we show that deep linear networks exhibit critical learning periods for multi-source integration, while shallow networks do not. We also find the existence of critical learning periods for deep multi-source networks on image classification tasks, in the presence of a temporary weak or uncorrelated source. To better understand how the internal representations change according to disturbances or sensory deficits on realistic tasks, we introduce a measure of source sensitivity, which allows us to track the inhibition and integration of sources during training. Our analysis of inhibition suggests cross-source reconstruction as a natural auxiliary training objective, and indeed we show that architectures trained with cross-sensor reconstruction objectives are remarkably more resilient to critical periods. Our findings shed light on how critical learning periods may arise from competition between sources, which begins during the early stages of development in deep artificial and biological networks.",
        "url": "https://www.world-wide.org/cosyne-23/critical-learning-periods-multisensory-145305d4"
    },
    "Hebbian learning of a multi-layered cerebellar network with quadratic memory capacity": {
        "title": "Hebbian learning of a multi-layered cerebellar network with quadratic memory capacity",
        "authors": "Naoki Hiratani",
        "date": "Saturday, 11 March 2023",
        "location": "III-108",
        "abstract": "A fundamental goal of neuroscience is the functional understanding of neural circuit architecture. Previous studies revealed the importance of network depth in visual and auditory circuits, but it remains elusive why predominantly non-convolutional circuits, such as the cerebellum or olfactory systems, have multiple feedforwardly connected layers. Recent deep learning works revealed that a two-hidden-layer network has a quadratically more memory capacity than a single-hidden-layer network with the same number of hidden layer neurons, suggesting the importance of the network depth for memory capacity. However, those studies were based on non-local tuning of synaptic weights; thus, whether the depth provides memory gain to the brain under biologically-plausible learning remains unclear. Here, we show analytically, and demonstrate numerically, that error-driven Hebbian learning is sufficient to achieve quadratic memory capacity in a two-hidden-layer network with gating when the activity sparseness is optimized. This gated two-hidden-layer network exhibits several similarities with the cerebellum: First, the cerebellum mainly has two hidden layers, granule cells and Purkinje cells, between mossy fibers (input) and cerebellar nuclei (output). Secondly, learning takes place at the connections between granule cells and Purkinje cells, which is modulated multiplicatively by the presynaptic activity, an error signal from climbing fiber, and shunting inhibition from stellate cells. Lastly, the number of granule cells is similar to the total number of Purkinje cell dendritic branches, though much more numerous than the Purkinje cell population. Our work thus advances the Marr-Albus-Ito model of the cerebellum from a deep learning perspective.",
        "url": "https://www.world-wide.org/cosyne-23/hebbian-learning-multi-layered-cerebellar-c5a7d443"
    },
    "Cerebellar interneurons encode single steps in locomotion": {
        "title": "Cerebellar interneurons encode single steps in locomotion",
        "authors": "Heike Stein, Andry Andrianarivelo, Jeremy Gabillet, Clarisse Batifol, Alex Cayco Gajic, Michael Graupner",
        "date": "Saturday, 11 March 2023",
        "location": "III-109",
        "abstract": "Locomotion in complex environments depends on the precise timing and active control of single paw movements in order to adapt steps to surface structure and coordinate between paws. Control of motor timing crucially depends on the cerebellum, which has been shown to provide signals necessary for movement initiation and termination. While recent work found single-paw kinematics during locomotion to be encoded in cerebellar Purkinje cells, precise, event-related activity in the cerebellum in more complex environments is less well understood. Moreover, whether precise action timing in complex environments is controlled upstream in the cerebellar circuit is currently unknown. To address this question, we studied step-related activity in cerebellar molecular layer interneurons (MLIs) which provide direct, fast control of Purkinje cell activity. We trained mice to walk on a motorized, runged treadmill while simultaneously acquiring behavioral videos and electrophysiological recordings from MLIs. Paw trajectories were extracted from videos and divided into swing and stance phases. Over several days of learning, mice became increasingly proficient at walking on the runged treadmill, so that they made fewer, longer strides with faster swings and fewer missteps. When analyzing behaviorally-evoked responses in MLIs, we found sharp changes in activity in relation to paw swing and stance onsets. To uniquely attribute neural activity patterns to single paw movements, we fitted sparsity-constrained linear models with swing and stance event kernels. While most MLIs in the left simplex preferentially encoded front left paw variables, a large proportion of cells additionally showed activity variations related to multiple paws. Throughout learning, we found increases in swing and stance encoding on the timescale of a single session as well as over multiple sessions. Together, these results demonstrate that single-paw movement initiation and termination during complex locomotor behavior is encoded in cerebellar MLIs across different stages of locomotor proficiency.",
        "url": "https://www.world-wide.org/cosyne-23/cerebellar-interneurons-encode-single-afb4e7e4"
    },
    "Detecting rhythmic spiking through the power spectra of point process model residuals": {
        "title": "Detecting rhythmic spiking through the power spectra of point process model residuals",
        "authors": "Karin Cox, Daisuke Kase, Robert Turner",
        "date": "Saturday, 11 March 2023",
        "location": "III-110",
        "abstract": "Oscillations in neural activity are often studied in signals that reflect electrical currents aggregated over neuronal populations (e.g., local field potentials). Ideally, we could straightforwardly analyze oscillations in individual neurons’ firing, by estimating the power spectral density (PSD) of spike trains. Unfortunately, spike train spectra exhibit a global distortion generated by the neuronal recovery period (“RP”, the post-spike drop in spike probability, which can extend beyond the refractory period). This distortion can increase the rate of false negatives and false positives from statistical tests for oscillatory effects in the PSD. A common procedure (ISI “shuffling”) can correct for RP distortion by removing the spectral component explained by the inter-spike interval (ISI) distribution. However, this procedure sacrifices any oscillation-related structure in the ISIs – which can be considerable for sparsely spiking units – and power at the corresponding frequencies in the PSD. Here, we ask whether a new “residuals” method can improve upon the shuffling method’s performance. For this method, we first estimate the RP duration from the ISI distribution. We then fit the spike train with an autoregressive Poisson regression model of equivalent order, and compute the PSD of the residuals. We initially compared the residuals and shuffling methods on a diverse set of simulated spike trains. The residuals method demonstrated increased sensitivity in detecting oscillations, particularly when spiking was sparse. Subsequent evaluations used single-unit data acquired from the internal globus pallidus (GPi) and ventrolateral anterior thalamus (VLa) of a parkinsonian monkey, in which pathological alpha-beta oscillations [8-30 Hz] were anticipated. For both regions, we observed examples of candidate alpha-beta oscillations that the residuals method uniquely detected; such examples were most frequent in the sparsely spiking VLa. Overall, these results suggest previous underestimation of rhythmic activity in sparsely spiking units, and encourage further development of the residuals method.",
        "url": "https://www.world-wide.org/cosyne-23/detecting-rhythmic-spiking-through-power-7e954960"
    },
    "Inferring the order of stable and context dependent perceptual biases in human vision": {
        "title": "Inferring the order of stable and context dependent perceptual biases in human vision",
        "authors": "Timothy Sheehan, Sunyoung Park, John Serences",
        "date": "Saturday, 11 March 2023",
        "location": "III-111",
        "abstract": "Perception is transformed by both stable and time varying (contextual) expectations. This influence is observable in the domain of orientation processing as cardinal bias (repulsion from more common vertical and horizontal orientations) and serial dependance (attraction towards recent stimuli) [1,2]. These biases operate on vastly different time scales and have typically been studied in isolation. Investigating the properties of these two biases in tandem may reveal important insights into general principles of perception (efficient coding, Bayesian inference) that are obscured when studied in isolation. Here, we modeled the responses of human observers in a 2AFC delayed orientation discrimination task. Responses displayed substantial cardinal (6.5±1.2° peak repulsion from cardinal axes, mean±SD) and serial biases (3.6±1.9° peak attraction towards previous stimulus) relative to their overall precision (σ=9.9±0.36°). By leveraging incorrect responses, we found that the center of attraction towards the previous trial was heavily shifted towards the mis-remembered item (shift 16.79±0.79°). To further infer the order that expectations are applied in this hidden process, we fit 6 alternative models and evaluated the resulting cross-validated likelihoods. Responses were best explained when the inducing stimulus included all known biases (including cardinal, its own history bias, and residual misperception not accounted for) and this dynamic history information was integrated at the end of the processing stream (p<.001 compared to all competing models). This suggests that while long term priors are used to make the earliest stages of encoding more efficient, short term expectations are applied at a later stage to support immediate goals. More generally, these results provide a framework for understanding how long term priors (likely arising during development) interact with dynamic contextual factors to jointly drive complex behaviors. [1] Girchick et al.,2011. NatNeuro; [2] Fischer&Whitney,2014. NatNeuro",
        "url": "https://www.world-wide.org/cosyne-23/inferring-order-stable-context-dependent-c95dbdb4"
    },
    "Stimulus selection and novelty detection via divergent synaptic plasticity in an olfactory circuit": {
        "title": "Stimulus selection and novelty detection via divergent synaptic plasticity in an olfactory circuit",
        "authors": "Hyong Kim & James Jeanne",
        "date": "Saturday, 11 March 2023",
        "location": "III-112",
        "abstract": "In nature, diverse sensory signals fluctuate in time and in space. Odors, for example, are distorted by wind into narrow filaments. When multiple spatially distinct odor sources exist, these filaments interleave but do not intermix. Such odor landscapes pose complementary challenges to animals – such as the fruit fly – that depend on olfaction to find food or mating partners. First, to select the best odor to track back to its source, the olfactory system must compare information from different filaments over relatively long timescales. Second, to remain on high alert to unexpected changes, such as a sudden increase in filament frequency, the olfactory system must respond to novelty on relatively short timescales. In Drosophila, projection neurons (PNs) innervating different glomeruli encode different but overlapping sets of odors. Similarly tuned PNs tend to target the same lateral horn neurons (LHNs). We investigated the odor coding transformation between PNs and LHNs, focusing on two LHN types that receive projections from the same two PNs. To mimic natural odor filaments, we delivered repeated pulses of odors that privately activate each of these two PNs while recording LHN activity with voltage imaging or electrophysiology. Despite receiving input from the same PNs, the two LHN types perform different operations. One LHN type responded to either odor presented in isolation but suppressed responses to the weaker odor when interleaved in time. This implements stimulus selection. The other LHN type suppressed responses to each odor independently over repeated pulses. This implements novelty detection. Paired recordings from connected PN-LHN pairs showed that synapses from the same PN operate with different short-term plasticity dynamics for different LHN targets. Synaptic dynamics were well-matched to odor coding dynamics of each LHN. This illustrates how variations in a basic building block of neural circuits (short-term plasticity) can implement diverse and complementary functions.",
        "url": "https://www.world-wide.org/cosyne-23/stimulus-selection-novelty-detection-13256b4d"
    },
    "A normative framework for balancing reward- and information-seeking behaviors in dynamic environments": {
        "title": "A normative framework for balancing reward- and information-seeking behaviors in dynamic environments",
        "authors": "Nicholas Barendregt, Zachary Kilpatrick, Joshua Gold, Kresimir Josic",
        "date": "Saturday, 11 March 2023",
        "location": "III-113",
        "abstract": "Our understanding of how the brain makes decisions has benefited greatly from normative theories that have, for example, established benchmarks for how specific forms of evidence accumulation and decision rules can optimally balance quantities like decision speed and accuracy. These theories have recently been expanded to include adaptive components that are necessary for effective decision making in dynamic environments. However, these extensions remain incomplete, because they have focused primarily on how an unconstrained agent manages single, independent decisions [1]. In contrast, real-world decision-makers are often constrained by limitations on resources like energy and time. These constraints can have complicated effects on not just single decisions, but also on sequences of decisions in volatile environments. Here we present a new theoretical framework for understanding quantitatively, and optimizing with respect to, the costs and benefits of different sequential decision-making behaviors in dynamic environments. Our framework is based on a Bayesian model of decision making in environments with temporally correlated structure. Specifically, we assumed that after each trial, the correct choice changes according to a discrete-state Markov process, and that the agent can take a limited number of actions per block of trials. The resulting rich, optimal choice behaviors depend strongly on task conditions, but generally exhibit the explore-exploit trade-off characteristic of many foraging tasks. Our major contribution is a predicted, sharp transition from exploratory to exploitative strategies when choice feedback provides more information about the next trial than the expected environmental evidence, and thus a comparison of reward-optimal and information-optimal strategies [2]. More generally, our work provides a broad, quantitative account, including experimentally testable predictions, of the effectiveness of different decision strategies under natural constraints.",
        "url": "https://www.world-wide.org/cosyne-23/normative-framework-balancing-reward--27737f6d"
    },
    "An optofluidic platform for interrogating chemosensory behavior and brainwide neural representation": {
        "title": "An optofluidic platform for interrogating chemosensory behavior and brainwide neural representation",
        "authors": "Kwun Hei Samuel Sy, Yu Hu, Danny C. W. Chan, Roy C. H. Chan, Jing Lyu, Zhongqi Li, Kenneth K. Y. Wong, Chung Hang Jonathan Choi, Vincent C. T. Mok, Hei-Ming Lai, Owen Randlett, Ho Ko",
        "date": "Saturday, 11 March 2023",
        "location": "III-114",
        "abstract": "Studying chemosensory processing desires precise chemical cue presentation, behavioral response monitoring, and large-scale neuronal activity recording. Larval zebrafish are especially attractive vertebrates for such study. Behavioral assays and imaging systems that can achieve the necessary spatial precision for chemical delivery is an important pre-requisite for data interpretation. Here we present Fish-on-Chips, a set of optofluidic tools for highly-controlled chemical delivery while simultaneously imaging behavioral outputs and whole-brain neuronal activities at cellular resolution in larval zebrafish. These include a fluidics-based swimming arena and an integrated microfluidics-light sheet fluorescence microscopy (µfluidics-LSFM) system, both of which utilize laminar fluid flows to achieve spatiotemporally precise chemical cue presentation. To demonstrate the strengths of the platform, we used the navigation arena to reveal previously unappreciated binasal input-dependent behavioral strategies that larval zebrafish adopt to evade cadaverine, a death-associated odor. Specifically, the larval zebrafish efficiently escape from cadaverine-carrying streams by making more frequent swim bouts and larger undirected turns. Binasal inputs are heavily required for the higher swim bout frequency, while each nasal input additively enhances angular velocity. The µfluidics-LSFM system enables sequential presentation of odor stimuli to individual or both nasal cavities separated by only ~100 µm. This allowed us to uncover brainwide neural representations of cadaverine sensing and binasal input summation in the vertebrate model. Specifically, the neural representation of cadaverine sensing is characterized by a wide range of ipsilateral-contralateral nasal input selectivity (i.e., from highly ipsilateral or contralateral input-selective, to responding equally to bilateral inputs), and nonlinear summation of bilateral afferent signals on a brainwide scale. Fish-on-Chips is readily generalizable and will empower the investigation of neural coding in the chemical senses.",
        "url": "https://www.world-wide.org/cosyne-23/optofluidic-platform-interrogating-45d72416"
    },
    "New tools for recording and interpreting brain-wide activity in C. elegans": {
        "title": "New tools for recording and interpreting brain-wide activity in C. elegans",
        "authors": "Jungsoo Kim, Adam Atanas, Ziyu Wang, Eric Bueno, McCoy Becker, Di Kang, Jungyeon Park, Cassi Estrem, Talya Kramer, Saba Baskoylu, Vikash Mansingkha, Steven Flavell",
        "date": "Saturday, 11 March 2023",
        "location": "III-115",
        "abstract": "Recent studies have shown that behavioral information is richly distributed across the brain, but how individual neurons across the brain encode behavior is largely unknown. However, it is challenging to record/interpret high quality single neuron traces across the brain. Here, we describe new hardware/software and analytical tools to address this. We engineered a microscope to record brain-wide activity and behavior of freely-moving C. elegans, wrote new image analysis software, and developed a probabilistic encoder model to delineate how each neuron encodes specific behavioral features. Extracting high quality neural traces from images is difficult due to the large amount of deformations as animals freely move. In our automatic extraction software, we construct registration graphs based on posture similarity, connecting timepoints that are similar enough to perform volumetric registration. Then using a custom clustering method, we link the ROIs over time to construct a neural time series for each neuron. The behavioral features are automatically extracted using custom neural networks and other computer vision methods. Overall, the new system gives us ~10x SNR improvement compared to the previous best system. We next constructed a single-neuron encoder model based on our observations which demonstrates that C. elegans neurons can: encode behavior at multiple timescales (e.g. current vs recent); encode multiple behaviors (i.e. “mixed selectivity”); and display rectified encodings based on locomotion state. To be able to interpret the fitted parameters, we used probabilistic inference (a resample move sequential Monte Carlo inference algorithm validated with simulation based calibration), which gives a posterior distribution for each parameter instead of a single estimate. Overall, this allows us to determine the precise tuning of how each neuron encodes different behavioral features. These new tools enable high-SNR brain-wide recordings from moving animals and interpretable modeling of how neurons across the brain encode behavior.",
        "url": "https://www.world-wide.org/cosyne-23/tools-recording-interpreting-brain-wide-42facf34"
    },
    "Neuronal circuits for robust online fixed-point detection": {
        "title": "Neuronal circuits for robust online fixed-point detection",
        "authors": "Runzhe Yang, David Lipshutz, Tiberiu Tesileanu, Dmitri Chklovskii, Johannes Friedrich",
        "date": "Saturday, 11 March 2023",
        "location": "III-116",
        "abstract": "A fundamental problem in systems neuroscience is understanding how the brain learns the non-linear dynamics of the complex world and identifies the environment's state. Data-driven learning in such high-dimensional spaces requires lifting the curse of dimensionality. One way of reducing dimensionality relies on extracting from observed trajectories the underlying topological skeleton, i.e., fixed points connected by invariant manifolds. Thus, online extraction of fixed points from input trajectories is an important task. Whereas Dynamic Mode Decomposition (DMD) provides a framework to calculate fixed points offline, efficiently extracting fixed points online remains an unsolved problem. Moreover, implementing the online algorithm in a biological neuronal circuit requires it to satisfy more constraints, such as local update rules and no reliance on external memory. In this work, we propose two biologically plausible neural networks with multi-compartment neurons for online fixed-point detection. The first neuronal circuit (circuit A) employs mostly local learning rules to update synaptic weights and estimate the linearized forward dynamics with high accuracy, and then utilizes the learned recurrent circuit to infer nearby fixed points. The second algorithm (circuit B) is a simpler recurrent neural network with synaptic weights learned by anti-Hebbian plasticity. Experiments show that circuit A can efficiently and robustly detect stable and unstable fixed points and all saddle points in switch-linear and non-linear systems. Though circuit B satisfies biological constraints more strictly, it converges slowly in practice. Our circuits are potential building blocks for a larger neuronal circuit for systems identification and model-based control.",
        "url": "https://www.world-wide.org/cosyne-23/neuronal-circuits-robust-online-fixed-point-803368e5"
    },
    "Dendritic excitability primarily controls overdispersion": {
        "title": "Dendritic excitability primarily controls overdispersion",
        "authors": "Zachary Friedenberger & Richard Naud",
        "date": "Saturday, 11 March 2023",
        "location": "III-117",
        "abstract": "A neuron’s input-output function is a central component of network dynamics and is commonly understood in terms of two fundamental operating regimes: 1) the mean-driven regime where the mean input drives regular and frequent firing, and 2) the fluctuation-driven regime where input fluctuations drive responses at relatively low firing frequency but with variable intervals. Active dendrites are expected to profoundly influence the input-output function by either controlling gain modulation or through the additive modulation by dendritic inputs that have been transformed nonlinearly as in an artificial neural network. However, both additive and gain modulations are thought to be weak in the presence of background fluctuations. Here we investigate how active dendrites, falling in either regime, shape the input-output function. Extending cable theory with features of generalized integrate and fire models, we develop a mean-field theory for neurons with active dendrites, capturing the integrative properties of dendrites and the soma in the presence of noise. We find that dendritic input primarily controls interspike interval dispersion, reaching overdispersed states unaccountable by Poisson processes, but commonly observed in vivo. This effect appears in the fluctuation-driven regime, largely before dendritic input makes additive or multiplicative modulation of the firing frequency. We show that this mechanism implies that increasing the strength of somatic inputs can increase interval dispersion as long as dendritic spikes are not consistently above threshold. Consequently, neurons display not two but three fundamental operating regimes, depending on whether dendritic spikes or the somatic input reaches threshold. We validate our prediction that dendritic input controls overdispersion by re-analyzing previously published dual patch clamp recordings of rat cortical neurons. This perspective of neuronal input-output functions has implications for theories of neural coding, the credit-assignment problem, control of trial-to-trial variability, pairwise correlations, and how attractor networks can reach highly dispersed firing states.",
        "url": "https://www.world-wide.org/cosyne-23/dendritic-excitability-primarily-controls-6e7deea1"
    },
    "Tuned inhibition explains strong correlations across segregated excitatory subnetworks": {
        "title": "Tuned inhibition explains strong correlations across segregated excitatory subnetworks",
        "authors": "Matthew Getz, Gregory Handy, Alex Negrón, Brent Doiron",
        "date": "Saturday, 11 March 2023",
        "location": "III-118",
        "abstract": "Understanding the basis of shared, across trial fluctuations in neural activity in mammalian cortex is critical to uncovering the nature of information processing in the brain. This correlated variability has often been related to the structure of cortical connectivity since variability not accounted for by signal changes likely arises from local circuit inputs. However, recent recordings from segregated networks of excitatory neurons in mouse primary visual cortex (V1) complicate this relationship. These results found that despite weak cross-network connection probability, noise correlations were significantly larger than one would expect. We aim to explore possible circuit mechanisms responsible for these enhanced positive correlations through biologically motivated cortical network models, with the hypothesis that they arise from unobserved inhibitory neurons. In particular, we consider networks with weakly interconnected excitatory populations, but either global or subpopulation-specific inhibitory populations. We then ask how correlations can be enhanced or marred via the strength of outgoing and incoming connections to these inhibitory populations. By performing a pathway expansion of the covariance matrix, we find that a single inhibitory population with sufficiently strong I to E connections can lead to stronger than expected positive correlations across excitatory populations. However, this result is highly parameter dependent. When considering an inhibition-stabilized network (ISN) the viable parameter regime shrinks dramatically into a narrow band close to the edge of stability. We find that both non-ISN and ISN regimes can recover the ability to robustly explain the experimental results by allowing for two tuned inhibitory populations, meaning that each inhibitory population preferentially connects to one of the two excitatory populations. Our results therefore imply that complexity in excitation should be mirrored by complexity in the structure of inhibition.",
        "url": "https://www.world-wide.org/cosyne-23/tuned-inhibition-explains-strong-correlations-8d6bf785"
    },
    "Granular retrosplenial cortex high frequency oscillation dynamics in hippocampo-cortical dialogue": {
        "title": "Granular retrosplenial cortex high frequency oscillation dynamics in hippocampo-cortical dialogue",
        "authors": "Kaiser Arndt, Earl Gilbert, Chelsea Buhler, Julia Basso, Daniel English, Lianne Klaver, Sam McKenzie",
        "date": "Saturday, 11 March 2023",
        "location": "III-119",
        "abstract": "We used dense (20 m site spacing) local field potential (LFP) and single unit recordings across all layers of the gRSC concurrent with CA1 LFP recordings in behaving mice to investigate circuit activity of high-frequency oscillations (HFOs) in theta and sharp wave-ripples (SWRs). By comparing HFOs occurring at times of SWRs (+/-50 ms) or during theta, we found using current-source density analysis that HFOs in different states are uniformly localized to layer 2/3 (L2/3) with current sources and sinks bridging the L1-L2/3 border. HFOs that occurred outside of SWR times where rhythmically locked to the descending phase of theta and co-occurred with HPC theta locked gamma oscillations. In ensemble recordings of gRSC neurons, subsets of both excitatory and inhibitory neurons had different activity during each type of HFO and findings were consistent with previously reported event triggered neural activity (Nitzan et al., 2020). Additionally, using mice chronically expressing the excitatory rhodopsin Channelrhodopsin in pyramidal cells, we show that a broad light stimulus delivered to specific layers with a LED probe is sufficient to induce HFOs in L2/3 and L5 (Wu, F. et al., 2015). Interestingly, while we don’t see HFOs naturally occurring in L5 the local synaptic network is structured to support HFOs. These findings suggest that gRSC networks support HFOs in the same location at different states, though the natural drivers of these HFO events are different between states. That being the SWR via excitatory subiculum connections, and the highly synchronous HPC-gRSC theta oscillation. HFO events in different states play key roles in hippocampo-cortical dialogue and may allow for information transfer using theta locked gamma-HFO synchrony during locomotion and SWR-HFO synchrony during quiet wakefulness.",
        "url": "https://www.world-wide.org/cosyne-23/granular-retrosplenial-cortex-high-frequency-46c370a7"
    },
    "Invertible readouts to improve the dynamical accuracy of neural population models": {
        "title": "Invertible readouts to improve the dynamical accuracy of neural population models",
        "authors": "Christopher Versteeg, Andrew Sedler, Chethan Pandarinath",
        "date": "Saturday, 11 March 2023",
        "location": "III-120",
        "abstract": "An emerging perspective in neuroscience connects neural dynamics, or the rules that govern how neural population activity develops over time, to functional computations performed by the brain [1]. Unfortunately, neural dynamics cannot be observed directly and must instead be inferred from neural recordings. One promising method to infer these dynamics is to use a latent dynamics model, commonly a Sequential Auto-Encoder (SAE), to reconstruct neural activity [2] with the assumption that better reconstruction performance corresponds to better dynamical accuracy. Unfortunately, most SAE readouts, the component of an SAE that maps from the latent activity to predicted neural activity, have critical shortcomings. First, they are usually simple linear models and therefore can’t capture potential nonlinearities between the latent and neural spaces. Second, they have a null-space, or a set of latent dimensions that don’t affect neural reconstruction. This null-space permits models to learn “superfluous” dynamics that improve reconstruction performance at the expense of dynamical accuracy. Our model, called Ordinary Differential equations auto-encoder with INvertible readout (ODIN), combines Neural Ordinary Differential Equation (NODE) [3] and Invertible Neural Networks (INNs) [4] into a new SAE variant with a trainable non-linear readout without a null-space. To validate ODIN’s dynamical accuracy, we simulated neuronal population activity from a low-D dynamical system embedded non-linearly into high-D neural space. We then trained ODIN and alternative models on these simulated data and quantified their dynamical accuracy. We found that ODIN’s dynamics were more accurate than comparable models with MLP or linear readouts (mean Hidden R2 of 0.93 vs. 0.80, 0.84, respectively), and that ODIN’s dynamical accuracy was more robust to changes in relevant hyperparameters. In summary, ODIN is a promising extension to existing SAE models that will improve our understanding of neural computation by enabling more accurate estimation of neural dynamics.",
        "url": "https://www.world-wide.org/cosyne-23/invertible-readouts-improve-dynamical-20f4e9bd"
    },
    "Context-Dependent Epoch Codes in Association Cortex Shape Neural Computations": {
        "title": "Context-Dependent Epoch Codes in Association Cortex Shape Neural Computations",
        "authors": "Frederick Berl, Hyojung Seo, Daeyeol Lee, John Murray",
        "date": "Saturday, 11 March 2023",
        "location": "III-121",
        "abstract": "Neural circuits adapt their computations to perform cognitive functions within and across tasks. These adaptations are vital for decision making, which often requires the integration of past information and present context to generate appropriate behaviors. Neurons in association cortices exhibit selective activity for task-relevant signals such as current and past choices and outcomes, yet how such selectivity is modulated by the task context is unclear. Interestingly, neuronal activity encodes time or epoch within the task as strongly as conventional task variables. Here we examined the intriguing hypothesis that such condition-independent \"epoch codes\" may play a role in shaping neural computations across time and contexts. We analyzed >800 single-neuron recordings from multiple association cortical areas — LIP, dlPFC, ACC, and SEF — while monkeys performed two different tasks: (i) a competitive \"matching pennies'' decision-making task that relies on the integration of choice and outcome memory across trials, and (ii) a control \"search\" task that does not require across-trial memory. We found that neuronal trace of choice and outcome is gated by an epoch code multiplicatively rather than additively. Furthermore, task-relevant memory signals are stronger and the epoch codes are modulated more during matching pennies than during search task. We also found significant differences in the geometry of population epoch-code trajectories across cortical areas. Notably, epoch codes in LIP and ACC were lower-dimensional, indicating less heterogeneity in patterns across neurons than those in dLPFC and SEF. Epoch codes in LIP exhibited less modulation by task context relative to the other regions. By separating epoch code from task-variable coding, we tested how epoch codes, and their contextual modulation, relate to task-relevant computations. Similarly, this characterization of contextual epoch codes across association cortical areas also revealed computational principles for dynamical network models of flexible cognitive processes.",
        "url": "https://www.world-wide.org/cosyne-23/context-dependent-epoch-codes-association-d7e2b0e2"
    },
    "Single-cell precision of axonal projection from the retina to the superior colliculus in mice": {
        "title": "Single-cell precision of axonal projection from the retina to the superior colliculus in mice",
        "authors": "Hiroki Asari",
        "date": "Saturday, 11 March 2023",
        "location": "III-122",
        "abstract": "Retinotopy is generally preserved across the visual system, but its cellular-level organization remains elusive. How precisely is topographic information transmitted from the retina? To address this question, here we combined experimental and computational modelling approaches. First, using two-photon calcium imaging of retinal ganglion cell (RGC) axons as well as local neurons in the superior colliculus (SC), we performed functional mapping of the retinocollicular projection at a single-cell resolution in awake mice. The tiling patterns of RGC axon terminals and their corresponding receptive fields (RFs) turned out to be nearly identical, and showed a significantly better agreement than the tiling patterns of SC somata and their RFs. This indicates a higher precision of retinotopy for RGC axons than for SC neurons. To better quantify the organization of the retinocollicular pathway, we next performed a computational modelling analysis based on the experimental data. By comparing the observed and simulated retinotopy patterns, we identified that 1) a jitter of RGC projection to a target location in SC is as small as 27 µm; and 2) individual SC neurons integrate inputs from around 5.5 RGCs on average, leading to a relatively less precise retinotopy on the postsynaptic side. These results highlight the precision of wiring in the brain even for a long-range projection such as the retinocollicular pathway, and suggest that retinotopy arises largely from topographically precise projection of presynaptic cells, rather than elaborating local circuitry to reconstruct the topography by postsynaptic cells.",
        "url": "https://www.world-wide.org/cosyne-23/single-cell-precision-axonal-projection-11436761"
    },
    "Density-based Neural Decoding using Spike Localization for Neuropixels Recordings": {
        "title": "Density-based Neural Decoding using Spike Localization for Neuropixels Recordings",
        "authors": "Yizi Zhang, Tianxiao He, Julien Boussard, Cole Hurwitz, Erdem Varol, Charlie Windolf, Olivier Winter, Matt Whiteway, The International Brain Lab The International Brain Lab, Liam Paninski",
        "date": "Saturday, 11 March 2023",
        "location": "III-123",
        "abstract": "Neural decoding is essential for understanding the association between neural activity and behavior. A prerequisite for most decoding methods is spike sorting, the assignment of action potentials (or spikes) to individual neurons. Current spike sorting algorithms, however, can be inaccurate and do not properly model uncertainty of spike assignments, therefore discarding information that could potentially improve decoding performance. Recent advances in high-channel-count probes like Neuropixels (NP) and extracellular analysis pipelines allow for extracting a rich set of spike features to directly decode behavioral correlates using unsorted spiking data. To this end, we propose a density-based decoding algorithm that incorporates our uncertainty about spike assignments in the form of parametric distributions of spike features. Our density-based decoding approach allows for retaining maximum information about the recording and for explicit uncertainty quantification of spike assignments. Our approach can also reduce the computational cost of neural decoding by avoiding spike sorting. With applications to electrophysiological and behavioral data from the International Brain Laboratory (IBL), we demonstrate that our density-based decoding algorithm can outperform decoding algorithms based on thresholding (i.e. multi-unit activity) and algorithms which rely on well-isolated, single-unit activity.",
        "url": "https://www.world-wide.org/cosyne-23/density-based-neural-decoding-using-82136f8c"
    },
    "A time-resolved theory of information encoding in recurrent neural networks": {
        "title": "A time-resolved theory of information encoding in recurrent neural networks",
        "authors": "Rainer Engelken & Sven Goedeke",
        "date": "Saturday, 11 March 2023",
        "location": "III-124",
        "abstract": "Information encoding in neural circuits depends on how well time-varying stimuli are encoded by neural populations. Slow neuronal timescales, noise, and network chaos can compromise reliable and rapid population response to external stimuli. A dynamic balance of externally incoming currents by strong recurrent inhibition was previously proposed as a mechanism to accurately and robustly encode a time-varying stimulus in balanced networks of binary neurons, but a theory for recurrent rate networks was missing. Here, we develop a non-stationary dynamic mean-field theory that transparently explains how a tight balance of excitatory currents by recurrent inhibition improves information encoding. We demonstrate that the mutual information rate of a time-varying input increases linearly with the tightness of balance, both in the presence of additive noise and with recurrently generated chaotic network fluctuations. We corroborated our findings in numerical experiments and demonstrated that recurrent networks with positive firing rates trained to transmit a time-varying stimulus generically use recurrent inhibition to increase the information rate. We also found that networks trained to transmit multiple independent time-varying signals spontaneously form multiple local inhibitory clusters, one for each input channel. Lastly, we confirm our theoretical findings in recurrent spiking networks. In conclusion, our findings suggest that feedforward excitatory input and local recurrent inhibition-as observed in many biological circuits-is a generic circuit motif for encoding and transmitting time-varying information in recurrent neural circuits.",
        "url": "https://www.world-wide.org/cosyne-23/time-resolved-theory-information-encoding-47fee561"
    },
    "Peripheral non-synaptic inhibition facilitates odor processing in fly brains": {
        "title": "Peripheral non-synaptic inhibition facilitates odor processing in fly brains",
        "authors": "Palka Puri, Johnatan Aljadeff, Shiuan-Tze Wu, Chih-Ying Su",
        "date": "Saturday, 11 March 2023",
        "location": "III-125",
        "abstract": "In insects, Olfactory Receptor Neurons ('ORNs') are grouped together into sensory hairs ('sensilla') in a stereotypical manner. Grouped ORNs: (i) antagonistically regulate the same behaviors, (ii) mutually inhibit each other via electrical interactions, and (iii) have a systematic size-asymmetry, resulting in asymmetric inhibitory interactions. The functional significance of this highly conserved organization is not known. We constructed a phenomenological model of nonlinearly coupled ORNs, which shows that inhibition between ORNs transiently amplifies the hedonic value ('valence') of an odor stimulus, as conveyed by ORN responses. Our analysis suggests that through this peripheral 'pre-processing' step, olfactory signals are prepared to be read-out effectively by central brain circuits. Specifically, in order to leverage the stimulus-specific valence amplification, downstream readouts of ORN activity must reflect peripheral sensory structure. Our analysis of Antennal Lobe (AL) to Lateral Horn (LH) connections in the fly connectome confirms these predictions: biases in AL to LH projections are consistent with interaction asymmetries of coupled ORNs. Further, using a population level model of coupled ORNs, we show that peripheral interactions modify the structure of AL responses. This modification is essential for the classification of high-dimensional stimuli in the Mushroom Body (MB), facilitated by random and expansive AL to MB projections. Taken together, stereotyped electrical inhibition between ORNs at the sensory periphery is crucial for odor processing in the fly brain.",
        "url": "https://www.world-wide.org/cosyne-23/peripheral-non-synaptic-inhibition-4787a5f5"
    },
    "Fitting normative neural sampling hypothesis models to neuronal response data": {
        "title": "Fitting normative neural sampling hypothesis models to neuronal response data",
        "authors": "Suhas Shrinivasan, Andreas Tolias, Edgar Y. Walker, Fabian Sinz",
        "date": "Saturday, 11 March 2023",
        "location": "III-126",
        "abstract": "A prominent theory of sensory perception advocates that perception in the brain is implemented via probabilistic inference. The neural sampling hypothesis (NSH) posits that neuronal responses to a stimulus represent samples from the posterior distribution over latent world state variables (e.g., object identity) that underlie the stimulus. Existing work on NSH commonly evaluates qualitative agreement of experimental data with simple generative models of the stimulus and does not fit NSH models to experimentally observed sensory population responses. We propose a novel formulation for NSH that allows us to directly fit NSH models to recorded stimulus-response pairs, and to formulate more flexible generative models. We formalize NSH as an equivalence between the distribution over stimulus-conditioned responses and the posterior distribution over stimulus-conditioned latent world-state variables. This enables us to fit generative models under NSH to responses and stimuli, including existing NSH models. Furthermore, we use a normalizing flow-based neural-network model and learn the generative model directly on image-response pairs. Our formulation allows us to directly compare NSH models to existing DNN-based encoding models of stimulus-conditioned responses. We fitted a Hoyer-Hyva ̈rinen NSH model directly on macaque V1 responses to natural images, and compared its performance to a state-of-the-art deep neural-network system identification models. We found that the NSH model was outperformed by even a simple linear- nonlinear model. While this is somewhat expected, the size of the performance gap clearly indicates that current NSH models are too simple for real responses and motivates the development of more complex generative models. Overall, our work is an important first step toward a more quantitative evaluation of NSH models and provides a novel framework that will let us learn the generative model directly on data, paving the way for a better understanding of probabilistic computational principles that underlie perception and behavior.",
        "url": "https://www.world-wide.org/cosyne-23/fitting-normative-neural-sampling-hypothesis-e0a126a1"
    },
    "Circuit-based framework for fine spatial scale clustering of orientation tuning in mouse V1": {
        "title": "Circuit-based framework for fine spatial scale clustering of orientation tuning in mouse V1",
        "authors": "Peijia Yu, Yuhan Yang, Olivia Gozel, Ian Oldenburg, Mario Dipoppa, L. Federico Rossi, Kenneth. D. Miller, Hillel Adesnik, Na Ji, Brent Doiron",
        "date": "Saturday, 11 March 2023",
        "location": "III-127",
        "abstract": "Recent population imaging studies in mouse primary visual cortex (V1) have revisited and questioned the traditional view of 'salt-and-pepper' organization of orientation tuning preference. A controversy has emerged on whether the organization is truly spatially disorganized, or if there is long-range (~100 μm) or short range (~10 μm) spatial clustering of orientation tuning. We imaged and analyzed the response profile (to orientated gratings) of in vivo populations of layer 2/3 (L2/3) and layer 4 (L4) neurons with a neuropil-free nuclear-targeted GCaMP6s indicator. These datasets provide an unprecedented picture of spatial responses, without the contamination of neuropil responses that can unduly bias correlated responses. A significant similarity of orientation tuning properties constrained over a fine spatial scale (around 5-20 μm) was revealed in both L2/3 and L4 -- we term this structure a 'micro-clustered' organization. To explore the novel elements of intracortical connectivity in mouse V1 that underlie the emergence and propagation of micro-clusters in L2/3, we considered an excitatory-inhibitory balanced network with spatially dependent connectivity. To cover the fine spatial scale correlations measured in vivo, in addition to the baseline recurrent synaptic wiring over hundreds of microns in mouse V1, we hypothesize a second, narrow scale wiring comparable to the size of the micro-clusters, so that the network model could quantitatively match the micro-clustered organization from L2/3 recordings. To validate this hypothesis, we leveraged techniques of rabies tracing and single-cell resolution holographic optogenetics to map the intracortical synaptic wiring of mouse V1 L2/3 pyramidal cells. In agreement with our model predictions, large neuron-to-neuron influences were restricted to cells that were within 20 μm of each other. Together, our work takes an important step in building a circuit-based theory of visual processing in mouse V1 over spatial scales that are often ignored, yet contain powerful synaptic interactions.",
        "url": "https://www.world-wide.org/cosyne-23/circuit-based-framework-fine-spatial-dcda4f16"
    },
    "Switching state-space models enable decoding of replay across multiple spatial environments": {
        "title": "Switching state-space models enable decoding of replay across multiple spatial environments",
        "authors": "Eric Denovellis, Jennifer Guidera, Loren Frank",
        "date": "Saturday, 11 March 2023",
        "location": "III-128",
        "abstract": "Replay, a phenomenon whereby cells reactivate representations of spatial trajectories, is thought to be crucial for the storage and consolidation of spatial memories. This phenomenon is commonly studied with respect to a single spatial environment. However, sleeping rats can replay trajectories of the spatial environment they previously experienced and awake rats can replay spatial trajectories of the spatial environment they are in and previously experienced environments. This means that care is needed when interpreting replay, as it may represent a replay of the current environment or another environment the animal has experienced. It is possible that replays that experimenters previously thought were not interpretable are actually coherent replays of another experience. More broadly, experiences occur across environments, and how the hippocampus and other brain areas might multiplex the replay of different experiences remains unknown. These issues motivated us to develop decoding methods that account for multiple spatial environments and provide a measure of statistical confidence with regards to which environment and trajectory are being represented. Here we take advantage of a switching point process state space model framework to develop such a method, leveraging spatial rate maps in each environment and prior knowledge about the spatial structure of environments. We show on simulated data how this model can turn \"noisy\" spatial trajectories decodes based on considering only one environment into interpretable trajectories in another environment. We then show on real data that we can decode replay of multiple environments. We believe this state space model will be important for understanding how the brain’s storage and consolidation mechanisms work in the context of more complex, real-world experiences. Moreover, as these methods can be applied to data across brain areas, they provide a robust framework for understanding how replay is represented across regions.",
        "url": "https://www.world-wide.org/cosyne-23/switching-state-space-models-enable-4f95b9cd"
    },
    "Inter-animal variability in learning depends on transfer of pre-task experience via the hippocampus": {
        "title": "Inter-animal variability in learning depends on transfer of pre-task experience via the hippocampus",
        "authors": "Cristofer Holobetz, Zhuonan Yang, Greer Williams, Shrabasti Jana, David Kastner",
        "date": "Saturday, 11 March 2023",
        "location": "III-129",
        "abstract": "Learning occurs in the context of individual prior experience. Variability in learning is, therefore, due to both differences in learning capacity as well as differences in those prior experiences. To describe the effect of prior experience on learning and to identify how the brain transfers this prior experience for current learning, we measured the behavior of many rats across two tasks on a six-arm track. In the first, reward was delivered after any transition between arms. In the second, reward was only delivered at three arms (2-3-4). To receive reward, it was necessary to alternate between the outer arms after each visit to the center arm (e.g., 3-4-3-2). During the first task, rats displayed variability in the structure of their arm visits. The behavior ranged between sweeping across the track (e.g., 1-2-3-4-5-6-5-4-3-2-1), and only going back and forth between two arms. The propensity of the rats to sweep in the first task predicted almost a quarter of specific errors made while learning the second task, illustrating the effect of initial conditions on learning. In a separate cohort of rats, we found that lesioning the hippocampus disrupted this relationship, indicating that the hippocampus plays a role in this information transfer. To identify the computational principles underlying this hippocampus function, we applied a recently developed computational model: the Tolman-Eichenbaum Machine (TEM). TEM posits that hippocampal encoding results from extracting predictable structure from sequences of stimuli. We reasoned and confirmed that the behavioral variability measured in our first task would lead to differences in hippocampal encoding in TEM. Therefore, we find that naturally occurring behavioral variability is enough to generate distinct hippocampal codes, and that these differences could provide the substrate for a neural implementation of transfer learning.",
        "url": "https://www.world-wide.org/cosyne-23/inter-animal-variability-learning-depends-30892087"
    },
    "Back to the present: self-supervised learning in neocortical microcircuits": {
        "title": "Back to the present: self-supervised learning in neocortical microcircuits",
        "authors": "Kevin Kermani Nejad, Loreen Hertäg, Paul Anastasiades, Rui Ponte Costa",
        "date": "Saturday, 11 March 2023",
        "location": "III-130",
        "abstract": "Sensory systems in the mammalian brain exhibit rich representations that ultimately support complex behaviours. Microcircuits across neocortical layers are believed to underlie the development of these representations, but exactly how this occurs remains unclear. In the canonical view of the neocortical microcircuit, first-order thalamic projections target layer 4 (L4), which in turn projects onto layer 2/3 (L2/3) pyramidal cells (PCs) and then finally onto layer 5 (L5) PCs. Although this is a motif found throughout the neocortex, the functional role of this architecture is not known. Here, inspired by recent observations showing that first-order thalamic input also targets L5 PCs, we introduce a model in which the canonical microcircuit enables the brain to learn through temporal self-supervision. In our model, L2/3 PCs learn to predict thalamic inputs by comparing past sensory information originating from L4 with the current thalamic input received by L5 PCs. First, we trained our model to predict upcoming visual input in a sequential task. When combined with top-down contextual input our model can successfully learn to predict visual input through local L2/3-L5 self-supervised learning. In addition, we show that this form of predictive learning leads to a network with sensory denoising properties. Next, we trained the model in visuomotor tasks in which the visual input is either linearly or non-linearly coupled to the animal's speed. After training, when halting the visual input, the network generates error signals that are reminiscent of mismatch responses observed experimentally in both superficial and deep layers. Overall, our work proposes that classical canonical microcircuit motifs underlies a form of self-supervised learning in the brain.",
        "url": "https://www.world-wide.org/cosyne-23/back-present-self-supervised-learning-36c66240"
    },
    "Maintenance of the timing information in olfactory working memory by global activity waves": {
        "title": "Maintenance of the timing information in olfactory working memory by global activity waves",
        "authors": "Xiaoxing Zhang, Ermeng Huang, Huangao Zhu, Da Xu, Zhaoqin Chen, Yulei Chen, Chengyu Li",
        "date": "Saturday, 11 March 2023",
        "location": "III-131",
        "abstract": "Working memory (WM) retains information during delay periods. How global neuronal activities maintain WM remains unclear. We recorded brain-wide activity via Neuropixels in mice performing a delay-varying olfactory WM task, to reveal animal’s capacity in maintaining both olfaction and duration information simultaneously. Neurons encoded WM information predominantly in transient patterns and generated cross-region activity waves, reflecting distinct cell assemblies that encoded olfaction-only, duration-only, or both information. The regional proportion of neurons and wave timing within cell assemblies were correlated with anatomical organization of the brain. Spike-correlogram analysis revealed stronger functional coupling within ten millisecond between neurons in a cell assembly, which could support activity waves through second-level activity loops. During training of artificial neural networks in classification tasks, accuracy is improved by using activity-wave constraints via local feedback inhibition. Thus, WM information could be maintained by global activity waves generated from cross-regional cell assemblies the brain. Our results might inspire new architecture of neural networks in maintaining multiple information.",
        "url": "https://www.world-wide.org/cosyne-23/maintenance-timing-information-olfactory-2f5ba597"
    },
    "Sensory priors, and choice and outcome history in service of optimal behaviour in noisy environments": {
        "title": "Sensory priors, and choice and outcome history in service of optimal behaviour in noisy environments",
        "authors": "Elena Menichini, Victor Pedrosa, Quentin Pajot-Moric, Viktor Plattner, Liang Zhou, Peter Latham, Athena Akrami",
        "date": "Saturday, 11 March 2023",
        "location": "III-132",
        "abstract": "While navigating the world, we constantly make decisions under uncertainty. In face of noisy perceptions, we build and continuously update our priors and expectations about future events in order to efficiently estimate and map sensory information to actions. In a non-stationary environment, exploratory behaviour may represent an optimal strategy to optimise reward at any given context. Even in stationary environments, animals may perform this innate exploratory behaviour and exhibit unexpected biases. In this work, we investigate how previous experience – sensory priors, as well as choice and outcome history ­– can inform subjects’ decision-making in a perceptual categorization task, where sensory statistics is manipulated. We compare human, rat, and mouse performance on a 2-alternative-forced-choice (2AFC) sound categorization task. Importantly, we expose subjects to different stimulus statistics, while keeping category probabilities equal. Humans, rats, and mice develop a stimulus-dependent bias that increases reward to a near-optimal level. Despite the overall stimulus-dependent bias that is similar across species, humans vs rodents show distinct trial-to-trial learning updates. Our proposed computational model accounts for this bias and predicts different trial-to-trial updates. Finally, we perform neuronal recordings from rat prefrontal cortex (PFC) and posterior thalamus. Stimulus identity and category are encoded on a single-neuron level in both areas. Additionally, animal choice can be decoded from neuronal population activity. Only in PFC, inter-trial activity reflects animal optimal biases and hence exhibits signatures of sensory prior representations. Overall, our study unravels an optimal behaviour that emerges from a trial-to-trial learning strategy that is different across species. Our results also suggest that the prefrontal structures in the rat brain might encode sensory prior representations.",
        "url": "https://www.world-wide.org/cosyne-23/sensory-priors-choice-outcome-history-34aa4cd6"
    },
    "Encoding priors in recurrent neural circuits with dendritic nonlinearities": {
        "title": "Encoding priors in recurrent neural circuits with dendritic nonlinearities",
        "authors": "Benjamin Lyo, Eero Simoncelli, Cristina Savin",
        "date": "Saturday, 11 March 2023",
        "location": "III-133",
        "abstract": "The view of the world through the lens of our senses is noisy and incomplete. Confronted with this uncertainty, the brain relies on knowledge about the natural world and the current task context to perceive and to act. The framework of Bayesian inference successfully formalizes this knowledge in terms of probabilistic priors, and perception/action as probabilistic inference. However, our understanding of how such priors are obtained, represented and used by the brain remains limited. Here we build upon the recent success in machine learning of “diffusion models” as a means of learning and using priors over images. We construct a recurrent circuit model that can implicitly represent sensory priors and combine them with other sources of information to encode task-specific posteriors. Our solution relies on dendritic nonlinearities, optimized for denoising, and stochastic somatic activity modulated by a global oscillation. Integrating these elements into a densely connected recurrent network results in circuit dynamics that sample from the prior at a rate given by the period of the global oscillation. When combined with additional inputs reflecting sensory or top-down contextual information, the dynamics generate samples from the corresponding posterior. As a simple illustration of the process, we design a low-dimensional dataset mimicking properties of natural images, and demonstrate sampling from the associated prior and context-conditional posterior. These simulations show that the network is capable of performing inference with nontrivial multimodal distributions and that it can reorganize its dynamics to include the influence of top-down contextual signals. Overall, our model provides a new framework for investigating circuit-level representations of priors and their use for guiding behavior across tasks.",
        "url": "https://www.world-wide.org/cosyne-23/encoding-priors-recurrent-neural-circuits-18322cdc"
    },
    "Visuomotor integration gives rise to three-dimensional receptive fields in the primary visual cortex": {
        "title": "Visuomotor integration gives rise to three-dimensional receptive fields in the primary visual cortex",
        "authors": "Yiran He, Antonin Blot, Petr Znamenskiy",
        "date": "Saturday, 11 March 2023",
        "location": "III-134",
        "abstract": "Distinguishing near and far visual cues is an essential computation that animals must carry out to guide behavior using vision. When animals move, self-motion creates motion parallax — an important but poorly understood source of depth information — whereby the speed of optic flow generated by self-motion depends on the depth of visual cues. This enables animals to estimate depth by comparing visual motion and self-motion speeds. As neurons in the mouse primary visual cortex (V1) are broadly modulated by locomotion, we hypothesized that they may integrate visual- and locomotion-related signals to estimate depth from motion parallax. To test this hypothesis, we designed a virtual reality (VR) environment for mice, where visual cues were presented at different virtual distances from the mouse and motion parallax was the only cue for depth, and recorded neuronal activity in V1 using two-photon calcium imaging. We found that the majority of excitatory neurons in layer 2/3 of V1 were selective for virtual depth. Neurons with different depth preferences were spatially intermingled, with nearby cells often tuned for disparate depths. Moreover, depth tuning could not be fully accounted for by either running speed or optic flow speed tuning in isolation, but arose from the integration of both signals. Specifically, depth selectivity of V1 neurons was explained by the ratio of preferred running and optic flow speeds. Finally, many neurons responded selectively to visual stimuli presented at a specific retinotopic location and virtual depth, demonstrating that during active locomotion V1 neuronal responses can be characterized by three-dimensional receptive fields. These results challenge the traditional view of V1 as a feed-forward filter bank, and suggest that the widespread modulation of V1 neurons by locomotion and other movements plays an essential role in estimation of depth from motion parallax.",
        "url": "https://www.world-wide.org/cosyne-23/visuomotor-integration-gives-rise-three-dimensional-c61c2a3d"
    },
    "Neuronal extraction of statistical patterns embedded in time series": {
        "title": "Neuronal extraction of statistical patterns embedded in time series",
        "authors": "Sandra Nestler, Moritz Helias, Matthieu Gilson",
        "date": "Saturday, 11 March 2023",
        "location": "III-135",
        "abstract": "Neuronal systems need to process temporal signals. Here, we hypothesize that temporal (co-)fluctuations – corresponding to high-order statistics beyond the average activity – are relevant for computation. The proposed biologically inspired feedforward neuronal model is able to extract information from up to the third order cumulant to perform time series classification. This model relies on a nonlinear gain function to combine the different statistical orders of the inputs, after a usual weighted summation. In addition to the afferent synaptic weights, the nonlinear gain function is optimized, which enables the combination of cumulants in a synergistic manner to maximize the classification accuracy. The approach is demonstrated both on synthetic and real world datasets of multivariate time series to test the classification performance and to interpret the tunable gain function. Moreover, we show that our biological scheme makes a better use of the number of trainable parameters as compared to a classical machine-learning scheme. Our findings emphasize the benefit of biological neuronal architectures, paired with dedicated learning algorithms, for the processing of information embedded in higher-order statistical cumulants of temporal (co-)fluctuations.",
        "url": "https://www.world-wide.org/cosyne-23/neuronal-extraction-statistical-patterns-46dcdceb"
    },
    "Paradoxical self-sustained dynamics emerge from orchestrated excitatory and inhibitory homeostatic plasticity rules": {
        "title": "Paradoxical self-sustained dynamics emerge from orchestrated excitatory and inhibitory homeostatic plasticity rules",
        "authors": "Saray Soldado-Magraner, Michael J. Seay, Rodrigo Laje, Dean Buonomano",
        "date": "Saturday, 11 March 2023",
        "location": "III-136",
        "abstract": "Cortical networks have the remarkable ability to self-assemble into dynamic regimes in which excitatory positive feedback is balanced by recurrent inhibition. This inhibition-stabilized regime is increasingly viewed as the default dynamic regime of the cortex but how it emerges in an unsupervised manner remains an open question. Theoretical work has established that four sets of weights (WE←E, WE←I, WI←E, WI←I) must obey specific relationships to produce inhibition-stabilized dynamics, but it is not known how the brain autonomously sets the values of all four weight classes to be in the suitable regime. We prove that classic forms of homeostatic plasticity are unable to generate inhibition-stabilized dynamics and that their instability is caused by a signature property of inhibition-stabilized networks: the paradoxical effect. We next derive a novel family of cross-homeostatic rules for the four weight classes that overcome the paradoxical effect and robustly lead to the emerge of stable dynamics. These local rules shed new light on how the brain may reach its default dynamic state and provide a valuable tool to self-assemble artificial neural networks into ideal computational regimes.",
        "url": "https://www.world-wide.org/cosyne-23/paradoxical-self-sustained-dynamics-b769e429"
    },
    "A Bayesian hierarchical latent variable model for spike train data analysis": {
        "title": "A Bayesian hierarchical latent variable model for spike train data analysis",
        "authors": "Josefina Correa Menendez, Earl Miller, Emery Brown",
        "date": "Saturday, 11 March 2023",
        "location": "III-137",
        "abstract": "A common approach to analyzing spike train data in stimulus-response experiments is to estimate spike rates relative to the stimulus onset. These experiments typically involve collecting measurements from the same subject across several trials and sessions, and performing the same experiment across multiple subjects. Accounting for these sources of variability is important to accurately estimate the population response. However, current spike rate estimation methods only allow for estimating trial-level, session-level or group-level spike rates, neglecting the variability between levels. We develop a Bayesian hierarchical latent variable model for estimating population and subject-level spike rate functions from multi-subject, multi-session and multi-trial spike train data. We model the contribution of a stimulus to spiking dynamics through a stochastic ordinary differential equation model, where a stimulus has a cumulative effect on latent dynamics that decays exponentially upon its offset. This effect is governed by parameters that can be specified as prior distributions. Thus, the model can capture a broad range of dynamics including sustained inhibition or excitation and transient inhibition or excitation. Our approach provides goodness-of-fit assessment and a Monte Carlo algorithm for computing confidence intervals for population and subject-level spike rate functions, and for performing uncertainty quantification on model parameters. We assess the accuracy of our model in simulation. We apply our model to data from previously published stimulus-response experiments to characterize the effect of: 1. thalamic stimulation on cortical spiking in non-human primates under propofol-induced unconsciousness; 2. a repetitive whisker stimulus on simultaneous recordings from individual thalamic barreloids in the rat somatosensory whisker/barrel system; 3. photoinhibition of the anterior lateral motor cortex during a pole location discrimination task. By using a hierarchical Bayesian framework, our model pools information across levels and can estimate population-level spike rates that accurately describe data across all levels of the hierarchy.",
        "url": "https://www.world-wide.org/cosyne-23/bayesian-hierarchical-latent-variable-06d934a1"
    },
    "Generalization from one exemplar in mice and neurons": {
        "title": "Generalization from one exemplar in mice and neurons",
        "authors": "Miguel Angel Nuñez Ochoa, Lin Zhong, Fengtong Du, Carsen Stringer, Marius Pachitariu",
        "date": "Saturday, 11 March 2023",
        "location": "III-138",
        "abstract": "Learning general principles from single examples is a hallmark of high cognitive functions. This type of learning is computationally challenging for artificial agents, yet many animals such as primates can perform it with ease. To study one-exemplar generalization in the lab, it would be ideal to develop appropriate behavioral tasks in more tractable model organisms, such as rodents. Here we report that mice can perform one-exemplar generalization with difficult texture-based visual stimuli such as “leaves” and “rocks”. We trained mice to discriminate between single images from two texture categories, using water rewards for one of the images. Once the mice were trained, we introduced two unrewarded test images from the same two texture categories. Mice responded to the new image from the rewarded category, despite the lack of reinforcement, but not to the new image from the unrewarded category. The same task could not be solved by low-level features from an artificial neural network. To test what neural properties may give rise to generalization, we recorded simultaneously from large neural populations in primary and higher-order visual cortex in naive mice, while presenting the same set of images we used for the trained mice. Simple linear decoders trained on neural responses to single exemplars were able to generalize to new exemplars, similar to the behavior of the mice. To look for changes in neural coding after learning, we also recorded large neural populations in trained mice, which we are currently investigating. Our results establish mice as a viable model to study generalization from one example and thus enable a wide range of neuroscience techniques to be used for identifying the generalization algorithms used by the brain.",
        "url": "https://www.world-wide.org/cosyne-23/generalization-from-exemplar-mice-neurons-1328ea01"
    },
    "Composition of prefrontal ensembles in virtual fear of heights decision-making task": {
        "title": "Composition of prefrontal ensembles in virtual fear of heights decision-making task",
        "authors": "Stephanie Staszko, Abigail Yu, Samira Glaeser-Khan, Rachel Oren, Jen-Hau Yang, Aakash Basu, Alfred Kaye",
        "date": "Saturday, 11 March 2023",
        "location": "III-139",
        "abstract": "An animal’s ability to evaluate environmental threats and mount an appropriate behavioral response is critical to survival. Based on previous literature in rodents and humans, we developed a novel rodent fear of heights task which is highly controllable and can be used to interrogate neural computations underlying innate threat processing. We developed a virtual height threat task in which animals are placed on a pole and must choose to exit to either a “close” or “far” virtual platform. We find that animals perform around chance levels when the discrepancy between visual stimuli is small (5cm) but choose the “close” platform significantly more often when the discrepancy is large (20cm). Fiber photometry of calcium in the locus coeruleus (LC) and norepinephrine (NE) in the medial prefrontal cortex (mPFC) reveals these regions respond to height threat and the threat signal dissipates once the animal transitions from height exposure to safety. Single cell calcium imaging of mPFC neurons demonstrates a similar activation pattern on a population level, but that individual neurons display distinct response patterns to height threat exposure and at the decision point. As norepinephrine is known to play a role in both arousal and fear, leveraging a highly controllable visual threat behavior will allow for dissection of the neural computations underlying norepinephrine’s role in exploratory versus defensive behaviors. How individual neurons work within ensembles to differentially encode height threat and influence decision making given the same NE input poses an interesting question for understanding communication within and between neural networks.",
        "url": "https://www.world-wide.org/cosyne-23/composition-prefrontal-ensembles-virtual-4b1a9384"
    },
    "Brain-Rhythm-based Inference (BRyBI) for time-scale invariant speech processing": {
        "title": "Brain-Rhythm-based Inference (BRyBI) for time-scale invariant speech processing",
        "authors": "Olesia Dogonasheva, Denis Zakharov, Anne-Lise Giraud, Boris Gutkin",
        "date": "Saturday, 11 March 2023",
        "location": "III-140",
        "abstract": "Rhythms stretching across multiple interacting frequencies and spatial scales are ubiquitous in brain activity during complex cognitive tasks. Yet their functional significance is hotly debated between a structural epiphenomenon of brain activity and mechanisms implementing computations. Speech processing, with its temporal cadence and multi-scale of syntactic invariants (syllables, words), is a paradigmatic example where rhythms have been proposed to play a key role [1], with a speech-modulated hierarchical structure of intercoupled cortical oscillations correlating with successful comprehension. Experiments show that speech recognition remains largely intact when compressed up to a certain temporal factor [2] and the re-spacing chunks of incomprehensible compressed speech with silences recovers comprehension. Previous models proposed that theta-gamma interactions enable syllable parsing [3,4]. However, this did not resolve questions about word recognition and, notably, the observed role of delta rhythm in top-down information flow. To address the above questions, we propose an inference model (BRyBI) that incorporates a wide range of brain-rhythm data mechanistically and accounts for time-invariant word recognition. In this model, the hierarchically arranged interacting rhythms actively maintain top-down and bottom-up information flow during the inference process: theta-gamma interactions predict and parse phonemes/syllable sequences, while the delta-rhythm adaptively generates the inferred word context. We show that word recognition degrades when the speed of words and syllables is compressed beyond the delta and theta rhythms, respectively. The top-down contextual delta-implemented context allows us to explain why re-spacing compressed speech recovers comprehension. Our model further predicts that delta-implemented word context allows for syllable parsing without a precise locking of the theta-rhythmic activity. In general, we propose a potential resolution to the debated role of brain oscillations as mechanisms to control bottom-up and top-down flows of information to contextualize sensory inference processes.",
        "url": "https://www.world-wide.org/cosyne-23/brain-rhythm-based-inference-brybi-4f781b9f"
    }
}